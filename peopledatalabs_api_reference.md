# People Data Labs API Reference

Pages: 197


---
# https://docs.peopledatalabs.com/docs

# Welcome to our docs!

Use the side panel on the left side to navigate the individual sections or use the Search bar in the top right to find something specific.

Don't forget to sign up for a **free account** here: <https://dashboard.peopledatalabs.com>

Once you've signed up, visit our [API Quickstart](/docs/quickstart) to get moving right away or check out our [API Playground](https://dashboard.peopledatalabs.com/tools/api-playground) tool within the PDL Dashboard to start testing without writing a single line of code.

Already familiar with APIs? Check out our [Recipes](/recipes) for a step-by-step walkthrough of implementing our APIs.

Need a flat-file instead? Visit [Data License Overview](/docs/data-license) to learn more and connect with a member of our team.

  

Please let us know if you have suggestions, questions, or feedback by visiting our [public roadmap](https://feedback.peopledatalabs.com).

---



*Know someone whoâ€™d thrive building data products and helping us launch whatâ€™s next? Weâ€™d love to meet!*

*Check out our[open roles](https://www.peopledatalabs.com/company?utm_source=docs&utm_medium=footer&utm_campaign=cta#jobs) â†’*

Updated 30 days ago

---

Did this page help you?

Yes

No

---
# https://docs.peopledatalabs.com/docs/intro

# Welcome to our docs!

Use the side panel on the left side to navigate the individual sections or use the Search bar in the top right to find something specific.

Don't forget to sign up for a **free account** here: <https://dashboard.peopledatalabs.com>

Once you've signed up, visit our [API Quickstart](/docs/quickstart) to get moving right away or check out our [API Playground](https://dashboard.peopledatalabs.com/tools/api-playground) tool within the PDL Dashboard to start testing without writing a single line of code.

Already familiar with APIs? Check out our [Recipes](/recipes) for a step-by-step walkthrough of implementing our APIs.

Need a flat-file instead? Visit [Data License Overview](/docs/data-license) to learn more and connect with a member of our team.

  

Please let us know if you have suggestions, questions, or feedback by visiting our [public roadmap](https://feedback.peopledatalabs.com).

---



*Know someone whoâ€™d thrive building data products and helping us launch whatâ€™s next? Weâ€™d love to meet!*

*Check out our[open roles](https://www.peopledatalabs.com/company?utm_source=docs&utm_medium=footer&utm_campaign=cta#jobs) â†’*

Updated 30 days ago

---

Did this page help you?

Yes

No

---
# https://docs.peopledatalabs.com/docs/data-license

We provide many of our customers bulk person datasets in the form of an annual license. Some customers license our entire dataset while others license custom subsets of the data. To learn more, [speak with one of our Data Consultants](https://www.peopledatalabs.com/talk-to-sales).

## The value of a License

### 1. You have the data on premise.

During the license period, the customer has the right to use the data in any way as long as it is compliant with our [Acceptable Data Use Policy](https://www.peopledatalabs.com/acceptable-data-use-policy).

### 2. Unparalleled data coverage

Read more about our [coverage](/docs/datasets) here.

### 3. You get access to our customer success team

We provide all our volume API and license customers dedicated [engineering support](/docs/customer-support), including a shared Slack channel and a support email. Working with large datasets is hard. Our customer success team helps ensure that you get a ROI from the data as quickly as possible.

### 4. Unlimited access

Often search and matching APIs become prohibitively expensive at large volumes, but we hope to disrupt this market by providing the same or better data at a significantly lower price for larger engineering products.

### 5. Flexible licensing parameters

We allow customers to slice and dice the data in order to ensure that they only receive (and spend money on) the profiles that they need.

### Tailored Delivery Solutions

We offer a variety of options for how to [receive data licenses](/docs/receiving-and-updating-data) including deliveries through S3, GCP, Azure and more. Additionally, we also offer [Delta Files](/docs/delta-file-deliveries) consisting of just the subset of modified records from each build to streamline your data ingestion workflows.

Updated 4 months ago

---

Did this page help you?

Yes

No

---
# https://docs.peopledatalabs.com/docs/delta-file-deliveries

# What is a Delta File?

Delta Files are a new delivery format for data licenses that contains just the changes between the current delivery and the previous one (i.e. the â€œdeltaâ€ between the two updates). Delta Files are designed to be significantly smaller both in terms of file size and number of records, with the goal of being simpler, faster and easier for users to ingest into their data pipeline.

Delta File Deliveries are organized into 5 subfolders containing records that have changed between the previous delivery and the current one. The subfolders are:

1. Merged IDs
2. Added Records
3. Updated Records
4. Opted Out IDs
5. Deleted IDs

> âš ï¸
>
> ### Limitations
>
> Delta Files are currently **only available for Person Data Licenses** and are **not yet available for delivery through Snowflake**.

## How does it work?

Delta Files are custom generated for each customer based on their current data license slice and delivery cadences. When building the data delivery for each customer, we compare the most recent build of our data against the last delivered set of data received by the customer.

We then extract just the subset of records that have changed and group them into the 5 directories listed above, which is delivered as a Delta File delivery. Delta files are delivered using the existing set delivery channels available to data license customers.

During the initial onboarding period, customers will receive both the full data license as well as the delta file delivery in order to support transitioning to the new delivery format.

> âš ï¸
>
> ### Important Reminders
>
> There are a couple important requirements when using Delta Files to update your dataset:
>
> * You must be up-to-date with your last full license delivery before switching over to Delta Files (meaning you have completed ingesting it). This is to ensure that you do not retain any out-of-date records in your pipeline.
> * If you decide to change the data slice that you are licensing from PDL (i.e. any change to the underlying query), you will need to first re-ingest an initial full license delivery before switching back to Delta Files.

## How to get access

Delta Files are available as an add-on for Data License Customers.

As of our May 2024 (v26.1) release, this offering is currently in an open beta available for customers to evaluate the new format and share any additional feedback.

At this time, the delta file format is not supported on Snowflake and only supported for Person data licenses, with potential to provide similar delta files for our Snowflake customers and company data in the future.

To sign up for beta access to the Delta Files, please reach out to your Customer Success team

Updated 4 months ago

---

Did this page help you?

Yes

No

---
# https://docs.peopledatalabs.com/docs/quickstart

## Overview

This Quickstart is a brief introduction to our data and APIs.

Donâ€™t worry if youâ€™ve never used an API before, as with a little copy-and-paste magic weâ€™ll get you up and running quickly.

In just a few minutes, you will be retrieving and accessing real person and company data directly from our datasets.

Hereâ€™s what weâ€™ll cover:

1. Creating an account
2. Sending your first Person Enrichment API request
3. Sending your first Company Enrichment API request

Updated 4 months ago

---

* [Create an account](/docs/create-an-account)

Did this page help you?

Yes

No

---
# https://docs.peopledatalabs.com/docs/create-an-account

To access our data, you will need an API key.

You can get one by creating a free account at [www.peopledatalabs.com/signup](http://www.peopledatalabs.com/signup), clicking **API Keys**, and copying the **Active Key**.

> ðŸš§
>
> ### Warning!
>
> This is your ***secret*** API key, so please keep it private. We charge you credits based on usage associated with it. If for some reason you need a new API key, you can always generate one from the dashboard.

Updated 4 months ago

---

* [Send your first Person Enrichment API request](/docs/send-your-first-person-enrichment-api-call)

Did this page help you?

Yes

No

---
# https://docs.peopledatalabs.com/docs/send-your-first-person-enrichment-api-call

## Overview

The Person Enrichment API allows you to get additional information about an individual using data you already have like name, email, LinkedIn URL, and more. Once you have your API key, you can look up a person profile from our Person Dataset using the [Person Enrichment API](/docs/enrichment-api).

## Sending your first request

ðŸ’¡ **Did you know you can send an API request in the same way you navigate to a webpage?**

Copy the following URL and paste it into a new tab in your browser.

> â—ï¸
>
> ### Before pasting the URL
>
> * Replace `XXXX` after `api_key` with your API key
> * This will **consume 1 API credit** of your free 100 monthly credits for the Person Enrichment API. To read more about credits, check out this [Help Center article](https://support.peopledatalabs.com/hc/en-us/articles/23553812020891-Pricing-Overview)

URL

```
https://api.peopledatalabs.com/v5/person/enrich?api_key=XXXX&pretty=True&profile=linkedin.com/in/seanthorne
```

The result should look something like this:

> ðŸ“˜
>
> ### Pro tip
>
> If you want a better way to work with the result in a browser, consider downloading a [JSON Formatting extension](https://chromewebstore.google.com/detail/json-formatter/bcjindcccaagfpapjjmafapmmgkkhgoa?pli=1)

**Here's what just happened:**

1. You sent an API request to the Person Enrichment API for the profile associated with the following LinkedIn account: `linkedin.com/in/seanthorne`
2. The Person Enrichment API finds the best matching profile record in our [Person Dataset](/docs/datasets)
3. The API returns a JSON-formatted [profile record](/docs/example-record) in response with a `200` status, which indicates that a record was successfully found
4. The result of the above URL should be the profile for Sean Thorne (the co-founder of People Data Labs) from our [Person Dataset](/docs/datasets)

**A couple key points to note on profiles in our datasets:**

* Every profile record in our datasets is returned as a [JSON](http://en.wikipedia.org/wiki/JSON) object
* Profiles in our Person Dataset will contain information relating to hundreds of fields in our [Person Schema](/docs/fields), which can enable a wide range of different use cases

### Try Looking Up Your Own Person Profile

You can also look up someone besides our venerable co-founder. Copy the profile URL of your favorite person on [LinkedIn](https://www.linkedin.com/) (which could even be yourself). Use it to run the following command:

> â—ï¸
>
> ### Before pasting the URL
>
> * Replace `XXXX` after `api_key` with your API key
> * Replace `YYYY` after `profile` with the LinkedIn URL that you want to â€œenrichâ€
> * This will **consume 1 API credit** of your free 100 monthly credits for the Person Enrichment API. To read more about credits, check out this [Help Center article](https://support.peopledatalabs.com/hc/en-us/articles/23553812020891-Pricing-Overview)

URL

```
https://api.peopledatalabs.com/v5/person/enrich?api_key=XXXX&pretty=True&profile=YYYY
```

This time you should see one of 2 results:

1. A profile from our Person Dataset containing all the information that we have associated with that LinkedIn URL (similar to what we got before.)
2. An status code of 404 indicating that the profile could not be found in our dataset. If this happens, try picking a different LinkedIn profile to enrich.

In the above example, you're simply looking up profiles by their LinkedIn URL, but the Person Enrichment API supports lookups using a [variety of different inputs](/docs/input-parameters-person-enrichment-api), such as name, email, phone numbers, employer, locations and more. Feel free to dive deeper into the [Person Enrichment API](/docs/enrichment-api), but at this point you should have a basic understanding of the type of information contained within our Person Dataset.

Updated 4 months ago

---

* [Send your first Company Enrichment API request](/docs/send-your-first-company-enrichment-api-request)

Did this page help you?

Yes

No

---
# https://docs.peopledatalabs.com/docs/fields

# Overview

This page details the Person Data that we provide through our Person APIs, such as [Person Enrichment](/docs/person-enrichment-api) and [Person Search](/docs/person-search-api).

> ðŸ“˜
>
> ### Field Availability
>
> **Not all fields are available in all bundles.**
>
> Free plans, by default, do not have access to contact fields like emails, phone numbers, and street addresses and will instead appear as true if the value exists or false if it does not. To unlock the values, please upgrade to a Pro plan. Read more here: [Plan types: Free vs Pro](https://support.peopledatalabs.com/hc/en-us/articles/27546010665115-Plan-types-Free-vs-Pro)

* For more information about data formatting, see [Data Types](/docs/data-types) and [Data Formatting](/docs/data-formatting)
* For a full example record, see [Example Person Record](/docs/example-record).
* For a simplified overview of our person fields, check out the [Person Data Overview](/docs/person-data-overview).
* For more details about our person fields, including fill rates and which fields are included in the base vs premium [field bundles](/docs/person-data-field-bundles), check out our [Person Stats](/docs/datasets) pages.
* For a full data ingestion JSON schema, check out [this page](/docs/receiving-and-updating-data#data-ingestion-schemas).
* If you'd like access to premium fields or have questions about which fields are included in your specific field bundle(s), please [speak to one of our data consultants](https://peopledatalabs.com/talk-to-sales).

---

## Identifiers

### `first_name`

|  |  |
| --- | --- |
| Description | The person's first name. |
| Data Type | `String` |

#### Field Details

The person's first name.

#### Example

JSON

```
"first_name": "sean"
```

### `full_name`

|  |  |
| --- | --- |
| Description | The person's full name. |
| Data Type | `String` |

#### Field Details

The first and the last name fields appended with a space.

#### Example

JSON

```
"full_name": "sean thorne"
```

### `id`

|  |  |
| --- | --- |
| Description | A unique persistent identifier for the person. |
| Data Type | `String` |

#### Field Details

The ID is a unique, persistent, and hashed value that represents a specific person.

As of [v24](/changelog/october-2023-release-notes-v24#person-id-max-length), IDs have a max length of **64 characters**, although in practice we expect IDs to be closer to 32 characters in length.

See `<https://docs.peopledatalabs.com/docs/persistent-ids>` for more information.

#### Example

JSON

```
"id": "qEnOZ5Oh0poWnQ1luFBfVw_0000"
```

### `last_initial`

|  |  |
| --- | --- |
| Description | The first letter of the person's last name. |
| Data Type | `String (1 character)` |

#### Field Details

The first letter of the person's last name.

#### Example

JSON

```
"last_initial": "t"
```

### `last_name`

|  |  |
| --- | --- |
| Description | The person's last name. |
| Data Type | `String` |

#### Field Details

The person's last name.

#### Example

JSON

```
"last_name": "thorne"
```

### `middle_initial`

|  |  |
| --- | --- |
| Description | The first letter of the person's middle name. |
| Data Type | `String (1 character)` |

#### Field Details

The first letter of the person's middle name.

#### Example

JSON

```
"middle_initial": "f"
```

### `middle_name`

|  |  |
| --- | --- |
| Description | The person's middle name. |
| Data Type | `String` |

#### Field Details

The person's middle name.

#### Example

JSON

```
"middle_name": "fong"
```

### `name_aliases`

|  |  |
| --- | --- |
| Description | Any other names the person goes by. |
| Data Type | `Array [String]` |

#### Field Details

Any associated names or aliases besides the primary one used in the [`full_name`](#full_name) field.

> ðŸ’¡
>
> ### Sort Order
>
> Name aliases are sorted with the primary alias first. The remaining aliases are sorted by `num_sources`, `last_seen`, `first_seen`, `full_name`, all in reverse order (highest first, most recent, Zâ†’A):
>
> 1. Primary name first
> 2. `num_sources` (highest first)
> 3. `last_seen` (most recent first)
> 4. `first_seen` (most recent first)
> 5. `full_name` (Zâ†’A)

#### Example

JSON

```
"name_aliases": [
    "andrew nichol",
    "r andrew nichol",
    "robert nichol"
  ]
```

## Contact Information

### `emails`

|  |  |
| --- | --- |
| Description | Email addresses associated with the person. |
| Data Type | `Array [Object]` |

#### Field Details

> âš ï¸
>
> **Note** This array contains historical email addresses and should **not** directly be used for email outreach. [Recommended Alternatives](/docs/email-data-for-outreach)

Each email associated with the person will be added to this list as its own object.

| Field | Data Type | Description |
| --- | --- | --- |
| `address` | `String` | The fully parsed email address |
| `first_seen` | [`String (Date)`](/docs/data-types#dates) | The date that this entity was first associated with the Person record. |
| `last_seen` | [`String (Date)`](/docs/data-types#dates) | The date that this entity was last associated with the Person record. |
| `num_sources` | `Integer (> 0)` | The number of sources that have contributed to the association of this entity with the Person record. |
| `md5_hash` | `String` | A 128-bit hash of an email in md5 format. |
| `sha_256_hash` | `String` | A 256-bit hash of an email in sha256 format. |
| `type` | `Enum (String)` | The type of email address. Must be one of our [Canonical Email Types](/docs/email-types) |

> ðŸ’¡
>
> ### Sort Order
>
> Emails are sorted first by `last_seen`, then by `first_seen`, `email` , all in reverse order (most recent first, Zâ†’A):
>
> 1. `last_seen` (most recent first)
> 2. `first_seen` (most recent first)
> 3. `email` (Zâ†’A)

#### Example

JSON

```
"emails": [
    {
      "address": "sean@peopledatalabs.com",
      "type": "current_professional",
      "md5_hash": "89eb6bc60e92f3d6ffbb4e7b4d15cacd",
      "sha_256_hash": "138ea1a7076bb01889af2309de02e8b826c27f022b21ea8cf11aca9285d5a04e",
      "first_seen": "2017-06-02",
      "last_seen": "2019-07-18",
      "num_sources": 17
    },
    {
      "address": "sean@gmail.com",
      "type": "personal",
      "md5_hash": "17725f5327de7695d658f124636cbd23",
      "sha_256_hash": "ae0591a02b4cb0be73fff1ebe061a95b1bfc23350a9a297923edda014c6a88f8",
      "first_seen": "2017-06-02",
      "last_seen": "2019-07-18",
      "num_sources": 17
    }
  ]
```

### `mobile_phone`

|  |  |
| --- | --- |
| Description | The personal mobile phone associated with this individual. Mobile phones can only be associated with 1 person in the PDL data. |
| Data Type | [`String (Phone)`](https://docs.peopledatalabs.com/docs/data-types#phone-numbers) |

#### Field Details

The `mobile_phone` field is generated from a highly confident source of mobile phones. We've hand-validated a sample of these and seen over 90% accuracy.

#### Example

JSON

```
"mobile_phone": "+15558675309"
```

### `personal_emails`

|  |  |
| --- | --- |
| Description | All personal emails associated with the person. |
| Data Type | `Array [String]` |

#### Field Details

The list of all [`emails`](#emails) tagged as `type = personal`.

> ðŸ’¡
>
> ### Sort Order
>
> Personal emails are sorted with the recommended personal email first. The remaining emails are sorted in the same order as the `emails` array:`last_seen`, then by `first_seen`, `email`, all in reverse order (most recent first, Zâ†’A):
>
> 1. Recommended personal email first
> 2. `last_seen` (most recent first)
> 3. `first_seen` (most recent first)
> 4. `email` (Zâ†’A)

#### Example

JSON

```
"personal_emails": [
    "sean@gmail.com"
  ]
```

### `phone_numbers`

|  |  |
| --- | --- |
| Description | All phone numbers associated with the person. |
| Data Type | [`Array [String (Phone)]`](https://docs.peopledatalabs.com/docs/data-types#phone-numbers) |

#### Field Details

For more detailed metadata on individual phone numbers, see the [`phones`](#phones) field.

> ðŸ’¡
>
> ### Sort Order
>
> Phone numbers are sorted with any mobile phone numbers first. The rest of the array is sorted by `num_sources`, `last_seen`, `first_seen`, all in reverse order and using the E.164 format (highest first, most recent first):
>
> 1. Mobile phone numbers first
> 2. `num_sources` (highest first)
> 3. `last_seen` (most recent first)
> 4. `first_seen` (most recent first)

#### Example

JSON

```
"phone_numbers": [
    "+15558675309"
  ]
```

### `phones`

|  |  |
| --- | --- |
| Description | The list of phone numbers associated with this record with additional metadata. |
| Data Type | `Array [Object]` |

#### Field Details

Each phone number object in this list will contain the following information.

| Field | Data Type | Description |
| --- | --- | --- |
| `first_seen` | [`String (Date)`](/docs/data-types#dates) | The date that this number was first associated with this record. |
| `last_seen` | [`String (Date)`](/docs/data-types#dates) | The date that this number was last associated with this record. |
| `num_sources` | `Integer (> 0)` | The number of sources that have contributed to the association of this profile with this record. |
| `number` | [`String (Phone)`](/docs/data-types#phone-numbers) | The phone number. |

> ðŸ’¡
>
> ### Sort Order
>
> Phones are sorted with any mobile phone numbers first. The rest of the array is sorted by `num_sources`, `last_seen`, `first_seen`, all in reverse order and using the E.164 format (highest first, most recent first):
>
> 1. Mobile phone numbers first
> 2. `num_sources` (highest first)
> 3. `last_seen` (most recent first)
> 4. `first_seen` (most recent first)

#### Example

JSON

```
"phones": [
    {
      "number": "+15558675309",
      "first_seen": "2017-06-02",
      "last_seen": "2019-07-18",
      "num_sources": 17
    }
  ]
```

### `recommended_personal_email`

|  |  |
| --- | --- |
| Description | The best available email to reach a person. |
| Data Type | `String` |

#### Field Details

This field is generated by analyzing the all of a person's emails in the [`personal_emails`](#personal_emails) list to identify the best available email.

Through testing, weâ€™ve found that using the email identified in `recommended_personal_email` versus selecting a random email address from [`personal_emails`](#personal_emails) resulted in ~37% higher deliverability.

#### Example

JSON

```
"recommended_personal_email": "sean@gmail.com"
```

### `work_email`

|  |  |
| --- | --- |
| Description | The person's current work email. |
| Data Type | `String` |

#### Field Details

The value for this field must use valid email address formatting. It is common and expected that work email domains may differ from the company's website for a number of reasons:

* The company changed their website domain
* The company has opted for a shorter email domain
* The company has been merged into or was acquired by another company

#### Example

JSON

```
"work_email": "sean@peopledatalabs.com"
```

## Current Company

These fields describe the company the person currently works at. These fields will match the corresponding values in our [Company Schema](/docs/company-schema) and will use the same formatting and parsing logic.

### `job_company_12mo_employee_growth_rate`

|  |  |
| --- | --- |
| Description | The personâ€™s current companyâ€™s percentage increase in total headcount over the past 12 months. Mapped from [`employee_growth_rate.12_month`](https://docs.peopledatalabs.com/docs/company-schema#employee_growth_rate).  Growth rate is calculated as `(current_employee_count / previous_employee_count) - 1`. |
| Data Type | `Float` |

#### Example

JSON

```
"job_company_12mo_employee_growth_rate": -0.1379
```

### `job_company_facebook_url`

|  |  |
| --- | --- |
| Description | The person's current company's [Facebook URL](https://docs.peopledatalabs.com/docs/company-schema#facebook_url). |
| Data Type | `String` |

#### Example

JSON

```
"job_company_facebook_url": "facebook.com/peopledatalabs"
```

### `job_company_founded`

|  |  |
| --- | --- |
| Description | The person's current company's [founding year](https://docs.peopledatalabs.com/docs/company-schema#founded). |
| Data Type | `Integer (> 0)` |

#### Example

JSON

```
"job_company_founded": 2015
```

### `job_company_employee_count`

|  |  |
| --- | --- |
| Description | The total number of PDL profiles associated with the personâ€™s current company. Mapped from [`employee_count`](https://docs.peopledatalabs.com/docs/company-schema#employee_count). |
| Data Type | `Integer (>= 0)` |

#### Example

JSON

```
"job_company_employee_count": 125
```

### `job_company_id`

|  |  |
| --- | --- |
| Description | The person's current company's [PDL ID](https://docs.peopledatalabs.com/docs/company-schema#id). |
| Data Type | `String` |

#### Example

JSON

```
"job_company_id": "tnHcNHbCv8MKeLh92946LAkX6PKg"
```

### `job_company_industry`

|  |  |
| --- | --- |
| Description | The person's current company's [industry](https://docs.peopledatalabs.com/docs/company-schema#industry). |
| Data Type | `Enum (String)` |

#### Example

JSON

```
"job_company_industry": "computer software"
```

### `job_company_industry_v2`

|  |  |
| --- | --- |
| Description | The [v2 industry](https://docs.peopledatalabs.com/docs/company-schema#industries-v2) for the personâ€™s current company. |
| Data Type | [`Enum (String)`](https://docs.peopledatalabs.com/docs/company-schema#industries-v2) |

#### Example

JSON

```
"job_company_industry_v2": "internet marketplace platforms"
```

#### Details

Industry v2 is the self-reported industry from an expanded list of [Canonical V2 Industries](/docs/industries-v2). If no industry is found, the field will be `null`

### `job_company_inferred_revenue`

|  |  |
| --- | --- |
| Description | The [estimated annual revenue range](https://docs.peopledatalabs.com/docs/company-schema#inferred_revenue) in USD of the personâ€™s current company. |
| Data Type | `Enum (String)` |

#### Example

JSON

```
"job_company_inferred_revenue": "$25M-$50M"
```

### `job_company_linkedin_id`

|  |  |
| --- | --- |
| Description | The person's current company's [LinkedIn ID](https://docs.peopledatalabs.com/docs/company-schema#linkedin_id). |
| Data Type | `String` |

#### Example

JSON

```
"job_company_linkedin_id": "18170482"
```

### `job_company_linkedin_url`

|  |  |
| --- | --- |
| Description | The person's current company's [LinkedIn URL](https://docs.peopledatalabs.com/docs/company-schema#linkedin_url). |
| Data Type | `String` |

#### Example

JSON

```
"job_company_linkedin_url": "linkedin.com/company/peopledatalabs"
```

### `job_company_location_address_line_2`

|  |  |
| --- | --- |
| Description | The person's current company's headquarters' [street address line 2](https://docs.peopledatalabs.com/docs/data-formatting#common-location-fields). |
| Data Type | `String` |

#### Example

JSON

```
"job_company_location_address_line_2": "suite 1670"
```

### `job_company_location_continent`

|  |  |
| --- | --- |
| Description | The person's current company's headquarters' [continent](https://docs.peopledatalabs.com/docs/data-types#locations). |
| Data Type | `Enum (String)` |

#### Example

JSON

```
"job_company_location_continent": "north america"
```

### `job_company_location_country`

|  |  |
| --- | --- |
| Description | The person's current company's headquarters' [country](https://docs.peopledatalabs.com/docs/data-types#locations). |
| Data Type | `Enum (String)` |

#### Example

JSON

```
"job_company_location_country": "united states"
```

### `job_company_location_geo`

|  |  |
| --- | --- |
| Description | The person's current company's headquarters' [city-center geographic coordinates](https://docs.peopledatalabs.com/docs/data-types#locations). |
| Data Type | `String` |

#### Example

JSON

```
"job_company_location_geo": "37.77,-122.41"
```

### `job_company_location_locality`

|  |  |
| --- | --- |
| Description | The person's current company's headquarters' [locality](https://docs.peopledatalabs.com/docs/data-types#locations). |
| Data Type | `String` |

#### Example

JSON

```
"job_company_location_locality": "san francisco"
```

### `job_company_location_metro`

|  |  |
| --- | --- |
| Description | The person's current company's headquarters' [metro area](https://docs.peopledatalabs.com/docs/data-formatting#locations). |
| Data Type | `Enum (String)` |

#### Example

JSON

```
"job_company_location_metro": "san francisco, california"
```

### `job_company_location_name`

|  |  |
| --- | --- |
| Description | The person's current company's headquarters' [location name](https://docs.peopledatalabs.com/docs/data-formatting#locations). |
| Data Type | `String` |

#### Example

JSON

```
"job_company_location_name": "san francisco, california, united states"
```

### `job_company_location_postal_code`

|  |  |
| --- | --- |
| Description | The person's current company's headquarters' [postal code](https://docs.peopledatalabs.com/docs/data-formatting#locations). |
| Data Type | `String` |

#### Example

JSON

```
"job_company_location_postal_code": "94105"
```

### `job_company_location_region`

|  |  |
| --- | --- |
| Description | The person's current company's headquarters' [region](https://docs.peopledatalabs.com/docs/data-formatting#locations). |
| Data Type | `String` |

#### Example

JSON

```
"job_company_location_region": "california"
```

### `job_company_location_street_address`

|  |  |
| --- | --- |
| Description | The person's current company's headquarters' [street address](https://docs.peopledatalabs.com/docs/data-formatting#locations). |
| Data Type | `String` |

#### Example

JSON

```
"job_company_location_street_address": "455 market st"
```

### `job_company_name`

|  |  |
| --- | --- |
| Description | The person's current company's [name](https://docs.peopledatalabs.com/docs/company-schema#name). |
| Data Type | `String` |

#### Example

JSON

```
"job_company_name": "people data labs"
```

### `job_company_size`

|  |  |
| --- | --- |
| Description | The person's current company's [size range](https://docs.peopledatalabs.com/docs/company-sizes). |
| Data Type | `Enum (String)` |

#### Example

JSON

```
"job_company_size": "51-200"
```

### `job_company_ticker`

|  |  |
| --- | --- |
| Description | The person's current company's [ticker](https://docs.peopledatalabs.com/docs/company-schema#ticker). |
| Data Type | `String` |

#### Example

JSON

```
"job_company_ticker": "goog"
```

### `job_company_total_funding_raised`

|  |  |
| --- | --- |
| Description | The [cumulative amount of money raised](https://docs.peopledatalabs.com/docs/company-schema#total_funding_raised) in USD by the personâ€™s current company during all publicly disclosed funding rounds. |
| Data Type | `Integer (> 0)` |

#### Example

JSON

```
"job_company_total_funding_raised": 55250000.0
```

### `job_company_twitter_url`

|  |  |
| --- | --- |
| Description | The person's current company's [Twitter URL](https://docs.peopledatalabs.com/docs/company-schema#twitter_url). |
| Data Type | `String` |

#### Example

JSON

```
"job_company_twitter_url": "twitter.com/peopledatalabs"
```

### `job_company_type`

|  |  |
| --- | --- |
| Description | The person's current company's [type](https://docs.peopledatalabs.com/docs/company-schema#type). |
| Data Type | `Enum (String)` |

#### Example

JSON

```
"job_company_type": "public"
```

### `job_company_website`

|  |  |
| --- | --- |
| Description | The person's current company's [website](https://docs.peopledatalabs.com/docs/company-schema#website). |
| Data Type | `String` |

#### Example

JSON

```
"job_company_website": "peopledatalabs.com"
```

## Current Job

These fields describe the person's most recent work experience.

### `inferred_salary`

|  |  |
| --- | --- |
| Description | The inferred salary range (USD) for the person's current job. |
| Data Type | `Enum (String)` |

#### Field Details

Must be one of our [Canonical Inferred Salary Ranges](/docs/inferred-salaries).

#### Example

JSON

```
"inferred_salary": "70,000-85,000"
```

### `job_last_changed`

|  |  |
| --- | --- |
| Description | The timestamp that reflects when the top-level job information changed. |
| Data Type | [`String (Date)`](https://docs.peopledatalabs.com/docs/data-types#dates) |

#### Field Details

An update is the time when the current employment information is modified in the record.

> ðŸš§
>
> ### Limitations of Observed Data
>
> This field reflects **observed data**. This means that this timestamp will reflect the date when updates were propagated into our data build from our data sources, and may contain some lag time compared to real-life events. For example, if User A changed their job on October 1, 2023, but did not update that publicly until December 1, 2023, our timestamp for job\_last\_changed will be December.

#### Example

JSON

```
"job_last_changed": "2023-12-01"
```

### `job_last_verified`

|  |  |
| --- | --- |
| Description | The timestamp that reflects when the top level job information was last validated by a data source. |
| Data Type | [`String (Date)`](https://docs.peopledatalabs.com/docs/data-types#dates) |

#### Field Details

An update is the time when the information in a record is validated through a data source. For more information how this timestamp is generated see: [Experience & Location Updates](/docs/last_updated-field)

#### Example

JSON

```
"job_last_verified": "2024-01-05"
```

### `job_onet_broad_occupation`

|  |  |
| --- | --- |
| Description | The O\*NET Broad Occupation associated with the personâ€™s current job title. |
| Data Type | `String` |

#### Example

JSON

```
"job_onet_broad_occupation": "Chief Executives"
```

### `job_onet_code`

|  |  |
| --- | --- |
| Description | The 8-digit O\*NET code for the personâ€™s current job title. |
| Data Type | `String` |

#### Field Details

The 8-digit O\*NET code for the personâ€™s current job title, [following the 2018 SOC guidelines](https://www.bls.gov/soc/2018/soc_2018_class_and_coding_structure.pdf).

#### Example

JSON

```
"job_onet_code": "11-1011.00"
```

### `job_onet_major_group`

|  |  |
| --- | --- |
| Description | The O\*NET Major Group associated with the personâ€™s current job title. |
| Data Type | `String` |

#### Example

JSON

```
"job_onet_major_group": "Management Occupations"
```

### `job_onet_minor_group`

|  |  |
| --- | --- |
| Description | The O\*NET Minor Group associated with the personâ€™s current job title. |
| Data Type | `String` |

#### Example

JSON

```
"job_onet_minor_group": "Top Executives"
```

### `job_onet_specific_occupation`

|  |  |
| --- | --- |
| Description | The O\*NET Specific Occupation associated with the personâ€™s current job title. |
| Data Type | `String` |

#### Example

JSON

```
"job_onet_specific_occupation": "Chief Executives"
```

### `job_onet_specific_occupation_detail`

|  |  |
| --- | --- |
| Description | A more detailed job title classification than O\*NET Specific Occupation. |
| Data Type | `String` |

#### Field Details

A more detailed job title for records where the specific occupation within O\*NET's standard hierarchy isn't granular enough to accurately describe the job title.

For example, the highest level of granularity in O\*NET for C-suite positions is Chief Executives. With this field, we can specify the type of executive role.

#### Example

JSON

```
"job_onet_specific_occupation_detail": "Chief Technology Officer"
```

### `job_start_date`

|  |  |
| --- | --- |
| Description | The date the person started their current job. |
| Data Type | [`String (Date)`](https://docs.peopledatalabs.com/docs/data-types#dates) |

#### Example

JSON

```
"job_start_date": "2015-03"
```

### `job_summary`

|  |  |
| --- | --- |
| Description | User-inputted summary of their current job. |
| Data Type | `String` |

#### Field Details

The summary is lowercased, but otherwise kept as-is from the raw source.

#### Example

JSON

```
"job_summary": "worked on the \"search analytics\" team to understand our users better"
```

### `job_title`

|  |  |
| --- | --- |
| Description | The person's current job title. |
| Data Type | `String` |

#### Field Details

The person's current job title.

#### Example

JSON

```
"job_title": "co-founder and chief executive officer"
```

### `job_title_class`

|  |  |
| --- | --- |
| Description | The expense line item category this employee would fall into. |
| Data Type | `Enum (String)` |

#### Field Details

Each class in the list will be one of our [Canonical Job Title Classes](/docs/job-title-class-post-v271).

#### Example

JSON

```
"job_title_class": "research_and_development"
```

### `job_title_levels`

|  |  |
| --- | --- |
| Description | The derived level(s) of the person's current job title. |
| Data Type | `Array [Enum (String)]` |

#### Field Details

Each level in the list will be one of our [Canonical Job Title Levels](/docs/job-title-levels).

Job Title Levels Hierarchy from "least important" to "most important":

Unpaid
Training
Entry
Manager
Senior
Partner
Director
VP
Owner
CXO

Note: The `cxo` level is a catch-all for "Chief \_\_ Officer" roles, so a CEO, CIO, CTO, etc. will all have `job_title_levels: ["cxo"]`.

#### Example

JSON

```
"job_title_levels": ["cxo", "owner"]
```

### `job_title_role`

|  |  |
| --- | --- |
| Description | The derived role of the person's current job title. |
| Data Type | `Enum (String)` |

#### Field Details

The value will be one of our [Canonical Job Roles](/docs/job-title-roles).

> ðŸš§
>
> ### Major Update as of v29.1 (February 29.1)
>
> In v29.1 (February 2024) we made significant improvements to our role and sub\_role categorizations and updated many of the canonical values associated with these fields.
>
> Please see our [February 2025 Release Notes (v29.1)](/changelog/february-2025-release-notes-v291)for further information.

#### Example

JSON

```
"job_title_role": "operations"
```

### `job_title_sub_role`

|  |  |
| --- | --- |
| Description | The derived subrole of the person's current job title. |
| Data Type | `Enum (String)` |

#### Field Details

The value will be one of our [Canonical Job Sub Roles](/docs/job-title-subroles). Each subrole maps to a role. See `<https://docs.peopledatalabs.com/docs/title-subroles-to-roles>` for a complete mapping list.

> ðŸš§
>
> ### Major Update as of v29.1 (February 29.1)
>
> In v29.1 (February 2024) we made significant improvements to our role and sub\_role categorizations and updated many of the canonical values associated with these fields.
>
> Please see our [February 2025 Release Notes (v29.1)](/changelog/february-2025-release-notes-v291)for further information.

#### Example

JSON

```
"job_title_sub_role": "logistics"
```

## Demographics

### `birth_date`

|  |  |
| --- | --- |
| Description | The day the person was born. |
| Data Type | [`String (Date)`](https://docs.peopledatalabs.com/docs/data-types#dates) |

#### Field Details

If this field exists, [`birth_year`](#birth_year) will agree with it.

#### Example

JSON

```
"birth_date": "1990-12-02"
```

### `birth_year`

|  |  |
| --- | --- |
| Description | The year the person was born. |
| Data Type | `Integer` |

#### Field Details

The approximated birth year associated with this person profile. If a profile has a [`birth_date`](#birth_date), the `birth_year` field will match it.

#### Example

JSON

```
"birth_year": 1990
```

### `sex`

> ðŸš§
>
> ### `gender` was renamed to `sex` in v26.0
>
> In v26.0 (April 2024) we renamed this field from `gender` to `sex`, in accordance with legislative changes defining aspects of gender as sensitive personal data (which PDL does not process or output).
>
> Please see our [April 2024 Release Announcement (v26.0)](/changelog/april-2024-release-announcement-v260#rename-gender-breaking) for further information.

|  |  |
| --- | --- |
| Description | The person's sex. |
| Data Type | `Enum (String)` |

#### Field Details

The value will always be one of our [Canonical Sex](/docs/sex).

#### Example

JSON

```
"sex": "male"
```

### `languages`

|  |  |
| --- | --- |
| Description | Languages the person knows. |
| Data Type | `Array [Object]` |

#### Field Details

The languages listed are based on user input, we do not verify them.

| Field | Data Type | Description |
| --- | --- | --- |
| `name` | `Enum (String)` | The language. Must be one of our [Canonical Languages](/docs/language-names). |
| `proficiency` | `Integer (1-5)` | Self-ranked language proficiency from 1 (limited) to 5 (fluent). |

> ðŸ’¡
>
> ### Sort Order
>
> Languages are sorted by `proficiency` first, followed by `name`, all in reverse order (highest proficiency first, Zâ†’A):
>
> 1. `proficiency` (highest first)
> 2. `name` (Zâ†’A)

#### Example

JSON

```
"languages": [
    {
      "name": "english",
      "proficiency": 5
    }
  ]
```

## Education

### `education`

|  |  |
| --- | --- |
| Description | The person's education information. |
| Data Type | `Array [Object]` |

#### Field Details

The education objects associated with this person profile, which, when output in CSV format, have indexing based on recency and associativity.

Each education object in the list will include the following data:

| Field | Data Type | Description |
| --- | --- | --- |
| `degrees` | `Array [Enum (String)]` | The degrees the person earned at the school. All values will be [Canonical Education Degrees](/docs/education-degrees) |
| `end_date` | [`String (Date)`](/docs/data-types#dates) | The date the person left the school. If the person is still at the school, will be `null`. |
| `gpa` | `Float` | The GPA the person earned at the school. |
| `majors` | `Array [Enum (String)]` | All majors earned at the school. All values will be [Canonical Education Majors](/docs/education-majors). |
| `minors` | `Array [Enum (String)]` | All minors earned at the school. All values will be [Canonical Education Majors](/docs/education-majors). |
| `raw` | `Array [String]` | Raw education data that was parsed into the `degrees`, `majors`, and `minors` fields. |
| [`school`](#educationschool) | `Object` | The school the person attended. |
| `start_date` | [`String (Date)`](/docs/data-types#dates) | The date the person started at the school. |
| `summary` | `String` | User-inputted summary of their education. |

> ðŸ’¡
>
> ### Sort Order
>
> Education entries are sorted first by `start_date`, then by `end_date`. If dates are identical, then sorting occurs by `school.name`, followed by `majors`, `minors` and `degrees`, all in reverse order (most recent first, Zâ†’A):
>
> 1. `start_date`(most recent first)
> 2. `end_date` (most recent first)
> 3. `school.name` (Zâ†’A)
> 4. countries`majors` (Zâ†’A)
> 5. `minors` (Zâ†’A)
> 6. `degrees` (Zâ†’A)

##### `education.school`

To tap into our school matching logic, use our [School Cleaner API](/docs/cleaner-apis) to retrieve possible school values.

| Field | Sub Field | Data Type | Description |
| --- | --- | --- | --- |
| `domain` |  | `String` | The primary website domain associated with the school. |
| `facebook_url` |  | `String` | The school's Facebook URL |
| `id` |  | `String` | The **NON-PERSISTENT** ID for the school in our records. |
| `linkedin_id` |  | `String` | The school's LinkedIn ID |
| `linkedin_url` |  | `String` | The school's LinkedIn URL |
| `location` |  | `Object` | The location of the school. See [Common Location Fields](/docs/data-formatting#common-location-fields) for detailed field descriptions. |
|  | `continent` | `Enum (String)` |  |
|  | `country` | `Enum (String)` |  |
|  | `locality` | `String` |  |
|  | `name` | `String` |  |
|  | `region` | `String` |  |
| `name` |  | `String` | The name of the school. |
| `raw` |  | `Array [String]` | Raw school name. |
| `twitter_url` |  | `String` | The school's Twitter URL |
| `type` |  | `Enum (String)` | The school type. Will be one of our [Canonical School Types](/docs/education-school-types). |
| `website` |  | `String` | The website URL associated with the school, which could include subdomains. |

#### Example

JSON

```
"education": [
    {
      "school": {
        "name": "university of oregon",
        "type": "post-secondary institution",
        "id": "64LkgfdwWYkCC2TjbldMDQ_0",
        "location": {
          "name": "eugene, oregon, united states",
          "locality": "eugene",
          "region": "oregon",
          "country": "united states",
          "continent": "north america"
        },
        "linkedin_url": "linkedin.com/school/university-of-oregon",
        "linkedin_id": "19207",
        "facebook_url": "facebook.com/universityoforegon",
        "twitter_url": "twitter.com/uoregon",
        "website": "uoregon.edu",
        "domain": "uoregon.edu",
        "raw": [
          "university of oregon"
        ]
      },
      "end_date": "2014",
      "start_date": "2010",
      "gpa": null,
      "degrees": [],
      "majors": [
        "entrepreneurship"
      ],
      "minors": [],
      "raw": [
        "data analytics & entrepreneurship",
        ", entrepreneurship",
        "entrepreneurship"
      ],
      "summary": "when i was at oregon i volunteered at a local homeless shelter 3 days a week"
    },
  ]
```

## Location

For more information on our standard location fields, see [Common Location Fields](/docs/data-formatting#common-location-fields).

### `countries`

|  |  |
| --- | --- |
| Description | All [countries](https://docs.peopledatalabs.com/docs/data-types#common-location-fields) associated with the person. |
| Data Type | `Array [Enum (String)]` |

> ðŸ’¡
>
> ### Sort Order
>
> Countries are sorted using location sort order, with any duplicate countries removed.
>
> **Location Sort Order**
>
> Locations are sorted by primary location first. The remaining locations are sorted by `first_seen`, `last_seen`, `location_name`, `street_address`, then `address_line_2` in descending order (most recent first, Zâ†’A):
>
> 1. Primary location first
> 2. Sort by `first_seen` (most recent first)
> 3. Sort by `last_seen` (most recent first)
> 4. Sort by `location_name` (Zâ†’A)
> 5. Sort by `street_address` (Zâ†’A)
> 6. Sort by `address_line_2` (Zâ†’A)

#### Example

JSON

```
"countries": [
    "united states"
  ]
```

### `location_address_line_2`

|  |  |
| --- | --- |
| Description | The person's current [street address line 2](https://docs.peopledatalabs.com/docs/data-types#common-location-fields). |
| Data Type | `String` |

#### Example

JSON

```
"location_address_line_2": "apartment 12"
```

### `location_continent`

|  |  |
| --- | --- |
| Description | The [continent](https://docs.peopledatalabs.com/docs/data-types#common-location-fields) of the person's current address. One of our [Canonical Continents](https://docs.peopledatalabs.com/docs/location-continents). |
| Data Type | `Enum (String)` |

#### Example

JSON

```
"location_continent": "north america"
```

### `location_country`

|  |  |
| --- | --- |
| Description | The [country](https://docs.peopledatalabs.com/docs/data-types#common-location-fields) of the person's current address. One of our [Canonical Countries](https://docs.peopledatalabs.com/docs/location-countries). |
| Data Type | `Enum (String)` |

#### Example

JSON

```
"location_country": "united states"
```

### `location_geo`

|  |  |
| --- | --- |
| Description | The [geo code](https://docs.peopledatalabs.com/docs/data-types#common-location-fields) of the city center of the person's current address. |
| Data Type | `String` |

#### Example

JSON

```
"location_geo": "37.87,-122.27"
```

### `location_last_updated`

|  |  |
| --- | --- |
| Description | The timestamp that a new data source contributed to the record for the person's current address. |
| Data Type | [`String (Date)`](https://docs.peopledatalabs.com/docs/data-types#dates) |

#### Field Details

An update is the time when either new information is added to the record or existing information is validated.

#### Example

JSON

```
"location_last_updated": "2018-11-05"
```

### `location_locality`

|  |  |
| --- | --- |
| Description | The [locality](https://docs.peopledatalabs.com/docs/data-types#common-location-fields) of the person's current address. |
| Data Type | `String` |

#### Example

JSON

```
"location_locality": "berkeley"
```

### `location_metro`

|  |  |
| --- | --- |
| Description | The [metro](https://docs.peopledatalabs.com/docs/data-types#common-location-fields) of the person's current address. One of our [Canonical Metros](https://docs.peopledatalabs.com/docs/location-metros). |
| Data Type | `Enum (String)` |

#### Example

JSON

```
"location_metro": "san francisco, california"
```

### `location_name`

|  |  |
| --- | --- |
| Description | The [location](https://docs.peopledatalabs.com/docs/data-types#common-location-fields) of the person's current address. |
| Data Type | `String` |

#### Example

JSON

```
"location_name": "berkeley, california, united states"
```

### `location_names`

|  |  |
| --- | --- |
| Description | All [location names](https://docs.peopledatalabs.com/docs/data-types#common-location-fields) associated with the person. |
| Data Type | `Array [String]` |

> ðŸ’¡
>
> ### Sort Order
>
> Location names are sorted by location order with duplicate names removed
>
> **Location Sort Order**
>
> Locations are sorted by primary location first. The remaining locations are sorted by `first_seen`, `last_seen`, `location_name`, `street_address`, then `address_line_2` in descending order (most recent first, Zâ†’A):
>
> 1. Primary location first
> 2. Sort by `first_seen` (most recent first)
> 3. Sort by `last_seen` (most recent first)
> 4. Sort by `location_name` (Zâ†’A)
> 5. Sort by `street_address` (Zâ†’A)
> 6. Sort by `address_line_2` (Zâ†’A)

#### Example

JSON

```
"location_names": [
    "berkeley, california, united states",
    "san francisco, california, united states"
  ]
```

### `location_postal_code`

|  |  |
| --- | --- |
| Description | The [postal code](https://docs.peopledatalabs.com/docs/data-types#common-location-fields) of the person's current address. |
| Data Type | `String` |

#### Example

JSON

```
"location_postal_code": "94704"
```

### `location_region`

|  |  |
| --- | --- |
| Description | The [region](https://docs.peopledatalabs.com/docs/data-types#common-location-fields) of the person's current address. |
| Data Type | `String` |

#### Example

JSON

```
"location_region": "california"
```

### `location_street_address`

|  |  |
| --- | --- |
| Description | The person's current [street address](https://docs.peopledatalabs.com/docs/data-types#common-location-fields). |
| Data Type | `String` |

#### Example

JSON

```
"location_street_address": "455 fake st"
```

### `regions`

|  |  |
| --- | --- |
| Description | All [regions](https://docs.peopledatalabs.com/docs/data-types#common-location-fields) associated with the person. |
| Data Type | `Array [String]` |

> ðŸ’¡
>
> ### Sort Order
>
> Regions are sorted by location order, with any duplicate regions removed.
>
> **Location Sort Order**
>
> Locations are sorted by primary location first. The remaining locations are sorted by `first_seen`, `last_seen`, `location_name`, `street_address`, then `address_line_2` in descending order (most recent first, Zâ†’A):
>
> 1. Primary location first
> 2. Sort by `first_seen` (most recent first)
> 3. Sort by `last_seen` (most recent first)
> 4. Sort by `location_name` (Zâ†’A)
> 5. Sort by `street_address` (Zâ†’A)
> 6. Sort by `address_line_2` (Zâ†’A)

#### Example

JSON

```
"regions": [
    "california, united states"
  ]
```

### `street_addresses`

|  |  |
| --- | --- |
| Description | All [street addresses](https://docs.peopledatalabs.com/docs/data-types#common-location-fields) associated with the person. |
| Data Type | `Array [Object]` |

#### Field Details

Each address associated with the person will be added to this list as its own object.

In addition to the [Common Location Fields](/docs/data-types#common-location-fields), `street_addresses` will also include:

| Field | Data Type | Description |
| --- | --- | --- |
| `first_seen` | [`String (Date)`](/docs/data-types#dates) | The date that this entity was first associated with the Person record. |
| `last_seen` | [`String (Date)`](/docs/data-types#dates) | The date that this entity was last associated with the Person record. |
| `num_sources` | `Integer (> 0)` | The number of sources that have contributed to the association of this entity with the Person record. |

> ðŸ’¡
>
> ### Sort Order
>
> Street addresses are sorted by location order.
>
> **Location Sort Order**
>
> Locations are sorted by primary location first. The remaining locations are sorted by `first_seen`, `last_seen`, `location_name`, `street_address`, then `address_line_2` in descending order (most recent first, Zâ†’A):
>
> 1. Primary location first
> 2. Sort by `first_seen` (most recent first)
> 3. Sort by `last_seen` (most recent first)
> 4. Sort by `location_name` (Zâ†’A)
> 5. Sort by `street_address` (Zâ†’A)
> 6. Sort by `address_line_2` (Zâ†’A)

#### Example

JSON

```
"street_addresses": [
    {
      "name": "berkeley, california, united states",
      "locality": "berkeley",
      "metro": "san francisco, california",
      "region": "california",
      "country": "united states",
      "continent": "north america",
      "street_address": "455 fake st",
      "address_line_2": "apartment 12",
      "postal_code": "94704",
      "geo": "37.87,-122.27",
      "first_seen": "2017-06-02",
      "last_seen": "2019-07-18",
      "num_sources": 17
    }
  ]
```

## Lower Confidence Data

PDL values high confidence data that is very likely to be associated with a person. The data in these fields have lower confidence than the data used in other fields.

### `possible_birth_dates`

|  |  |
| --- | --- |
| Description | Birthdays associated with this person that have a lower level of confidence. |
| Data Type | [`Array [String (Date)]`](https://docs.peopledatalabs.com/docs/data-types#dates) |

#### Field Details

The dates in this field use the same format as the [`birth_date`](#birth_date) field.

> ðŸ’¡
>
> ### Sort Order
>
> Possible birth dates are sorted by `num_sources`, `last_seen`, `first_seen`, `birth_date`, all in reverse order (highest first, most recent first):
>
> 1. `num_sources` (highest first)
> 2. `last_seen` (most recent first)
> 3. `first_seen` (most recent first)
> 4. `birth_date` (most recent first)

#### Example

JSON

```
"possible_birth_dates": [
    "1991-05-26",
    "1992-05-26"
  ]
```

### `possible_emails`

|  |  |
| --- | --- |
| Description | Email addresses associated with this person that have a lower level of confidence. |
| Data Type | `Array [Object]` |

#### Field Details

This field uses the same format as the [`emails`](#emails) field.

> ðŸ’¡
>
> ### Sort Order
>
> Possible emails are sorted by `last_seen`, `first_seen`, `email`, all in reverse order (most recent first, Zâ†’A):
>
> 1. `last_seen` (most recent first)
> 2. `first_seen` (most recent first)
> 3. `email` (Zâ†’A)

#### Example

JSON

```
"possible_emails": [
    {
      "address": "sean@peopledatalabs.com",
      "type": null,
      "first_seen": "2021-06-13",
      "last_seen": "2021-06-13",
      "num_sources": 2
    }
  ]
```

### `possible_location_names`

|  |  |
| --- | --- |
| Description | Locations associated with this person that have a lower level of confidence. |
| Data Type | `Array [String]` |

#### Field Details

This field uses the same format as the [`location_names`](#location_names) field.

Possible locations are inferred based on phone area codes, university location, and other associations.

> ðŸ’¡
>
> ### Sort Order
>
> Possible locations are sorted by `first_seen`, `last_seen`, `location.name`, all in reverse order (most recent first, Zâ†’A):
>
> 1. `first_seen` (most recent first)
> 2. `last_seen` (most recent first)
> 3. `location.name` (Zâ†’A)

#### Example

JSON

```
"possible_location_names": [
    "berkeley, california, united states",
    "san francisco, california, united states"
  ]
```

### `possible_phones`

|  |  |
| --- | --- |
| Description | Phone numbers associated with this person that have a lower level of confidence. |
| Data Type | `Array [Object]` |

#### Field Details

This field uses the same format as the [`phones`](#phones) field.

> ðŸ’¡
>
> ### Sort Order
>
> Possible phones are sorted by `num_sources`, `last_seen`, `first_seen`, all in reverse order and using the E.164 format (highest first, most recent first):
>
> 1. `num_sources` (highest first)
> 2. `last_seen` (most recent first)
> 3. `first_seen`(most recent first)

#### Example

JSON

```
"possible_phones": [
    {
      "number": "+15558675309",
      "first_seen": "2021-06-13",
      "last_seen": "2021-06-13",
      "num_sources": 2
    }
  ]
```

### `possible_profiles`

|  |  |
| --- | --- |
| Description | Social profiles associated with this person that have a lower level of confidence. |
| Data Type | `Array [Object]` |

#### Field Details

This field uses the same format as the [`profiles`](#profiles) field.

> ðŸ’¡
>
> ### Sort Order
>
> Possible profiles are sorted first by return status codes (200 > unknown > 404). The array is then sorted by number of profiles globally, `last_seen`, `first_seen`, `username`, `id`, all in reverse order (highest first, most recent first, Zâ†’A):
>
> 1. Status Codes:
>    * Profiles with 200 return status codes are first
>    * Profiles with unknown return status codes come next
>    * Profiles with 404 return status codes are placed last
> 2. Number of profiles globally (highest first)
> 3. `last_seen` (most recent first)
> 4. `first_seen` (most recent first)
> 5. `username` (Zâ†’A)
> 6. `id` (Zâ†’A)

#### Example

JSON

```
"possible_profiles": [
    {
      "network": "linkedin",
      "id": "145991517",
      "url": "linkedin.com/in/seanthorne",
      "username": "seanthorne",
      "first_seen": "2021-06-13",
      "last_seen": "2021-06-13",
      "num_sources": 2
    }
  ]
```

### `possible_street_addresses`

|  |  |
| --- | --- |
| Description | Addresses associated with this person that have a lower level of confidence. |
| Data Type | `Array [Object]` |

#### Field Details

This field uses the same format as the [`street_addresses`](#street_addresses) field.

> ðŸ’¡
>
> ### Sort Order
>
> Possible street addresses are sorted by `first_seen`, `last_seen`, `location.name`, `location.street_address`, `location.address_line_2`, all in reverse order (most recent first, Zâ†’A):
>
> 1. `first_seen` (most recent first)
> 2. `last_seen` (most recent first)
> 3. `location.name` (Zâ†’A)
> 4. `location.street_address` (Zâ†’A)
> 5. `location.address_line_2` (Zâ†’A)

#### Example

JSON

```
"possible_street_addresses": [
    {
      "name": "berkeley, california, united states",
      "locality": "berkeley",
      "metro": "san francisco, california",
      "region": "california",
      "country": "united states",
      "continent": "north america",
      "street_address": "455 fake st",
      "address_line_2": "apartment 12",
      "postal_code": "94704",
      "geo": "37.87,-122.27",
      "first_seen": "2021-06-13",
      "last_seen": "2021-06-13",
      "num_sources": 2
    }
  ]
```

## Social Presence

We currently cover person social profiles on our [Canonical Profile Networks](/docs/profile-networks). All profiles we've found for a person will be added to the [`profiles`](#profiles) list.

Each social profile URL has one or more standard formats that we parse and turn into a standard PDL format for that social URL. We invalidate profiles that have non-valid person stubs (for example, `linkedin.com/company`), and we also have a blacklist of usernames that we know are invalid.

We do not validate if a URL is valid (that is, whether you can access it) because doing this at scale is considered a Direct Denial of Service (DDoS) attack and/or a form of crawling. This is highly discouraged! We try to mitigate invalid URLs as much as possible by using Entity Resolution (Merging) to link URLs together and then tagging the primary URL at the top level for key networks.

### `facebook_friends`

|  |  |
| --- | --- |
| Description | The number of Facebook friends the person has. |
| Data Type | `Integer (>= 0)` |

#### Example

JSON

```
"facebook_friends": 3912
```

### `facebook_id`

|  |  |
| --- | --- |
| Description | The person's Facebook profile ID based on source agreement. |
| Data Type | `String` |

#### Example

JSON

```
"facebook_id": "1089351304"
```

### `facebook_url`

|  |  |
| --- | --- |
| Description | The person's Facebook profile URL based on source agreement. |
| Data Type | `String` |

#### Example

JSON

```
"facebook_url": "facebook.com/deseanthorne"
```

### `facebook_username`

|  |  |
| --- | --- |
| Description | The person's Facebook profile username based on source agreement. |
| Data Type | `String` |

#### Example

JSON

```
"facebook_username": "deseanthorne"
```

### `github_url`

|  |  |
| --- | --- |
| Description | The person's GitHub profile URL based on source agreement. |
| Data Type | `String` |

#### Example

JSON

```
"github_url": "github.com/deseanathan_thornolotheu"
```

### `github_username`

|  |  |
| --- | --- |
| Description | The person's GitHub profile username based on source agreement. |
| Data Type | `String` |

#### Example

JSON

```
"github_username": "deseanathan_thornolotheu"
```

### `linkedin_connections`

|  |  |
| --- | --- |
| Description | The number of LinkedIn connections the person has. |
| Data Type | `Integer (>= 0)` |

#### Field Details

Typically between 0-500.

#### Example

JSON

```
"linkedin_connections": 432
```

### `linkedin_id`

|  |  |
| --- | --- |
| Description | The person's LinkedIn profile ID. This is null when no values in the "profiles" array are active. |
| Data Type | `String` |

#### Example

JSON

```
"linkedin_id": "145991517"
```

### `linkedin_url`

|  |  |
| --- | --- |
| Description | The person's current LinkedIn profile URL. This is null when no values in the "profiles" array are active. |
| Data Type | `String` |

#### Example

JSON

```
"linkedin_url": "linkedin.com/in/seanthorne"
```

### `linkedin_username`

|  |  |
| --- | --- |
| Description | The person's LinkedIn profile username. This is null when no values in the "profiles" array are active. |
| Data Type | `String` |

#### Example

JSON

```
"linkedin_username": "seanthorne"
```

### `profiles`

|  |  |
| --- | --- |
| Description | Social profiles associated with the person. |
| Data Type | `Array [Object]` |

#### Field Details

Each profile associated with the person will be added to this list as its own object.

| Field | Data Type | Description |
| --- | --- | --- |
| `id` | `String` | The profile ID (format varies based on social network). |
| `first_seen` | [`String (Date)`](/docs/data-types#dates) | The date that this entity was first associated with the Person record. |
| `last_seen` | [`String (Date)`](/docs/data-types#dates) | The date that this entity was last associated with the Person record. |
| `network` | `Enum (String)` | The social network the profile is on. Must be one of our [Canonical Profile Networks](/docs/profile-networks). |
| `num_sources` | `Integer (> 0)` | The number of sources that have contributed to the association of this entity with the Person record. |
| `url` | `String` | The profile URL. |
| `username` | `String` | The profile username. |

> ðŸ’¡
>
> ### Sort Order
>
> Profiles are sorted with the primary profiles listed first (facebook, linkedin, twitter, and github, in that order). The rest of the array is then sorted by status codes (200 > unknown > 404), number of profiles globally, `last_seen`, `first_seen`, `username`, `id`, all in reverse order (highest first, most recent first, Zâ†’A):
>
> 1. Primary profiles first
>    1. Facebook
>    2. LinkedIn
>    3. Twitter
>    4. Github
> 2. Status Codes:
>    * Profiles with 200 return status codes are first
>    * Profiles with unknown return status codes come next
>    * Profiles with 404 return status codes are placed last
> 3. Number of profiles globally (highest first)
> 4. `last_seen` (most recent first)
> 5. `first_seen` (most recent first)
> 6. `username` (Zâ†’A)
> 7. `id` (Zâ†’A)

#### Example

JSON

```
"profiles": [
    {
      "network": "linkedin",
      "id": "145991517",
      "url": "linkedin.com/in/seanthorne",
      "username": "seanthorne",
      "first_seen": "2017-06-02",
      "last_seen": "2019-07-18",
      "num_sources": 17
    }
  ]
```

### `twitter_url`

|  |  |
| --- | --- |
| Description | The person's Twitter profile URL based on source agreement. |
| Data Type | `String` |

#### Example

JSON

```
"twitter_url": "twitter.com/seanthorne5"
```

### `twitter_username`

|  |  |
| --- | --- |
| Description | The person's Twitter profile username based on source agreement. |
| Data Type | `String` |

#### Example

JSON

```
"twitter_username": "seanthorne5"
```

## Work History

### `certifications`

|  |  |
| --- | --- |
| Description | Any certifications the person has. |
| Data Type | `Array [Object]` |

#### Field Details

The certifications listed are based on user input, we do not verify them.

| Field | Data Type | Description |
| --- | --- | --- |
| `end_date` | [`String (Date)`](/docs/data-types#dates) | The expiration date of the certification. |
| `name` | `String` | Certification name |
| `organization` | `String` | The organization awarding the certification. |
| `start_date` | [`String (Date)`](/docs/data-types#dates) | The date the certification was awarded. |

> ðŸ’¡
>
> ### Sort Order
>
> Certifications are sorted first by `start_date`, then by `end_date` and finally by `name`, all in reverse order (most recent first, Zâ†’A):
>
> 1. `start_date` (most recent first)
> 2. `end_date` (most recent first)
> 3. `name` (Zâ†’A)

#### Example

JSON

```
"certifications": [
    {
      "name": "machine learning certification",
      "organization": "coursera",
      "start_date": "2022-03",
      "end_date": "2023-04"
    }
  ]
```

### `experience`

|  |  |
| --- | --- |
| Description | The person's work experience. |
| Data Type | `Array [Object]` |

#### Field Details

The experience object that is tagged as `experience.is_primary = True` is copied over to the flattened `job_` fields (see [Current Job](#current-job) and [Current Company](#current-company)).

Each work experience object contains the following fields:

| Field | Data Type | Description |
| --- | --- | --- |
| [`company`](#experiencecompany) | `Object` | The company where the person worked. |
| `end_date` | [`String (Date)`](/docs/data-types#dates) | The date the person left the company. If the person is still working for the company, will be `null`. |
| `first_seen` | [`String (Date)`](/docs/data-types#dates) | The date that this entity was first associated with the Person record. |
| `last_seen` | [`String (Date)`](/docs/data-types#dates) | The date that this entity was last associated with the Person record. |
| `is_primary` | `Boolean` | Whether this is the person's current job or not. If `true`, this experience will be used to populate the `job_` fields. |
| `location_names` | `Array [String]` | Locations where the person has worked while with this company |
| `num_sources` | `Integer (> 0)` | The number of sources that have contributed to the association of this entity with the Person record. |
| `start_date` | [`String (Date)`](/docs/data-types#dates) | The date the person started at the company. |
| `summary` | `String` | User-inputted summary of their work experience. |
| [`title`](#experiencetitle) | `Object` | The person's job title while at the company. |

> ðŸ’¡
>
> ### Sort Order
>
> Experience entries are sorted with the primary experience first. The remaining entries are then sorted by `start_date`, `end_date`, `company.name`, and `title.name`, all in reverse order (most recent first, Zâ†’A):
>
> 1. Primary Experience (`is_primary = True` )
> 2. `start_date` (most recent first)
> 3. `end_date` (most recent first)
> 4. `company.name` (Zâ†’A)
> 5. `title.name` (Zâ†’A)

##### `experience.company`

The fields in `experience.company` map to the corresponding fields in our [Company Schema](/docs/company-schema). The same parsing and formatting logic apply.

| Field | Sub Field | Data Type | Description |
| --- | --- | --- | --- |
| `facebook_url` |  | `String` | The company's [Facebook URL](/docs/company-schema#facebook_url) |
| `founded` |  | `Integer (> 0)` | The [founding year](/docs/company-schema#founded) of the company. |
| `id` |  | `String` | The company's [PDL ID](/docs/company-schema#id) |
| `industry` |  | `Enum (String)` | The self-identified [industry](/docs/company-schema#industry) of the company. Must be one of the [Canonical Industries](/docs/industries). |
| `industry_v2` |  | `Enum (String)` | The v2 industry for the company.  Industry v2 is the self-reported industry from an expanded list of [Canonical v2 Industries](/docs/industries-v2). If no industry is found, the field will be `null` |
| `linkedin_id` |  | `String` | The company's [LinkedIn ID](/docs/company-schema#linkedin_id) |
| `linkedin_url` |  | `String` | The company's [LinkedIn URL](/docs/company-schema#linkedin_url) |
| `location` |  | `Object` | The location of the company's headquarters. See [Common Location Fields](/docs/data-types#common-location-fields) for detailed field descriptions. |
|  | `address_line_2` | `String` |  |
|  | `continent` | `Enum (String)` |  |
|  | `country` | `Enum (String)` |  |
|  | `geo` | `String` |  |
|  | `locality` | `String` |  |
|  | `metro` | `Enum (String)` |  |
|  | `name` | `String` |  |
|  | `postal_code` | `String` |  |
|  | `region` | `String` |  |
|  | `street_address` | `String` |  |
| `name` |  | `String` | The [company name](/docs/company-schema#name), cleaned and standardized. |
| `raw` |  | `Array [String]` | Raw company name. |
| `size` |  | `Enum (String)` | The self-reported [company size range](/docs/company-schema#size). Must be one of our [Canonical Company Sizes](/docs/company-sizes). |
| `ticker` |  | `String` | The [company ticker](/docs/company-schema#type). This field will only have a value if the company's `type` is `public`. |
| `twitter_url` |  | `String` | The company's [Twitter URL](/docs/company-schema#twitter_url) |
| `type` |  | `Enum (String)` | The [company type](/docs/company-schema#type). Must be one of our [Canonical Company Types](/docs/company-types). |
| `website` |  | `String` | The company's [primary website](/docs/company-schema#website), cleaned and standardized. |

##### `experience.title`

See the corresponding [Current Job](#current-job) fields for more details on the information included and formatting of these fields.

| Field | Data Type | Description |
| --- | --- | --- |
| `levels` | `Array [Enum (String)]` | [Canonical Job Title Levels](/docs/job-title-levels). |
| `name` | `String` | The cleaned job title. |
| `raw` | `Array [String]` | Raw job title input. |
| `role` | `Enum (String)` | One of the [Canonical Job Roles](/docs/job-title-roles). |
| `sub_role` | `Enum (String)` | One of the [Canonical Job Sub Roles](/docs/job-title-subroles). |
| `class` | `Enum (String)` | One of the [Canonical Job Classes](/docs/job-title-class-post-v271) . |

> ðŸ’¡
>
> ### Sort Order (`experience.title.levels`)
>
> Title levels are sorted from most important to least important based on the following ranking:
>
> 1. `cxo` (first)
> 2. `owner`
> 3. `vp`
> 4. `director`
> 5. `partner`
> 6. `senior`
> 7. `manager`
> 8. `entry`
> 9. `training`
> 10. `unpaid` (last)

#### Example

JSON

```
"experience": [
    {
      "company": {
        "name": "people data labs",
        "size": "11-50",
        "id": "peopledatalabs",
        "founded": 2015,
        "industry": "computer software",
        "location": {
          "name": "san francisco, california, united states",
          "locality": "san francisco",
          "region": "california",
          "metro": "san francisco, california",
          "country": "united states",
          "continent": "north america",
          "street_address": "455 market street",
          "address_line_2": "suite 1670",
          "postal_code": "94105",
          "geo": "37.77,-122.41"
        },
        "linkedin_url": "linkedin.com/company/peopledatalabs",
        "linkedin_id": "18170482",
        "facebook_url": "facebook.com/peopledatalabs",
        "twitter_url": "twitter.com/peopledatalabs",
        "website": "peopledatalabs.com",
        "ticker": null,
        "type": "private",
        "raw": [
          "people data labs"
        ],
      },
      "location_names": ["san francisco, california, united states"],
      "end_date": null,
      "start_date": "2015-03",
      "title": {
        "name": "chief executive officer and co-founder",
        "raw": [
          "co-founder &amp; ceo",
          "co-founder & ceo",
          "co-founder and chief executive officer"
        ],
        "role": "operations",
        "sub_role": "executive",
        "class": "general_and_administrative"
        "levels": [
          "cxo",
          "owner"
        ],
      },
      "is_primary": true,
      "summary": "worked on the \"search analytics\" team to understand our users better",
      "first_seen": "2018-10-11",
      "last_seen": "2022-11-15",
      "num_sources": 17
    },
  ]
```

### `headline`

|  |  |
| --- | --- |
| Description | The brief headline associated with a person profile. |
| Data Type | `String` |

#### Field Details

The self-written headline tied to the person profile (often a LinkedIn headline).

The summary is lowercased, but otherwise kept as-is from the raw source.

#### Example

JSON

```
"headline": "senior data engineer at people data labs"
```

### `industry`

|  |  |
| --- | --- |
| Description | The most relevant industry for this person based on their work history. |
| Data Type | `Enum (String)` |

#### Field Details

A person's industry is determined based on their tagged personal industries and the industries of the companies that they have worked for.

The value will be one of our [Canonical Industries](/docs/industries).

#### Example

JSON

```
"industry": "computer software"
```

### `inferred_years_experience`

|  |  |
| --- | --- |
| Description | The person's inferred years of total work experience. |
| Data Type | `Integer (0 - 100)` |

#### Field Details

The value will be between 0 and 100.

#### Example

JSON

```
"inferred_years_experience": 7
```

### `interests`

|  |  |
| --- | --- |
| Description | The person's self-reported interests. |
| Data Type | `Array [String]` |

#### Field Details

Each interest is cleaned (lowercased, stripped of whitespace, etc.). We don't have a canonical list of interests but we remove profanity and do some basic cleaning.

> ðŸ’¡
>
> ### Sort Order
>
> Interests are sorted alphabetically (from Aâ†’Z)

#### Example

JSON

```
"interests": [
    "data",
    "software"
  ]
```

### `job_history`

|  |  |
| --- | --- |
| Description | Additional professional positions that may have been removed or changed on resumes. |
| Data Type | `Array [Object]` |

#### Field Details

Any additional job history information PDL has that is not included in the [`experience`](#experience) field.

Usually these are positions that have been removed or changed on resumes.

| Field | Data Type | Description |
| --- | --- | --- |
| `company_id` | `String` | [PDL Company ID](/docs/company-schema#id) |
| `company_name` | `String` | [Company Name](/docs/company-schema#name) |
| `first_seen` | [`String (Date)`](/docs/data-types#dates) | The date that this experience was first associated with this record. |
| `last_seen` | [`String (Date)`](/docs/data-types#dates) | The date that this experience was last associated with this record. |
| `num_sources` | `Integer (> 0)` | The number of sources that have contributed to the association of this profile with this record. |
| `title` | `String` | [Job Title](#job_title) at this company. |

> ðŸ’¡
>
> ### Sort Order
>
> Job history entries are sorted by `start_date`, `end_date`, `company.name`, and `title.name`, all in reverse order (most recent first, Zâ†’A):
>
> 1. `start_date` (most recent first)
> 2. `end_date` (most recent first)
> 3. `company.name` (Zâ†’A)
> 4. `title.name` (Zâ†’A)

#### Example

JSON

```
"job_history": [
    {
      "company_id": "OMdETRug8CpuRDWGkhQ35wx8CvVk",
      "company_name": "auntie annes",
      "title": "food service supervisor",
      "first_seen": "2016-05-17",
      "last_seen": "2020-05-30",
      "num_sources": 12
    }
  ]
```

### `skills`

|  |  |
| --- | --- |
| Description | The person's self-reported skills. |
| Data Type | `Array [String]` |

#### Field Details

Each skill is cleaned (lowercased, stripped of whitespace, etc.). We do not always strip punctuation because it can be relevant for some skills (ex: `"c++"` vs `"c"`).

We do not do any canonicalization, so `"java"` and `"java 8.0"` are considered separate skills. For this reason, we encourage our customers to use fuzzy text matching with the `skills` field.

> ðŸ’¡
>
> ### Sort Order
>
> Skills are sorted alphabetically (from Aâ†’Z)

#### Example

JSON

```
"skills": [
    "entrepreneurship"
  ]
```

### `summary`

|  |  |
| --- | --- |
| Description | User-inputted personal summary. |
| Data Type | `String` |

#### Field Details

The self-written summary tied to the person profile (often a LinkedIn summary).

The summary is lowercased, but otherwise kept as-is from the raw source.

#### Example

JSON

```
"summary": "growth-hacker and digital nomad"
```

---

# PDL Record Information & Metadata

### `dataset_version`

|  |  |
| --- | --- |
| Description | The major or minor release number. |
| Data Type | `String` |

#### Field Details

This field currently exists in [Person Enrichment API](/docs/person-enrichment-api) responses.

Note: This number corresponds to the [data release number](/changelog), not the API release number.

#### Example

JSON

```
"dataset_version": "19.2"
```

### `first_seen`

|  |  |
| --- | --- |
| Description | The date when this record was first created in our data. |
| Data Type | [`String (Date)`](https://docs.peopledatalabs.com/docs/data-types#dates) |

#### Example

JSON

```
"first_seen": "2017-06-02"
```

### `num_records`

|  |  |
| --- | --- |
| Description | The number of unique raw records contributing to this specific PDL profile. |
| Data Type | `Integer (> 0)` |

#### Example

JSON

```
"num_records": 420
```

### `num_sources`

|  |  |
| --- | --- |
| Description | The number of unique sources contributing to this specific PDL profile. |
| Data Type | `Integer (> 0)` |

#### Example

JSON

```
"num_sources": 72
```

### operation\_id

|  |  |
| --- | --- |
| Description | An identifier for an operation in a Data License delivery, used for troubleshooting. |
| Data Type | `String` |

#### Field Details

This field exists only in [Data License](/docs/data-license) deliveries, and allows PDL employees to identify the timestamp and operations performed on the internal data in order to return a record in a delivery.

#### Example

JSON

```
"operation_id": "acee3bde2e1a2cb7e75c57b80d5b7bc2d5de5b02e7ea51f91304c28df77251dc"
```

Updated about 11 hours ago

---

Did this page help you?

Yes

No

---
# https://docs.peopledatalabs.com/docs/location-metros

| Canonical Values for Location Metros |
| --- |
| abilene, texas |
| akron, ohio |
| albany, georgia |
| albany, new york |
| albany, oregon |
| albuquerque, new mexico |
| alexandria, louisiana |
| allentown, pennsylvania |
| altoona, pennsylvania |
| amarillo, texas |
| ames, iowa |
| anchorage, alaska |
| ann arbor, michigan |
| anniston, alabama |
| appleton, wisconsin |
| asheville, north carolina |
| athens, georgia |
| atlanta, georgia |
| atlantic city, new jersey |
| auburn, alabama |
| augusta, georgia |
| austin, texas |
| bakersfield, california |
| baltimore, maryland |
| bangor, maine |
| barnstable town, massachusetts |
| baton rouge, louisiana |
| battle creek, michigan |
| bay city, michigan |
| beaumont, texas |
| beckley, west virginia |
| bellingham, washington |
| bend, oregon |
| billings, montana |
| binghamton, new york |
| birmingham, alabama |
| bismarck, north dakota |
| blacksburg, virginia |
| bloomington, illinois |
| bloomington, indiana |
| bloomsburg, pennsylvania |
| boise city, idaho |
| boston, massachusetts |
| boulder, colorado |
| bowling green, kentucky |
| bremerton, washington |
| bridgeport, connecticut |
| brownsville, texas |
| brunswick, georgia |
| buffalo, new york |
| burlington, north carolina |
| burlington, vermont |
| california, maryland |
| canton, ohio |
| cape coral, florida |
| cape girardeau, missouri |
| carbondale, illinois |
| carson city, nevada |
| casper, wyoming |
| cedar rapids, iowa |
| chambersburg, pennsylvania |
| champaign, illinois |
| charleston, south carolina |
| charleston, west virginia |
| charlotte, north carolina |
| charlottesville, virginia |
| chattanooga, tennessee |
| cheyenne, wyoming |
| chicago, illinois |
| chico, california |
| cincinnati, ohio |
| clarksville, tennessee |
| cleveland, ohio |
| cleveland, tennessee |
| coeur d'alene, idaho |
| college station, texas |
| colorado springs, colorado |
| columbia, missouri |
| columbia, south carolina |
| columbus, georgia |
| columbus, indiana |
| columbus, ohio |
| corpus christi, texas |
| corvallis, oregon |
| crestview, florida |
| cumberland, maryland |
| dallas, texas |
| dalton, georgia |
| danville, illinois |
| daphne, alabama |
| davenport, iowa |
| dayton, ohio |
| decatur, alabama |
| decatur, illinois |
| deltona, florida |
| denver, colorado |
| des moines, iowa |
| detroit, michigan |
| district of columbia |
| dothan, alabama |
| dover, delaware |
| dubuque, iowa |
| duluth, minnesota |
| durham, north carolina |
| east stroudsburg, pennsylvania |
| eau claire, wisconsin |
| el centro, california |
| el paso, texas |
| elizabethtown, kentucky |
| elkhart, indiana |
| elmira, new york |
| enid, oklahoma |
| erie, pennsylvania |
| eugene, oregon |
| evansville, indiana |
| fairbanks, alaska |
| fargo, north dakota |
| farmington, new mexico |
| fayetteville, arkansas |
| fayetteville, north carolina |
| flagstaff, arizona |
| flint, michigan |
| florence, alabama |
| florence, south carolina |
| fond du lac, wisconsin |
| fort collins, colorado |
| fort smith, arkansas |
| fort wayne, indiana |
| fresno, california |
| gadsden, alabama |
| gainesville, florida |
| gainesville, georgia |
| gettysburg, pennsylvania |
| glens falls, new york |
| goldsboro, north carolina |
| grand forks, north dakota |
| grand island, nebraska |
| grand junction, colorado |
| grand rapids, michigan |
| grants pass, oregon |
| great falls, montana |
| greeley, colorado |
| green bay, wisconsin |
| greensboro, north carolina |
| greenville, north carolina |
| greenville, south carolina |
| gulfport, mississippi |
| hagerstown, maryland |
| hammond, louisiana |
| hanford, california |
| harrisburg, pennsylvania |
| harrisonburg, virginia |
| hartford, connecticut |
| hattiesburg, mississippi |
| hickory, north carolina |
| hilton head island, south carolina |
| hinesville, georgia |
| homosassa springs, florida |
| hot springs, arkansas |
| houma, louisiana |
| houston, texas |
| huntington, west virginia |
| huntsville, alabama |
| idaho falls, idaho |
| indianapolis, indiana |
| iowa city, iowa |
| ithaca, new york |
| jackson, michigan |
| jackson, mississippi |
| jackson, tennessee |
| jacksonville, florida |
| jacksonville, north carolina |
| janesville, wisconsin |
| jefferson city, missouri |
| johnson city, tennessee |
| johnstown, pennsylvania |
| jonesboro, arkansas |
| joplin, missouri |
| kahului, hawaii |
| kalamazoo, michigan |
| kankakee, illinois |
| kansas city, missouri |
| kennewick, washington |
| killeen, texas |
| kingsport, tennessee |
| kingston, new york |
| knoxville, tennessee |
| kokomo, indiana |
| la crosse, wisconsin |
| lafayette, indiana |
| lafayette, louisiana |
| lake charles, louisiana |
| lake havasu city, arizona |
| lakeland, florida |
| lancaster, pennsylvania |
| lansing, michigan |
| laredo, texas |
| las cruces, new mexico |
| las vegas, nevada |
| lawrence, kansas |
| lawton, oklahoma |
| lebanon, pennsylvania |
| lewiston, idaho |
| lewiston, maine |
| lexington, kentucky |
| lima, ohio |
| lincoln, nebraska |
| little rock, arkansas |
| logan, utah |
| longview, texas |
| longview, washington |
| los angeles, california |
| louisville, kentucky |
| lubbock, texas |
| lynchburg, virginia |
| macon, georgia |
| madera, california |
| madison, wisconsin |
| manchester, new hampshire |
| manhattan, kansas |
| mankato, minnesota |
| mansfield, ohio |
| mcallen, texas |
| medford, oregon |
| memphis, tennessee |
| merced, california |
| miami, florida |
| michigan city, indiana |
| midland, michigan |
| midland, texas |
| milwaukee, wisconsin |
| minneapolis, minnesota |
| missoula, montana |
| mobile, alabama |
| modesto, california |
| monroe, louisiana |
| monroe, michigan |
| montgomery, alabama |
| morgantown, west virginia |
| morristown, tennessee |
| mount vernon, washington |
| muncie, indiana |
| muskegon, michigan |
| myrtle beach, south carolina |
| napa, california |
| naples, florida |
| nashville, tennessee |
| new bern, north carolina |
| new haven, connecticut |
| new orleans, louisiana |
| new york, new york |
| niles, michigan |
| north port, florida |
| norwich, connecticut |
| ocala, florida |
| ocean city, new jersey |
| odessa, texas |
| ogden, utah |
| oklahoma city, oklahoma |
| olympia, washington |
| omaha, nebraska |
| orlando, florida |
| oshkosh, wisconsin |
| owensboro, kentucky |
| oxnard, california |
| palm bay, florida |
| panama city, florida |
| parkersburg, west virginia |
| pensacola, florida |
| peoria, illinois |
| philadelphia, pennsylvania |
| phoenix, arizona |
| pine bluff, arkansas |
| pittsburgh, pennsylvania |
| pittsfield, massachusetts |
| pocatello, idaho |
| port st. lucie, florida |
| portland, maine |
| portland, oregon |
| poughkeepsie, new york |
| prescott valley, arizona |
| providence, rhode island |
| provo, utah |
| pueblo, colorado |
| punta gorda, florida |
| racine, wisconsin |
| raleigh, north carolina |
| rapid city, south dakota |
| reading, pennsylvania |
| redding, california |
| reno, nevada |
| richmond, virginia |
| riverside, california |
| roanoke, virginia |
| rochester, minnesota |
| rochester, new york |
| rockford, illinois |
| rocky mount, north carolina |
| rome, georgia |
| sacramento, california |
| saginaw, michigan |
| salem, oregon |
| salinas, california |
| salisbury, maryland |
| salt lake city, utah |
| san angelo, texas |
| san antonio, texas |
| san diego, california |
| san francisco, california |
| san jose, california |
| san luis obispo, california |
| santa cruz, california |
| santa fe, new mexico |
| santa maria, california |
| santa rosa, california |
| savannah, georgia |
| scranton, pennsylvania |
| seattle, washington |
| sebastian, florida |
| sebring, florida |
| sheboygan, wisconsin |
| sherman, texas |
| shreveport, louisiana |
| sierra vista, arizona |
| sioux city, iowa |
| sioux falls, south dakota |
| south bend, indiana |
| spartanburg, south carolina |
| spokane, washington |
| springfield, illinois |
| springfield, massachusetts |
| springfield, missouri |
| springfield, ohio |
| st. cloud, minnesota |
| st. george, utah |
| st. joseph, missouri |
| st. louis, missouri |
| state college, pennsylvania |
| staunton, virginia |
| stockton, california |
| sumter, south carolina |
| syracuse, new york |
| tallahassee, florida |
| tampa, florida |
| terre haute, indiana |
| texarkana, texas |
| the villages, florida |
| toledo, ohio |
| topeka, kansas |
| trenton, new jersey |
| tucson, arizona |
| tulsa, oklahoma |
| tuscaloosa, alabama |
| twin falls, idaho |
| tyler, texas |
| urban honolulu, hawaii |
| utica, new york |
| valdosta, georgia |
| vallejo, california |
| victoria, texas |
| vineland, new jersey |
| virginia beach, virginia |
| visalia, california |
| waco, texas |
| walla walla, washington |
| warner robins, georgia |
| waterloo, iowa |
| watertown, new york |
| wausau, wisconsin |
| weirton, west virginia |
| wenatchee, washington |
| wheeling, west virginia |
| wichita falls, texas |
| wichita, kansas |
| williamsport, pennsylvania |
| wilmington, north carolina |
| winchester, virginia |
| winston, north carolina |
| worcester, massachusetts |
| yakima, washington |
| york, pennsylvania |
| youngstown, ohio |
| yuba city, california |
| yuma, arizona |

*Contents of this table were sourced from the following file on our public S3 bucket:[location\_metro.txt](https://pdl-prod-schema.s3.us-west-2.amazonaws.com/28.0/enums/location_metro.txt)*

## Relevant fields

* [`experience.company.location.metro`](/docs/fields#possible_street_addresses)
* [`job_company_location_metro`](/docs/fields#job_company_location_metro)
* [`location.metro`](/docs/company-schema#location) (Company)
* [`location_metro`](/docs/fields#location_metro) (Person)
* [`street_addresses.metro`](/docs/fields#street_addresses)
* [`possible_street_addresses.metro`](/docs/fields#possible_street_addresses)
* [`top_us_employee_metros`](/docs/company-schema#top_us_employee_metros)

Updated 4 months ago

---

Did this page help you?

Yes

No

---
# https://docs.peopledatalabs.com/docs/location-continents

| Canonical Values for Location Continents |
| --- |
| africa |
| antarctica |
| asia |
| europe |
| north america |
| oceania |
| south america |

*Contents of this table were sourced from the following file on our public S3 bucket:[location\_continent.txt](https://pdl-prod-schema.s3.us-west-2.amazonaws.com/28.0/enums/location_continent.txt)*

## Relevant fields

* [`education.school.location.continent`](/docs/fields#educationschool)
* [`experience.company.location.continent`](/docs/fields#experiencecompany)
* [`job_company_location_continent`](/docs/fields#job_company_location_continent)
* [`location.continent`](/docs/company-schema#location) (Company)
* [`location_continent`](/docs/fields#location_continent) (Person)
* [`possible_street_addresses.continent`](/docs/fields#possible_street_addresses)
* [`street_addresses.continent`](/docs/fields#street_addresses)

Updated 4 months ago

---

Did this page help you?

Yes

No

---
# https://docs.peopledatalabs.com/docs/language-names

| Canonical Values for Language Names |
| --- |
| afrikaans |
| akan |
| albanian |
| amazigh |
| american sign language |
| amharic |
| arabic |
| aramaic |
| armenian |
| assamese |
| aymara |
| azerbaijani |
| balochi |
| bambara |
| banda |
| bashkort |
| basque |
| belarusian |
| bemba |
| bengali |
| bhojpuri |
| bislama |
| bosnian |
| brahui |
| bulgarian |
| burmese |
| cantonese |
| catalan |
| cebuano |
| chechen |
| cherokee |
| chewa |
| croatian |
| czech |
| dakota |
| danish |
| dari |
| dholuo |
| dinka |
| dutch |
| english |
| esperanto |
| estonian |
| ewe |
| farsi |
| filipino |
| finnish |
| fon |
| french |
| fula |
| galician |
| georgian |
| german |
| gikuyu |
| greek |
| guarani |
| gujarati |
| haitian creole |
| hausa |
| hawaiian |
| hawaiian creole |
| hebrew |
| hiligaynon |
| hindi |
| hungarian |
| icelandic |
| igbo |
| ilocano |
| indonesian |
| inuit/inupiaq |
| irish gaelic |
| italian |
| japanese |
| jarai |
| javanese |
| k'iche' |
| kabyle |
| kannada |
| kashmiri |
| kazakh |
| khmer |
| khoekhoe |
| kinyarwanda |
| kongo |
| konkani |
| korean |
| kurdish |
| kyrgyz |
| lao |
| latin |
| latvian |
| lingala |
| lithuanian |
| macedonian |
| maithili |
| malagasy |
| malay |
| malayalam |
| mandarin |
| mandinka |
| marathi |
| mende |
| mongolian |
| nahuatl |
| navajo |
| nepali |
| norwegian |
| ojibwa |
| oriya |
| oromo |
| pashto |
| persian |
| polish |
| portuguese |
| punjabi |
| quechua |
| romani |
| romanian |
| russian |
| samoan |
| sanskrit |
| serbian |
| shona |
| sindhi |
| sinhala |
| sinhalese |
| slovak |
| slovene |
| slovenian |
| somali |
| songhay |
| spanish |
| swahili |
| swazi |
| swedish |
| tachelhit |
| tagalog |
| taiwanese |
| tajiki |
| tamil |
| tatar |
| telugu |
| thai |
| tibetic languages |
| tigrigna |
| tok pisin |
| tonga |
| tsonga |
| tswana |
| tuareg |
| turkish |
| turkmen |
| ukrainian |
| urdu |
| uyghur |
| uzbek |
| vietnamese |
| warlpiri |
| welsh |
| wolof |
| xhosa |
| yakut |
| yiddish |
| yoruba |
| yucatec |
| zapotec |
| zulu |

*Contents of this table were sourced from the following file on our public S3 bucket:[languages.name.txt](https://pdl-prod-schema.s3.us-west-2.amazonaws.com/28.0/enums/languages.name.txt)*

## Relevant fields

* [`languages.name`](/docs/fields#languages)

Updated 4 months ago

---

Did this page help you?

Yes

No

---
# https://docs.peopledatalabs.com/docs/person-enrichment-api

## Overview

The Person Enrichment API enables you to enrich data on a person by performing a one-to-one match of this person with the nearly three billion individual profiles that are hosted in our dataset. Once matched, you have access to all the fields in our [Person Schema](/docs/fields), which can include names, addresses, employment information and social media accounts.

## What's Next

Please check out the following pages for more information on the Person Enrichment API:

| Page | Description |
| --- | --- |
| [Quickstart](/docs/quickstart-person-enrichment-api) | A quick hands-on introduction to the API with simple code examples. |
| [Reference](/docs/reference-person-enrichment-api) | Detailed descriptions of the technical specifications and usage constraints. |
| [Input Parameters](/docs/input-parameters-person-enrichment-api) | In-depth explanations of the input parameters that the API supports. |
| [Output Response](/docs/output-response-person-enrichment-api) | In-depth explanations of the output response object that the API returns. |
| [Examples](/docs/examples-person-enrichment-api) | A collection of functional code examples and walkthroughs that illustrate various use cases and applications of the API. |
| [FAQs](/docs/faqs-person-enrichment-api) | Answers to commonly asked questions and other good-to-know information. |
| [Bulk Person Enrichment API](/docs/bulk-enrichment-api) | A supporting functionality to enrich multiple profiles in the same request. |
| [Preview Enrichment API](/docs/preview-enrichment-api) | A supporting functionality to preview which fields have non-null data for a particular person. |

---



*Know someone whoâ€™d thrive building data products and helping us launch whatâ€™s next? Weâ€™d love to meet!*

*Check out our[open roles](https://www.peopledatalabs.com/company?utm_source=docs&utm_medium=footer&utm_campaign=cta#jobs) â†’*

Updated 4 months ago

---

Did this page help you?

Yes

No

---
# https://docs.peopledatalabs.com/docs/education-degrees

| Canonical Values for Education Degrees |
| --- |
| associate of arts |
| associates |
| bachelor of aerospace engineering |
| bachelor of applied science |
| bachelor of architecture |
| bachelor of arts |
| bachelor of arts in business administration |
| bachelor of arts in communication |
| bachelor of arts in education |
| bachelor of biosystems engineering |
| bachelor of business administration |
| bachelor of chemical engineering |
| bachelor of civil engineering |
| bachelor of commerce |
| bachelor of design |
| bachelor of education |
| bachelor of electrical engineering |
| bachelor of engineering |
| bachelor of fine arts |
| bachelor of general studies |
| bachelor of industrial & systems engineering |
| bachelor of industrial design |
| bachelor of interdisciplinary studies |
| bachelor of interior architecture |
| bachelor of law |
| bachelor of liberal arts |
| bachelor of liberal arts and sciences |
| bachelor of materials engineering |
| bachelor of mathematics |
| bachelor of mechanical engineering |
| bachelor of medicine |
| bachelor of music |
| bachelor of music education |
| bachelor of pharmacy |
| bachelor of polymer and fiber engineering |
| bachelor of professional health science |
| bachelor of science |
| bachelor of science in aerospace engineering |
| bachelor of science in biomedical engineering |
| bachelor of science in business administration |
| bachelor of science in chemical engineering |
| bachelor of science in chemistry |
| bachelor of science in civil engineering |
| bachelor of science in commerce business administration |
| bachelor of science in computer science |
| bachelor of science in education |
| bachelor of science in electrical engineering |
| bachelor of science in engineering |
| bachelor of science in engineering technology |
| bachelor of science in geology |
| bachelor of science in human environmental sciences |
| bachelor of science in materials engineering |
| bachelor of science in mechanical engineering |
| bachelor of science in metallurgical engineering |
| bachelor of science in microbiology |
| bachelor of science in nursing |
| bachelor of science in social work |
| bachelor of social work |
| bachelor of software engineering |
| bachelor of technology |
| bachelor of textile engineering |
| bachelor of textile management and technology |
| bachelor of veterinary science |
| bachelor of wireless engineering |
| bachelors |
| doctor of audiology |
| doctor of business administration |
| doctor of chiropractic |
| doctor of dental surgery |
| doctor of education |
| doctor of jurisprudence |
| doctor of medical dentistry |
| doctor of medicine |
| doctor of ministry |
| doctor of musical arts |
| doctor of nursing practice |
| doctor of optometry |
| doctor of osteophathy |
| doctor of pharmacy |
| doctor of philosophy |
| doctor of physical therapy |
| doctor of psychology |
| doctor of public health |
| doctor of science |
| doctor of veterinary medicine |
| doctorates |
| magister juris |
| magisters |
| master of accountancy |
| master of accounting |
| master of aerospace engineering |
| master of agriculture |
| master of applied mathematics |
| master of aquaculture |
| master of arts |
| master of arts in education |
| master of arts in teaching |
| master of building construction |
| master of business administration |
| master of chemical engineering |
| master of civil engineering |
| master of commerce |
| master of communication disorders |
| master of community planning |
| master of dental surgery |
| master of design |
| master of divinity |
| master of education |
| master of electrical engineering |
| master of engineering |
| master of fine arts |
| master of health science |
| master of hispanic studies |
| master of industrial design |
| master of integrated design and construction |
| master of international studies |
| master of landscape architecture |
| master of laws |
| master of liberal arts |
| master of library & information studies |
| master of library science |
| master of materials engineering |
| master of mechanical engineering |
| master of music |
| master of natural resources |
| master of nurse anesthesia |
| master of political science |
| master of probability and statistics |
| master of professional studies |
| master of public administration |
| master of public health |
| master of real estate development |
| master of rehabilitation counseling |
| master of science |
| master of science in aerospace engineering |
| master of science in basic medical sciences |
| master of science in biomedical engineering |
| master of science in chemical engineering |
| master of science in chemistry |
| master of science in civil engineering |
| master of science in computer science |
| master of science in criminal justice |
| master of science in education |
| master of science in electrical engineering |
| master of science in engineering science & mechanics |
| master of science in forensic science |
| master of science in health administration |
| master of science in health informatics |
| master of science in human environmental sciences |
| master of science in industrial engineering |
| master of science in information systems |
| master of science in instructional leadership administration |
| master of science in justice and public safety |
| master of science in marine science |
| master of science in materials engineering |
| master of science in mechanical engineering |
| master of science in metallurgical engineering |
| master of science in nursing |
| master of science in occupational therapy |
| master of science in operations research |
| master of science in physician assistant studies |
| master of science in public health |
| master of science in software engineering |
| master of social work |
| master of software engineering |
| master of tax accounting |
| master of taxation |
| master of technical & professional communication |
| master of technology |
| master of urban and regional planning |
| masters |

*Contents of this table were sourced from the following file on our public S3 bucket:[education.degrees.txt](https://pdl-prod-schema.s3.us-west-2.amazonaws.com/28.0/enums/education.degrees.txt)*

## Relevant fields

* [`education.degrees`](/docs/fields#education-1)

Updated 4 months ago

---

Did this page help you?

Yes

No

---
# https://docs.peopledatalabs.com/docs/example-record

> ðŸ“˜
>
> ### Sandbox Data Example
>
> The example person record shown here is made up of synthetic data from our [Sandbox Dataset](/docs/sandbox-apis). It is representative of the structure and richness of PDLâ€™s full person records, without exposing any real personally identifiable information.
>
> Keep in mind that not all fields you see below will be available to every customer by default - field access depends on your package and subscription.

JSON

```
{
  "id": "geOZltvqXDfpKzxgrzmJZj_0000",
  "full_name": "kimberly kimberly patton",
  "first_name": "kimberly",
  "middle_initial": "k",
  "middle_name": "kimberly",
  "last_initial": "p",
  "last_name": "patton",
  "sex": null,
  "birth_year": 1966,
  "birth_date": "1966-04-08",
  "linkedin_url": "linkedin.com/in/kimberly_patton",
  "linkedin_username": "kimberly_patton",
  "linkedin_id": "geOZlt",
  "headline": null,
  "facebook_url": "facebook.com/kimberly_patton",
  "facebook_username": "kimberly_patton",
  "facebook_id": "geOZlt",
  "twitter_url": "twitter.com/kimberly_patton",
  "twitter_username": "kimberly_patton",
  "github_url": "github.com/kimberly_patton",
  "github_username": "kimberly_patton",
  "work_email": "kimberly_patton@hall-rios-and-miller.com",
  "personal_emails": [
    "kimberly_patton@me.com"
  ],
  "recommended_personal_email": "kimberly_patton@me.com",
  "mobile_phone": "+15814854381",
  "industry": "wireless",
  "job_title": "tax adviser",
  "job_title_role": null,
  "job_title_sub_role": null,
  "job_title_class": null,
  "job_title_levels": [
    "vp",
    "vp",
    "vp"
  ],
  "job_onet_code": null,
  "job_onet_major_group": null,
  "job_onet_minor_group": null,
  "job_onet_broad_occupation": null,
  "job_onet_specific_occupation": null,
  "job_onet_specific_occupation_detail": null,
  "job_company_id": "WjFS0JV5SpeFBTNNXNUGFhpOTuk4",
  "job_company_name": "hall, rios and miller",
  "job_company_website": "hall-rios-and-miller.com",
  "job_company_size": "10001+",
  "job_company_founded": 2000,
  "job_company_industry": "wireless",
  "job_company_industry_v2": "waste collection",
  "job_company_linkedin_url": "linkedin.com/company/hall-rios-and-miller",
  "job_company_linkedin_id": "76081381",
  "job_company_facebook_url": "facebook.com/hall-rios-and-miller",
  "job_company_twitter_url": "twitter.com/hall-rios-and-miller",
  "job_company_type": "nonprofit",
  "job_company_ticker": null,
  "job_company_location_name": "east diana, quebec, canada",
  "job_company_location_locality": "east diana",
  "job_company_location_metro": "east diana",
  "job_company_location_region": "quebec",
  "job_company_location_geo": "62.1627635,124.325527",
  "job_company_location_street_address": "11253 james lodge",
  "job_company_location_address_line_2": "apt. 211",
  "job_company_location_postal_code": "A9A 3A2",
  "job_company_location_country": "canada",
  "job_company_location_continent": "north america",
  "job_company_employee_count": 74299,
  "job_company_inferred_revenue": "$10B+",
  "job_company_12mo_employee_growth_rate": null,
  "job_company_total_funding_raised": null,
  "job_last_changed": "2026-02-11",
  "job_last_verified": "2026-02-11",
  "job_start_date": "2018-10-31",
  "job_summary": "tax adviser at hall, rios and miller",
  "location_name": "east diana, quebec, canada",
  "location_locality": "east diana",
  "location_metro": "east diana",
  "location_region": "quebec",
  "location_country": "canada",
  "location_continent": "north america",
  "location_street_address": "11253 james lodge",
  "location_address_line_2": "apt. 211",
  "location_postal_code": "A9A 3A2",
  "location_geo": "62.1627635,124.325527",
  "location_last_updated": "2026-02-11",
  "linkedin_connections": 9287,
  "facebook_friends": 9287,
  "inferred_salary": "150,000-250,000",
  "inferred_years_experience": 1,
  "summary": "tax adviser at hall, rios and miller",
  "phone_numbers": [
    "+12493405557"
  ],
  "phones": [
    {
      "number": "+12493405557",
      "first_seen": "2019-03-25",
      "last_seen": "2020-11-05",
      "num_sources": 3
    }
  ],
  "emails": [
    {
      "address": "ddavis1977@live.com",
      "type": "professional",
      "first_seen": "2026-01-23T04:42:55",
      "last_seen": "2026-02-03T06:59:50",
      "num_sources": 10
    }
  ],
  "interests": [],
  "skills": [],
  "location_names": [
    "north kristastad, texas, united states"
  ],
  "regions": [
    "texas"
  ],
  "countries": [
    "united states"
  ],
  "street_addresses": [
    {
      "name": "north kristastad, texas, united states",
      "locality": "north kristastad",
      "region": "texas",
      "metro": "north kristastad",
      "country": "united states",
      "continent": "north america",
      "street_address": "6649 heather ferry",
      "address_line_2": "suite 777",
      "postal_code": "66063",
      "geo": "-55.8451755,-2.658256",
      "first_seen": "2019-07-07",
      "last_seen": "2019-09-09",
      "num_sources": 2
    }
  ],
  "experience": [
    {
      "company": {
        "name": "hall, rios and miller",
        "size": "10001+",
        "id": "WjFS0JV5SpeFBTNNXNUGFhpOTuk4",
        "founded": 2000,
        "industry": "wireless",
        "industry_v2": "waste collection",
        "location": {
          "name": "east diana, quebec, canada",
          "locality": "east diana",
          "region": "quebec",
          "metro": "east diana",
          "country": "canada",
          "continent": "north america",
          "street_address": "11253 james lodge",
          "address_line_2": "apt. 211",
          "postal_code": "A9A 3A2",
          "geo": "62.1627635,124.325527"
        },
        "linkedin_url": "linkedin.com/company/hall-rios-and-miller",
        "linkedin_id": "76081381",
        "facebook_url": "facebook.com/hall-rios-and-miller",
        "twitter_url": "twitter.com/hall-rios-and-miller",
        "website": "hall-rios-and-miller.com",
        "ticker": null,
        "type": "nonprofit",
        "raw": [
          "hall, rios and miller"
        ],
        "fuzzy_match": null
      },
      "location_names": [
        "east diana, quebec, canada"
      ],
      "end_date": "2019-10-22",
      "start_date": "2018-10-31",
      "title": {
        "name": "tax adviser",
        "raw": [
          "tax adviser"
        ],
        "class": null,
        "role": null,
        "sub_role": null,
        "levels": [
          "vp",
          "vp",
          "vp"
        ]
      },
      "is_primary": true,
      "summary": "tax adviser at hall, rios and miller",
      "num_sources": 10,
      "first_seen": "2018-10-31",
      "last_seen": "2019-10-22"
    },
    {
      "company": {
        "name": "rios inc",
        "size": "10001+",
        "id": "ISjSoC2ei2HrBC4maLPnRTzphyH0",
        "founded": 1927,
        "industry": "libraries",
        "industry_v2": "it system training and support",
        "location": {
          "name": "cindyshire, ontario, canada",
          "locality": "cindyshire",
          "region": "ontario",
          "metro": "cindyshire",
          "country": "canada",
          "continent": "north america",
          "street_address": "426 bryant parkway",
          "address_line_2": "apt. 597",
          "postal_code": "A3A 3A8",
          "geo": "68.361694,73.037565"
        },
        "linkedin_url": "linkedin.com/company/rios-inc",
        "linkedin_id": "25871129",
        "facebook_url": "facebook.com/rios-inc",
        "twitter_url": "twitter.com/rios-inc",
        "website": "rios-inc.com",
        "ticker": null,
        "type": "private",
        "raw": [
          "rios inc"
        ],
        "fuzzy_match": null
      },
      "location_names": [
        "susanfurt, ontario, canada",
        "lake laura, texas, united states",
        "new andreastad, ontario, canada"
      ],
      "end_date": "2019-04-07",
      "start_date": "2018-08-27",
      "title": {
        "name": "community arts worker",
        "raw": [
          "community arts worker"
        ],
        "class": null,
        "role": null,
        "sub_role": null,
        "levels": [
          "cxo"
        ]
      },
      "is_primary": false,
      "summary": "community arts worker at rios inc",
      "num_sources": 2,
      "first_seen": "2019-09-16",
      "last_seen": "2019-04-07"
    }
  ],
  "education": [
    {
      "school": {
        "name": "bryant-martinez",
        "type": "primary school",
        "id": null,
        "location": {
          "name": "pearsonborough, quebec, canada",
          "locality": "pearsonborough",
          "region": "quebec",
          "country": "canada",
          "continent": "north america"
        },
        "linkedin_url": "linkedin.com/school/bryant-martinez",
        "facebook_url": "facebook.com/bryant-martinez",
        "twitter_url": "twitter.com/bryant-martinez",
        "linkedin_id": "41079723",
        "website": "bryant-martinez.edu",
        "domain": "bryant-martinez.edu",
        "raw": [
          "bryant-martinez"
        ]
      },
      "degrees": [
        "master of liberal arts"
      ],
      "start_date": "2002-02-06",
      "end_date": "2010-06-01",
      "majors": [
        "digital art",
        "history"
      ],
      "minors": [
        "pharmaceutical development",
        "greek literature and culture",
        "european modern languages"
      ],
      "gpa": 4.0,
      "raw": [
        "bryant-martinez"
      ],
      "summary": "master of liberal arts majoring in digital art, history"
    }
  ],
  "profiles": [
    {
      "network": "vimeo",
      "id": "hKmxpf",
      "url": "vimeo.com/kimberlypatton",
      "username": "kimberlypatton",
      "num_sources": 4,
      "first_seen": "2019-04-23",
      "last_seen": "2018-04-13"
    },
    {
      "network": "soundcloud",
      "id": "SYrGxw",
      "url": "soundcloud.com/kimberly_patton",
      "username": "kimberly_patton",
      "num_sources": 10,
      "first_seen": "2019-01-27",
      "last_seen": "2020-09-25"
    },
    {
      "network": "linkedin",
      "id": "geOZlt",
      "url": "linkedin.com/in/kimberly_patton",
      "username": "kimberly_patton",
      "num_sources": 10,
      "first_seen": "2018-10-31",
      "last_seen": "2019-10-22"
    },
    {
      "network": "facebook",
      "id": "geOZlt",
      "url": "facebook.com/kimberly_patton",
      "username": "kimberly_patton",
      "num_sources": 10,
      "first_seen": "2018-10-31",
      "last_seen": "2019-10-22"
    },
    {
      "network": "twitter",
      "id": "geOZlt",
      "url": "twitter.com/kimberly_patton",
      "username": "kimberly_patton",
      "num_sources": 10,
      "first_seen": "2018-10-31",
      "last_seen": "2019-10-22"
    },
    {
      "network": "github",
      "id": "geOZlt",
      "url": "github.com/kimberly_patton",
      "username": "kimberly_patton",
      "num_sources": 10,
      "first_seen": "2018-10-31",
      "last_seen": "2019-10-22"
    }
  ],
  "name_aliases": [
    "k.p"
  ],
  "possible_emails": [],
  "possible_profiles": [
    {
      "network": "wordpress",
      "id": "jobfdp",
      "url": "wordpress.com/kimberly_patton",
      "username": "kimberly_patton",
      "num_sources": 2,
      "first_seen": "2019-07-27",
      "last_seen": "2020-12-14"
    },
    {
      "network": "meetup",
      "id": "AKQZxJ",
      "url": "meetup.com/k_p_75",
      "username": "k_p_75",
      "num_sources": 6,
      "first_seen": "2018-12-05",
      "last_seen": "2020-10-18"
    }
  ],
  "possible_phones": [
    {
      "number": "+12686024811",
      "first_seen": "2018-07-24",
      "last_seen": "2020-11-03",
      "num_sources": 7
    },
    {
      "number": "+16049242736",
      "first_seen": "2018-06-23",
      "last_seen": "2019-09-12",
      "num_sources": 5
    },
    {
      "number": "+12368990911",
      "first_seen": "2019-06-18",
      "last_seen": "2020-02-05",
      "num_sources": 6
    }
  ],
  "possible_street_addresses": [
    {
      "name": "williamview, california, united states",
      "locality": "williamview",
      "region": "california",
      "metro": "williamview",
      "country": "united states",
      "continent": "north america",
      "street_address": "66379 andrea lane",
      "address_line_2": "apt. 214",
      "postal_code": "67722",
      "geo": "-7.793674,138.869920",
      "first_seen": "2019-04-10",
      "last_seen": "2020-12-28",
      "num_sources": 4
    },
    {
      "name": "port cassandra, ontario, canada",
      "locality": "port cassandra",
      "region": "ontario",
      "metro": "port cassandra",
      "country": "canada",
      "continent": "north america",
      "street_address": "0596 reginald cove",
      "address_line_2": "apt. 562",
      "postal_code": "A7A 7A3",
      "geo": "41.883778,59.471652",
      "first_seen": "2018-03-18",
      "last_seen": "2021-10-04",
      "num_sources": 1
    },
    {
      "name": "saraport, british columbia, canada",
      "locality": "saraport",
      "region": "british columbia",
      "metro": "saraport",
      "country": "canada",
      "continent": "north america",
      "street_address": "5971 cody cove suite 171",
      "address_line_2": "suite 093",
      "postal_code": "A7A 1A7",
      "geo": "-77.8454585,-82.076514",
      "first_seen": "2018-02-11",
      "last_seen": "2020-09-04",
      "num_sources": 2
    }
  ],
  "possible_location_names": [
    "williamview, california, united states",
    "port cassandra, ontario, canada",
    "saraport, british columbia, canada"
  ],
  "possible_birth_dates": [
    "1967-04-08T00:00:00"
  ],
  "job_history": [
    {
      "company_id": "hall-rios-and-miller",
      "company_name": "hall, rios and miller",
      "title": "tax adviser",
      "first_seen": "2018-10-31",
      "last_seen": "2019-10-22",
      "num_sources": 10
    },
    {
      "company_id": "rios-inc",
      "company_name": "rios inc",
      "title": "community arts worker",
      "first_seen": "2019-09-16",
      "last_seen": "2019-04-07",
      "num_sources": 2
    }
  ],
  "certifications": [
    {
      "organization": "wilson and sons",
      "start_date": "2017-01-03",
      "end_date": "2013-04-25",
      "name": "retail manager"
    }
  ],
  "languages": [
    {
      "name": "sindhi",
      "proficiency": 3
    },
    {
      "name": "zulu",
      "proficiency": 5
    },
    {
      "name": "jarai",
      "proficiency": 1
    },
    {
      "name": "yiddish",
      "proficiency": 4
    }
  ],
  "first_seen": "2018-02-20",
  "num_sources": 39,
  "num_records": 5,
  "dataset_version": "v33.1"
}
```

Updated about 11 hours ago

---

Did this page help you?

Yes

No

---
# https://docs.peopledatalabs.com/docs/input-parameters-person-enrichment-api

## Request Requirements

The request must have enough data points to find a clear match. A valid request must include at least one of the following groups of optional parameters:

```
profile OR email OR phone OR email_hash OR lid OR pdl_id OR ( 
    (
        (first_name AND last_name) OR name) AND 
        (company OR school OR location OR street_address OR locality 
         OR region OR country OR postal_code OR birth_date)
    )
```

### `api_key`

| Type | Description | Default | Example |
| --- | --- | --- | --- |
| `String` | Your secret API key. |  |  |

Your API Key **must** be included in either the request header or the `api_key` parameter. For more information about request authentication, see the [Authentication](/docs/authentication) page.

---

## Optional Request Parameters

### `pdl_id`

| Type | Description | Example |
| --- | --- | --- |
| `String` | The [PDL Persistent ID](/docs/persistent-ids) for a record in our Person Dataset.    **Note:** If you enrich on ID and anything else, only ID is used and the other inputs for matching are ignored. | `qEnOZ5Oh0poWnQ1luFBfVw_0000` |

### `name`

| Type | Description | Example |
| --- | --- | --- |
| `String` | The person's full name, at least the first and last. | `Jennifer C. Jackson` |

### `first_name`

| Type | Description | Example |
| --- | --- | --- |
| `String` | The person's first name. | `Jennifer` |

### `last_name`

| Type | Description | Example |
| --- | --- | --- |
| `String` | The person's last name. | `Jackson` |

### `middle_name`

| Type | Description | Example |
| --- | --- | --- |
| `String` | The person's middle name. | `Cassandra` |

### `location`

| Type | Description | Example |
| --- | --- | --- |
| `String` | The location where a person lives. This can be anything from a street address to a country name. | `Medford, OR USA` |

### `street_address`

| Type | Description | Example |
| --- | --- | --- |
| `String` | The street address where the person lives. | `1234 Main Street` |

### `locality`

| Type | Description | Example |
| --- | --- | --- |
| `String` | The locality where the person lives. | `Boise` |

### `region`

| Type | Description | Example |
| --- | --- | --- |
| `String` | The state or region where the person lives. | `Idaho` |

### `country`

| Type | Description | Example |
| --- | --- | --- |
| `String` | The country where the person lives. | `United States` |

### `postal_code`

| Type | Description | Example |
| --- | --- | --- |
| `String` | The postal code where the person lives. If there is no value for country, the postal code is assumed to be US. | `83701` |

### `company`

| Type | Description | Example |
| --- | --- | --- |
| `String` | The name, website, or social URL of a company where the person has worked. | `Amazon` |

### `school`

| Type | Description | Example |
| --- | --- | --- |
| `String` | The name, website or social URL of a university or college the person has attended. | `University of Iowa` |

### `phone`

| Type | Description | Example |
| --- | --- | --- |
| `String` | A phone number the person has used. \*\*Input must begin with `+[country code]` for a match to be returned. \*\* | `+1 555-234-1234` |

### `email`

| Type | Description | Example |
| --- | --- | --- |
| `String` | An email the person has used. | `renee.c.paulsen1959@yahoo.com` |

### `email_hash`

| Type | Description | Example |
| --- | --- | --- |
| `String` | The SHA-256 or MD5 email hash. | `e206e6cd7fa5f9499fd6d2d943dcf7d9c1469bad351061483f5ce7181663b8d4` |

### `profile`

| Type | Description | Example |
| --- | --- | --- |
| `String` | A social profile that the person has used (see [list of available social profiles](/docs/social-networks)). | `https://linkedin.com/in/seanthorne` |

### `lid`

| Type | Description | Example |
| --- | --- | --- |
| `String` | The person's LinkedIn ID. | `145991517` |

### `birth_date`

| Type | Description | Example |
| --- | --- | --- |
| `String` | The person's birth date: either the year or a full birth date in the format `YYYY-MM-DD`. | `1996-10-01` |

### `data_include`

| Type | Description | Default | Example |
| --- | --- | --- | --- |
| `String` | A comma-separated string of fields that you want the response to include. |  | `"full_name,emails.address"` |

If this input parameter is not included, the full [person profile](/docs/fields) will be returned.

Include multiple fields by separating each with a comma. Include specific subfields by using dot notation (ex: `emails.address`).

Exclude field(s) by using `-` as the first character. Entering `-` will exclude all of the comma-separated fields following the character and needs to be entered only once. For example, `"-education,mobile_phone"` will remove the `education` and `mobile_phone fields` from the enriched profile response.

To exclude all data from being returned, use `data_include=""`.

### `pretty`

| Type | Description | Default | Example |
| --- | --- | --- | --- |
| `Boolean` | Whether the output should have [human-readable](http://jsonprettyprint.net/) indentation. | `false` | `true` |

### `min_likelihood`

| Type | Description | Default | Example |
| --- | --- | --- | --- |
| `Integer` | The minimum likelihood score that a response must have in order to count as a match. | `2` | `6` |

This parameter allows you to balance precision and recall. In other words, using a high `min_likelihood` value will only return very strong matches but at the risk of not returning any match at all if none can be found above the `min_likelihood` threshold. Alternatively, using a low `min_likelihood` value is more likely to give you a match but at the cost of returning a potentially weaker match.

By default, match recall is kept very high, so a response that returns a likelihood score of `2` will have roughly a 10-30% chance of being the person requested. Adding more data points to your requests will increase the probability of a successful match (high likelihood score and is actually the requested person).

Some general rules of thumb for setting this parameter:

* For use cases which rely on a high degree of data accuracy, use a value of â‰¥ `6`.
* Requests made with only a few less-specific data points will return lower scores.
* Requests made with only a few data points (for example, a name and a location), will rarely return a likelihood score > `4`.
* Requests made with just a name return a score between `2` and `5`, based on the quality of the match.
* Requests made with just an email will rarely return a likelihood score > `6`.

### `include_if_matched`

| Type | Description | Default | Example |
| --- | --- | --- | --- |
| `Boolean` | If `true`, the response will include the top-level field [`matched`](/docs/output-response-person-enrichment-api) that contains a list of every query input that matched this profile. | `false` | `true` |

As an example, if we wanted to enrich Sean Thorne using the following query:

JSON

```
{
   "first_name": "sean",
   "last_name": "thorne",
   "company": "people data labs",
   "location": "abu dhabi",
   "include_if_matched": true
}
```

Since Sean's location is in California and not Abu Dhabi in the dataset, the response would contain:

JSON

```
{
   "matched": [
        "company",
        "name"
    ]
}
```

### `required`

| Type | Description | Default | Example |
| --- | --- | --- | --- |
| `String` | The fields a response must have in order to count as a match. |  | `education AND (emails OR phone_numbers)` |

This parameter ensures that we only charge you for responses that include the data fields that you're interested in. You can use any top-level [fields](/docs/fields) as required parameters, except those that you use as search parameters, input fields, and fields that are not included in API responses based on your API key. If you include a field in both the request and the `required` parameter, the `required` parameter will not work.

Format the value as a boolean statement.

**Examples**

*The response must contain a Linkedin URL*:

cURL

```
required=linkedin_url
```

*The response must contain experience and a current work email*:

cURL

```
required=experience AND work_email
```

*The response must contain experience or emails*:

cURL

```
required=experience OR emails
```

*The response must contain education and either emails or phone\_numbers*:

cURL

```
required=education AND (emails OR phone_numbers)
```

Python3 SDKcURLJavaScriptRubyGoPython3

```
import json

# See https://github.com/peopledatalabs/peopledatalabs-python
from peopledatalabs import PDLPY

# Create a client, specifying your API key
CLIENT = PDLPY(
    api_key="YOUR API KEY",
)

# Create a parameters JSON object
PARAMS = {
    "name": ["Sean Thorne"],    
    "profile": ["www.twitter.com/seanthorne5", "linkedin.com/in/seanthorne"],
    "required": "emails"
}

# Pass the parameters object to the Person Enrichment API
json_response = CLIENT.person.enrichment(**PARAMS).json()

# Check for successful response
if json_response["status"] == 200:
  record = json_response['data']

  # Print selected fields
  print(
    record['work_email'],
    record['full_name'],
    record['job_title'],
    record['job_company_name']
  )

  print(f"Successfully enriched profile with PDL data.")

  # Save enrichment data to JSON file
  with open("my_pdl_enrichment.jsonl", "w") as out:
    out.write(json.dumps(record) + "\n")
else:
  print("Enrichment unsuccessful. See error and try again.")
  print("error:", json_response)
```

```
curl -X GET -G \
  'https://api.peopledatalabs.com/v5/person/enrich' \
  -H 'X-Api-Key: xxxx' \
  --data-urlencode 'name=Sean Thorne' \
  --data-urlencode 'profile=www.twitter.com/seanthorne5' \
  --data-urlencode 'required=emails'
```

```
// See https://github.com/peopledatalabs/peopledatalabs-js
import PDLJS from 'peopledatalabs';

import fs from 'fs';

// Create a client, specifying your API key
const PDLJSClient = new PDLJS({ apiKey: "YOUR API KEY" });

// Create a parameters JSON object
const params = {
  name: "Sean Thorne",
  profile: "www.twitter.com/seanthorne5",
  profile: "linkedin.com/in/seanthorne",
  required: "emails"
}

// Pass the parameters object to the Person Enrichment API
PDLJSClient.person.enrichment(params).then((data) => {
    var record = data.data
    
    // Print selected fields
    console.log(
        record["work_email"],
        record["full_name"],
        record["job_title"],
        record["job_company_name"],
        )
        
    console.log("Successfully enriched profile with PDL data.")
    
    // Save enrichment data to JSON file
    fs.writeFile("my_pdl_enrichment.jsonl", Buffer.from(JSON.stringify(record)), (err) => {
        if (err) throw err;
    });
}).catch((error) => {
  console.log(error);
});
```

```
require 'json'

# See https://github.com/peopledatalabs/peopledatalabs-ruby
require 'peopledatalabs'

# Set your API key
Peopledatalabs.api_key = 'YOUR API KEY'

# Create a parameters JSON object
PARAMS = {
    "name": ["Sean Thorne"],    
    "profile": ["www.twitter.com/seanthorne5", "linkedin.com/in/seanthorne"],
    "required": "emails"
}

# Pass the parameters object to the Person Enrichment API
json_response = Peopledatalabs::Enrichment.person(params: PARAMS)

# Check for successful response
if json_response['status'] == 200
    record = json_response['data']
    
    # Print selected fields
    puts \
        "#{record['work_email']} \
         #{record['full_name']} \
         #{record['job_title']} \
         #{record['job_company_name']}"
    
    puts "Successfully enriched profile with PDL data."
    
    # Save enrichment data to JSON file
    File.open("my_pdl_enrichment.jsonl", "w") do |out|
        out.write(JSON.dump(record) + "\n")
    end
else
    puts "Enrichment unsuccessful. See error and try again."
    puts "error: #{json_response}"
end
```

```
package main

import (
    "fmt"
    "os"
    "encoding/json"
    "context"
)

// See https://github.com/peopledatalabs/peopledatalabs-go
import (
    pdl "github.com/peopledatalabs/peopledatalabs-go"
    pdlmodel "github.com/peopledatalabs/peopledatalabs-go/model"
)

func main() {
    // Set your API key
    apiKey := "YOUR API KEY"
    // Set API key as environmental variable
    // apiKey := os.Getenv("API_KEY")

    // Create a client, specifying your API key
    client := pdl.New(apiKey)
    
    // Create a parameters JSON object
    params := pdlmodel.EnrichPersonParams {
        PersonParams: pdlmodel.PersonParams {
            Name: []string{"Sean Thorne"},
            Profile: []string{"www.twitter.com/seanthorne5", "linkedin.com/in/seanthorne"},
        },
        AdditionalParams: pdlmodel.AdditionalParams {
            Required: "emails",
        },
    }

    // Pass the parameters object to the Person Enrichment API
    response, err := client.Person.Enrich(context.Background(), params)
    
    // Check for successful response
    if err == nil {
        // Convert the API response to JSON
        jsonResponse, jsonErr := json.Marshal(response.Data)
        if jsonErr == nil {
            var record map[string]interface{}
            json.Unmarshal(jsonResponse, &record)
            // Print selected fields
            fmt.Println(
                       record["work_email"], 
                       record["full_name"], 
                       record["job_title"], 
                       record["job_company_name"])
        
            fmt.Println("Successfully enriched profile with PDL data.")
        
            // Save enrichment data to JSON file
            out, outErr := os.Create("my_pdl_enrichment.jsonl")
            defer out.Close()
            if outErr == nil {
                out.WriteString(string(jsonResponse) + "\n")
            }
            out.Sync()
        }
   	} else {
        fmt.Println("Enrichment unsuccessful. See error and try again.")
        fmt.Println("error:", err)
    }
}
```

```
import requests, json

# Set your API key
API_KEY = "YOUR API KEY"

# Set the Person Enrichment API URL
PDL_URL = "https://api.peopledatalabs.com/v5/person/enrich"

# Create a parameters JSON object
PARAMS = {
    "api_key": API_KEY,
    "name": ["Sean Thorne"],    
    "profile": ["www.twitter.com/seanthorne5", "linkedin.com/in/seanthorne"],
    "required": "emails"
}

# Pass the parameters object to the Person Enrichment API
json_response = requests.get(PDL_URL,  params=PARAMS).json()

# Check for successful response
if json_response["status"] == 200:
  record = json_response['data']

  # Print selected fields
  print(
    record['work_email'],
    record['full_name'],
    record['job_title'],
    record['job_company_name']
  )

  print(f"Successfully enriched profile with PDL data.")

  # Save enrichment data to JSON file
  with open("my_pdl_enrichment.jsonl", "w") as out:
    out.write(json.dumps(record) + "\n")
else:
  print("Enrichment unsuccessful. See error and try again.")
  print("error:", json_response)
```

**Valid Required Parameters**

You may specify any [top-level fields](/docs/fields) in the `required` parameter such as the fields below:

> âš ï¸
>
> You must have access to the appropriate [Person Data Field Bundle](/docs/person-data-field-bundles) for any field you provide as a `required` parameter.

| Field Name |
| --- |
| `birth_date` |
| `birth_year` |
| `certifications` |
| `countries` |
| `dataset_version` |
| `education` |
| `emails` |
| `experience` |
| `facebook_friends` |
| `facebook_id` |
| `facebook_url` |
| `facebook_username` |
| `first_name` |
| `first_seen` |
| `full_name` |
| `sex` |
| `github_url` |
| `github_username` |
| `headline` |
| `id` |
| `industry` |
| `inferred_salary` |
| `inferred_years_experience` |
| `interests` |
| `job_company_12mo_employee_growth_rate` |
| `job_company_employee_count` |
| `job_company_facebook_url` |
| `job_company_founded` |
| `job_company_id` |
| `job_company_industry` |
| `job_company_inferred_revenue` |
| `job_company_linkedin_id` |
| `job_company_linkedin_url` |
| `job_company_location_address_line_2` |
| `job_company_location_continent` |
| `job_company_location_country` |
| `job_company_location_geo` |
| `job_company_location_locality` |
| `job_company_location_metro` |
| `job_company_location_name` |
| `job_company_location_postal_code` |
| `job_company_location_region` |
| `job_company_location_street_address` |
| `job_company_name` |
| `job_company_size` |
| `job_company_ticker` |
| `job_company_total_funding_raised` |
| `job_company_twitter_url` |
| `job_company_type` |
| `job_company_website` |
| `job_history` |
| `job_last_changed` |
| `job_last_verified` |
| `job_onet_broad_occupation` |
| `job_onet_code` |
| `job_onet_major_group` |
| `job_onet_minor_group` |
| `job_onet_specific_occupation` |
| `job_onet_specific_occupation_detail` |
| `job_start_date` |
| `job_summary` |
| `job_title` |
| `job_title_levels` |
| `job_title_role` |
| `job_title_sub_role` |
| `job_title_class` |
| `languages` |
| `last_initial` |
| `last_name` |
| `linkedin_connections` |
| `linkedin_id` |
| `linkedin_url` |
| `linkedin_username` |
| `location_address_line_2` |
| `location_continent` |
| `location_country` |
| `location_geo` |
| `location_last_updated` |
| `location_locality` |
| `location_metro` |
| `location_name` |
| `location_names` |
| `location_postal_code` |
| `location_region` |
| `location_street_address` |
| `middle_initial` |
| `middle_name` |
| `mobile_phone` |
| `name_aliases` |
| `num_records` |
| `num_sources` |
| `operation_id` |
| `personal_emails` |
| `phone_numbers` |
| `phones` |
| `possible_birth_dates` |
| `possible_emails` |
| `possible_location_names` |
| `possible_phones` |
| `possible_profiles` |
| `possible_street_addresses` |
| `profiles` |
| `recommended_personal_email` |
| `regions` |
| `skills` |
| `street_addresses` |
| `summary` |
| `twitter_url` |
| `twitter_username` |
| `work_email` |

  

### `titlecase`

| Type | Description | Default | Example |
| --- | --- | --- | --- |
| `Boolean` | All text in API responses returns as lowercase by default. Setting `titlecase` to `true` will titlecase response data instead. | `false` | `true` |

Updated 14 days ago

---

Did this page help you?

Yes

No

---
# https://docs.peopledatalabs.com/docs/inferred-salaries

| Canonical Values for Inferred Salaries |
| --- |
| <20,000 |
| 20,000-25,000 |
| 25,000-35,000 |
| 35,000-45,000 |
| 45,000-55,000 |
| 55,000-70,000 |
| 70,000-85,000 |
| 85,000-100,000 |
| 100,000-150,000 |
| 150,000-250,000 |
| > 250,000 |

*Contents of this table were sourced from the following file on our public S3 bucket:[inferred\_salary.txt](https://pdl-prod-schema.s3.us-west-2.amazonaws.com/28.0/enums/inferred_salary.txt)*

## Relevant fields

* [`inferred_salary`](/docs/fields#inferred_salary)

Updated 4 months ago

---

Did this page help you?

Yes

No

---
# https://docs.peopledatalabs.com/docs/industries

| Canonical Values for Industries |
| --- |
| accounting |
| airlines/aviation |
| alternative dispute resolution |
| alternative medicine |
| animation |
| apparel & fashion |
| architecture & planning |
| arts and crafts |
| automotive |
| aviation & aerospace |
| banking |
| biotechnology |
| broadcast media |
| building materials |
| business supplies and equipment |
| capital markets |
| chemicals |
| civic & social organization |
| civil engineering |
| commercial real estate |
| computer & network security |
| computer games |
| computer hardware |
| computer networking |
| computer software |
| construction |
| consumer electronics |
| consumer goods |
| consumer services |
| cosmetics |
| dairy |
| defense & space |
| design |
| e-learning |
| education management |
| electrical/electronic manufacturing |
| entertainment |
| environmental services |
| events services |
| executive office |
| facilities services |
| farming |
| financial services |
| fine art |
| fishery |
| food & beverages |
| food production |
| fund-raising |
| furniture |
| gambling & casinos |
| glass, ceramics & concrete |
| government administration |
| government relations |
| graphic design |
| health, wellness and fitness |
| higher education |
| hospital & health care |
| hospitality |
| human resources |
| import and export |
| individual & family services |
| industrial automation |
| information services |
| information technology and services |
| insurance |
| international affairs |
| international trade and development |
| internet |
| investment banking |
| investment management |
| judiciary |
| law enforcement |
| law practice |
| legal services |
| legislative office |
| leisure, travel & tourism |
| libraries |
| logistics and supply chain |
| luxury goods & jewelry |
| machinery |
| management consulting |
| maritime |
| market research |
| marketing and advertising |
| mechanical or industrial engineering |
| media production |
| medical devices |
| medical practice |
| mental health care |
| military |
| mining & metals |
| motion pictures and film |
| museums and institutions |
| music |
| nanotechnology |
| newspapers |
| non-profit organization management |
| oil & energy |
| online media |
| outsourcing/offshoring |
| package/freight delivery |
| packaging and containers |
| paper & forest products |
| performing arts |
| pharmaceuticals |
| philanthropy |
| photography |
| plastics |
| political organization |
| primary/secondary education |
| printing |
| professional training & coaching |
| program development |
| public policy |
| public relations and communications |
| public safety |
| publishing |
| railroad manufacture |
| ranching |
| real estate |
| recreational facilities and services |
| religious institutions |
| renewables & environment |
| research |
| restaurants |
| retail |
| security and investigations |
| semiconductors |
| shipbuilding |
| sporting goods |
| sports |
| staffing and recruiting |
| supermarkets |
| telecommunications |
| textiles |
| think tanks |
| tobacco |
| translation and localization |
| transportation/trucking/railroad |
| utilities |
| venture capital & private equity |
| veterinary |
| warehousing |
| wholesale |
| wine and spirits |
| wireless |
| writing and editing |

*Contents of this table were sourced from the following file on our public S3 bucket:[industry.txt](https://pdl-prod-schema.s3.us-west-2.amazonaws.com/28.0/enums/industry.txt)*

## Relevant fields

* [`experience.company.industry`](/docs/fields#experiencecompany)
* [`industry`](/docs/fields#industry)
* [`job_company_industry`](/docs/fields#job_company_industry)

Updated 4 months ago

---

Did this page help you?

Yes

No

---
# https://docs.peopledatalabs.com/docs/reference-person-enrichment-api

The Person Enrichment API provides a **one-to-one** person match, retrieving up-to-date information on a unique individual.

# Endpoint

The endpoint for the Person Enrichment API is `https://api.peopledatalabs.com/v5/person/enrich`.

# Person Enrichment API Access and Billing

You can access the Person Enrichment API through our [self-signup dashboard](https://peopledatalabs.com/signup/)

When the API finds a matching person, it returns this person along with an HTTP response code of `200`. When it doesn't find a matching person, it returns an HTTP response code of `404`. We charge **per match**.

# Requests

See [Authentication](/docs/authentication) and [Requests](/docs/requests) sections to see all possible ways to input a request. We recommend using a JSON object to capture input parameters and will do so in the examples.

# Rate Limiting

Our default limit for free customers is 100 per minute. Our default limit for paying customers is 1,000 per minute.

**Note**: To allow for more enrichments without putting too much strain on our system, you can use the [Bulk Person Enrichment API](/docs/bulk-person-enrichment-api) to increase the number of enrichments per request, effectively increasing your rate limit by up to a hundred times.

# Input Parameters

When querying the API in URL, you can add data points to a queried person as key/value pairs at the end of a `v5` request string.

You can use the following parameters to specify information on a requested person. Adding more data points to a request increases the probability of a `200` response and will further increase the accuracy of the response's [Likelihood Score](/docs/output-response-person-enrichment-api#likelihood).

All query parameters listed below are optional.

> ðŸ“˜
>
> ### For more details, see [Input Parameters - Person Enrichment API](/docs/input-parameters-person-enrichment-api)
>
> You can also click on the individual parameter names in the table below to view more information on them.

| ParameterÂ Name | Description | Example |
| --- | --- | --- |
| [`pdl_id`](/docs/input-parameters-person-enrichment-api#pdl_id) | The [PDL Persistent ID](/docs/persistent-ids) for a record in our Person Dataset.   * \*Note:\*\* If you enrich on ID and anything else, only ID is used and the other inputs for matching are ignored. | `qEnOZ5Oh0poWnQ1luFBfVw_0000` |
| [`name`](/docs/input-parameters-person-enrichment-api#name) | The person's full name, at least the first and last. | `Jennifer C. Jackson` |
| [`first_name`](/docs/input-parameters-person-enrichment-api#first_name) | The person's first name. | `Jennifer` |
| [`last_name`](/docs/input-parameters-person-enrichment-api#last_name) | The person's last name. | `Jackson` |
| [`middle_name`](/docs/input-parameters-person-enrichment-api#middle_name) | The person's middle name. | `Cassandra` |
| [`location`](/docs/input-parameters-person-enrichment-api#location) | The location in which a person lives. This can be anything from a street address to a country name. | `Medford, OR USA` |
| [`street_address`](/docs/input-parameters-person-enrichment-api#street_address) | The street address at which the person lives. | `1234 Main Street` |
| [`locality`](/docs/input-parameters-person-enrichment-api#locality) | The locality in which the person lives. | `Boise` |
| [`region`](/docs/input-parameters-person-enrichment-api#region) | The state or region in which the person lives. | `Idaho` |
| [`country`](/docs/input-parameters-person-enrichment-api#country) | The country in which the person lives. | `United States` |
| [`postal_code`](/docs/input-parameters-person-enrichment-api#postal_code) | The postal code in which the person lives. If there is no value for `country`, the postal code is assumed to be in the US. | `83701` |
| [`company`](/docs/input-parameters-person-enrichment-api#company) | The name, website or social URL of the company where the person has worked. | `Amazon Web Services` |
| [`school`](/docs/input-parameters-person-enrichment-api#school) | The name, website or social URL of the university or college that the person has attended. | `University of Iowa` |
| [`phone`](/docs/input-parameters-person-enrichment-api#phone) | A phone number the person has used. \*\*Input must begin with`+[country code]` for a match to be returned. \*\* | `+1 555-234-1234` |
| [`email`](/docs/input-parameters-person-enrichment-api#email) | The email that the person has used. | `renee.c.paulsen1959@yahoo.com` |
| [`email_hash`](/docs/input-parameters-person-enrichment-api#email_hash) | The SHA-256 or MD5 email hash. | `e206e6cd7fa5f9499fd6d2d943dcf7d9c1469bad351061483f5ce7181663b8d4` |
| [`profile`](/docs/input-parameters-person-enrichment-api#profile) | A social profile that the person has used (see [list of available social profiles](/docs/social-networks)). | `https://linkedin.com/in/seanthorne`. |
| [`lid`](/docs/input-parameters-person-enrichment-api#lid) | The person's LinkedIn ID. | `145991517` |
| [`birth_date`](/docs/input-parameters-person-enrichment-api#birth_date) | The person's birth date: either the year or a full birth date. | `1996-10-01` |
| [`api_key`](/docs/input-parameters-person-enrichment-api#api_key) | Your secret API key.   **Note**: You can also provide this in the request header instead, as shown on the [Authentication](/docs/authentication) page. |  |

## Additional Input Parameters

You are not required to use the following additional input parameters. They generally transform or control various aspects of the enrichment process (returning matches or formatting results.)

| ParameterÂ Name | Description | Example |
| --- | --- | --- |
| [`titlecase`](/docs/input-parameters-person-enrichment-api#titlecase) | All text in the API responses returns as lowercase by default. Setting `titlecase` to `true` will titlecase the data in `200` responses. | `false` |
| [`pretty`](/docs/input-parameters-person-enrichment-api#pretty) | Whether the output should have [human-readable](http://jsonprettyprint.net/) indentation. | `true` |
| [`min_likelihood`](/docs/input-parameters-person-enrichment-api#min_likelihood) | The minimum `likelihood` score that a response must have to return a `200` status code. | `2` |
| [`include_if_matched`](/docs/input-parameters-person-enrichment-api#include_if_matched) | If set to `true`, the response will include a top-level field called [`matched`](/docs/output-response-person-enrichment-api#matched) (along with `data`, `status` and so forth), containing a value for each queried field parameter that was "matched" during our internal query. | `false` |
| [`required`](/docs/input-parameters-person-enrichment-api#required) | The fields and data points that a response must have to return a `200` status code. | `"education AND (emails OR phone_numbers)"` |
| [`data_include`](/docs/input-parameters-person-enrichment-api#data_include) | A comma-separated string of the fields that you want the response to include.  Begin the string with a `-` if you want to *exclude* the specified fields. If you want to exclude all data from being returned, use `data_include=""`. | `"full_name,emails.address"` |

## Minimum Inputs

The minimum combination of data points that a request must contain in order to return a `200` response are:

cURL

```
profile OR email OR phone OR email_hash OR lid OR ( 
    (
        (first_name AND last_name) OR name) AND 
        (locality OR region OR company OR school OR location OR postal_code)
    )
```

# Output Response

When you execute an API request, we preprocess the queried data points and build them into a query, which we then execute against our [API dataset](/docs/datasets#api-dataset). If the query yields one or more matching persons from the dataset, we return in the API response the person who is most likely the person requested, along with a `200` HTTP response code. If we do not find a match, we return a `404` HTTP response code.

## Response Fields

> ðŸ“˜
>
> ### For more details, see [Output Response - Person Enrichment API](/docs/output-response-person-enrichment-api)
>
> You can also click the field names in the table below to view more information on them.

| Field | Description | Type |
| --- | --- | --- |
| [`data`](/docs/output-response-person-enrichment-api#data) | A matched profile record that contains fields from our [Person Schema](/docs/fields). Any fields in the profile record that do not contain any data will have a `null` value. | `Object` |
| [`status`](/docs/output-response-person-enrichment-api#status) | The response code. See a description of our [error codes](errors). | `Integer` |
| [`likelihood`](/docs/output-response-person-enrichment-api#likelihood) | The degree of confidence. The field is an integer between `1` and `10` and represents how confident we are that the person we returned is the same as the person you requested. You can control the minimum likelihood score a response must have in order to return a `200` by using the [`min_likelihood`](/docs/input-parameters-person-enrichment-api#min_likelihood) parameter in the API request. | `Integer` |

## Response Data Structure

Here is an example response from the Person Enrichment API:

JSON

```
{
    "status": 200,
    "likelihood": 10,
    "data":  {
            "id": "qEnOZ5Oh0poWnQ1luFBfVw_0000",
            "full_name": "sean thorne",
            ...
     }
}
```

See [Example Person Record](/docs/example-record) for a full example of the fields included in the `data` object.

## Errors

If the request encounters an error, it will instead return an Error Response in the format described in [Errors](/docs/errors).

Updated 4 months ago

---

Did this page help you?

Yes

No

---
# https://docs.peopledatalabs.com/docs/authentication

## Authentication

There are three ways to authenticate requests:

* [In URL](/docs/authentication#in-url)
* [In Header](/docs/authentication#in-header)
* [In SDKs](/docs/authentication#in-sdks)

### In URL

Python3cURL

```
import requests

# Set your API key
API_KEY = "YOUR API KEY"

# Set the Person Enrichment API URL, including the API key
PDL_URL = "https://api.peopledatalabs.com/v5/person/enrich?api_key={}".format(API_KEY)

# Pass the URL to the Person Enrichment API
json_response = requests.get(PDL_URL).json()
```

```
curl -X GET \
  'https://api.peopledatalabs.com/v5/person/enrich?api_key=xxxx'
```

### In Header

Python3cURL

```
import requests

# Set your API key
API_KEY = "YOUR API KEY"

# Set the Person Enrichment API URL
PDL_URL = "https://api.peopledatalabs.com/v5/person/enrich"

# Set the headers
HEADERS = {
    "X-Api-Key": API_KEY
}

# Pass the URL and the headers to the Person Enrichment API
json_response = requests.get(PDL_URL,  headers=HEADERS).json()
```

```
curl -X GET \
  'https://api.peopledatalabs.com/v5/person/enrich' \ 
  -H 'X-Api-Key: xxxx'
```

### In SDKs

Python3JavaScriptRubyGo

```
# See https://github.com/peopledatalabs/peopledatalabs-python
from peopledatalabs import PDLPY

# Create a client, specifying your API key
CLIENT = PDLPY(
    api_key="YOUR API KEY",
)

# Create a parameters JSON object
PARAMS = {
    "company": ["Hallspot", "People Data Labs"],
  	"email": ["sean.thorne@talentiq.co"]
}

# Pass the parameters object to the Person Enrichment API
response = CLIENT.person.enrichment(**PARAMS)

# Print the API response
print(response.text)
```

```
// See https://github.com/peopledatalabs/peopledatalabs-js
import PDLJS from 'peopledatalabs';

// Create a client, specifying your API key
const PDLJSClient = new PDLJS({ apiKey: "YOUR API KEY" });

// Create a parameters JSON object
const params = {
    company: "Hallspot",
    company: "People Data Labs",
    email: "sean.thorne@talentiq.co"
}

// Pass the parameters object to the Person Enrichment API
PDLJSClient.person.enrichment(params).then((response) => {
    // Print the API response in JSON format
    console.log(response);
}).catch((error) => {
    console.log(error);
});
```

```
# See https://github.com/peopledatalabs/peopledatalabs-ruby
require 'peopledatalabs'

# Set your API key
Peopledatalabs.api_key = 'YOUR API KEY'

# Create a parameters JSON object
PARAMS = {
    "company": ["Hallspot", "People Data Labs"],
  	"email": ["sean.thorne@talentiq.co"]
}

# Pass the parameters object to the Person Enrichment API
response = Peopledatalabs::Enrichment.person(params: PARAMS)

# Print the API response
puts response
```

```
package main

import (
    "fmt"
    "context"
)

// See https://github.com/peopledatalabs/peopledatalabs-go
import (
    pdl "github.com/peopledatalabs/peopledatalabs-go"
    pdlmodel "github.com/peopledatalabs/peopledatalabs-go/model"
)

func main() {
    // Set your API key
    apiKey := "YOUR API KEY"
    // Set API key as environmental variable
    // apiKey := os.Getenv("API_KEY")

    // Create a client, specifying your API key
    client := pdl.New(apiKey)
    
    // Create a parameters JSON object
    params := pdlmodel.EnrichPersonParams {
        PersonParams: pdlmodel.PersonParams {
            Company: []string{"Hallspot", "People Data Labs"},
            Email: []string{"sean.thorne@talentiq.co"},
        },
    }

    // Pass the parameters object to the Person Enrichment API
    response, err := client.Person.Enrich(context.Background(), params)
    
    // Print the API response
    if err == nil {
        fmt.Println(response)
    }  
}
```

Requests with an invalid API Key will return a `401` [Error](/docs/errors).

If you need any assistance, or if you would like to either request a new API key or delete your existing key, please contact your account manager or reach out to us at [[support@peopledatalabs.com](mailto:support@peopledatalabs.com)](mailto:support@peopledatalabs.com)

Updated 4 months ago

---

Did this page help you?

Yes

No

---
# https://docs.peopledatalabs.com/docs/preview-enrichment-api

## Overview

The Preview Enrichment API supports our [Person Enrichment API](/docs/person-enrichment-api) by providing a preview of what fields have data in a record.

Weâ€™ve heard from many of our users in the lead/candidate search platform market that they often â€œteaseâ€ their users with previews of contact information for a person to incentivize them. The Preview Enrichment API will help solve this problem.

## Request Format

The endpoint for the Preview Enrichment API is `https://api.peopledatalabs.com/v5/person/enrich/preview`.

See [Input Parameters - Person Enrichment API](/docs/input-parameters-person-enrichment-api) for details on the supported parameters. All valid input parameters for the Person Enrichment API will work the same way for the Preview Enrichment API.

### Example

Python3cURL

```
import requests, json

# Set your API key
API_KEY = "YOUR API KEY"

# Set the Preview Enrichment API URL
PDL_URL = "https://api.peopledatalabs.com/v5/person/enrich/preview"

# Set the headers
HEADERS = {
    "X-Api-Key": API_KEY
}

# Create a parameters JSON object
PARAMS = {
    "email": ["sean@peopledatalabs.com"],
    "min_likelihood": 6
}

# Pass the parameters object to the Person Enrichment API
json_response = requests.get(PDL_URL, headers=HEADERS, params=PARAMS).json()

# Check for successful response
if json_response["status"] == 200:
  record = json_response['data']

  # Save enrichment data to JSON file
  with open("my_pdl_enrichment_preview.jsonl", "w") as out:
    out.write(json.dumps(record) + "\n")
else:
  print("Enrichment preview unsuccessful. See error and try again.")
  print("error:", json_response)
```

```
curl -X GET -G \
  'https://api.peopledatalabs.com/v5/person/enrich/preview' \
  -H 'X-Api-Key: xxxx' \
  --data-urlencode 'email=sean@peopledatalabs.com'
```

## Response Format

The Preview Enrichment API is a wrapper on the Person Enrichment API, meaning it returns all of [the same fields](/docs/fields) as the Person Enrichment API, but with **true / false** values instead (**true** meaning we have a value for that field and **false** meaning we do not have a value for it).

Any nested objects will not be included in the Preview Enrichment response. For example, if a record has data for the `education` field, the response will have `"education": true`, but will not list any of the subfields (such as `education.major`).

To help users know which record they're looking at, the following fields will have the actual data if it exists for the record: `id`, `full_name`, `sex`, `linkedin_url`, `industry`, `job_title`, `job_title_levels`, `job_company_name`, `job_company_website`, `location_name`. All other fields will have true/false values as described above.

The output is formatted as such:

| Field Name | Type | Description |
| --- | --- | --- |
| `data` | `Object` | The person response object. |
| `status` | `Integer` | The HTTP status code. |
| `likelihood` | `Integer` | The likelihood score. |

### Full Example Response

JSON

```
{
   "status": 200,
   "likelihood": 6,
   "data": {
       "id": "qEnOZ5Oh0poWnQ1luFBfVw_0000",
       "full_name": "sean thorne",
       "sex": "male",
       "linkedin_url": "linkedin.com/in/seanthorne",
       "industry": "computer software",
       "job_title": "co-founder and chief executive officer",
       "job_title_role": null,
       "job_title_sub_role": null,
       "job_title_levels": [
           "owner",
           "cxo"
       ],
       "job_company_name": "people data labs",
       "job_company_website": "peopledatalabs.com",
       "location_name": "san francisco, california, united states",
       "birth_date": false,
       "birth_year": true,
       "countries": true,
       "education": true,
       "emails": true,
       "experience": true,
       "facebook_id": true,
       "facebook_url": true,
       "facebook_username": true,
       "first_name": true,
       "github_url": false,
       "github_username": false,
       "interests": true,
       "job_company_facebook_url": true,
       "job_company_founded": true,
       "job_company_id": true,
       "job_company_industry": true,
       "job_company_linkedin_id": true,
       "job_company_linkedin_url": true,
       "job_company_location_address_line_2": true,
       "job_company_location_continent": true,
       "job_company_location_country": true,
       "job_company_location_geo": true,
       "job_company_location_locality": true,
       "job_company_location_metro": true,
       "job_company_location_name": true,
       "job_company_location_postal_code": true,
       "job_company_location_region": true,
       "job_company_location_street_address": true,
       "job_company_size": true,
       "job_company_twitter_url": true,
       "job_last_updated": true,
       "job_last_changed": true,
       "job_last_verified": true,
       "job_start_date": true,
       "last_initial": true,
       "last_name": true,
       "linkedin_id": true,
       "linkedin_username": true,
       "location_address_line_2": false,
       "location_continent": true,
       "location_country": true,
       "location_geo": true,
       "location_last_updated": true,
       "location_locality": true,
       "location_metro": true,
       "location_names": true,
       "location_postal_code": false,
       "location_region": true,
       "location_street_address": false,
       "middle_initial": true,
       "middle_name": true,
       "mobile_phone": true,
       "personal_emails": false,
       "phone_numbers": true,
       "profiles": true,
       "regions": true,
       "skills": true,
       "street_addresses": false,
       "twitter_url": true,
       "twitter_username": true,
       "work_email": true
   },
   "dataset_version": "19.2"
}
```

### Field Availability

The Preview Enrichment API will only return the fields shown in the example response above. Even if you have purchased additional fields or bundles for Person Enrichment, those fields will not show in the Preview Enrichment response.

### Errors

If the request encounters an error, it will instead return an Error Response in the format described in [Errors](/docs/errors).

## Access & Billing

The Preview Enrichment API is available for purchase by enterprise Person Enrichment customers. If youâ€™d like access, please [reach out to us](https://www.peopledatalabs.com/talk-to-sales).

Updated 4 months ago

---

Did this page help you?

Yes

No

---
# https://docs.peopledatalabs.com/docs/quickstart-person-enrichment-api

## Getting Started

In order to use our Person Enrichment API, you must have an active API key. You can look up your API key by logging into our [self-serve dashboard](https://www.peopledatalabs.com/main/api-keys) and going to the **API Keys** section.

> ðŸ‘
>
> ### Need an API Key?
>
> If you don't have an API key, you can easily create one by [signing up](https://peopledatalabs.com/signup) for a self-serve account. For more information, check out our [Self-Serve Quickstart Guide](https://blog.peopledatalabs.com/post/self-signup-api-quickstart), which walks you through the sign-up process as well as shows you how to use the self-serve API dashboard.

## Simple Example

As mentioned in the [Overview](/docs/person-enrichment-api#overview), the Person Enrichment API is a means of performing a one-to-one match of an individual with those included in our [Person Dataset](/docs/fields). In order to use the Person Enrichment API, **you will need at least one of the[input parameters](/docs/input-parameters-person-enrichment-api) of the API**.

Here's a quick example that demonstrates retrieving a record with a [`profile`](fields#profile) of `http://linkedin.com/in/seanthorne`:

Python3 SDKcURLJavaScriptRubyGoPython3

```
import json

# See https://github.com/peopledatalabs/peopledatalabs-python
from peopledatalabs import PDLPY

# Create a client, specifying your API key
CLIENT = PDLPY(
    api_key="YOUR API KEY",
)

# Create a parameters JSON object
PARAMS = {
    "profile": ["linkedin.com/in/seanthorne"]
}

# Pass the parameters object to the Person Enrichment API
json_response = CLIENT.person.enrichment(**PARAMS).json()

# Print the API response in JSON format
print(json_response)
```

```
curl -X GET \
  'https://api.peopledatalabs.com/v5/person/enrich?api_key=xxxx&profile=linkedin.com/in/seanthorne'
```

```
// See https://github.com/peopledatalabs/peopledatalabs-js
import PDLJS from 'peopledatalabs';

// Create a client, specifying your API key
const PDLJSClient = new PDLJS({ apiKey: "YOUR API KEY" });

// Create a parameters JSON object
const params = {
  profile: "http://linkedin.com/in/seanthorne"
}

// Pass the parameters object to the Person Enrichment API
PDLJSClient.person.enrichment(params).then((jsonResponse) => {
  // Print the API response in JSON format
  console.log(jsonResponse);
}).catch((error) => {
  console.log(error);
});
```

```
require 'json'

# See https://github.com/peopledatalabs/peopledatalabs-ruby
require 'peopledatalabs'

# Set your API key
Peopledatalabs.api_key = 'YOUR API KEY'

# Create a parameters JSON object
PARAMS = {
    profile: ['linkedin.com/in/seanthorne']
}

# Pass the parameters object to the Person Enrichment API
json_response = Peopledatalabs::Enrichment.person(params: PARAMS)

# Print the API response in JSON format
puts JSON.dump(json_response)
```

```
package main

import (
    "fmt"
    "encoding/json"
    "context"
)

// See https://github.com/peopledatalabs/peopledatalabs-go
import (
    pdl "github.com/peopledatalabs/peopledatalabs-go"
    pdlmodel "github.com/peopledatalabs/peopledatalabs-go/model"
)

func main() {
    // Set your API key
    apiKey := "YOUR API KEY"
    // Set API key as environmental variable
    // apiKey := os.Getenv("API_KEY")

    // Create a client, specifying your API key
    client := pdl.New(apiKey)
    
    // Create a parameters JSON object
    params := pdlmodel.EnrichPersonParams {
        PersonParams: pdlmodel.PersonParams {
            Profile: []string{"linkedin.com/in/seanthorne"},
        },
    }

    // Pass the parameters object to the Person Enrichment API
    response, err := client.Person.Enrich(context.Background(), params)
    
    // Convert the API response to JSON
    jsonResponse, jsonErr := json.Marshal(response.Data)

    // Print the API response
    if err == nil && jsonErr == nil {
        fmt.Println(string(jsonResponse))
    }  
}
```

```
import requests

# Set your API key
API_KEY = "YOUR API KEY"

# Set the Person Enrichment API URL
PDL_URL = "https://api.peopledatalabs.com/v5/person/enrich"

# Create a parameters JSON object
PARAMS = {
    "api_key": API_KEY,
    "profile": ["linkedin.com/in/seanthorne"]
}

# Pass the parameters object to the Person Enrichment API
json_response = requests.get(PDL_URL, params=PARAMS).json()

# Print the API response in JSON format
print(json_response)
```

The API will return the matching person record if the LinkedIn URL passed to it exists in our dataset.

The result of running the above code should be the profile for Sean Thorne (the CEO of People Data Labs) from our Person Dataset. To see Sean's full profile that would be returned in the `data` object, check out our [Example Person Record](/docs/example-record).

JSON

```
{
  "status": 200,
  "likelihood": 10,
  "data": {
    "id": "qEnOZ5Oh0poWnQ1luFBfVw_0000",
    "full_name": "sean thorne",
    ...
  }
}
```

If you don't get this response, check out our [Errors](/docs/errors) page for more information.

---

Updated 4 months ago

---

Did this page help you?

Yes

No

---
# https://docs.peopledatalabs.com/docs/job-title-roles

> ðŸ“˜
>
> ### Launched in v28.0 (October 2024)
>
> The roles on this page are the officially supported set of canonical values used across all datasets for all PDL customers. **Support for the previous (legacy) taxonomy has now fully ended.**
>
> To view the previous role values, see: [Legacy Job Title Roles (pre-v27.1)](/docs/job-title-roles-legacy-v271)
>
> For additional information, please see the [February 2025 Release Notes (v29.1)](/changelog/february-2025-release-notes-v291).

| Canonical Values for Job Title Roles |
| --- |
| advisory |
| analyst |
| creative |
| education |
| engineering |
| finance |
| fulfillment |
| health |
| hospitality |
| human\_resources |
| legal |
| manufacturing |
| marketing |
| operations |
| partnerships |
| product |
| professional\_service |
| public\_service |
| research |
| sales |
| sales\_engineering |
| support |
| trade |
| unemployed |

*Contents of this table were sourced from the following file on our public S3 bucket:[job\_title\_role.txt](https://pdl-prod-schema.s3.us-west-2.amazonaws.com/30.0/enums/job_title_role.txt)*

## Relevant fields

* [`average_tenure_by_role`](/docs/company-schema#average_tenure_by_role)
* [`employee_count_by_month_by_role`](/docs/company-schema#employee_count_by_month_by_role)
* [`employee_count_by_role`](/docs/company-schema#employee_count_by_role)
* [`employee_growth_rate_12_month_by_role`](/docs/company-schema#employee_growth_rate_12_month_by_role)
* [`experience.title.role`](/docs/fields#experiencetitle)
* [`job_title_role`](/docs/fields#job_title_role)
* [`recent_exec_departures.job_title_role`](/docs/company-schema#recent_exec_departures)
* [`recent_exec_departures.new_company_job_title_role`](/docs/company-schema#recent_exec_departures)
* [`recent_exec_hires.job_title_role`](/docs/company-schema#recent_exec_hires)
* [`recent_exec_hires.previous_company_job_title_role`](/docs/company-schema#recent_exec_hires)
* [`top_next_employers_by_role`](/docs/company-schema#top_next_employers_by_role)
* [`top_previous_employers_by_role`](/docs/company-schema#top_previous_employers_by_role)

## See Also

* [Job Title Subroles](/docs/job-title-subroles)
* [Mapping Title Subroles to Roles](/docs/title-subroles-to-roles)

Updated 4 months ago

---

Did this page help you?

Yes

No

---
# https://docs.peopledatalabs.com/docs/bulk-enrichment-api

## Overview

The Bulk Enrichment API provides a way to enrich multiple profiles using the [Person Enrichment API](/docs/person-enrichment-api) in one request.

> ðŸ“˜
>
> ### Bulk Enrichment vs Person Search
>
> The Bulk Enrichment API is **NOT** the same as the [Person Search API](/docs/person-search-api).
>
> The Bulk Enrichment API is the same as calling the [Person Enrichment API](/docs/person-enrichment-api) multiple times.
>
> Use the Bulk Enrichment API when you want to get detailed profiles for a set of people you already know (such as getting the work history of each person in a list of job candidate emails). Use the Person Search API to find an undetermined number of people that match your search criteria (such as finding possible job candidates based on their work history).

## Request Format

The endpoint for the bulk enrichment api is `POST https://api.peopledatalabs.com/v5/person/bulk`.

You can enrich up to 100 persons in a single request.

The request body must contain an array called `requests` with 1-100 individual request objects, each containing a `params` object for each request's parameters.

| Field Name | Description | Type |
| --- | --- | --- |
| `requests` | All requests to make in the bulk enrichment. | `Array [Object]` |
| `params` | The parameters for a single enrichment call. | `Object` |

JSON

```
{
  "requests": [
    {
      "params": {
        ...
      }
    },
    {
      "params": {
        ...
      }
    },
    ...
  ]
}
```

See [Input Parameters - Person Enrichment API](/docs/input-parameters-person-enrichment-api) for details on the supported Enrichment API parameters.

## Response Format

Bulk Enrichment responses are a **JSON Array** of objects with the following fields:

| Field Name | Description | Type |
| --- | --- | --- |
| `data` | The person response object. | `Object` |
| `status` | The HTTP status code. | `Integer` |
| `likelihood` | The likelihood score. | `Integer` |
| `metadata` | Any metadata that the user included in the request. [OPTIONAL] | `Object` |

**Note**: Metadata is on a per-request basis, and generally you should use it to connect requests to responses within a call. See [this section](/docs/bulk-enrichment-api#tracking-responses) for more information.

JSON

```
[
	{"status": 200, "likelihood": 10, "data": ...},
	{"status": 200, "likelihood": 10, "data": ...}
]
```

The order the objects appear in the response list is the same as the order of the `params` in the input `requests` array.

Each response contains an individual status code that shows whether the enrichment for that particular request was successful (`200`) or not. See [Errors](/docs/errors) for a detailed breakdown on all possible status codes.

We will deduct the number of remaining Enrichment credits in your account by the number of `200` status responses in a Bulk Enrichment request as though you made each request individually.

## Example

Python3 SDKcURLJavaScriptRubyGoPython3

```
import json

# See https://github.com/peopledatalabs/peopledatalabs-python
from peopledatalabs import PDLPY

# Create a client, specifying your API key
CLIENT = PDLPY(
    api_key="YOUR API KEY",
)

# Create an array of parameters JSON objects
DATA = {
   "required": "profiles",
   "include_if_matched": "True",
   "requests": [
       {
           "params": {
               "profile": ["linkedin.com/in/seanthorne"]
           }
       },
       {
           "params": {
               "profile": ["linkedin.com/in/randrewn"]
           }
       }
   ]
}

# Pass the bulk parameters object to the Bulk Person Enrichment API
json_responses = CLIENT.person.bulk(**DATA).json()

# Iterate through the array of API responses
for response in json_responses:
  # Check for successful response
  if response['status'] == 200:

    record = response['data']

    # Print selected fields
    print(
      record['work_email'],
      record['full_name'],
      record['job_title'],
      record['job_company_name']
    )

    print(f"Successfully enriched profile with PDL data.")

    # Save enrichment data to JSON file
    with open(f"my_pdl_enrichment.{record['linkedin_username']}.jsonl", "w") as out:
      out.write(json.dumps(record) + "\n")
  else:
    print("Enrichment unsuccessful. See error and try again.")
    print("error:", response)
```

```
curl -X POST "https://api.peopledatalabs.com/v5/person/bulk" \
-H 'Content-Type: application/json' \
-H 'X-Api-Key: XXX' \
-d ' {
    "requests": [
    	{
    		"params": {
    			"profile": ["linkedin.com/in/seanthorne"],
    			"location": ["SF Bay Area"],
    			"name": ["Sean F. Thorne"]
    		}
    	},
    	{
    		"params": {
    			"profile": ["https://www.linkedin.com/in/haydenconrad/"],
    			"first_name": "Hayden",
    			"last_name": "Conrad"
    		}
    	}
    ]
}'
```

```
// See https://github.com/peopledatalabs/peopledatalabs-js
import PDLJS from 'peopledatalabs';

import fs from 'fs';

// Create a client, specifying your API key
const PDLJSClient = new PDLJS({ apiKey: "YOUR API KEY" });

// Create an array of parameters JSON objects
const records = {
  requests: [
    {
      params: {
        profile: ['linkedin.com/in/seanthorne']
      }
    },
    {
      params: {
        profile: ['linkedin.com/in/randrewn']
      }
    }
  ]
};

// Pass the parameters object to the Bulk Person Enrichment API
PDLJSClient.person.bulk.enrichment(records).then((data) => {
    var record
    
    // Iterate through the array of API responses
    for (let response in data) {
    
        // Check for successful response
        if (data[response].status == 200) {
        	record = data[response].data
     
          // Print selected fields
        	console.log(
            	record["work_email"],
            	record["full_name"],
            	record["job_title"],
            	record["job_company_name"],
            )
        
        	console.log("Successfully enriched profile with PDL data.")
    
        	// Save enrichment data to JSON file
        	fs.writeFile(`my_pdl_enrichment.${record["linkedin_username"]}.jsonl`, Buffer.from(JSON.stringify(record)), (err) => {
            	if (err) throw err;
        	});
        }
        else {
        	console.log("Enrichment unsuccessful. See error and try again.")
    			console.log(data[response]);
        }
    }
}).catch((error) => {
    console.log("Enrichment unsuccessful. See error and try again.")
    console.log(error);
});
```

```
require 'json'

# See https://github.com/peopledatalabs/peopledatalabs-ruby
require 'peopledatalabs'

# Set your API key
Peopledatalabs.api_key = 'YOUR API KEY'

# Create an array of parameters JSON objects
DATA = {
   "requests": [
       {
           "params": {
               "profile": ["linkedin.com/in/seanthorne"]
           }
       },
       {
           "params": {
               "profile": ["linkedin.com/in/randrewn"]
           }
       }
   ]
}

# Pass the bulk parameters object to the Bulk Person Enrichment API
json_response = Peopledatalabs::Bulk.person(params: DATA)
items = json_response['items']

# Iterate through the array of API responses
items.each do |response|
    # Check for successful response
    if response['status'] == 200
        record = response['data']
    
        # Print selected fields
        puts \
            "#{record['work_email']} \
             #{record['full_name']} \
             #{record['job_title']} \
             #{record['job_company_name']}"
    
        puts "Successfully enriched profile with PDL data."
    
        # Save enrichment data to JSON file
        File.open("my_pdl_enrichment.#{record['linkedin_username']}.jsonl", "w") do |out|
            out.write(JSON.dump(record) + "\n")
        end
    else
        puts "Enrichment unsuccessful. See error and try again."
        puts "error: #{json_response}"
    end
end
```

```
package main

import (
    "fmt"
    "os"
    "encoding/json"
    "context"
)

// See https://github.com/peopledatalabs/peopledatalabs-go
import (
    pdl "github.com/peopledatalabs/peopledatalabs-go"
    pdlmodel "github.com/peopledatalabs/peopledatalabs-go/model"
)

func main() {
    // Set your API key
    apiKey := "YOUR API KEY"
    // Set API key as environmental variable
    // apiKey := os.Getenv("API_KEY")

    // Create a client, specifying your API key
    client := pdl.New(apiKey)
    
    // Create an array of parameters JSON objects
    params := pdlmodel.BulkEnrichPersonParams {
        Requests: []pdlmodel.BulkEnrichSinglePersonParams {
            {
                Params: pdlmodel.PersonParams {
                    Profile:  []string{"linkedin.com/in/seanthorne"},
                },
            },
            {
                Params: pdlmodel.PersonParams {
                    Profile:  []string{"linkedin.com/in/randrewn"},
                },
           },
        },
    }

    // Pass the parameters object to the Bulk Person Enrichment API
    responses, err := client.Person.BulkEnrich(context.Background(), params)
    
    // Iterate through the array of API responses
    for _, response := range responses {
        // Check for successful response
        if err == nil {
            // Convert the API response to JSON
            jsonResponse, jsonErr := json.Marshal(response.Data)
            if jsonErr == nil {
                var record map[string]interface{}
                json.Unmarshal(jsonResponse, &record)
                // Print selected fields
                fmt.Println(
                            record["work_email"], 
                            record["full_name"], 
                            record["job_title"], 
                            record["job_company_name"])
        
                fmt.Println("Successfully enriched profile with PDL data.")
        
                // Save enrichment data to JSON file
                out, outErr := os.Create(fmt.Sprintf("my_pdl_enrichment.%s.jsonl", record["linkedin_username"]))
                defer out.Close()
                if outErr == nil {
                    out.WriteString(string(jsonResponse) + "\n")
                }
                out.Sync()
            }
   	    } else {
            fmt.Println("Enrichment unsuccessful. See error and try again.")
            fmt.Println("error:", err)
        }
    }

}
```

```
import requests
import json

# Set your API key
API_KEY = "YOUR API KEY"

# Pass your API key in header
HEADERS = {
   'X-Api-Key': API_KEY,
   'Content-Type': 'application/json',
}
 
# Create an array of parameters JSON objects
DATA = {
   "requests": [
       {
           "params": {
               "profile": ["linkedin.com/in/seanthorne"]
           }
       },
       {
           "params": {
               "profile": ["linkedin.com/in/randrewn"]
           }
       }
   ]
}

# Pass the bulk parameters object to the Bulk Person Enrichment API using POST method
json_responses = requests.post(
   'https://api.peopledatalabs.com/v5/person/bulk',
   headers=HEADERS,
   json=DATA
).json()
 
# Iterate through the array of API responses
for response in json_responses:
  # Check for successful response
  if response["status"] == 200:

    record = response['data']

    # Print selected fields
    print(
      record['work_email'],
      record['full_name'],
      record['job_title'],
      record['job_company_name']
    )

    print(f"Successfully enriched profile with PDL data.")

    # Save enrichment data to JSON file
    with open(f"my_pdl_enrichment.{record['linkedin_username']}.jsonl", "w") as out:
      out.write(json.dumps(record) + "\n")
  else:
    print("Enrichment unsuccessful. See error and try again.")
    print("error:", response)
```

## Tracking Responses

The API always returns response objects in the same order as they were defined in the `requests` array. You can also add an optional `metadata` object to each request, containing any information specific to that request. If you define `metadata` in a request object, the API will return it unchanged in that request's corresponding response object:

Python3 SDKcURLJavaScriptRubyGoPython3

```
import json

# See https://github.com/peopledatalabs/peopledatalabs-python
from peopledatalabs import PDLPY

# Create a client, specifying your API key
CLIENT = PDLPY(
    api_key="YOUR API KEY",
)

# Create an array of parameters JSON objects
DATA = {
    "required": "profiles",
    "include_if_matched": "True",
    "requests": [
    	{
    		# Include metadata object
    		"metadata": {
    			"user_id": "123"
    		},
    		"params": {
    			"profile": ["linkedin.com/in/seanthorne"],
    			"location": ["SF Bay Area"],
    			"name": ["Sean F. Thorne"]
    		}
    	},
    	{
    		# Include metadata object
    		"metadata": {
    			"user_id": "345"
    		},
    		"params": {
    			"profile": ["https://www.linkedin.com/in/haydenconrad/"],
    			"first_name": "Hayden",
    			"last_name": "Conrad"
    		}
    	}
    ]
}

# Pass the bulk parameters object to the Bulk Person Enrichment API
json_response = CLIENT.person.bulk(**DATA).json()

# Print the API response
print(json.dumps(json_response))
```

```
curl -X POST "https://api.peopledatalabs.com/v5/person/bulk" \
-H 'Content-Type: application/json' \
-H 'X-Api-Key: XXX' \
-d ' {
    "requests": [
    	{
    		"metadata": {
    			"user_id": "123"
    		},
    		"params": {
    			"profile": ["linkedin.com/in/seanthorne"],
    			"location": ["SF Bay Area"],
    			"name": ["Sean F. Thorne"]
    		}
    	},
    	{
    		"metadata": {
    			"user_id": "345"
    		},
    		"params": {
    			"profile": ["https://www.linkedin.com/in/haydenconrad/"],
    			"first_name": "Hayden",
    			"last_name": "Conrad"
    		}
    	}
    ]
}'
```

```
// See https://github.com/peopledatalabs/peopledatalabs-js
import PDLJS from 'peopledatalabs';

// Create a client, specifying your API key
const PDLJSClient = new PDLJS({ apiKey: "YOUR API KEY" });

// Create an array of parameters JSON objects
const records = {
  requests: [
    {
      // Include metadata object
      metadata: {
        user_id: "123"
      },
      params: {
        profile: ['linkedin.com/in/seanthorne'],
  			location: "SF Bay Area",
  			name: "Sean F Thorne"
      }
    },
    {
      // Include metadata object
      metadata: {
        user_id: "345"
      },
      params: {
        profile: ["https://www.linkedin.com/in/haydenconrad/"],
        first_name: "Hayden",
        last_name: "Conrad"
      }
    }
  ]
};

// Pass the parameters object to the Bulk Person Enrichment API
PDLJSClient.person.bulk(records).then((data) => {
  // Print the API response
  console.log(data);
}).catch((error) => {
  console.log(error);
});
```

```
require 'json'

# See https://github.com/peopledatalabs/peopledatalabs-ruby
require 'peopledatalabs'

# Set your API key
Peopledatalabs.api_key = 'YOUR API KEY'

# Create an array of parameters JSON objects
DATA = {
    "requests": [
    	{
    		# Include metadata object
    		"metadata": {
    			"user_id": "123"
    		},
    		"params": {
    			"profile": ["linkedin.com/in/seanthorne"],
    			"location": ["SF Bay Area"],
    			"name": ["Sean F. Thorne"]
    		}
    	},
    	{
    		# Include metadata object
    		"metadata": {
    			"user_id": "345"
    		},
    		"params": {
    			"profile": ["https://www.linkedin.com/in/haydenconrad/"],
    			"first_name": "Hayden",
    			"last_name": "Conrad"
    		}
    	}
    ]
}

# Pass the bulk parameters object to the Bulk Person Enrichment API
json_response = Peopledatalabs::Bulk.person(params: DATA)

# Print the API response
puts JSON.dump(json_response)
```

```
package main

import (
    "fmt"
    "encoding/json"
    "context"
)

// See https://github.com/peopledatalabs/peopledatalabs-go
import (
    pdl "github.com/peopledatalabs/peopledatalabs-go"
    pdlmodel "github.com/peopledatalabs/peopledatalabs-go/model"
)

func main() {
    // Set your API key
    apiKey := "YOUR API KEY"
    // Set API key as environmental variable
    // apiKey := os.Getenv("API_KEY")

    // Create a client, specifying your API key
    client := pdl.New(apiKey)
    
    // Create an array of parameters JSON objects
    params := pdlmodel.BulkEnrichPersonParams {
        Requests: []pdlmodel.BulkEnrichSinglePersonParams {
            {
                // Include metadata object
                Metadata: map[string]string {
                    "user_id": "123",
                },
                Params: pdlmodel.PersonParams {
                    Profile:  []string{"linkedin.com/in/seanthorne"},
                    Location:  []string{"SF Bay Area"},
                    Name:  []string{"Sean F. Thorne"},
                },
            },
            {
                // Include metadata object
                Metadata: map[string]string {
                    "user_id": "345",
                },
                Params: pdlmodel.PersonParams {
                    Profile:  []string{"https://www.linkedin.com/in/haydenconrad/"},
                    FirstName:  []string{"Hayden"},
                    LastName:  []string{"Conrad"},
                },
           },
        },
    }

    // Pass the parameters object to the Bulk Person Enrichment API
    response, err := client.Person.BulkEnrich(context.Background(), params)
    
    // Check for successful response
    if err == nil {
        // Convert the API response to JSON
        data, jsonErr := json.Marshal(response)
        // Print the API response
        if (jsonErr == nil) {
            fmt.Println(string(data))
        }
    }
 }
```

```
import requests
import json

# Pass your API key in header
HEADERS = {
    'Content-Type': 'application/json',
  	'X-api-key': 'YOUR API KEY'
}

# Create an array of parameters JSON objects
DATA = {
    "requests": [
    	{
    		# Include metadata object
    		"metadata": {
    			"user_id": "123"
    		},
    		"params": {
    			"profile": ["linkedin.com/in/seanthorne"],
    			"location": ["SF Bay Area"],
    			"name": ["Sean F. Thorne"]
    		}
    	},
    	{
    		# Include metadata object
    		"metadata": {
    			"user_id": "345"
    		},
    		"params": {
    			"profile": ["https://www.linkedin.com/in/haydenconrad/"],
    			"first_name": "Hayden",
    			"last_name": "Conrad"
    		}
    	}
    ]
}

# Pass the bulk parameters object to the Bulk Person Enrichment API
json_response = requests.post(
  'https://api.peopledatalabs.com/v5/person/bulk',
  headers=HEADERS,
  json=DATA
).json()

# Print the API response
print(json.dumps(json_response))
```

JSON

```
[
	{"metadata": {"user_id": "123"}, "status": 200, "likelihood": 10, "data": ...},
	{"metadata": {"user_id": "345"}, "status": 200, "likelihood": 10, "data": ...}
]
```

## Global Filtering and Formatting

You can define any of the response filtering or formatting parameters documented in the [Input Parameters - Person Enrichment API](/docs/input-parameters-person-enrichment-api) page globally for all request objects.

Any response filtering and formatting parameters that you define within in an individual `params` object will override those defined in the global request body.

Python3 SDKcURLJavaScriptRubyGoPython3

```
import json

# See https://github.com/peopledatalabs/peopledatalabs-python
from peopledatalabs import PDLPY

# Create a client, specifying your API key
CLIENT = PDLPY(
    api_key="YOUR API KEY",
)

# Create an array of parameters JSON objects
DATA = {
	# Set global filter
	"required": "emails AND profiles",
	"requests": [
		{
			"params": {
				"profile": ["linkedin.com/in/seanthorne"],
				"location": ["SF Bay Area"],
				"name": ["Sean F. Thorne"]
			}
		},
		{
			"params": {
				"profile": ["https://www.linkedin.com/in/haydenconrad/"],
				"first_name": "Hayden",
				"last_name": "Conrad"
			}
		}
	]
}

# Pass the bulk parameters object to the Bulk Person Enrichment API
json_response = CLIENT.person.bulk(**DATA).json()

# Print the API response
print(json.dumps(json_response))
```

```
curl -X POST "https://api.peopledatalabs.com/v5/person/bulk" \
-H 'Content-Type: application/json' \
-H 'X-Api-Key: XXX' \
-d ' {
	"required": "emails AND profiles",
	"requests": [
    	{
    		"params": {
    			"profile": ["linkedin.com/in/seanthorne"],
    			"location": ["SF Bay Area"],
    			"name": ["Sean F. Thorne"]
    		}
    	},
    	{
    		"params": {
    			"profile": ["https://www.linkedin.com/in/haydenconrad/"],
    			"first_name": "Hayden",
    			"last_name": "Conrad"
    		}
    	}
    ]
}'
```

```
// See https://github.com/peopledatalabs/peopledatalabs-js
import PDLJS from 'peopledatalabs';

// Create a client, specifying your API key
const PDLJSClient = new PDLJS({ apiKey: "YOUR API KEY" });

// Create an array of parameters JSON objects
const records = {
  // Set global filter
  required: "emails AND profiles",
  requests: [
    {
      params: {
        profile: ['linkedin.com/in/seanthorne'],
  			location: "SF Bay Area",
  			name: "Sean F Thorne"
      }
    },
    {
      params: {
        profile: ["https://www.linkedin.com/in/haydenconrad/"],
        first_name: "Hayden",
        last_name: "Conrad"
      }
    }
  ]
};

// Pass the parameters object to the Bulk Person Enrichment API
PDLJSClient.person.bulk(records).then((data) => {
  // Print the API response
  console.log(data);
}).catch((error) => {
  console.log(error);
});
```

```
require 'json'

# See https://github.com/peopledatalabs/peopledatalabs-ruby
require 'peopledatalabs'

# Set your API key
Peopledatalabs.api_key = 'YOUR API KEY'

# Create an array of parameters JSON objects
DATA = {
	# Set global filter
	"required": "emails AND profiles",
	"requests": [
		{
			"params": {
				"profile": ["linkedin.com/in/seanthorne"],
				"location": ["SF Bay Area"],
				"name": ["Sean F. Thorne"]
			}
		},
		{
			"params": {
				"profile": ["https://www.linkedin.com/in/haydenconrad/"],
				"first_name": "Hayden",
				"last_name": "Conrad"
			}
		}
	]
}

# Pass the bulk parameters object to the Bulk Person Enrichment API
json_response = Peopledatalabs::Bulk.person(params: DATA)

# Print the API response
puts JSON.dump(json_response)
```

```
package main

import (
    "fmt"
    "encoding/json"
    "context"
)

// See https://github.com/peopledatalabs/peopledatalabs-go
import (
    pdl "github.com/peopledatalabs/peopledatalabs-go"
    pdlmodel "github.com/peopledatalabs/peopledatalabs-go/model"
)

func main() {
    // Set your API key
    apiKey := "YOUR API KEY"
    // Set API key as environmental variable
    // apiKey := os.Getenv("API_KEY")

    // Create a client, specifying your API key
    client := pdl.New(apiKey)
    
    // Create an array of parameters JSON objects
    params := pdlmodel.BulkEnrichPersonParams {
        // Set global filter
        Required: "emails AND profiles",
        Requests: []pdlmodel.BulkEnrichSinglePersonParams {
            {
                Params: pdlmodel.PersonParams {
                    Profile:  []string{"linkedin.com/in/seanthorne"},
                    Location:  []string{"SF Bay Area"},
                    Name:  []string{"Sean F. Thorne"},
                },
            },
            {
                 Params: pdlmodel.PersonParams {
                    Profile:  []string{"https://www.linkedin.com/in/haydenconrad/"},
                    FirstName:  []string{"Hayden"},
                    LastName:  []string{"Conrad"},
                },
           },
        },
    }

    // Pass the parameters object to the Bulk Person Enrichment API
    response, err := client.Person.BulkEnrich(context.Background(), params)
    
    // Check for successful response
    if err == nil {
        // Convert the API response to JSON
        data, jsonErr := json.Marshal(response)
        // Print the API response
        if (jsonErr == nil) {
            fmt.Println(string(data))
        }
    }
 }
```

```
import requests
import json

# Pass your API key in header
HEADERS = {
	'Content-Type': 'application/json',
	'X-api-key': 'YOUR API KEY'
}

# Create an array of parameters JSON objects
DATA = {
	# Set global filter
	"required": "emails AND profiles",
	"requests": [
		{
			"params": {
				"profile": ["linkedin.com/in/seanthorne"],
				"location": ["SF Bay Area"],
				"name": ["Sean F. Thorne"]
			}
		},
		{
			"params": {
				"profile": ["https://www.linkedin.com/in/haydenconrad/"],
				"first_name": "Hayden",
				"last_name": "Conrad"
			}
		}
	]
}

# Pass the bulk parameters object to the Bulk Person Enrichment API
json_response = requests.post(
  'https://api.peopledatalabs.com/v5/person/bulk',
  headers=HEADERS,
  json=DATA
).json()

# Print the API response
print(json.dumps(json_response))
```

## Malformed, Unauthenticated, or Throttled Requests

Any malformed, unauthenticated, or throttled requests will return errors in the same format as documented in the [Errors](/docs/errors) page.

Python3 SDKcURLJavaScriptRubyGoPython3

```
import json

# See https://github.com/peopledatalabs/peopledatalabs-python
from peopledatalabs import PDLPY

# Create a client, specifying your API key
CLIENT = PDLPY(
    api_key="YOUR API KEY",
)

# Create a parameters JSON object without a requests array
DATA = {"required": "names"}

# Catch exception when passing the parameters object to the Bulk Person Enrichment API
try:
    json_response = CLIENT.person.bulk(**DATA).json()
except Exception as err:
    print(err);
```

```
curl -X POST "https://api.peopledatalabs.com/v5/person/bulk" \
-H 'Content-Type: application/json' \
-H 'X-Api-Key: XXX' \
-d ' {
	"required": "names"
}'
```

```
// See https://github.com/peopledatalabs/peopledatalabs-js
import PDLJS from 'peopledatalabs';

// Create a client, specifying your API key
const PDLJSClient = new PDLJS({ apiKey: "YOUR API KEY" });

// Create a parameters JSON object without a requests array
const records = {
  required: "names"
};

// Catch exception when passing the parameters object to the Bulk Person Enrichment API
PDLJSClient.person.bulk(records).then((data) => {
  console.log(data);
}).catch((error) => {
  console.log(error);
});
```

```
require 'json'

# See https://github.com/peopledatalabs/peopledatalabs-ruby
require 'peopledatalabs'

# Set your API key
Peopledatalabs.api_key = 'YOUR API KEY'

# Create a parameters JSON object without a requests array
DATA = {"required": "names"}

# Pass the parameters object to the Bulk Person Enrichment API
json_response = Peopledatalabs::Bulk.person(params: DATA)

# Check for error
if json_response['status'] != 200
    puts json_response['error']['message']
end
```

```
package main

import (
    "fmt"
    "encoding/json"
    "context"
)

// See https://github.com/peopledatalabs/peopledatalabs-go
import (
    pdl "github.com/peopledatalabs/peopledatalabs-go"
    pdlmodel "github.com/peopledatalabs/peopledatalabs-go/model"
)

func main() {
    // Set your API key
    apiKey := "YOUR API KEY"
    // Set API key as environmental variable
    // apiKey := os.Getenv("API_KEY")

    // Create a client, specifying your API key
    client := pdl.New(apiKey)
    
    // Create a parameters JSON object without a requests array
    data := pdlmodel.BulkEnrichPersonParams {
        Required: "names",
    }

    // Pass the parameters object to the Bulk Person Enrichment API
    response, err := client.Person.BulkEnrich(context.Background(), data)
    
    // Check for error
    if err == nil {
        fmt.Println(response)
    } else {
        message, jsonErr := json.Marshal(err)
        if jsonErr == nil {
            fmt.Println(string(message))
        }
    }
 }
```

```
import requests
import json

# Pass your API key in header
HEADERS = {
    'Content-Type': 'application/json',
  	'X-api-key': 'YOUR API KEY'
}

# Create a parameters JSON object without a requests array
DATA = {"required": "names"}

# Pass the parameters object to the Bulk Person Enrichment API
response = requests.post(
    'https://api.peopledatalabs.com/v5/person/bulk',
  	headers=HEADERS,
  	json=DATA
)

# Print error
print(response.text)
```

JSON

```
{
    "status": 400,
    "error": {
        "type": "invalid_request_error",
        "message": "Request object must contain `requests` field"
    }
}
```

Updated 4 months ago

---

Did this page help you?

Yes

No

---
# https://docs.peopledatalabs.com/docs/email-types

| Canonical Values for Email Types |
| --- |
| current\_professional |
| disposable |
| personal |
| professional |

*Contents of this table were sourced from the following file on our public S3 bucket:[emails.type.txt](https://pdl-prod-schema.s3.us-west-2.amazonaws.com/28.0/enums/emails.type.txt)*

## Relevant fields

* [`emails.type`](/docs/fields#possible_emails)
* [`possible_emails.type`](/docs/fields#possible_emails)

Updated 4 months ago

---

Did this page help you?

Yes

No

---
# https://docs.peopledatalabs.com/docs/data-types

The Schema pages contain every available field for each dataset. Each field has a listed type. This page includes additional details about the supported data types if they differ from the industry standard definition.

# Array [Enum (String)]

A comma separated list of enumerated values. You can find the enumerated values here: [Canonical Field Values](/docs/canonical-data).

# Array [Object]

A comma separated list of objects. Our [`naics`](/docs/company-schema#naics) field demonstrates this concept.

# Dates

Dates can be accurate to the day (`YYYY-MM-DD`), the month (`YYYY-MM`) or the year (`YYYY`). The most specific date value that we have for a field will be used. In general, dates are stored as `String` values. The `founded` field in the [Company Schema](/docs/company-schema) is stored as an `Integer` data type and describes the year the company was founded.

# Enum (String)

A string that contains one of our enumerated values. You can find the enumerated values here: [Canonical Field Values](/docs/canonical-data).

# Integer (>=0) or (1-5) or (>0)

Our integers are general positive values and some fields, like [`languages.proficiency`](/docs/fields#languages), have a limited range of observed values.

# Object

Fields with this data type contain nested data values. Our [`experience`](/docs/fields#experience) and [`education`](/docs/fields#education) fields demonstrate this concept.

# Strings

Unless otherwise stated in the Schema page for a field, all strings will be lowercase with all leading or trailing whitespace removed.

Updated 4 months ago

---

Did this page help you?

Yes

No

---
# https://docs.peopledatalabs.com/docs/examples-person-enrichment-api

# Examples

When specifying query parameters within a URL, you should separate them with an ampersand (`&`). When specifying query parameters within a JSON object, you should use lists for the request parameters.

We've provided code samples in cURL, Python, Ruby, Go and JavaScript. If you aren't comfortable working in any of these languages, feel free to use this [handy tool](https://curl.trillworks.com/) to convert code from cURL to the language of your choice.

> ðŸ’¡
>
> ### We want your feedback!
>
> Do you see a bug? Is there an example you'd like to see that's not listed here?
>
> Head over to the public roadmap and submit a [bug ticket](https://peopledatalabs.canny.io/bugs) or a [feature request](https://peopledatalabs.canny.io/feature-requests) and receive automatic notifications as your bug is resolved or your request is implemented.

The following examples match a field (or a set of fields) to a person record:

## LinkedIn URL

Python3 SDKcURLJavaScriptRubyGoPython3

```
import json

# See https://github.com/peopledatalabs/peopledatalabs-python
from peopledatalabs import PDLPY

# Create a client, specifying your API key
CLIENT = PDLPY(
    api_key="YOUR API KEY",
)

# Create a parameters JSON object
PARAMS = {
    "profile": ["http://linkedin.com/in/seanthorne"],
  	"min_likelihood": 6
}

# Pass the parameters object to the Person Enrichment API
json_response = CLIENT.person.enrichment(**PARAMS).json()

# Check for successful response
if json_response["status"] == 200:
  record = json_response['data']

  # Print selected fields
  print(
    record['work_email'],
    record['full_name'],
    record['job_title'],
    record['job_company_name']
  )

  print(f"Successfully enriched profile with PDL data.")

  # Save enrichment data to JSON file
  with open("my_pdl_enrichment.jsonl", "w") as out:
    out.write(json.dumps(record) + "\n")
else:
  print("Enrichment unsuccessful. See error and try again.")
  print("error:", json_response)
```

```
curl -X GET -G \
  'https://api.peopledatalabs.com/v5/person/enrich'\
  -H 'X-Api-Key: xxxx' \
  --data-urlencode 'min_likelihood=6'\
 	--data-urlencode 'profile=http://linkedin.com/in/seanthorne'
```

```
// See https://github.com/peopledatalabs/peopledatalabs-js
import PDLJS from 'peopledatalabs';

import fs from 'fs';

// Create a client, specifying your API key
const PDLJSClient = new PDLJS({ apiKey: "YOUR API KEY" });

// Create a parameters JSON object
const params = {
  profile: "http://linkedin.com/in/seanthorne",
  min_likelihood: 6
}

// Pass the parameters object to the Person Enrichment API
PDLJSClient.person.enrichment(params).then((data) => {
    var record = data.data
    
    // Print selected fields
    console.log(
        record["work_email"],
        record["full_name"],
        record["job_title"],
        record["job_company_name"],
        )
        
    console.log("Successfully enriched profile with PDL data.")
    
    // Save enrichment data to JSON file
    fs.writeFile("my_pdl_enrichment.jsonl", Buffer.from(JSON.stringify(record)), (err) => {
        if (err) throw err;
    });
}).catch((error) => {
    console.log("Enrichment unsuccessful. See error and try again.")
    console.log(error);
});
```

```
require 'json'

# See https://github.com/peopledatalabs/peopledatalabs-ruby
require 'peopledatalabs'

# Set your API key
Peopledatalabs.api_key = 'YOUR API KEY'

# Create a parameters JSON object
PARAMS = {
    "profile": ["http://linkedin.com/in/seanthorne"],
  	"min_likelihood": 6
}

# Pass the parameters object to the Person Enrichment API
json_response = Peopledatalabs::Enrichment.person(params: PARAMS)

# Check for successful response
if json_response['status'] == 200
    record = json_response['data']
    
    # Print selected fields
    puts \
        "#{record['work_email']} \
         #{record['full_name']} \
         #{record['job_title']} \
         #{record['job_company_name']}"
    
    puts "Successfully enriched profile with PDL data."
    
    # Save enrichment data to JSON file
    File.open("my_pdl_enrichment.jsonl", "w") do |out|
        out.write(JSON.dump(record) + "\n")
    end
else
    puts "Enrichment unsuccessful. See error and try again."
    puts "error: #{json_response}"
end
```

```
package main

import (
    "fmt"
    "os"
    "encoding/json"
    "context"
)

// See https://github.com/peopledatalabs/peopledatalabs-go
import (
    pdl "github.com/peopledatalabs/peopledatalabs-go"
    pdlmodel "github.com/peopledatalabs/peopledatalabs-go/model"
)

func main() {
    // Set your API key
    apiKey := "YOUR API KEY"
    // Set API key as environmental variable
    // apiKey := os.Getenv("API_KEY")

    // Create a client, specifying your API key
    client := pdl.New(apiKey)
    
    // Create a parameters JSON object
    params := pdlmodel.EnrichPersonParams {
        PersonParams: pdlmodel.PersonParams {
            Profile: []string{"linkedin.com/in/seanthorne"},
        },
        AdditionalParams: pdlmodel.AdditionalParams {
            MinLikelihood: 6,
        },
    }

    // Pass the parameters object to the Person Enrichment API
    response, err := client.Person.Enrich(context.Background(), params)
    
    // Check for successful response
    if err == nil {
        // Convert the API response to JSON
        jsonResponse, jsonErr := json.Marshal(response.Data)
        if jsonErr == nil {
            var record map[string]interface{}
            json.Unmarshal(jsonResponse, &record)
            // Print selected fields
            fmt.Println(
                       record["work_email"], 
                       record["full_name"], 
                       record["job_title"], 
                       record["job_company_name"])
        
            fmt.Println("Successfully enriched profile with PDL data.")
        
            // Save enrichment data to JSON file
            out, outErr := os.Create("my_pdl_enrichment.jsonl")
            defer out.Close()
            if outErr == nil {
                out.WriteString(string(jsonResponse) + "\n")
            }
            out.Sync()
        }
   	} else {
        fmt.Println("Enrichment unsuccessful. See error and try again.")
        fmt.Println("error:", err)
    }
}
```

```
import requests, json

# Set your API key
API_KEY = "YOUR API KEY"

# Set the Person Enrichment API URL
PDL_URL = "https://api.peopledatalabs.com/v5/person/enrich"

# Create a parameters JSON object
PARAMS = {
    "api_key": API_KEY,
    "profile": ["http://linkedin.com/in/seanthorne"],
  	"min_likelihood": 6
}

# Pass the parameters object to the Person Enrichment API
json_response = requests.get(PDL_URL, params=PARAMS).json()

# Check for successful response
if json_response["status"] == 200:
  record = json_response['data']

  # Print selected fields
  print(
    record['work_email'],
    record['full_name'],
    record['job_title'],
    record['job_company_name']
  )

  print(f"Successfully enriched profile with PDL data.")

  # Save enrichment data to JSON file
  with open("my_pdl_enrichment.jsonl", "w") as out:
    out.write(json.dumps(record) + "\n")
else:
  print("Enrichment unsuccessful. See error and try again.")
  print("error:", json_response)
```

## Email

Python3 SDKcURLJavaScriptRubyGoPython3

```
import json

# See https://github.com/peopledatalabs/peopledatalabs-python
from peopledatalabs import PDLPY

# Create a client, specifying your API key
CLIENT = PDLPY(
    api_key="YOUR API KEY",
)

# Create a parameters JSON object
PARAMS = {
    "email": ["sean@peopledatalabs.com"] 
}

# Pass the parameters object to the Person Enrichment API
json_response = CLIENT.person.enrichment(**PARAMS).json()

# Check for successful response
if json_response["status"] == 200:
  record = json_response['data']

  # Print selected fields
  print(
    record['work_email'],
    record['full_name'],
    record['job_title'],
    record['job_company_name']
  )

  print(f"Successfully enriched profile with PDL data.")

  # Save enrichment data to JSON file
  with open("my_pdl_enrichment.jsonl", "w") as out:
    out.write(json.dumps(record) + "\n")
else:
  print("Enrichment unsuccessful. See error and try again.")
  print("error:", json_response)
```

```
curl -X GET -G \
  'https://api.peopledatalabs.com/v5/person/enrich' \
  -H 'X-Api-Key: xxxx' \
  --data-urlencode 'email=sean@peopledatalabs.com'
```

```
// See https://github.com/peopledatalabs/peopledatalabs-js
import PDLJS from 'peopledatalabs';

import fs from 'fs';

// Create a client, specifying your API key
const PDLJSClient = new PDLJS({ apiKey: "YOUR API KEY" });

// Create a parameters JSON object
const params = {
  email: "sean@peopledatalabs.com"
}

// Pass the parameters object to the Person Enrichment API
PDLJSClient.person.enrichment(params).then((data) => {
    var record = data.data
    
    // Print selected fields
    console.log(
        record["work_email"],
        record["full_name"],
        record["job_title"],
        record["job_company_name"],
        )
        
    console.log("Successfully enriched profile with PDL data.")
    
    // Save enrichment data to JSON file
    fs.writeFile("my_pdl_enrichment.jsonl", Buffer.from(JSON.stringify(record)), (err) => {
        if (err) throw err;
    });
}).catch((error) => {
    console.log("Enrichment unsuccessful. See error and try again.")
    console.log(error);
});
```

```
require 'json'

# See https://github.com/peopledatalabs/peopledatalabs-ruby
require 'peopledatalabs'

# Set your API key
Peopledatalabs.api_key = 'YOUR API KEY'

# Create a parameters JSON object
PARAMS = {
    "email": ["sean@peopledatalabs.com"] 
}

# Pass the parameters object to the Person Enrichment API
json_response = Peopledatalabs::Enrichment.person(params: PARAMS)

# Check for successful response
if json_response['status'] == 200
    record = json_response['data']
    
    # Print selected fields
    puts \
        "#{record['work_email']} \
         #{record['full_name']} \
         #{record['job_title']} \
         #{record['job_company_name']}"
    
    puts "Successfully enriched profile with PDL data."
    
    # Save enrichment data to JSON file
    File.open("my_pdl_enrichment.jsonl", "w") do |out|
        out.write(JSON.dump(record) + "\n")
    end
else
    puts "Enrichment unsuccessful. See error and try again."
    puts "error: #{json_response}"
end
```

```
package main

import (
    "fmt"
    "os"
    "encoding/json"
    "context"
)

// See https://github.com/peopledatalabs/peopledatalabs-go
import (
    pdl "github.com/peopledatalabs/peopledatalabs-go"
    pdlmodel "github.com/peopledatalabs/peopledatalabs-go/model"
)

func main() {
    // Set your API key
    apiKey := "YOUR API KEY"
    // Set API key as environmental variable
    // apiKey := os.Getenv("API_KEY")

    // Create a client, specifying your API key
    client := pdl.New(apiKey)
    
    // Create a parameters JSON object
    params := pdlmodel.EnrichPersonParams {
        PersonParams: pdlmodel.PersonParams {
            Email: []string{"sean@peopledatalabs.com"},
        },
    }

    // Pass the parameters object to the Person Enrichment API
    response, err := client.Person.Enrich(context.Background(), params)
    
    // Check for successful response
    if err == nil {
        // Convert the API response to JSON
        jsonResponse, jsonErr := json.Marshal(response.Data)
        if jsonErr == nil {
            var record map[string]interface{}
            json.Unmarshal(jsonResponse, &record)
            // Print selected fields
            fmt.Println(
                       record["work_email"], 
                       record["full_name"], 
                       record["job_title"], 
                       record["job_company_name"])
        
            fmt.Println("Successfully enriched profile with PDL data.")
        
            // Save enrichment data to JSON file
            out, outErr := os.Create("my_pdl_enrichment.jsonl")
            defer out.Close()
            if outErr == nil {
                out.WriteString(string(jsonResponse) + "\n")
            }
            out.Sync()
        }
   	} else {
        fmt.Println("Enrichment unsuccessful. See error and try again.")
        fmt.Println("error:", err)
    }
}
```

```
import requests, json

# Set your API key
API_KEY = "YOUR API KEY"

# Set the Person Enrichment API URL
PDL_URL = "https://api.peopledatalabs.com/v5/person/enrich"

# Create a parameters JSON object
PARAMS = {
    "api_key": API_KEY,
    "email": ["sean@peopledatalabs.com"]   
}

# Pass the parameters object to the Person Enrichment API
json_response = requests.get(PDL_URL, params=PARAMS).json()

# Check for successful response
if json_response["status"] == 200:
  record = json_response['data']

  # Print selected fields
  print(
    record['work_email'],
    record['full_name'],
    record['job_title'],
    record['job_company_name']
  )

  print(f"Successfully enriched profile with PDL data.")

  # Save enrichment data to JSON file
  with open("my_pdl_enrichment.jsonl", "w") as out:
    out.write(json.dumps(record) + "\n")
else:
  print("Enrichment unsuccessful. See error and try again.")
  print("error:", json_response)
```

## Email Hash

**Note**: you can use MD5 or SHA-256 hashes.

Python3 SDKcURLJavaScriptRubyGoPython3

```
import json

# See https://github.com/peopledatalabs/peopledatalabs-python
from peopledatalabs import PDLPY

# Create a client, specifying your API key
CLIENT = PDLPY(
    api_key="YOUR API KEY",
)

# Create a parameters JSON object
PARAMS = {
    "email_hash": ["e206e6cd7fa5f9499fd6d2d943dcf7d9c1469bad351061483f5ce7181663b8d4"]
}

# Pass the parameters object to the Person Enrichment API
json_response = CLIENT.person.enrichment(**PARAMS).json()

# Check for successful response
if json_response["status"] == 200:
  record = json_response['data']

  # Print selected fields
  print(
    record['work_email'],
    record['full_name'],
    record['job_title'],
    record['job_company_name']
  )

  print(f"Successfully enriched profile with PDL data.")

  # Save enrichment data to JSON file
  with open("my_pdl_enrichment.jsonl", "w") as out:
    out.write(json.dumps(record) + "\n")
else:
  print("Enrichment unsuccessful. See error and try again.")
  print("error:", json_response)
```

```
curl -X GET -G \
  'https://api.peopledatalabs.com/v5/person/enrich' \
  -H 'X-Api-Key: xxxx' \
  --data-urlencode 'email_hash=e206e6cd7fa5f9499fd6d2d943dcf7d9c1469bad351061483f5ce7181663b8d4'
```

```
// See https://github.com/peopledatalabs/peopledatalabs-js
import PDLJS from 'peopledatalabs';

import fs from 'fs';

// Create a client, specifying your API key
const PDLJSClient = new PDLJS({ apiKey: "YOUR API KEY" });

// Create a parameters JSON object
const params = {
  email_hash: "e206e6cd7fa5f9499fd6d2d943dcf7d9c1469bad351061483f5ce7181663b8d4"
}

// Pass the parameters object to the Person Enrichment API
PDLJSClient.person.enrichment(params).then((data) => {
    var record = data.data
    
    // Print selected fields
    console.log(
        record["work_email"],
        record["full_name"],
        record["job_title"],
        record["job_company_name"],
        )
        
    console.log("Successfully enriched profile with PDL data.")
    
    // Save enrichment data to JSON file
    fs.writeFile("my_pdl_enrichment.jsonl", Buffer.from(JSON.stringify(record)), (err) => {
        if (err) throw err;
    });
}).catch((error) => {
    console.log("Enrichment unsuccessful. See error and try again.")
    console.log(error);
});
```

```
require 'json'

# See https://github.com/peopledatalabs/peopledatalabs-ruby
require 'peopledatalabs'

# Set your API key
Peopledatalabs.api_key = 'YOUR API KEY'

# Create a parameters JSON object
PARAMS = {
    "email_hash": ["e206e6cd7fa5f9499fd6d2d943dcf7d9c1469bad351061483f5ce7181663b8d4"]
}

# Pass the parameters object to the Person Enrichment API
json_response = Peopledatalabs::Enrichment.person(params: PARAMS)

# Check for successful response
if json_response['status'] == 200
    record = json_response['data']
    
    # Print selected fields
    puts \
        "#{record['work_email']} \
         #{record['full_name']} \
         #{record['job_title']} \
         #{record['job_company_name']}"
    
    puts "Successfully enriched profile with PDL data."
    
    # Save enrichment data to JSON file
    File.open("my_pdl_enrichment.jsonl", "w") do |out|
        out.write(JSON.dump(record) + "\n")
    end
else
    puts "Enrichment unsuccessful. See error and try again."
    puts "error: #{json_response}"
end
```

```
package main

import (
    "fmt"
    "os"
    "encoding/json"
    "context"
)

// See https://github.com/peopledatalabs/peopledatalabs-go
import (
    pdl "github.com/peopledatalabs/peopledatalabs-go"
    pdlmodel "github.com/peopledatalabs/peopledatalabs-go/model"
)

func main() {
    // Set your API key
    apiKey := "YOUR API KEY"
    // Set API key as environmental variable
    // apiKey := os.Getenv("API_KEY")

    // Create a client, specifying your API key
    client := pdl.New(apiKey)
    
    // Create a parameters JSON object
    params := pdlmodel.EnrichPersonParams {
        PersonParams: pdlmodel.PersonParams {
            EmailHash: []string{"e206e6cd7fa5f9499fd6d2d943dcf7d9c1469bad351061483f5ce7181663b8d4"},
        },
    }

    // Pass the parameters object to the Person Enrichment API
    response, err := client.Person.Enrich(context.Background(), params)
    
    // Check for successful response
    if err == nil {
        // Convert the API response to JSON
        jsonResponse, jsonErr := json.Marshal(response.Data)
        if jsonErr == nil {
            var record map[string]interface{}
            json.Unmarshal(jsonResponse, &record)
            // Print selected fields
            fmt.Println(
                       record["work_email"], 
                       record["full_name"], 
                       record["job_title"], 
                       record["job_company_name"])
        
            fmt.Println("Successfully enriched profile with PDL data.")
        
            // Save enrichment data to JSON file
            out, outErr := os.Create("my_pdl_enrichment.jsonl")
            defer out.Close()
            if outErr == nil {
                out.WriteString(string(jsonResponse) + "\n")
            }
            out.Sync()
        }
   	} else {
        fmt.Println("Enrichment unsuccessful. See error and try again.")
        fmt.Println("error:", err)
    }
}
```

```
import requests, json

# Set your API key
API_KEY = "YOUR API KEY"

# Set the Person Enrichment API URL
PDL_URL = "https://api.peopledatalabs.com/v5/person/enrich"

# Create a parameters JSON object
PARAMS = {
    "api_key": API_KEY,
    "email_hash": ["e206e6cd7fa5f9499fd6d2d943dcf7d9c1469bad351061483f5ce7181663b8d4"]   
}

# Pass the parameters object to the Person Enrichment API
json_response = requests.get(PDL_URL, params=PARAMS).json()

# Check for successful response
if json_response["status"] == 200:
  record = json_response['data']

  # Print selected fields
  print(
    record['work_email'],
    record['full_name'],
    record['job_title'],
    record['job_company_name']
  )

  print(f"Successfully enriched profile with PDL data.")

  # Save enrichment data to JSON file
  with open("my_pdl_enrichment.jsonl", "w") as out:
    out.write(json.dumps(record) + "\n")
else:
  print("Enrichment unsuccessful. See error and try again.")
  print("error:", json_response)
```

## Email and Company

Python3 SDKcURLJavaScriptRubyGoPython3

```
import json

# See https://github.com/peopledatalabs/peopledatalabs-python
from peopledatalabs import PDLPY

# Create a client, specifying your API key
CLIENT = PDLPY(
    api_key="YOUR API KEY",
)

# Create a parameters JSON object
PARAMS = {
    "company": ["Hallspot", "People Data Labs"],
  	"email": ["sean.thorne@talentiq.co"]
}

# Pass the parameters object to the Person Enrichment API
json_response = CLIENT.person.enrichment(**PARAMS).json()

# Check for successful response
if json_response["status"] == 200:
  record = json_response['data']

  # Print selected fields
  print(
    record['work_email'],
    record['full_name'],
    record['job_title'],
    record['job_company_name']
  )

  print(f"Successfully enriched profile with PDL data.")

  # Save enrichment data to JSON file
  with open("my_pdl_enrichment.jsonl", "w") as out:
    out.write(json.dumps(record) + "\n")
else:
  print("Enrichment unsuccessful. See error and try again.")
  print("error:", json_response)
```

```
curl -X GET -G \
  'https://api.peopledatalabs.com/v5/person/enrich'\
  -H 'X-Api-Key: xxxx' \
  --data-urlencode 'company=People Data Labs'\
 	--data-urlencode 'company=Hallspot'\
  --data-urlencode 'email=sean.thorne@talentiq.co'
```

```
// See https://github.com/peopledatalabs/peopledatalabs-js
import PDLJS from 'peopledatalabs';

import fs from 'fs';

// Create a client, specifying your API key
const PDLJSClient = new PDLJS({ apiKey: "YOUR API KEY" });

// Create a parameters JSON object
const params = {
  company: "Hallspot",
  company: "People Data Labs",
  email: "sean.thorne@talentiq.co"
}

// Pass the parameters object to the Person Enrichment API
PDLJSClient.person.enrichment(params).then((data) => {
    var record = data.data
    
    // Print selected fields
    console.log(
        record["work_email"],
        record["full_name"],
        record["job_title"],
        record["job_company_name"],
        )
        
    console.log("Successfully enriched profile with PDL data.")
    
    // Save enrichment data to JSON file
    fs.writeFile("my_pdl_enrichment.jsonl", Buffer.from(JSON.stringify(record)), (err) => {
        if (err) throw err;
    });
}).catch((error) => {
    console.log("Enrichment unsuccessful. See error and try again.")
    console.log(error);
});
```

```
require 'json'

# See https://github.com/peopledatalabs/peopledatalabs-ruby
require 'peopledatalabs'

# Set your API key
Peopledatalabs.api_key = 'YOUR API KEY'

# Create a parameters JSON object
PARAMS = {
    "company": ["Hallspot", "People Data Labs"],
  	"email": ["sean.thorne@talentiq.co"]
}

# Pass the parameters object to the Person Enrichment API
json_response = Peopledatalabs::Enrichment.person(params: PARAMS)

# Check for successful response
if json_response['status'] == 200
    record = json_response['data']
    
    # Print selected fields
    puts \
        "#{record['work_email']} \
         #{record['full_name']} \
         #{record['job_title']} \
         #{record['job_company_name']}"
    
    puts "Successfully enriched profile with PDL data."
    
    # Save enrichment data to JSON file
    File.open("my_pdl_enrichment.jsonl", "w") do |out|
        out.write(JSON.dump(record) + "\n")
    end
else
    puts "Enrichment unsuccessful. See error and try again."
    puts "error: #{json_response}"
end
```

```
package main

import (
    "fmt"
    "os"
    "encoding/json"
    "context"
)

// See https://github.com/peopledatalabs/peopledatalabs-go
import (
    pdl "github.com/peopledatalabs/peopledatalabs-go"
    pdlmodel "github.com/peopledatalabs/peopledatalabs-go/model"
)

func main() {
    // Set your API key
    apiKey := "YOUR API KEY"
    // Set API key as environmental variable
    // apiKey := os.Getenv("API_KEY")

    // Create a client, specifying your API key
    client := pdl.New(apiKey)
    
    // Create a parameters JSON object
    params := pdlmodel.EnrichPersonParams {
        PersonParams: pdlmodel.PersonParams {
            Company: []string{"Hallspot", "People Data Labs"},
            Email: []string{"sean.thorne@talentiq.co"},
        },
    }

    // Pass the parameters object to the Person Enrichment API
    response, err := client.Person.Enrich(context.Background(), params)
    
    // Check for successful response
    if err == nil {
        // Convert the API response to JSON
        jsonResponse, jsonErr := json.Marshal(response.Data)
        if jsonErr == nil {
            var record map[string]interface{}
            json.Unmarshal(jsonResponse, &record)
            // Print selected fields
            fmt.Println(
                       record["work_email"], 
                       record["full_name"], 
                       record["job_title"], 
                       record["job_company_name"])
        
            fmt.Println("Successfully enriched profile with PDL data.")
        
            // Save enrichment data to JSON file
            out, outErr := os.Create("my_pdl_enrichment.jsonl")
            defer out.Close()
            if outErr == nil {
                out.WriteString(string(jsonResponse) + "\n")
            }
            out.Sync()
        }
   	} else {
        fmt.Println("Enrichment unsuccessful. See error and try again.")
        fmt.Println("error:", err)
    }
}
```

```
import requests, json

# Set your API key
API_KEY = "YOUR API KEY"

# Set the Person Enrichment API URL
PDL_URL = "https://api.peopledatalabs.com/v5/person/enrich"

# Create a parameters JSON object
PARAMS = {
    "api_key": API_KEY,
    "company": ["Hallspot", "People Data Labs"],
  	"email": ["sean.thorne@talentiq.co"]
}

# Pass the parameters object to the Person Enrichment API
json_response = requests.get(PDL_URL, params=PARAMS).json()

# Check for successful response
if json_response["status"] == 200:
  record = json_response['data']

  # Print selected fields
  print(
    record['work_email'],
    record['full_name'],
    record['job_title'],
    record['job_company_name']
  )

  print(f"Successfully enriched profile with PDL data.")

  # Save enrichment data to JSON file
  with open("my_pdl_enrichment.jsonl", "w") as out:
    out.write(json.dumps(record) + "\n")
else:
  print("Enrichment unsuccessful. See error and try again.")
  print("error:", json_response)
```

## Name and Company and School

Python3 SDKcURLJavaScriptRubyGoPython3

```
import json

# See https://github.com/peopledatalabs/peopledatalabs-python
from peopledatalabs import PDLPY

# Create a client, specifying your API key
CLIENT = PDLPY(
    api_key="YOUR API KEY",
)

# Create a parameters JSON object
PARAMS = {
    "company": ["TalentIQ Technologies"],   
  	"first_name": ["Sean"],
    "last_name": ["Thorne"],
    "school": ["University of Oregon"]
}

# Pass the parameters object to the Person Enrichment API
json_response = CLIENT.person.enrichment(**PARAMS).json()

# Check for successful response
if json_response["status"] == 200:
  record = json_response['data']

  # Print selected fields
  print(
    record['work_email'],
    record['full_name'],
    record['job_title'],
    record['job_company_name']
  )

  print(f"Successfully enriched profile with PDL data.")

  # Save enrichment data to JSON file
  with open("my_pdl_enrichment.jsonl", "w") as out:
    out.write(json.dumps(record) + "\n")
else:
  print("Enrichment unsuccessful. See error and try again.")
  print("error:", json_response)
```

```
curl -X GET -G \
  'https://api.peopledatalabs.com/v5/person/enrich' \
  -H 'X-Api-Key: xxxx' \
  --data-urlencode 'company=TalentIQ Technologies' \
  --data-urlencode 'first_name=Sean' \
  --data-urlencode 'last_name=Thorne' \
  --data-urlencode 'school=University of Oregon'
```

```
// See https://github.com/peopledatalabs/peopledatalabs-js
import PDLJS from 'peopledatalabs';

import fs from 'fs';

// Create a client, specifying your API key
const PDLJSClient = new PDLJS({ apiKey: "YOUR API KEY" });

// Create a parameters JSON object
const params = {
  company: "TalentIQ Technologies",
  first_name: "Sean",
  last_name: "Thorne",
  school: "University of Oregon"
}

// Pass the parameters object to the Person Enrichment API
PDLJSClient.person.enrichment(params).then((data) => {
    var record = data.data
    
    // Print selected fields
    console.log(
        record["work_email"],
        record["full_name"],
        record["job_title"],
        record["job_company_name"],
        )
        
    console.log("Successfully enriched profile with PDL data.")
    
    // Save enrichment data to JSON file
    fs.writeFile("my_pdl_enrichment.jsonl", Buffer.from(JSON.stringify(record)), (err) => {
        if (err) throw err;
    });
}).catch((error) => {
    console.log("Enrichment unsuccessful. See error and try again.")
    console.log(error);
});
```

```
require 'json'

# See https://github.com/peopledatalabs/peopledatalabs-ruby
require 'peopledatalabs'

# Set your API key
Peopledatalabs.api_key = 'YOUR API KEY'

# Create a parameters JSON object
PARAMS = {
    "company": ["TalentIQ Technologies"],   
  	"first_name": ["Sean"],
    "last_name": ["Thorne"],
    "school": ["University of Oregon"]
}

# Pass the parameters object to the Person Enrichment API
json_response = Peopledatalabs::Enrichment.person(params: PARAMS)

# Check for successful response
if json_response['status'] == 200
    record = json_response['data']
    
    # Print selected fields
    puts \
        "#{record['work_email']} \
         #{record['full_name']} \
         #{record['job_title']} \
         #{record['job_company_name']}"
    
    puts "Successfully enriched profile with PDL data."
    
    # Save enrichment data to JSON file
    File.open("my_pdl_enrichment.jsonl", "w") do |out|
        out.write(JSON.dump(record) + "\n")
    end
else
    puts "Enrichment unsuccessful. See error and try again."
    puts "error: #{json_response}"
end
```

```
package main

import (
    "fmt"
    "os"
    "encoding/json"
    "context"
)

// See https://github.com/peopledatalabs/peopledatalabs-go
import (
    pdl "github.com/peopledatalabs/peopledatalabs-go"
    pdlmodel "github.com/peopledatalabs/peopledatalabs-go/model"
)

func main() {
    // Set your API key
    apiKey := "YOUR API KEY"
    // Set API key as environmental variable
    // apiKey := os.Getenv("API_KEY")

    // Create a client, specifying your API key
    client := pdl.New(apiKey)
    
    // Create a parameters JSON object
    params := pdlmodel.EnrichPersonParams {
        PersonParams: pdlmodel.PersonParams {
            Company: []string{"TalentIQ Technologies"},
            FirstName: []string{"Sean"},
            LastName: []string{"Thorne"},
            School: []string{"University of Oregon"},
        },
    }

    // Pass the parameters object to the Person Enrichment API
    response, err := client.Person.Enrich(context.Background(), params)
    
    // Check for successful response
    if err == nil {
        // Convert the API response to JSON
        jsonResponse, jsonErr := json.Marshal(response.Data)
        if jsonErr == nil {
            var record map[string]interface{}
            json.Unmarshal(jsonResponse, &record)
            // Print selected fields
            fmt.Println(
                       record["work_email"], 
                       record["full_name"], 
                       record["job_title"], 
                       record["job_company_name"])
        
            fmt.Println("Successfully enriched profile with PDL data.")
        
            // Save enrichment data to JSON file
            out, outErr := os.Create("my_pdl_enrichment.jsonl")
            defer out.Close()
            if outErr == nil {
                out.WriteString(string(jsonResponse) + "\n")
            }
            out.Sync()
        }
   	} else {
        fmt.Println("Enrichment unsuccessful. See error and try again.")
        fmt.Println("error:", err)
    }
}
```

```
import requests, json

# Set your API key
API_KEY = "YOUR API KEY"

# Set the Person Enrichment API URL
PDL_URL = "https://api.peopledatalabs.com/v5/person/enrich"

# Create a parameters JSON object
PARAMS = {
    "api_key": API_KEY,
    "company": ["TalentIQ Technologies"],   
  	"first_name": ["Sean"],
    "last_name": ["Thorne"],
    "school": ["University of Oregon"]
}

# Pass the parameters object to the Person Enrichment API
json_response = requests.get(PDL_URL, params=PARAMS).json()

# Check for successful response
if json_response["status"] == 200:
  record = json_response['data']

  # Print selected fields
  print(
    record['work_email'],
    record['full_name'],
    record['job_title'],
    record['job_company_name']
  )

  print(f"Successfully enriched profile with PDL data.")

  # Save enrichment data to JSON file
  with open("my_pdl_enrichment.jsonl", "w") as out:
    out.write(json.dumps(record) + "\n")
else:
  print("Enrichment unsuccessful. See error and try again.")
  print("error:", json_response)
```

## Name and Location and Twitter and Phone

Python3 SDKcURLJavaScriptRubyGoPython3

```
import json

# See https://github.com/peopledatalabs/peopledatalabs-python
from peopledatalabs import PDLPY

# Create a client, specifying your API key
CLIENT = PDLPY(
    api_key="YOUR API KEY",
)

# Create a parameters JSON object
PARAMS = {
    "name": ["Sean Thorne"],   
  	"location": ["SF Bay Area"],
    "profile": ["www.twitter.com/seanthorne5"],
    "phone": ["+15555091234"]
}

# Pass the parameters object to the Person Enrichment API
json_response = CLIENT.person.enrichment(**PARAMS).json()

# Check for successful response
if json_response["status"] == 200:
  record = json_response['data']

  # Print selected fields
  print(
    record['work_email'],
    record['full_name'],
    record['job_title'],
    record['job_company_name']
  )

  print(f"Successfully enriched profile with PDL data.")

  # Save enrichment data to JSON file
  with open("my_pdl_enrichment.jsonl", "w") as out:
    out.write(json.dumps(record) + "\n")
else:
  print("Enrichment unsuccessful. See error and try again.")
  print("error:", json_response)
```

```
curl -X GET -G \
  'https://api.peopledatalabs.com/v5/person/enrich' \
  -H 'X-Api-Key: xxxx' \
  --data-urlencode 'name=Sean Thorne' \
  --data-urlencode 'location=SF Bay Area' \
  --data-urlencode 'profile=www.twitter.com/seanthorne5' \
  --data-urlencode 'phone=+15555091234'
```

```
// See https://github.com/peopledatalabs/peopledatalabs-js
import PDLJS from 'peopledatalabs';

import fs from 'fs';

// Create a client, specifying your API key
const PDLJSClient = new PDLJS({ apiKey: "YOUR API KEY" });

// Create a parameters JSON object
const params = {
  name: "Sean Thorne",
  location: "SF Bay Area",
  profile: "www.twitter.com/seanthorne5",
  phone: "+15555091234"
}

// Pass the parameters object to the Person Enrichment API
PDLJSClient.person.enrichment(params).then((data) => {
    var record = data.data
    
    // Print selected fields
    console.log(
        record["work_email"],
        record["full_name"],
        record["job_title"],
        record["job_company_name"],
        )
        
    console.log("Successfully enriched profile with PDL data.")
    
    // Save enrichment data to JSON file
    fs.writeFile("my_pdl_enrichment.jsonl", Buffer.from(JSON.stringify(record)), (err) => {
        if (err) throw err;
    });
}).catch((error) => {
    console.log("Enrichment unsuccessful. See error and try again.")
    console.log(error);
});
```

```
require 'json'

# See https://github.com/peopledatalabs/peopledatalabs-ruby
require 'peopledatalabs'

# Set your API key
Peopledatalabs.api_key = 'YOUR API KEY'

# Create a parameters JSON object
PARAMS = {
    "name": ["Sean Thorne"],   
  	"location": ["SF Bay Area"],
    "profile": ["www.twitter.com/seanthorne5"],
    "phone": ["+15555091234"]
}

# Pass the parameters object to the Person Enrichment API
json_response = Peopledatalabs::Enrichment.person(params: PARAMS)

# Check for successful response
if json_response['status'] == 200
    record = json_response['data']
    
    # Print selected fields
    puts \
        "#{record['work_email']} \
         #{record['full_name']} \
         #{record['job_title']} \
         #{record['job_company_name']}"
    
    puts "Successfully enriched profile with PDL data."
    
    # Save enrichment data to JSON file
    File.open("my_pdl_enrichment.jsonl", "w") do |out|
        out.write(JSON.dump(record) + "\n")
    end
else
    puts "Enrichment unsuccessful. See error and try again."
    puts "error: #{json_response}"
end
```

```
package main

import (
    "fmt"
    "os"
    "encoding/json"
    "context"
)

// See https://github.com/peopledatalabs/peopledatalabs-go
import (
    pdl "github.com/peopledatalabs/peopledatalabs-go"
    pdlmodel "github.com/peopledatalabs/peopledatalabs-go/model"
)

func main() {
    // Set your API key
    apiKey := "YOUR API KEY"
    // Set API key as environmental variable
    // apiKey := os.Getenv("API_KEY")

    // Create a client, specifying your API key
    client := pdl.New(apiKey)
    
    // Create a parameters JSON object
    params := pdlmodel.EnrichPersonParams {
        PersonParams: pdlmodel.PersonParams {
            Name: []string{"Sean Thorne"},
            Location: []string{"SF Bay Area"},
            Profile: []string{"www.twitter.com/seanthorne5"},
            Phone: []string{"+15555091234"},
        },
    }

    // Pass the parameters object to the Person Enrichment API
    response, err := client.Person.Enrich(context.Background(), params)
    
    // Check for successful response
    if err == nil {
        // Convert the API response to JSON
        jsonResponse, jsonErr := json.Marshal(response.Data)
        if jsonErr == nil {
            var record map[string]interface{}
            json.Unmarshal(jsonResponse, &record)
            // Print selected fields
            fmt.Println(
                       record["work_email"], 
                       record["full_name"], 
                       record["job_title"], 
                       record["job_company_name"])
        
            fmt.Println("Successfully enriched profile with PDL data.")
        
            // Save enrichment data to JSON file
            out, outErr := os.Create("my_pdl_enrichment.jsonl")
            defer out.Close()
            if outErr == nil {
                out.WriteString(string(jsonResponse) + "\n")
            }
            out.Sync()
        }
   	} else {
        fmt.Println("Enrichment unsuccessful. See error and try again.")
        fmt.Println("error:", err)
    }
}
```

```
import requests, json

# Set your API key
API_KEY = "YOUR API KEY"

# Set the Person Enrichment API URL
PDL_URL = "https://api.peopledatalabs.com/v5/person/enrich"

# Create a parameters JSON object
PARAMS = {
    "api_key": API_KEY,
    "name": ["Sean Thorne"],   
  	"location": ["SF Bay Area"],
    "profile": ["www.twitter.com/seanthorne5"],
    "phone": ["+15555091234"]
}

# Pass the parameters object to the Person Enrichment API
json_response = requests.get(PDL_URL, params=PARAMS).json()

# Check for successful response
if json_response["status"] == 200:
  record = json_response['data']

  # Print selected fields
  print(
    record['work_email'],
    record['full_name'],
    record['job_title'],
    record['job_company_name']
  )

  print(f"Successfully enriched profile with PDL data.")

  # Save enrichment data to JSON file
  with open("my_pdl_enrichment.jsonl", "w") as out:
    out.write(json.dumps(record) + "\n")
else:
  print("Enrichment unsuccessful. See error and try again.")
  print("error:", json_response)
```

## Multiple Values for the Same Parameter

Most query parameters can take multiple values. To do so, append the parameter with values as many times as needed. The only parameters that **cannot** exist multiple times are `locality`, `region`, `country` and `street_address`, as these are linearly related and multiple inputs would make it impossible to match. To match multiple locations, use the `location` parameter.

Python3 SDKcURLJavaScriptRubyGoPython3

```
import json

# See https://github.com/peopledatalabs/peopledatalabs-python
from peopledatalabs import PDLPY

# Create a client, specifying your API key
CLIENT = PDLPY(
    api_key="YOUR API KEY",
)

# Create a parameters JSON object
PARAMS = {
    "name": ["Sean Thorne"],    
    "profile": ["www.twitter.com/seanthorne5", "linkedin.com/in/seanthorne"]
}

# Pass the parameters object to the Person Enrichment API
json_response = CLIENT.person.enrichment(**PARAMS).json()

# Check for successful response
if json_response["status"] == 200:
  record = json_response['data']

  # Print selected fields
  print(
    record['work_email'],
    record['full_name'],
    record['job_title'],
    record['job_company_name']
  )

  print(f"Successfully enriched profile with PDL data.")

  # Save enrichment data to JSON file
  with open("my_pdl_enrichment.jsonl", "w") as out:
    out.write(json.dumps(record) + "\n")
else:
  print("Enrichment unsuccessful. See error and try again.")
  print("error:", json_response)
```

```
curl -X GET -G \
  'https://api.peopledatalabs.com/v5/person/enrich' \
  -H 'X-Api-Key: xxxx' \
  --data-urlencode 'name=Sean Thorne' \
  --data-urlencode 'profile=www.twitter.com/seanthorne5' \
  --data-urlencode 'profile=linkedin.com/in/seanthorne'
```

```
// See https://github.com/peopledatalabs/peopledatalabs-js
import PDLJS from 'peopledatalabs';

import fs from 'fs';

// Create a client, specifying your API key
const PDLJSClient = new PDLJS({ apiKey: "YOUR API KEY" });

// Create a parameters JSON object
const params = {
  name: "Sean Thorne",
  profile: "www.twitter.com/seanthorne5",
  profile: "linkedin.com/in/seanthorne"
}

// Pass the parameters object to the Person Enrichment API
PDLJSClient.person.enrichment(params).then((data) => {
    var record = data.data
    
    // Print selected fields
    console.log(
        record["work_email"],
        record["full_name"],
        record["job_title"],
        record["job_company_name"],
        )
        
    console.log("Successfully enriched profile with PDL data.")
    
    // Save enrichment data to JSON file
    fs.writeFile("my_pdl_enrichment.jsonl", Buffer.from(JSON.stringify(record)), (err) => {
        if (err) throw err;
    });
}).catch((error) => {
    console.log("Enrichment unsuccessful. See error and try again.")
    console.log(error);
});
```

```
require 'json'

# See https://github.com/peopledatalabs/peopledatalabs-ruby
require 'peopledatalabs'

# Set your API key
Peopledatalabs.api_key = 'YOUR API KEY'

# Create a parameters JSON object
PARAMS = {
    "name": ["Sean Thorne"],    
    "profile": ["www.twitter.com/seanthorne5", "linkedin.com/in/seanthorne"]
}

# Pass the parameters object to the Person Enrichment API
json_response = Peopledatalabs::Enrichment.person(params: PARAMS)

# Check for successful response
if json_response['status'] == 200
    record = json_response['data']
    
    # Print selected fields
    puts \
        "#{record['work_email']} \
         #{record['full_name']} \
         #{record['job_title']} \
         #{record['job_company_name']}"
    
    puts "Successfully enriched profile with PDL data."
    
    # Save enrichment data to JSON file
    File.open("my_pdl_enrichment.jsonl", "w") do |out|
        out.write(JSON.dump(record) + "\n")
    end
else
    puts "Enrichment unsuccessful. See error and try again."
    puts "error: #{json_response}"
end
```

```
package main

import (
    "fmt"
    "os"
    "encoding/json"
    "context"
)

// See https://github.com/peopledatalabs/peopledatalabs-go
import (
    pdl "github.com/peopledatalabs/peopledatalabs-go"
    pdlmodel "github.com/peopledatalabs/peopledatalabs-go/model"
)

func main() {
    // Set your API key
    apiKey := "YOUR API KEY"
    // Set API key as environmental variable
    // apiKey := os.Getenv("API_KEY")

    // Create a client, specifying your API key
    client := pdl.New(apiKey)
    
    // Create a parameters JSON object
    params := pdlmodel.EnrichPersonParams {
        PersonParams: pdlmodel.PersonParams {
            Name: []string{"Sean Thorne"},
            Profile: []string{"www.twitter.com/seanthorne5", "linkedin.com/in/seanthorne"},
        },
    }

    // Pass the parameters object to the Person Enrichment API
    response, err := client.Person.Enrich(context.Background(), params)
    
    // Check for successful response
    if err == nil {
        // Convert the API response to JSON
        jsonResponse, jsonErr := json.Marshal(response.Data)
        if jsonErr == nil {
            var record map[string]interface{}
            json.Unmarshal(jsonResponse, &record)
            // Print selected fields
            fmt.Println(
                       record["work_email"], 
                       record["full_name"], 
                       record["job_title"], 
                       record["job_company_name"])
        
            fmt.Println("Successfully enriched profile with PDL data.")
        
            // Save enrichment data to JSON file
            out, outErr := os.Create("my_pdl_enrichment.jsonl")
            defer out.Close()
            if outErr == nil {
                out.WriteString(string(jsonResponse) + "\n")
            }
            out.Sync()
        }
   	} else {
        fmt.Println("Enrichment unsuccessful. See error and try again.")
        fmt.Println("error:", err)
    }
}
```

```
import requests, json

# Set your API key
API_KEY = "YOUR API KEY"

# Set the Person Enrichment API URL
PDL_URL = "https://api.peopledatalabs.com/v5/person/enrich"

# Create a parameters JSON object
PARAMS = {
    "api_key": API_KEY,
    "name": ["Sean Thorne"],    
    "profile": ["www.twitter.com/seanthorne5", "linkedin.com/in/seanthorne"]
}

# Pass the parameters object to the Person Enrichment API
json_response = requests.get(PDL_URL, params=PARAMS).json()

# Check for successful response
if json_response["status"] == 200:
  record = json_response['data']

  # Print selected fields
  print(
    record['work_email'],
    record['full_name'],
    record['job_title'],
    record['job_company_name']
  )

  print(f"Successfully enriched profile with PDL data.")

  # Save enrichment data to JSON file
  with open("my_pdl_enrichment.jsonl", "w") as out:
    out.write(json.dumps(record) + "\n")
else:
  print("Enrichment unsuccessful. See error and try again.")
  print("error:", json_response)
```

## Using POST Requests

*"I want to use POST requests instead of GET requests so that I can make queries with a lot of parameters."*

> ðŸ“˜
>
> ### Difference Between GET and POST Requests
>
> See this article for a comparison of the [differences between GET and POST requests](https://www.w3schools.com/tags/ref_httpmethods.asp). The biggest difference is that POST requests don't have any limits on the amount of data that you can pass in the request.

Python3cURL

```
import requests, json

# Set your API key
API_KEY = "YOUR API KEY"

# Set the Person Enrichment API URL
PDL_URL = "https://api.peopledatalabs.com/v5/person/enrich"

# Create a parameters JSON object
PAYLOAD = {
    "api_key": API_KEY,
    "name": ["Sean Thorne"],    
    "profile": ["www.twitter.com/seanthorne5", "linkedin.com/in/seanthorne"]
}

# Pass the parameters object to the Person Enrichment API
json_response = requests.post(PDL_URL, json=PAYLOAD).json()

# Check for successful response
if json_response["status"] == 200:
  record = json_response['data']

  # Print selected fields
  print(
    record['work_email'],
    record['full_name'],
    record['job_title'],
    record['job_company_name']
  )

  print(f"Successfully enriched profile with PDL data.")

  # Save enrichment data to JSON file
  with open("my_pdl_enrichment.jsonl", "w") as out:
    out.write(json.dumps(record) + "\n")
else:
  print("Enrichment unsuccessful. See error and try again.")
  print("error:", json_response)
```

```
curl -X POST "https://api.peopledatalabs.com/v5/person/enrich" \
-H "Content-Type: application/json" \
-d '{
  "api_key": "YOUR API KEY",
  "name": ["Sean Thorne"],    
  "profile": ["www.twitter.com/seanthorne5", "linkedin.com/in/seanthorne"]
}'
```

Updated 4 months ago

---

Did this page help you?

Yes

No

---
# https://docs.peopledatalabs.com/docs/company-sizes

| Canonical Values for Company Sizes |
| --- |
| 1-10 |
| 11-50 |
| 51-200 |
| 201-500 |
| 501-1000 |
| 1001-5000 |
| 5001-10000 |
| 10001+ |

*Contents of this table were sourced from the following file on our public S3 bucket:[job\_company\_size.txt](https://pdl-prod-schema.s3.us-west-2.amazonaws.com/28.0/enums/job_company_size.txt)*

## Relevant Fields

* [`experience.company.size`](/docs/fields#experiencecompany)
* [`job_company_size`](/docs/fields#job_company_size)
* [`size`](/docs/company-schema#size)

Updated 4 months ago

---

Did this page help you?

Yes

No

---
# https://docs.peopledatalabs.com/docs/job-title-class-post-v271

> ðŸ“˜
>
> ### Launched in v28.0 (October 2024)
>
> The new field `job_title_class` and taxonomy below is now fully available to all customers via API and flat file deliveries.
>
> * API customers may access this taxonomy by passing the parameter `updated_title_roles` and setting the value to `true`.
> * Data License customers should reach out to your dedicated customer team to opt-in to the updated taxonomy if your data deliveries for v28.0, v28.1, v28.2, and v29.0 (Oct - Jan releases).
>
> Please see our [October 2024 Release Announcement (v28.0)](/changelog/october-2024-release-announcement-v280#taxonomy-stats) for further information.

| Canonical Values for Job Title Class |
| --- |
| general\_and\_administrative |
| research\_and\_development |
| sales\_and\_marketing |
| services |
| unemployed |

*Contents of this table were sourced from the following file on our public S3 bucket:[job\_title\_role.txt](https://pdl-prod-schema.s3.us-west-2.amazonaws.com/30.0/enums/job_title_class.txt)*

## Relevant fields

* [`job_title_class`](/docs/fields#job_title_class)
* [`experience.title.class`](/docs/fields#experiencetitle)

Updated 4 months ago

---

Did this page help you?

Yes

No

---
# https://docs.peopledatalabs.com/docs/requests

## Overview

The Person Enrichment API enables you to enrich data on a person by performing a one-to-one match of this person with the nearly three billion individual profiles that are hosted in our dataset. Once matched, you have access to all the fields in our [Person Schema](/docs/fields), which can include names, addresses, employment information and social media accounts.

## What's Next

Please check out the following pages for more information on the Person Enrichment API:

| Page | Description |
| --- | --- |
| [Quickstart](/docs/quickstart-person-enrichment-api) | A quick hands-on introduction to the API with simple code examples. |
| [Reference](/docs/reference-person-enrichment-api) | Detailed descriptions of the technical specifications and usage constraints. |
| [Input Parameters](/docs/input-parameters-person-enrichment-api) | In-depth explanations of the input parameters that the API supports. |
| [Output Response](/docs/output-response-person-enrichment-api) | In-depth explanations of the output response object that the API returns. |
| [Examples](/docs/examples-person-enrichment-api) | A collection of functional code examples and walkthroughs that illustrate various use cases and applications of the API. |
| [FAQs](/docs/faqs-person-enrichment-api) | Answers to commonly asked questions and other good-to-know information. |
| [Bulk Person Enrichment API](/docs/bulk-enrichment-api) | A supporting functionality to enrich multiple profiles in the same request. |
| [Preview Enrichment API](/docs/preview-enrichment-api) | A supporting functionality to preview which fields have non-null data for a particular person. |

---



*Know someone whoâ€™d thrive building data products and helping us launch whatâ€™s next? Weâ€™d love to meet!*

*Check out our[open roles](https://www.peopledatalabs.com/company?utm_source=docs&utm_medium=footer&utm_campaign=cta#jobs) â†’*

Updated 4 months ago

---

Did this page help you?

Yes

No

---
# https://docs.peopledatalabs.com/docs/last_updated-field

As described in [Data Updates](/docs/data-updates), keeping our `experience` and `locations` objects current is one of our primary focuses. Here we outline how we communicate these updates to customers across both fields.

## `job_` and `location_` fields

Every `experience` and `locations` object has an `is_primary` field that contains a boolean value. For a single profile, there will be *at most* one profile tagged as primary. This profile will appear in the flattened `job_` and `location_` fields. The primary values are the ones we believe to be the most recent/relevant object from the `experience`/`locations` array.

## `last_updated` Field

The `last_updated` field exists for both `locations` objects and the top-level experience object (as the [`job_last_verified`](docs:fields#job_last_verified) field). It indicates the last time one of our [Data Union partners](/docs/data-sources) saw a person's location and/or current job "in the wild." Since many of our data partners are themselves focused on data accuracy, we are able to utilize their timestamps to accurately map when this value was last seen. The `last_updated` date does not necessarily indicate that a change in the field occurred but when the most recent data source was provided this data and confirmed its accuracy.

Updated 4 months ago

---

Did this page help you?

Yes

No

---
# https://docs.peopledatalabs.com/docs/send-your-first-company-enrichment-api-request

## Look Up a Company Profile Using the Company Enrichment API

Next, letâ€™s look at some records in the [Company Dataset](/docs/company-stats).

Just as you used the Person Enrichment API to retrieve the profile of a specific person, you can use the [Company Enrichment API](/docs/company-enrichment-api) to retrieve the profile of a specific company. Letâ€™s retrieve the record for People Data Labs using our LinkedIn profile: `linkedin.com/company/peopledatalabs/`

## Sending your first request

Copy the following URL and paste it into a new tab in your browser.

> â—ï¸
>
> ### Before pasting the URL
>
> * Replace `XXXX` after `api_key` with your API key
> * This will **consume 1 API credit** of your free 100 monthly credits for the Company Enrichment API. To read more about credits, check out this [Help Center article](https://support.peopledatalabs.com/hc/en-us/articles/23553812020891-Pricing-Overview)

URL

```
https://api.peopledatalabs.com/v5/company/enrich?api_key=XXXX&pretty=True&profile=linkedin.com/company/peopledatalabs
```

The result should look something like this:

> ðŸ“˜
>
> ### Pro tip
>
> If you want a better way to work with the result in a browser, consider downloading a [JSON Formatting extension](https://chromewebstore.google.com/detail/json-formatter/bcjindcccaagfpapjjmafapmmgkkhgoa?pli=1)

As with records in our Person Dataset, company profiles in our Company Dataset are stored as JSON objects, and they contain information for the fields in our [Company Schema](/docs/company-fields).

### Try Looking Up Another Company Profile

Next, try looking up another company profile. This time, find your favorite company on [LinkedIn](https://www.linkedin.com/). For example, [Google](https://www.linkedin.com/company/google/). Go to the companyâ€™s profile page and copy the URL.

As you should now be trying to get a feel for the type of data available within in the PDL datasets, try a few different LinkedIn URLs. Here are some examples:

* `https://www.linkedin.com/company/google/`
* `https://www.linkedin.com/company/amazon/`
* `https://www.linkedin.com/company/apple/`

Once you have chosen a LinkedIn URL, run the following command:

> â—ï¸
>
> ### Before pasting the URL
>
> * Replace `XXXX` after `api_key` with your API key
> * Replace `YYYY` after `profile` with the desired LinkedIn URL
> * This will **consume 1 API credit** of your free 100 monthly credits for the Company Enrichment API. To read more about credits, check out this [Help Center article](https://support.peopledatalabs.com/hc/en-us/articles/23553812020891-Pricing-Overview)

Shell

```
https://api.peopledatalabs.com/v5/company/enrich?api_key=XXXX&pretty=True&profile=YYYY
```

In the response, you should see either:

* The full PDL company profile associated with the LinkedIn URL that you submitted.
* An [error](/docs/errors) indicating that no matching record could be found, in which case you can try one of the example LinkedIn URLs listed above.

We encourage you to look up a number of company profiles to get a sense of the type of coverage and information that our datasets offer.

Updated 4 months ago

---

* [Quickstart wrap up](/docs/quickstart-wrapup)

Did this page help you?

Yes

No

---
# https://docs.peopledatalabs.com/docs/company-schema

# Overview

This page details the company-related fields that we provide through the [Company Enrichment](/docs/company-enrichment-api) and [Company Search](/docs/company-search-api) APIs.

* [Base Company Fields](#base-company-fields): Common fields available to all customers by default
* [Company Insights Fields](#company-insights-fields): Premium fields presenting summaries of the employee headcount and trends, built by aggregating data from our Person dataset
* [Premium Company Fields](#premium-company-fields): Premium company fields such as related companies, subsidiaries, acquisitions and more

> ðŸ“˜
>
> ### Field Availability
>
> Please note: Not all fields are available in all bundles.

* For more information about data formatting, see [Data Types](/docs/data-types).
* For a full example record, see [Example Company Record](/docs/example-company-record).
* For a simplified overview of our company fields, check out the [Company Data Overview](/docs/company-data-overview).
* For more details about our company fields, including fill rates and which fields are included in the base vs premium [field bundles](/docs/data-field-bundles), check out our [Company Stats](/docs/company-stats) pages.
* For a full data ingestion JSON schema, check out [this page](/docs/receiving-and-updating-data#data-ingestion-schemas).
* If you'd like access to premium fields or have questions about which fields are included in your specific field bundle(s), please [speak to one of our data consultants](https://peopledatalabs.com/talk-to-sales).

---

# Base Company Fields

These fields are available to all customers by default.

## Identifiers

### `id`

|  |  |
| --- | --- |
| Description | The identifier for the company. |
| Data Type | `String` |

#### Field Details

The ID is a unique, hashed value that represents a specific company record.

#### Example

JSON

```
"id": "tnHcNHbCv8MKeLh92946LAkX6PKg"
```

### `name`

|  |  |
| --- | --- |
| Description | The company's main common name. |
| Data Type | `String` |

#### Field Details

The company name will be lowercase with any leading/trailing whitespace removed. It is **not** guaranteed to be unique.

For the correct capitalization of the company name, see [`display_name`](#display_name).

The name value returned here does not undergo much cleaning or standardization. However, we clean and tokenize company names behind the scenes so they can be found using the [Company Search API](/docs/company-search-api). To see how company name cleaning works, check out the [Company Cleaner API](/docs/cleaner-apis#companyclean).

#### Example

JSON

```
"name": "people data labs"
```

### `display_name`

|  |  |
| --- | --- |
| Description | The company name, capitalized using the companyâ€™s self-reported name. |
| Data Type | `String` |

#### Field Details

The `display_name` field preserves the capitalization of the company name (unlike [`name`](#name) which is always lowercase). `display_name` is set using the companyâ€™s self-reported name, so it should be accurate even for companies with non-standard capitalization (such as VMware, FedEx, or Dell EMC).

Use this field to display properly capitalized company names in a UI or other customer-facing project or product.

#### Example

JSON

```
"display_name": "VMware"
```

## Company Information

### `affiliated_profiles`

|  |  |
| --- | --- |
| Description | [Company IDs](#id) that are affiliated with the queried company (parents and subsidiaries.) |
| Data Type | `Array [String]` |

#### Field Details

A list of [Company IDs](#id) that we have flagged as having an association to this company (either a parent or a subsidiary.) See [Parents and Subsidiaries](#parents-and-subsidiaries) for fields based on specific company associations.

#### Example

JSON

```
"affiliated_profiles": [
    "a1cpOkL4SHp0wSAKjbCeuwtAlno0",
    "3WBa1kollMtBbib5DoiCwwhyD9ks"
  ]
```

### `alternative_domains`

|  |  |
| --- | --- |
| Description | A list of alternate domains associated with this company. |
| Data Type | `Array [String]` |

#### Field Details

If a company rebrands or otherwise changes its primary domain, old company websites will be kept in this list.

See [`website`](#website) for how we handle domains.

#### Example

JSON

```
"alternative_domains": [
    "peopledatalabs.com",
    "talentiq.co",
    "peopledatalabs.co"
  ]
```

### `alternative_names`

|  |  |
| --- | --- |
| Description | A list of names associated with this company. |
| Data Type | `Array [String]` |

#### Field Details

A list of [names](#name) associated with the company filtered to ensure data quality.

#### Example

JSON

```
"alternative_names": [
    "people data labs",
    "people data labs inc",
    "talentiq"
  ]
```

### `employee_count`

|  |  |
| --- | --- |
| Description | The current number of employees working at the company based on our number of profiles. |
| Data Type | `Integer (>= 0)` |

#### Field Details

`employee_count` is an integer greater than or equal to zero. We calculate it by finding the number of profiles whose `experience.company.id`  matches the company with a non-null `job_start_date` and no end date.

For the company's self-reported size range, use the [`size`](#size) field instead. For more information about the different types of employee count data we provide, see [Employee Count Fields](/docs/employee-count-fields).

This number may be higher or lower than a company's real employee count depending on how many false positives and false negatives we have in our data as well as missing or duplicate individuals.

#### Example

JSON

```
"employee_count": 78
```

### `employee_count_by_country`

|  |  |
| --- | --- |
| Description | The number of current employees broken out by country. |
| Data Type | `Object` |

#### Field Details

Each country will be one of our [Canonical Countries](/docs/location-countries). For more information about how each count is calculated, see [Employee Count Breakdowns](/docs/company-schema#employee-count-breakdowns).

Beginning in v25.0, this field will also contain an `other_uncategorized` subfield. Profiles that we have associated with the company but do not have enough information to assign a location to will be included in this field. For more information, see [Employee Count Fields](/docs/employee-count-fields).

#### Example

JSON

```
"employee_count_by_country": {
    "united states": 67,
    "canada": 2,
    "india": 1,
    "bangladesh": 1,
    "other_uncategorized": 2
  }
```

### `founded`

|  |  |
| --- | --- |
| Description | The founding year of the company. |
| Data Type | `Integer (> 0)` |

#### Field Details

The founding year will be an integer greater than zero. If no year is found, it will be `null`.

If different sources list different founding years, we will choose the year that appears in the most sources. If multiple years appear in the same number of sources, we will use the latest year.

#### Example

JSON

```
"founded": 2015
```

### `headline`

|  |  |
| --- | --- |
| Description | The companyâ€™s headline summary. |
| Data Type | `String` |

#### Field Details

`headline` is a short description of the company, limited to 300 characters.

#### Example

JSON

```
"headline": "Your Single Source of Truth"
```

### `size`

|  |  |
| --- | --- |
| Description | A range representing the number of people working at the company. |
| Data Type | `Enum (String)` |

#### Field Details

The value of this field will be one of our canonical [Company Sizes](/docs/company-sizes). We derive it from the company's self-reported size on their social media profile.

For the true number of employees, use the [`employee_count`](#employee_count) field.

#### Example

JSON

```
"size": "11-50"
```

### `summary`

|  |  |
| --- | --- |
| Description | A description of the company. |
| Data Type | `String` |

#### Field Details

The company summary is a lowercase string and can contain escape characters such as `\n`. The string is limited to a maximum of 1000 characters.

#### Example

```
  "summary": "people data labs builds people data. \n\nuse our dataset
              of 1.5 billion unique person profiles to build products,
              enrich person profiles, power predictive modeling/ai,
              analysis, and more. we work with technical teams as their
              engineering focused people data partner. \n\nwe work with
              thousands of data science teams as their engineering focused
              people data partner. these include enterprises like adidas,
              ebay, and acxiom, as well as startups like madison logic,
              zoho, and workable. we are a deeply technical company, and
              are backed by two leading engineering venture capital firms
              - founders fund and 8vc.",
```

### `tags`

|  |  |
| --- | --- |
| Description | Tags associated with the company. |
| Data Type | `Array [String]` |

#### Field Details

Each tag is a lowercase string.

There may be tags that seem to overlap (for example: `"data"`, `"analytics"` and `"data and analytics"`). This is intentional so that it is easier to search for companies matching a tag.

#### Example

JSON

```
"tags": [
    "data",
    "people data",
    "data science",
    "artificial intelligence",
    "data and analytics",
    "machine learning",
    "analytics",
    "database",
    "software",
    "developer apis"
   ]
```

### `website`

|  |  |
| --- | --- |
| Description | The primary company website. |
| Data Type | `String` |

#### Field Details

This field contains the address of the primary company website associated with the record.

We standardize websites by removing `https://www.` and any additional subdomains and paths (with certain exceptions). Popular hosting platforms (like Facebook, Blogspot, Wix, etc.) will retain their subdomains and paths. For example, `samspizza.blogspot.com` or `etsy.com/sams-pizza`.

Websites using link shortening services (like Bit.ly, TinyURL, ShortURL, etc.) will appear in full.

We have a list of invalid URL items (domains, subdomains and TLDs) that we check against. We also check if an iteration of the company name appears in the website address as a simple validation.

Ideally, this is the website address that people commonly use when accessing a company's site (such as `facebook.com`) and not an alias (such as `fb.com`).

As with [Social Presence](#social-presence), we do **not** verify that the website is valid.

#### Example

JSON

```
"website": "peopledatalabs.com"
```

## Funding Data

### `funding_stages`

|  |  |
| --- | --- |
| Description | All disclosed funding stages for the company. |
| Data Type | `Array [Enum (String)]` |

#### Field Details

An unordered list of all funding stages for funding events announced by the company.

This is generated from the separate events in [`funding_details.funding_type`](#funding_details).

All values in the list must be [Canonical Funding Rounds](/docs/funding-rounds). If there are multiple events tied to the same round (ex: Series A), that label will only appear once in the list.

#### Example

JSON

```
"funding_stages": [
    "series_b",
    "series_a",
    "seed"
  ]
```

### `last_funding_date`

|  |  |
| --- | --- |
| Description | The date of the companyâ€™s most recent funding event. |
| Data Type | [`String (Date)`](https://docs.peopledatalabs.com/docs/data-types#dates) |

#### Field Details

The date of the companyâ€™s most recent funding event. This represents the publicly disclosed date of the closing of the financing, and will be independent of any prior dates associated with that same funding round.

#### Example

JSON

```
"last_funding_date": "2021-11-16"
```

### `latest_funding_stage`

|  |  |
| --- | --- |
| Description | The stage of the companyâ€™s most recent funding event. |
| Data Type | `Enum (String)` |

#### Field Details

Must be one of the [Canonical Funding Rounds](/docs/funding-rounds).

#### Example

JSON

```
"latest_funding_stage": "series_b"
```

### `number_funding_rounds`

|  |  |
| --- | --- |
| Description | The number of funding rounds announced by the company. |
| Data Type | `Integer (> 0)` |

#### Field Details

The number of separate funding events for the company. This is the total number of events in [`funding_details`](#funding_details).

If multiple events are tied to the same funding round, they will each be counted toward the total (ex: 3 Series A events will add 3 to the total count).

#### Example

JSON

```
"number_funding_rounds": 7
```

### `total_funding_raised`

|  |  |
| --- | --- |
| Description | The cumulative amount raised by the company in USD. |
| Data Type | `Float (> 0)` |

#### Field Details

The cumulative amount raised by the company during all publicly disclosed funding rounds.

The value for this field is represented in USD. It is the sum of all known values from individual funding rounds (each of which is represented in $ USD using â€œthen-currentâ€ currency exchange rates).

#### Example

JSON

```
"total_funding_raised": 55250000.0
```

## Industry Types

### `industry`

|  |  |
| --- | --- |
| Description | The self-reported industry of the company. |
| Data Type | `Enum (String)` |

#### Field Details

Industry is self-reported and will be one of our [Canonical Industries](/docs/industries). If no industry is found, the field will be `null`.

#### Example

JSON

```
"industry": "animation"
```

  

### `industry_v2`

|  |  |
| --- | --- |
| Description | Industry v2 is the self-reported industry from an expanded list of [Canonical v2 Industries](https://docs.peopledatalabs.com/docs/industries-v2). If no industry is found, the field will be `null` |
| Data Type | [`Enum (String)`](https://docs.peopledatalabs.com/docs/industries-v2) |

#### Field Details

Industry is self-reported and will be one of our [Canonical V2 Industries](/docs/industries-v2). If no industry is found, the field will be `null`.

#### Example

JSON

```
"industry": "textile manufacturing"
```

### `naics`

|  |  |
| --- | --- |
| Description | An array of objects containing the industry classifications for a company according to the North American Industry Classification System (NAICS). A company can (and frequently does) have multiple NAICS codes. |
| Data Type | `Array [Object]` |

#### Field Details

Each NAICS code associated with the company will be included in the list. For each NAICS code, we provide the actual six-digit code as well as the official description for each level of the NAICS code.

PDL uses [NAICS 2017 industry categorization](https://www.bls.gov/cew/classifications/industry/home.htm).

PDL offers self-reported NAICS industry categorizations within the company data, where this data serves as an alternative to Industry and SIC for users to categorize or segment companies. Because the data PDL publishes represents self-reported data where the industry values were selected by employees of those companies prior to the 2022 revision, we have not bulk converted to, or inferred, NAICS 2022 categories for our existing NAICS values.

A NAICS code doesnâ€™t have to use all six digits. Any unspecified field(s) in our data will have a `null` value.

| Field | Data Type | Description |
| --- | --- | --- |
| `naics_code` | `String` | The NAICS code associated with a companyâ€™s industry classification. [See canonical values](/docs/naics-codes). |
| `sector` | `String` | The industry classification according to the first two digits in the NAICS code. [See canonical values](/docs/naics-sectors). |
| `sub_sector` | `String` | The industry classification according to the first three digits in the NAICS code. [See canonical values](/docs/naics-subsectors). |
| `industry_group` | `String` | The industry classification according to the first four digits in the NAICS code. [See canonical values](/docs/naics-industry-groups). |
| `naics_industry` | `String` | The industry classification according to the first five digits in the NAICS code. [See canonical values](/docs/naics-industries). |
| `national_industry` | `String` | The industry classification according to all six digits in the NAICS code. [See canonical values.](/docs/naics-national-industries) |

#### Example

JSON

```
"naics": [
    {
      "naics_code": "423920",
      "sector": "wholesale trade",
      "sub_sector": "merchant wholesalers, durable goods",
      "industry_group": "miscellaneous durable goods merchant wholesalers",
      "naics_industry": "toy and hobby goods and supplies merchant wholesalers",
      "national_industry": "toy and hobby goods and supplies merchant wholesalers"
    },
    ...
  ]
```

### `sic`

|  |  |
| --- | --- |
| Description | An array of objects containing the industry classifications for a company according to the Standard Industrial Classification (SIC) system. A company can (and frequently does) have multiple SIC codes. |
| Data Type | `Array [Object]` |

#### Field Details

Each SIC code associated with the company will be included in the list. For each SIC code, we provide the actual four-digit code as well as the official description for each level of the SIC code.

A SIC code doesnâ€™t have to use all four digits. Any unspecified field(s) in our data will have a `null` value.

| Field | Data Type | Description |
| --- | --- | --- |
| `sic_code` | `String` | The SIC code associated with a companyâ€™s industry classification. |
| `major_group` | `String` | The industry classification according to the first two digits in the SIC code. |
| `industry_group` | `String` | The industry classification according to the first three digits in the SIC code. |
| `industry_sector` | `String` | The industry classification according to all four digits in the SIC code. |

#### Example

JSON

```
"sic": [
    {
      "sic_code": "7372",
      "major_group": "business services",
      "industry_group": "computer programming, data processing, and other computer related services",
      "industry_sector": "prepackaged software"
    },
    ...
   ]
```

## Primary Location

### `location`

|  |  |
| --- | --- |
| Description | An object containing increasingly granular information about the location of the companyâ€™s current headquarters. |
| Data Type | `Object` |

#### Field Details

A company's location is the location of its Headquarters (HQ). We determine a companyâ€™s current Headquarters/primary office based on the location that we see most often in our sources.

For more information on our standard location fields, see [Data Formatting: Locations](/docs/data-formatting#locations).

#### Example

JSON

```
"location": {
    "name": "san francisco, california, united states",
    "locality": "san francisco",
    "region": "california",
    "metro": "san francisco, california",
    "country": "united states",
    "continent": "north america",
    "street_address": "455 market street",
    "address_line_2": "suite 1670",
    "postal_code": "94105",
    "geo": "37.77,-122.41"
  }
```

## Stock Information

### `mic_exchange`

|  |  |
| --- | --- |
| Description | The MIC code for the stock exchange that the company's [ticker](#ticker) is listed on. |
| Data Type | `Enum (String)` |

#### Field Details

`mic_exchange` represents the Market Identified Code (MIC) standard exchange code corresponding to the stock exchange of the company.

The value of `mic_exchange` will always be one of our [Canonical MIC Codes](/docs/mic-codes) or `null` if there is no [ticker](#ticker).

#### Example

JSON

```
"mic_exchange": "xnams"
```

### `ticker`

|  |  |
| --- | --- |
| Description | The company ticker (only for public companies.) |
| Data Type | `String (Uppercase)` |

#### Field Details

`ticker` is the uppercase string of the companyâ€™s stock symbol.

If a company is not public (as listed in its [`type`](#type)), its ticker will be `null`.

#### Example

JSON

```
"ticker": "MOO"
```

### `type`

|  |  |
| --- | --- |
| Description | The company type. |
| Data Type | `Enum (String)` |

#### Field Details

`type` will be one of the Canonical [Company Types](/docs/company-types). If a company has a known [`ticker`](#ticker), then its `type` is public. If a company does not have a ticker and its ultimate parent company does, then its type is public\_subsidiary.

#### Example

JSON

```
"type": "private"
```

## Social Presence

We currently include company social profiles for LinkedIn, Yellow Pages, Xing, Twitter, Facebook and Crunchbase. Any profiles that we find for the company from these sources will be added to the [`profiles`](#profiles) list.

Each social profile URL has one or more standard formats that we parse and turn into a standard PDL format for that social URL. We invalidate profiles that have non-valid company stubs (for example, `linkedin.com/in`), and we also have a blacklist of usernames that we know are invalid.

We do **not** validate if a URL is valid (that is, whether you can access it) because doing this at scale is considered a Direct Denial of Service (DDoS) attack and/or a form of crawling. This is highly discouraged! We try to mitigate invalid URLs as much as possible by using Entity Resolution (Merging) to link URLs together and then tagging the primary URL at the top level for key networks.

### `linkedin_id`

|  |  |
| --- | --- |
| Description | The main LinkedIn profile ID for the company based on source agreement. |
| Data Type | `String` |

#### Example

JSON

```
"linkedin_id": "18170482"
```

### `linkedin_slug`

|  |  |
| --- | --- |
| Description | The companyâ€™s LinkedIn URL slug. |
| Data Type | `String` |

#### Field Details

To support our [upcoming change to PDL Company IDs](/changelog/january-2024-release-notes-v25#company-id), we are adding the new `linkedin_slug` field. This field is generated in the same way as our [current company `id` field](/docs/company-schema#id).

For new company records that do not have associated LinkedIn pages, this field will be null.

#### Example

JSON

```
"linkedin_slug": "peopledatalabs"
```

### `linkedin_url`

|  |  |
| --- | --- |
| Description | The main LinkedIn profile URL for the company based on source agreement. |
| Data Type | `String` |

#### Example

JSON

```
"linkedin_url": "linkedin.com/company/peopledatalabs"
```

### `facebook_url`

|  |  |
| --- | --- |
| Description | The main Facebook profile URL for the company based on source agreement. |
| Data Type | `String` |

#### Example

JSON

```
"facebook_url": "facebook.com/peopledatalabs"
```

### `twitter_url`

|  |  |
| --- | --- |
| Description | The main Twitter profile URL for the company based on source agreement. |
| Data Type | `String` |

#### Example

JSON

```
"twitter_url": "twitter.com/peopledatalabs"
```

### `profiles`

|  |  |
| --- | --- |
| Description | A list of all known social profile URLs for the company from [our known sources](#social-presence). |
| Data Type | `Array [String]` |

#### Example

JSON

```
"profiles": [
    "linkedin.com/company/peopledatalabs",
    "linkedin.com/company/18170482",
    "facebook.com/peopledatalabs",
    "twitter.com/peopledatalabs",
    "crunchbase.com/organization/talentiq"
  ]
```

## PDL Record Information & Metadata

### `dataset_version`

|  |  |
| --- | --- |
| Description | The major or minor release number. |
| Data Type | `String` |

#### Field Details

Note: This number corresponds to the [data release number](/changelog), not the API release number.

#### Example

JSON

```
"dataset_version": "19.2"
```

---

# Company Insights Fields

Premium fields presenting summaries of the employee headcount and trends, built by aggregating data from from our [Person Dataset](/docs/fields).

## Average Employee Tenure

Average employee tenure is the average number of years employees work for the company. It is represented by a floating number greater than zero and rounded to the nearest thousandth. It could skew lower if there have been a lot of recent hires.

The average is calculated using `experience.start_date` and `experience.end_date` for each employee found in our Person records.

If no start date is given or if a date only contains a year but no month, then the experience is not counted toward the average.

### `average_employee_tenure`

|  |  |
| --- | --- |
| Description | The average years of experience at the company. |
| Data Type | `Float (> 0)` |

#### Field Details

This insight shows the average number of years that employees at the company have worked based on `experience.start_date` and `experience.end_date`.

#### Example

JSON

```
"average_employee_tenure": 2.75
```

### `average_tenure_by_level`

|  |  |
| --- | --- |
| Description | The average years of experience at the company by job level. |
| Data Type | `Object` |

#### Field Details

This insight shows the average number of years that employees at the company have worked broken out by their level at the company. The average for each level is calculated using the same logic as [`average_employee_tenure`](#average_employee_tenure).

The level names come from `experience.title.levels`, meaning they will always be one of the [Canonical Job Levels](/docs/job-title-levels).

#### Example

JSON

```
"average_tenure_by_level": {
    "entry": 0.3,
    "unpaid": 2.0,
    "senior": 6.0,
    "director": 3.0,
    "vp": 2.4,
    "training": 0.2,
    "manager": 4.0,
    "owner": 3.2,
    "partner": 2.4,
    "cxo": 8.1
  }
```

### `average_tenure_by_role`

|  |  |
| --- | --- |
| Description | The average years of experience at the company by job role. |
| Data Type | `Object` |

#### Field Details

This insight shows the average number of years that employees at the company have worked broken out by their role at the company. The average for each role is calculated using the same logic as [`average_employee_tenure`](#average_employee_tenure).

The role names come from `experience.title.role`, meaning they will always be one of the [Canonical Job Roles](/docs/job-title-roles).

#### Example

JSON

```
"average_tenure_by_role": {
    "real_estate": 4.5,
    "design": 2.0,
    "trades": 3.2,
    "marketing": 0.1,
    "education": 6.5,
    "legal": 8.0,
    "customer_service": 4.0,
    "finance": 5.0,
    "public_relations": 8.1,
    "engineering": 2.1,
    "human_resources": 0.5,
    "media": 0.4,
    "sales": 0.6,
    "operations": 0.1,
    "health": 2.0
  }
```

## Employee Count Breakdowns

The count for each category will always be an integer value greater than or equal to zero.

This number may be higher or lower than a company's real employee count depending on how many false positives and false negatives we have in our data, missing and duplicate individuals, and missing information on start dates and job roles.

If no start date is given, then the experience is not counted.

For the overall employee count, see [`employee_count`](#employee_count). For the company's self-reported size, see [`size`](#size).

Note that discrepancies between the [`employee_count`](#employee_count), the most recent [`employee_count_by_month`](#employee_count_by_month), and aggregated[`employee_count_by_month_by_role`](#employee_count_by_month_by_role) and [`employee_count_by_month_by_level`](#employee_count_by_month_by_level) counts are expected. For more information about the logic used to calculate these values, see [this page](/docs/employee-count-fields).

### `employee_count_by_month`

|  |  |
| --- | --- |
| Description | The number of employees at the end of each month. |
| Data Type | `Object` |

#### Field Details

The total number of profiles associated with this company at the end of each month in the format `YYYY-MM`. The date range begins at the start date of the first associated employee or January 1, 2010, whichever is most recent. The final month in the range will be the last full month before the last monthly [Data Build](/docs/data-build). Most often this is the month before request was submitted. For example, if you make a request mid-March, the response will contain all data up to that February.

#### Example

JSON

```
"employee_count_by_month": {
    "2021-07": 84,
    "2021-08": 86,
    "2021-09": 84
  }
```

### `employee_count_by_month_by_level`

|  |  |
| --- | --- |
| Description | The number of employees at the end of each month, broken down by job level. |
| Data Type | `Object` |

#### Field Details

The total number of profiles associated with this company at the end of each month in the format `YYYY-MM` broken down by `experience.title.levels`. The level names will always be one of the [Canonical Job Levels](/docs/job-title-levels).

The date range begins at the start date of the first associated employee or January 1, 2010, whichever is most recent. The final month in the range will be the last full month before the last monthly [Data Build](/docs/data-build). Most often this is the month before request was submitted. For example, if you make a request mid-March, the response will contain all data up to that February.

If a person changes levels within a company during the same month, they will be counted in the same month towards both levels. An individual may have more than a single level for the same experience object, in which case they will contribute towards multiple levels.

#### Example

JSON

```
"employee_count_by_month_by_level": {
    "2015-03": {
      "partner": 0,
      "vp": 0,
      "owner": 1,
      "entry": 0,
      "director": 0,
      "unpaid": 0,
      "senior": 0,
      "cxo": 1,
      "manager": 0,
      "training": 0
    },
    ...
    "2021-06": {
      "partner": 0,
      "vp": 3,
      "owner": 1,
      "entry": 10,
      "director": 2,
      "unpaid": 2,
      "senior": 5,
      "cxo": 1,
      "manager": 3,
      "training": 0
    }
  }
```

### `employee_count_by_month_by_role`

|  |  |
| --- | --- |
| Description | The number of employees at the end of each month, broken down by job role. |
| Data Type | `Object` |

#### Field Details

The total number of profiles associated with this company at the end of each month in the format `YYYY-MM` broken down by `experience.title.role`. The role names will always be one of the [Canonical Job Roles](/docs/job-title-roles).

The date range begins at the start date of the first associated employee or January 1, 2010, whichever is most recent. The final month in the range will be the last full month before the last monthly [Data Build](/docs/data-build). Most often this is the month before request was submitted. For example, if you make a request mid-March, the response will contain all data up to that February.

If a person changes roles with a company during the same month, they will only be counted for a single role.

Beginning in v25.0, each month will also contain an `other_uncategorized` subfield. Profiles that we have associated with the company but do not have enough information to assign a role to will be included in this field. For more information, see [Employee Count Fields](/docs/employee-count-fields).

#### Example

JSON

```
"employee_count_by_month_by_role": {
    "2015-03": {
      "engineering": 0,
      "education": 0,
      "media": 0,
      "design": 0,
      "trades": 0,
      "health": 0,
      "real_estate": 0,
      "customer_service": 0,
      "legal": 0,
      "human_resources": 0,
      "finance": 0,
      "public_relations": 0,
      "marketing": 0,
      "sales": 0,
      "operations": 0,
      "other_uncategorized": 1
    },
    ...
    "2021-06": {
      "engineering": 1,
      "education": 0,
      "media": 0,
      "design": 0,
      "trades": 0,
      "health": 0,
      "real_estate": 0,
      "customer_service": 0,
      "legal": 0,
      "human_resources": 0,
      "finance": 0,
      "public_relations": 0,
      "marketing": 0,
      "sales": 0,
      "operations": 0,
      "other_uncategorized": 8
    }
  }
```

### `employee_count_by_class`

|  |  |
| --- | --- |
| Description | The number of current employees broken down by [Job Title Class](https://docs.peopledatalabs.com/docs/job-title-class). |
| Data Type | `Object` |

#### Field Details

The total number of profiles associated with this company at the end of the most recent month, broken down by `experience.title.class`. The role names will always be one of the [Canonical Job Title Class](/docs/job-title-class) labels. This field will also contain an `other_uncategorized` subfield that contains profiles we have associated with the company but do not have enough information to assign a role to.

#### Example

JSON

```
"employee_count_by_class": {
    "other_uncategorized": 16,
    "general_and_administrative": 12,
    "research_and_development": 29,
    "sales_and_marketing": 22,
    "services": 14,
  }
```

### `employee_count_by_role`

|  |  |
| --- | --- |
| Description | The number of employees (`INT`) by Job Role on the final day of the most recent month. |
| Data Type | `Object` |

#### Field Details

The total number of profiles associated with this company at the end of the most recent month, broken down by `experience.title.role`. The role names will always be one of the [Canonical Job Roles](/docs/job-title-roles). This field will also contain an `other_uncategorized` subfield that contains profiles we have associated with the company but do not have enough information to assign a role to.

This field is equivalent to the final month in the [`employee_count_by_month_by_role`](/docs/company-schema#employee_count_by_month_by_role) field.

#### Example

JSON

```
"employee_count_by_role": {
    "real_estate": 0,
    "design": 2,
    "trades": 0,
    "marketing": 4,
    "education": 4,
    "legal": 0,
    "customer_service": 10,
    "finance": 6,
    "public_relations": 1,
    "engineering": 24,
    "human_resources": 3,
    "media": 1,
    "sales": 12,
    "operations": 10,
    "health": 0,
    "other_uncategorized": 10
  }
```

### `employee_count_by_sub_role`

|  |  |
| --- | --- |
| Description | The number of current employees broken down by [Job Title Sub Role](https://docs.peopledatalabs.com/docs/job-title-subroles). |
| Data Type | `Object` |

#### Field Details

The total number of profiles associated with this company at the end of the most recent month, broken down by `experience.title.sub_role`. The role names will always be one of the [Canonical Job Title Subroles](/docs/job-title-subroles). This field will also contain an `other_uncategorized` subfield that contains profiles we have associated with the company but do not have enough information to assign a role to.

#### Example

JSON

```
{
  "employee_count_by_sub_role": {
    "other_uncategorized": 19,
    "health_and_safety": 0,
    "graphic_design": 1,
    "veterinarian": 0,
    "data_science": 2,
    "restaurants": 0,
    "marketing_services": 2,
    "planning_and_analysis": 1,
...
    "mechanical": 0
  }
}
```

## Employee Growth and Churn Rates

All calculation time frames are based on the month that you make the request. If you make the request in April, the three-month rate will use data from January onward.

If no start date is given, then the experience is not counted.

Additionally, if a date only contains a year but no month, it is assumed to be to be January for start dates and December (or the current month if December is in the future) for end dates.

### `employee_churn_rate`

|  |  |
| --- | --- |
| Description | The rate of change in employee headcount from N months prior. |
| Data Type | `Object` |

#### Field Details

This is a representation of net employee turnover. The churn rate is rounded to four decimal points and is always greater than or equal to 0. If the company had 0 employees or did not exist at the start time for a specific window, then the churn rate is `null`.

Churn rate is calculated as `max(employee_count_n_months_ago - employee_count_current, 0)/employee_count_n_months_ago`. For example, if a company has 200 employees at the beginning of the month, and at the end of the month 100 leave and 100 remain then its churn rate = 100 / 200 = 0.5.

| Field | Data Type |
| --- | --- |
| `3_month` | `Float (>= 0)` |
| `6_month` | `Float (>= 0)` |
| `12_month` | `Float (>= 0)` |
| `24_month` | `Float (>= 0)` |

#### Example

JSON

```
"employee_churn_rate": {
    "3_month": 0.015,
    "6_month": 0.02,
    "12_month": 0.035,
    "24_month": 0.155
  }
```

### `employee_growth_rate`

|  |  |
| --- | --- |
| Description | The percentage increase in total headcount from N months prior. |
| Data Type | `Object` |

#### Field Details

The growth rate is rounded to four decimal points and can be negative if the current number of employees is less than in the past. If the company had zero employees or did not exist at the start time for a specific window, then the growth rate is `null`.

Growth rate is calculated as `(current_employee_count / previous_employee_count) - 1`. For example, if a company has 100 employees at the beginning of the month, and at the end of the month has grown to 200 employees then its growth rate = (200 / 100) - 1 = 1.0.

| Field | Data Type |
| --- | --- |
| `3_month` | `Float` |
| `6_month` | `Float` |
| `12_month` | `Float` |
| `24_month` | `Float` |

#### Example

JSON

```
"employee_growth_rate": {
    "3_month": 0.0595,
    "6_month": 0.0723,
    "12_month": 0.8542,
    "24_month": 1.4722
  }
```

### `employee_growth_rate_12_month_by_class`

|  |  |
| --- | --- |
| Description | The twelve month rate of change by [Job Title Class](https://docs.peopledatalabs.com/docs/job-title-class). |
| Data Type | `Object` |

#### Field Details

The 12 month growth rate of the total number of profiles associated with this company at the end of the most recent month in the format `YYYY-MM` broken down by `experience.title.class`. The role names will always be one of the [Canonical Job Title Class](/docs/job-title-class) labels. This field will also contain an `other_uncategorized` subfield that contains profiles we have associated with the company but do not have enough information to assign a role to.

The growth rate is rounded to four decimal points and can be negative if the current number of employees is less than in the past. If the company had zero employees or did not exist at the start time for a specific window, then the growth rate is `null`.

Growth rate is calculated as `(current_employee_count / previous_employee_count) - 1`. For example, if a company has 100 employees at the beginning of the month 12 months ago, and at the end of the most recent month has grown to 200 employees then its growth rate = (200 / 100) - 1 = 1.0.

The 12 month growth rate will be computed using the last full month before the last monthly Data Build. Most often this is the month before request was submitted. For example, if you make a request mid-March, the response will contain the 12 month growth rate from February."

#### Example

JSON

```
"employee_growth_rate_12_month_by_class": {
    "other_uncategorized": 0.2,
    "general_and_administrative": -0.167,
    "research_and_development": 0.1,
    "sales_and_marketing": -0.333,
    "services": 0.0,
  }
```

### `employee_growth_rate_12_month_by_role`

|  |  |
| --- | --- |
| Description | The twelve month rate of change (`FLOAT`) by Job Role on the final day of the most recent month. |
| Data Type | `Object` |

#### Field Details

The 12 month growth rate of the total number of profiles associated with this company at the end of the most recent month in the format `YYYY-MM` broken down by `experience.title.role`. The role names will always be one of the [Canonical Job Roles](/docs/job-title-roles). This field will also contain an `other_uncategorized` subfield that contains profiles we have associated with the company but do not have enough information to assign a role to.

The growth rate is rounded to four decimal points and can be negative if the current number of employees is less than in the past. If the company had zero employees or did not exist at the start time for a specific window, then the growth rate is `null`.

Growth rate is calculated as `(current_employee_count / previous_employee_count) - 1`. For example, if a company has 100 employees at the beginning of the month 12 months ago, and at the end of the most recent month has grown to 200 employees then its growth rate = (200 / 100) - 1 = 1.0.

The 12 month growth rate will be computed using the last full month before the last monthly Data Build. Most often this is the month before request was submitted. For example, if you make a request mid-March, the response will contain the 12 month growth rate from February.

#### Example

JSON

```
"employee_count_12_month_growth_by_role": {
    "real_estate": null,
    "design": -0.2500,
    "trades": null,
    "marketing": -0.5000,
    "education": 0.0000,
    "legal": null,
    "customer_service": -0.4545,
    "finance": -0.2500,
    "public_relations": null,
    "engineering": -0.1220,
    "human_resources": -0.1667,
    "media": 0.0000,
    "sales": -0.1852,
    "operations": 0.000,
    "health": null,
    "other_uncategorized": 0.1471
  }
```

### `employee_growth_rate_12_month_by_sub_role`

|  |  |
| --- | --- |
| Description | The twelve month rate of change by [Job Title Sub Role](https://docs.peopledatalabs.com/docs/job-title-subroles). |
| Data Type | `Object` |

#### Field Details

The 12 month growth rate of the total number of profiles associated with this company at the end of the most recent month in the format `YYYY-MM` broken down by `experience.title.sub_role`. The role names will always be one of the [Canonical Job Title Subroles](/docs/job-title-subroles). This field will also contain an `other_uncategorized` subfield that contains profiles we have associated with the company but do not have enough information to assign a role to.

The growth rate is rounded to four decimal points and can be negative if the current number of employees is less than in the past. If the company had zero employees or did not exist at the start time for a specific window, then the growth rate is `null`.

Growth rate is calculated as `(current_employee_count / previous_employee_count) - 1`. For example, if a company has 100 employees at the beginning of the month 12 months ago, and at the end of the most recent month has grown to 200 employees then its growth rate = (200 / 100) - 1 = 1.0.

The 12 month growth rate will be computed using the last full month before the last monthly Data Build. Most often this is the month before request was submitted. For example, if you make a request mid-March, the response will contain the 12 month growth rate from February.

#### Example

JSON

```
"employee_growth_rate_12_month_by_sub_role": {
    "other_uncategorized": -0.2667,
    "advisory": 0.0,
    "analyst": null,
    "creative": null,
    "education": 0.2,
    "engineering": -0.069,
    "finance": 0.0,
    "health": null,
    "hospitality": null,
    "product_design": -0.675,
    "recruiting": 0.0,
    "manufacturing": null,
    "marketing": 0.0,
    "solutions_engineer": -0.2667,
	...
    "retail": null
  }
```

## Gross Additions and Departures

This insight shows the total number of employees that joined or left the company each month.

The count for each month will always be an integer greater than or equal to zero. The month range begins at the start date of the first associated employee or January 1, 2010, whichever is most recent. The final month in the range will be the last full month before the last monthly [Data Build](/docs/data-build). Most often this is the month before request was submitted. For example, if you make a request mid-March, the response will contain all data up to that February.

This number may be higher or lower than a company's real employee count depending on how many false positives and false negatives we have in our data, missing and duplicate individuals, and missing information on start/end dates.

If a start or end date is not given or only contains a year but no month, it is not counted. This differs from [`employee_count_by_month`](#employee_count_by_month) that assumes January if there is no month.

### `gross_additions_by_month`

|  |  |
| --- | --- |
| Description | The total number of profiles that joined the company each month. |
| Data Type | `Object` |

#### Field Details

The total number of profiles that joined the company each month in the format `YYYY-MM` based on `experience.start_date`.

#### Example

JSON

```
"gross_additions_by_month": {
    "2015-03": 1,
    "2015-04": 1,
    ...
    "2021-05": 2,
    "2021-06": 2
  }
```

### `gross_departures_by_month`

|  |  |
| --- | --- |
| Description | The total number of profiles that left the company each month. |
| Data Type | `Object` |

#### Field Details

The total number of profiles that left the company each month in the format `YYYY-MM` based on `experience.end_date`.

#### Example

JSON

```
"gross_departures_by_month": {
    "2015-03": 1,
    "2015-04": 1,
    ...
    "2021-05": 2,
    "2021-06": 2
  }
```

## Inferred Revenue

### `inferred_revenue`

|  |  |
| --- | --- |
| Description | Company's estimated annual revenue range in US dollars. |
| Data Type | `Enum (String)` |

#### Field Details

A company's inferred revenue is an estimated range of its annual revenue in US dollars and can be used as a filter in [Company Search queries](/docs/company-search-api).

The revenue estimate is calculated using a predictive model that factors in details generated for our [Company Insights Fields](#company-insights-fields) (for example, [employee\_count\_by\_month\_by\_role](#employee_count_by_month_by_role)) as well as for other inputs that have been shown to be highly correlative.

The range will be one of our [Canonical Inferred Revenue Ranges](/docs/inferred-revenue-ranges).

#### Example

JSON

```
"inferred_revenue": "$10M-$25M"
```

## Recent Executive Changes

These insights provide details on executives that have joined or left the company in the past three months at the time you make the request.

There is no limit on the number of executives that can be in either list. To determine if someone is an executive, we check if their `experience.title.levels` in the company matches `CXO`, `owner` or `VP`. If no level is specified, then the experience is not counted.

If a start or end date is not given for an executive, then the experience is not counted. If the date only contains a year, the month is assumed to be January.

### `recent_exec_departures`

|  |  |
| --- | --- |
| Description | The profiles of all of CXOs, owners and VPs that have left the company in the last three months. |
| Data Type | `Array [Object]` |

#### Field Details

For each executive that has left the company in the past three months, we provide the following information:

| Field | Data Type | Description |
| --- | --- | --- |
| `departed_date` | `String (Date: YYYY-MM)` | The month the executive left the company. |
| `pdl_id` | `String` | The ID of the executive in our [Person Dataset](/docs/fields). |
| `job_title` | `String` | The executive's previous job title at the company. |
| `job_title_role` | `Enum (String)` | The executive's previous job role at the company. This will be one of the [Canonical Job Roles](/docs/job-title-roles). |
| `job_title_sub_role` | `Enum (String)` | The executive's previous job subrole at the company. This will be one of the [Canonical Job Subroles](/docs/job-title-subroles). |
| `job_title_class` | `Enum (String)` | The expense line item category this executive would fall into. This will be one of the [Canonical Job Classes](/docs/job-title-class) . |
| `job_title_levels` | `Array [Enum (String)]` | The executive's previous job levels at the company. This will be in the [Canonical Job Levels](/docs/job-title-levels). |
| `new_company_id` | `String` | The [ID](#id) of the new company the executive joined. |
| `new_company_job_title` | `String` | The executive's current job title at the new company. |
| `new_company_job_title_role` | `Enum (String)` | The executive's current job role at the new company. This will be one of the [Canonical Job Roles](/docs/job-title-roles). |
| `new_company_job_title_sub_role` | `Enum (String)` | The executive's current job subrole at the new company. This will be one of the [Canonical Job Classes](/docs/job-title-class) . |
| `new_company_job_title_class` | `Enum (String)` | The executive's current job class at the new company. This will be one of the [Canonical Job Subroles](/docs/job-title-subroles) . |
| `new_company_job_title_levels` | `Array [Enum (String)]` | The executive's current job levels at the new company. This will be in the [Canonical Job Levels](/docs/job-title-levels). |

#### Example

JSON

```
"recent_exec_departures": [
    {
      "departed_date": "2024-06",
      "pdl_id": "sosPKkiBABHsppzWEYyqgg_0000",
      "job_title": "vice president of revenue operations",
      "job_title_role": "analyst",
      "job_title_sub_role": "revenue_operations",
      "job_title_class": "general_and_administrative",
      "job_title_levels": ["vp"],
      "new_company_id": "ZFOfaDnanwu1hrtXsyfFEw521uw0",
      "new_company_job_title": "senior vice president, revenue operations",
      "new_company_job_title_role": "analyst",
      "new_company_job_title_sub_role": "revenue_operations",
      "new_company_job_title_class": "general_and_administrative",
      "new_company_job_title_levels": ["senior", "vp"]
    },
    ...
  ]
```

### `recent_exec_hires`

|  |  |
| --- | --- |
| Description | The profiles of all of CXOs, owners and VPs that have joined the company in the last three months. |
| Data Type | `Array [Object]` |

#### Field Details

For each executive that has joined the company in the past three months, we provide the following information:

| Field | Data Type | Description |
| --- | --- | --- |
| `joined_date` | `String (Date: YYYY-MM)` | The month the executive joined the company. |
| `pdl_id` | `String` | The ID of the executive in our [Person Dataset](/docs/fields). |
| `job_title` | `String` | The executive's current job title at the company. |
| `job_title_role` | `Enum (String)` | The executive's current job role at the company. This will be one of the [Canonical Job Roles](/docs/job-title-roles). |
| `job_title_sub_role` | `Enum (String)` | The executive's current job subrole at the company. This will be one of the [Canonical Job Subroles](/docs/job-title-subroles). |
| `job_title_class` | `Enum (String)` | The expense line item category this executive would fall into. This will be one of the [Canonical Job Classes](/docs/job-title-class) . |
| `job_title_levels` | `Array [Enum (String)]` | The executive's current job level at the company. This will be in the [Canonical Job Levels](/docs/job-title-levels). |
| `previous_company_id` | `String` | The [ID](#id) of the company the executive left. |
| `previous_company_job_title` | `String` | The executive's previous job title at the old company. |
| `previous_company_job_title_role` | `Enum (String)` | The executive's previous job role at the old company. This will be one of the [Canonical Job Roles](/docs/job-title-roles). |
| `previous_company_job_title_sub_role` | `Enum (String)` | The executive's previous job subrole at the old company. This will be one of the [Canonical Job Subroles](/docs/job-title-subroles). |
| `previous_company_job_title_class` | `Enum (String)` | The executive's previous job class at the old company. This will be one of the [Canonical Job Classes](/docs/job-title-class) . |
| `previous_company_job_title_levels` | `Array [Enum (String)]` | The executive's previous job levels at the old company. This will be in the [Canonical Job Levels](/docs/job-title-levels). |

#### Example

JSON

```
"recent_exec_hires": [
  {
    "joined_date": "2024-06",
    "pdl_id": "un-fsOccjHy1yElqJObW6g_0000",
    "job_title": "chief of staff to the chief executive officer and founder",
    "job_title_role": "operations",
    "job_title_sub_role": "aides",
    "job_title_class": "general_and_administrative",
    "job_title_levels": ["owner"],
    "previous_company_id": "RjhjJnYUCiAfXFyxCHLDQQ5opPrK",
    "previous_company_job_title": "business operations manager, reality labs",
    "previous_company_job_title_role": "professional_service",
    "previous_company_job_title_sub_role": "investment_banking",
    "previous_company_job_title_class": null,
    "previous_company_job_title_levels": ["manager"]
  },
    ...
  ]
```

## Top Next and Previous Employers

The top ten next and previous companies employees are broken down by job role.

Companies are listed using their [PDL Company ID](#id).

The first list of companies will be under the `"all"` key. This represents the top 10 companies for any role.

The roles are based on the employeeâ€™s role at the company queried. Each role listed in the break down will come from the [Canonical Job Roles](/docs/job-title-roles).

If no start date is given or no role exists, then the experience is not counted.

If there are fewer than ten next/previous employers for a role, it will return as many as there are.

### `top_next_employers`

|  |  |
| --- | --- |
| Description | The top ten companies employees moved to, and how many employees moved there, across all time periods. |
| Data Type | `Object` |

#### Field Details

This field uses `experience.title.role` and `experience.start_date` to find the top next employers. Companies are ranked by the number of previous employees currently employed there.

A company is considered to be a ""next employer"" if the employee has a start date after their start date for the company being queried.

This field is functionally identical to the legacy `top_next_employers_by_role field`, but adds a displayable company name to the response structure.

#### Example

JSON

```
"top_next_employers": {
  "finance": [
    {
      "id": "3kgY1DOS3BewEUBVRyl5Lg3tl13v",
      "count": 1,
      "display_name": "Essex Property Trust"
    },
    {
      "id": "OCuR0U1nT6kt66YfnUVKlQaeEYUr",
      "count": 1,
      "display_name": "Green Street"
    }
  ],
  "education": [
    {
      "id": "69IOeBijO7bNzClSGs6bxg4Dt7Ge",
      "count": 1,
      "display_name": "DoorDash"
    }
  ],
  "all": [
    {
      "id": "gbzAHmeUyu5rJyy4eUrPPgtM5jdC",
      "count": 5,
      "display_name": "Five by Five"
    },
    {
      "id": "Dn0GAueIRsYzwepbYEGIAQVi7Qyl",
      "count": 3,
      "display_name": "Anaconda"
    },
    ...
  ]
...
}
```

### `top_next_employers_12_month`

|  |  |
| --- | --- |
| Description | The top ten next employers, counting only employee changes within the last 12 months. |
| Data Type | `Object` |

#### Field Details

This field modifies the top\_next\_employers field, with a filter to only count for employees with job changes that have occurred within the last 12 months

#### Example

JSON

```
"top_next_employers_12_month": {
  "education": [
    {
      "id": "69IOeBijO7bNzClSGs6bxg4Dt7Ge",
      "count": 1,
      "display_name": "DoorDash"
    }
  ],
  "all": [
    {
      "id": "gbzAHmeUyu5rJyy4eUrPPgtM5jdC",
      "count": 4,
      "display_name": "Five by Five"
    },
    {
      "id": "Dn0GAueIRsYzwepbYEGIAQVi7Qyl",
      "count": 2,
      "display_name": "Anaconda"
    },
    ...
  ]
...
}
```

### `top_next_employers_by_role`

> âš ï¸
>
> ### Deprecated Field
>
> As of April 2025, the `top_next_employer_by_role` field is deprecated and no longer recommended for use. It will be fully replaced in July 2025 (v31.0) by the new [`top_next_employers`](#top_next_employers) field which is now available in beta. We encourage all users to transition to this new field before the final sunset in July.
>
> For more information please see our [April 2025 Release Notes (v30.0)](/changelog/april-2025-release-notes-v300).

|  |  |
| --- | --- |
| Description | The top ten companies employees moved to and how many employees moved there. |
| Data Type | `Object` |

#### Field Details

This insight uses `experience.title.role` and `experience.start_date` to find the top next employers. Companies are ranked by the number of previous employees currently employed there.

A company is considered to be a "next employer" if the employee has a start date after their start date for the company being queried.

#### Example

JSON

```
"top_next_employers_by_role": {
    "all": {
      "aKCIYBNF9ey6o5CjHCCO4goHYKlf" : 573,
      "RjhjJnYUCiAfXFyxCHLDQQ5opPrK" : 498,
      ...
    },
    "finance": {
      "RZOFiRjw26VpLObnwmYXGgRyn3aW" : 294,
      "BWiTKOBgRTsSttn62R7EBQvww4gF" : 112,
      ...
    },
    ...
  }
```

### `top_previous_employers`

|  |  |
| --- | --- |
| Description | The top ten previous companies employees worked for previously, and how many current employees were previously employed by them, across all time periods. |
| Data Type | `Object` |

#### Field Details

This field uses `experience.title.role` and `experience.start_date` to find the top previous employers. Companies are ranked by the number of current employees previously employed there.

A company is considered to be a "previous employer" if the employee has a start date before their start date for the company being queried.

This field is functionally identical to the legacy `top_previous_employers_by_role field`, but adds a displayable company name to the response structure."

#### Example

JSON

```
"top_previous_employers": {
  "finance": [
    {
      "id": "7L0SglhytLJVj2JOx3PqVgDa2lnM",
      "count": 1,
      "display_name": "MineralTree, Inc."
    },
    {
      "id": "HKCBzjcdUhVPHCmb246CSAYwkTC1",
      "count": 1,
      "display_name": "Center for Effective Government"
    },
    {
      "id": "Pt8QqdHiI5swPLyB4kwkWAnYh66C",
      "count": 1,
      "display_name": "University of Massachusetts Dartmouth"
    }
  ],
  "education": [
    {
      "id": "CKHJ5P60N4XW4oZXB8BdmgKL8vvO",
      "count": 1,
      "display_name": "US Army"
    },
    {
      "id": "DCD55P9HCbJ6EkJhEdPp0AFqPzf3",
      "count": 1,
      "display_name": "Oracle"
    }
  ],
  "all": [
    {
      "id": "aubMfPvUgxL09C7OTtPqqQFVuAR9",
      "count": 11,
      "display_name": "Pipl"
    },
    {
      "id": "Cw9vt7WFFRbhLDnoCeRbswn15Qhi",
      "count": 6,
      "display_name": "Intel Corporation"
    },
    ...
  ]
...
}
```

### `top_previous_employers_12_month`

|  |  |
| --- | --- |
| Description | The top ten previous employers, counting only employee changes within the last 12 months. |
| Data Type | `Object` |

#### Field Details

This field modifies the `top_previous_employers` field, with a filter to only count for employees with job changes that have occurred within the last 12 months

#### Example

JSON

```
"top_previous_employers_12_month": {
  "education": [
    {
      "id": "DCD55P9HCbJ6EkJhEdPp0AFqPzf3",
      "count": 1,
      "display_name": "Oracle"
    }
  ],
  "all": [
    {
      "id": "aubMfPvUgxL09C7OTtPqqQFVuAR9",
      "count": 3,
      "display_name": "Pipl"
    },
    {
      "id": "Cw9vt7WFFRbhLDnoCeRbswn15Qhi",
      "count": 2,
      "display_name": "Intel Corporation"
    },
    ...
  ]
...
}
```

### `top_previous_employers_by_role`

> âš ï¸
>
> ### Deprecated Field
>
> As of April 2025, the `top_previous_employer_by_role` field is deprecated and no longer recommended for use. It will be fully replaced in July 2025 (v31.0) by the new [`top_previous_employers`](#top_previous_employers) field which is now available in beta. We encourage all users to transition to this new field before the final sunset in July.
>
> For more information please see our [April 2025 Release Notes (v30.0)](/changelog/april-2025-release-notes-v300).

|  |  |
| --- | --- |
| Description | The top ten previous companies employees worked for and how many current employees were previously employed by them. |
| Data Type | `Object` |

#### Field Details

This insight uses `experience.title.role` and `experience.start_date` to find the top previous employers. Companies are ranked by the number of current employees previously employed there.

A company is considered to be a "previous employer" if the employee has a start date before their start date for the company being queried.

#### Example

JSON

```
"top_previous_employers_by_role": {
    "all": {
      "aKCIYBNF9ey6o5CjHCCO4goHYKlf" : 573,
      "RjhjJnYUCiAfXFyxCHLDQQ5opPrK" : 498,
      ...
    },
    "finance": {
      "RZOFiRjw26VpLObnwmYXGgRyn3aW" : 294,
      "BWiTKOBgRTsSttn62R7EBQvww4gF" : 112,
      ...
    },
    ...
  }
```

## Top US Metros

### `top_us_employee_metros`

|  |  |
| --- | --- |
| Description | The top ten US metros where employees are based. |
| Data Type | `Object` |

#### Field Details

This insight contains the top ten US metros for the company, ordered by the current headcount at each location. For each metro, we also provide the current headcount and the growth rate in that metro over the last twelve months.

Each metro listed is one of our [Canonical Metros](/docs/location-metros).

To determine the headcount at each location, we use our Person Data to find the location where each current employee works. If an employee does not have location data or they are not based in the US, they are not included in the count.

| Field | Data Type | Description |
| --- | --- | --- |
| `current_headcount` | `Integer (> 0)` | The number of employees in the metro. |
| `12_month_growth_rate` | `Float` | The [growth rate](#employee_growth_rate) in the metro over the last twelve months, precise to fourth decimal place. |

#### Example

JSON

```
"top_us_employee_metros": {
    "san francisco, california, united states" : {
      "current_headcount" : 1207,
      "12_month_growth_rate" : .0040
    },
    "austin, texas, united states" : {
      "current_headcount" : 532,
      "12_month_growth_rate" : .0900
    },
    ...
  }
```

---

# Premium Company Fields

These high-value fields are available through our premium offerings.

## Premium Company Information

### `linkedin_follower_count`

|  |  |
| --- | --- |
| Description | The number of followers on a companyâ€™s LinkedIn profile. |
| Data Type | `Integer (>= 0)` |

#### Field Details

The number of followers on a companyâ€™s LinkedIn profile.

#### Example

JSON

```
"linkedin_follower_count": 5880
```

## Funding Details

### `funding_details`

|  |  |
| --- | --- |
| Description | List of all funding events associated with the company, with corresponding details. |
| Data Type | `Array [Object]` |

#### Field Details

Each publicly disclosed funding event will be added to the `funding_details` list as an Object with the following fields:

| Field | Data Type | Description |
| --- | --- | --- |
| `funding_round_date` | [`String (Date)`](/docs/data-types#dates) | The publicly disclosed date of the closing of the financing event. |
| `funding_raised` | `Float (> 0)` | The total amount raised during the funding event. |
| `funding_currency` | `Enum (String)` | The currency code for the `funding_raised` value. Currently, this will always be `usd`. |
| `funding_type` | `Enum (String)` | The funding stage of the funding event. Must be one of our [Canonical Funding Rounds](/docs/funding-rounds). |
| `investing_companies` | `Array [String]` | The [PDL Company IDs](/docs/company-schema#id) of the investing companies participating in the funding event. |
| `investing_individuals` | `Array [String (Titlecase)]` | The names of any other investing individuals participating in the funding event. |

#### Example

JSON

```
"funding_details": [
    {
      "funding_round_date": "2021-11-16",
      "funding_raised": 45000000.0,
      "funding_currency": "usd",
      "funding_type": "series_b",
      "investing_companies": [
        "UHKkwjzET0f4c2FLBt5BOgB7eZH9",
        "s5O9wCcVnokBzzvX4TQwEwg07z1L"
      ],
      "investing_individuals": [
        "Guillaume \"G\" Cabane"
      ]
    },
    ...
  ]
```

## Parents and Subsidiaries

These insights provide the [company IDs](#id) of the queried company's parent and subsidiary companies.

### `all_subsidiaries`

|  |  |
| --- | --- |
| Description | The [IDs](#id) of every company owned by the queried company. |
| Data Type | `Array [String]` |

#### Field Details

The subsidiary company values will be the [ID](#id) of the company. If no subsidiaries are found, the value will be `null`.

#### Example

JSON

```
"all_subsidiaries" : [
    "HwrPqD6yDTnKmmPQFCgIeQ5hOn8j",
    "xhI4e4JvjGZF4SprW5hhCgmLfVjB",
    "niEc7rpuQ1GXwpuDPeeN2QWYggDC",
    "2BrnzFlEfHtRXJUakLCQYQuO0JnJ",
    "uBF8GihqobELnphsfR9ppwQbM9x7",
    "N7iFUv1vUYWF8t0JXHmL5gvFy4XE",
    "97JIBSIC059vdTevziAFJA7qSRNZ",
    "amtMwZGXmNDYoqBCSQBXQAxXVeWV"
  ]
```

### `direct_subsidiaries`

|  |  |
| --- | --- |
| Description | The [IDs](#id) of each company that the queried company directly owns. |
| Data Type | `Array [String]` |

#### Field Details

The subsidiary company values will be the [ID](#id) of the company. If no subsidiaries are found, the value will be `null`.

#### Example

JSON

```
"direct_subsidiaries" : [
    "HwrPqD6yDTnKmmPQFCgIeQ5hOn8j",
    "2BrnzFlEfHtRXJUakLCQYQuO0JnJ",
    "uBF8GihqobELnphsfR9ppwQbM9x7",
    "N7iFUv1vUYWF8t0JXHmL5gvFy4XE",
    "97JIBSIC059vdTevziAFJA7qSRNZ",
    "amtMwZGXmNDYoqBCSQBXQAxXVeWV"
  ]
```

### `immediate_parent`

|  |  |
| --- | --- |
| Description | The [ID](#id) of the company that directly owns the queried company. |
| Data Type | `String` |

#### Field Details

The parent company value will be the [ID](#id) of the company. If no parents are found, the value will be `null`.

#### Example

JSON

```
"immediate_parent": "amtMwZGXmNDYoqBCSQBXQAxXVeWV"
```

### `ultimate_parent`

|  |  |
| --- | --- |
| Description | The [ID](#id) of the ultimate organizational entity that owns the queried company. |
| Data Type | `String` |

#### Field Details

The parent company value will be the [ID](#id) of the company. If no parents are found, the value will be `null`.

#### Example

JSON

```
"ultimate_parent": "0XQ1XCKrHIFF3H6tBVRdzAIknJNS"
```

### `ultimate_parent_ticker`

|  |  |
| --- | --- |
| Description | Stock symbol of the company's ultimate parent (only for subsidiaries of public companies) |
| Data Type | `String` |

#### Field Details

The `ultimate_parent_ticker` field will be populated for records where the company is a subsidiary of a public company. These companies will also have a [`type`](/docs/company-schema#type) value of `public_subsidiary` following the v28.0 release in October 2024.

#### Example

JSON

```
"ultimate_parent_ticker": "CRM",
```

### `ultimate_parent_mic_exchange`

|  |  |
| --- | --- |
| Description | MIC exchange code that corresponds to the stock exchange of the company's ultimate parent (only for subsidiaries of public companies) |
| Data Type | `String` |

#### Field Details

The `ultimate_parent_mic_exchange` field will be populated for records where the company is a subsidiary of a public company. These companies will also have a [`type`](/docs/company-schema#type) value of `public_subsidiary` following the v28.0 release in October 2024.

#### Example

JSON

```
"ultimate_parent_mic_exchange": "XNYS"
```

## Affiliated Entities

### `affiliated_entities`

|  |  |
| --- | --- |
| Description | An object containing information on related company profiles. |
| Data Type | `Object` |

#### Field Details

| Field | Data Type | Description |
| --- | --- | --- |
| `affiliated_id` | `String` | PDL Company ID of the affiliated company record. |
| `display_name` | `String` | display\_name of the affiliated company record. |
| `relationship` | `Enum (String)` | Categorization of the relationship type to the affiliated company record. The value of this field will be one of our canonical [Relationship Types](/docs/relationship_types) |
| `relationship_catalyst` | `Enum (String)` | Categorization of the event that formed the relationship to the affiliated company record. The value of this field will be one of our canonical [Relationship Catalysts](/docs/relationship_catalysts) |
| `relationship_status` | `Enum (String)` | Whether the relationship is active, pending, or inactive. The value of this field will be one of our canonical [Relationship Statuses](/docs/relationship_status). |
| `start_date` | `String (Date)` | Date when the affiliated company became related. For mergers or acquisitions, this will be the date that the transaction is closed (when that information is available); otherwise, this will be the date announced. |
| `end_date` | `String (Date)` | When applicable, the date when the the affiliated company was divested or otherwise no longer affiliated. |
| `relationship_citations` | `Array [String]` | List of URL links to news articles, press releases, or company webpages that describe the business relationship. |

#### Example

JSON

```
"affiliated_entities": [
    {
      "affiliated_id": "es7LgyqRNsFDLcWXC3WAvACHVh9g",
      "display_name": "Salesforce",
      "relationship": "ultimate_parent"
    }
  ]
```

  

## Office Insights

### `locations`

|  |  |
| --- | --- |
| Description | An object containing increasingly granular information about all locations associated to the company. |
| Data Type | `Object` |

#### Field Details

In addition to a company's location of its Headquarters (HQ) we provide a list of known offices. As of v31.1 (August 2025 Release) we are also tagging offices as active or inactive and the date it was first and last observed in our data sources:

| Field | Data Type | Description |
| --- | --- | --- |
| `first_seen` | `String` | The date that this location was first observed in association with the company record. |
| `last_seen` | `String` | The date that this location was last observed in association with the company record. |
| `is_active` | `Boolean` | Denotes whether this location was active (â€œtrueâ€) or inactive (â€œfalseâ€) as of the last observation. |

For more information on our standard location fields, see [Data Formatting: Locations](/docs/data-formatting#locations).

#### Example

JSON

```
"locations": [
  {
    "name": "palo alto, california, united states",
    "locality": "palo alto",
    "region": "california",
    "metro": "san jose, california",
    "country": "united states",
    "continent": "north america",
    "street_address": "1455 3rd street",
    "address_line_2": null,
    "postal_code": "94304",
    "geo": "37.44,-122.14",
    "first_seen": "2022-06-11",
    "last_seen": "2024-03-12",
    "is_primary": false,
    "is_active": true
  },
  {
    "name": "san francisco, california, united states",
    "locality": "san francisco",
    "region": "california",
    "metro": "san francisco, california",
    "country": "united states",
    "continent": "north america",
    "street_address": "1455 3rd street",
    "address_line_2": null,
    "postal_code": "94108",
    "geo": "37.77,-122.41",
    "first_seen": "2022-06-11",
    "last_seen": "2024-03-12",
    "is_primary": false,
    "is_active": true
  },
  {
    "name": "san francisco, california, united states",
    "locality": "san francisco",
    "region": "california",
    "metro": "san francisco, california",
    "country": "united states",
    "continent": "north america",
    "street_address": "1725 3rd street",
    "address_line_2": null,
    "postal_code": "94158",
    "geo": "37.77,-122.41",
    "first_seen": "2022-06-11",
    "last_seen": "2024-03-12",
    "is_primary": true,
    "is_active": true
  },
```

  

### `num_active_locations`

|  |  |
| --- | --- |
| Description | Count of all active locations associated to the company record. |
| Data Type | `Integer > 0` |

#### Example

JSON

```
"num_active_locations": 20
```

  

### `num_total_locations`

|  |  |
| --- | --- |
| Description | Count of all locations associated with the company record. |
| Data Type | `Integer > 0` |

#### Example

JSON

```
"num_total_locations": 30
```

## Job Posting Insights

These fields provide an aggregate summary of the open and filled job postings at a company.

### `active_job_postings`

|  |  |
| --- | --- |
| Description | Count of distinct, active job postings that existed over the course of the most recent month. |
| Data Type | `Integer` |

#### Example

JSON

```
"active_job_postings": 4
```

### `deactivated_job_postings`

|  |  |
| --- | --- |
| Description | Count of distinct job postings that were removed/no longer captured over the course of the most recent month. |
| Data Type | `Integer` |

#### Example

JSON

```
"deactivated_job_postings": 3
```

### `active_job_postings_by_role`

|  |  |
| --- | --- |
| Description | Count of distinct, active job postings that existed over the course of the most recent month, categorized by Job Title Role. |
| Data Type | `Object` |

#### Example

JSON

```
"active_job_postings_by_role": {
    "support": 1,
    "product": 1,
    "engineering": 2
}
```

### `deactivated_job_postings_by_role`

|  |  |
| --- | --- |
| Description | Count of distinct, active job postings that were removed/no longer captured over the course of the most recent month, categorized by Job Title Role. |
| Data Type | `Object` |

#### Example

JSON

```
"deactivated_job_postings_by_role": {
    "other_uncategorized": 1,
    "product": 1,
    "engineering": 1
}
```

### `active_job_postings_by_class`

|  |  |
| --- | --- |
| Description | Count of distinct, active job postings that existed over the course of the most recent month, categorized by Job Title Class. |
| Data Type | `Object` |

#### Example

JSON

```
"active_job_postings_by_class": {
    "general_and_administrative": 1,
    "research_and_development": 2,
    "services": 1
}
```

### `deactivated_job_postings_by_class`

|  |  |
| --- | --- |
| Description | Count of distinct, active job postings that existed over the course of the most recent month, categorized by Job Title Class. |
| Data Type | `Object` |

#### Example

JSON

```
"deactivated_job_postings_by_class": {
    "other_uncategorized": 1,
    "general_and_administrative": 1,
    "research_and_development": 2
}
```

### `active_job_postings_by_sub_role`

|  |  |
| --- | --- |
| Description | Count of distinct, active job postings that existed over the course of the most recent month, categorized by Job Title Subrole. |
| Data Type | `Object` |

#### Example

JSON

```
"active_job_postings_by_sub_role": {
  "other_uncategorized": 1,
  "product_management" : 1,
  "data_engineering" : 2   
}
```

### `deactivated_job_postings_by_sub_role`

|  |  |
| --- | --- |
| Description | Count of distinct, active job postings that were removed/no longer captured over the course of the most recent month, categorized by Job Title Subrole. |
| Data Type | `Object` |

#### Example

JSON

```
"deactivated_job_postings_by_sub_role": {
  "other_uncategorized": 1,
  "product_management" : 1,
  "data_engineering" : 1   
}
```

### `active_job_postings_by_country`

|  |  |
| --- | --- |
| Description | Count of distinct, active job postings that existed over the course of the most recent month, categorized by the Country of the job posting. |
| Data Type | `Object` |

#### Example

JSON

```
"active_job_postings_by_country": {
    "other_uncategorized": 1,
    "remote_location": 8,
    "brazil": 36,
    "united states": 331,
    "canada": 84,
    "netherlands": 2
}
```

### `active_job_postings_by_metro`

|  |  |
| --- | --- |
| Description | Count of distinct, active job postings that existed over the course of the most recent month, categorized by the Metro of the job posting. |
| Data Type | `Object` |

#### Example

JSON

```
"active_job_postings_by_metro": {
    "other_uncategorized": 142,
    "remote_location": 8,
    "denver, colorado, united states": 1,
    "san francisco, california, united states": 127,
    "seattle, washington, united states": 35,
    "atlanta, georgia, united states": 1,        
    "new york, new york, united states": 100,
    "salt lake city, utah, united states": 54,
    "austin, texas, united states": 1,
    "san diego, california, united states": 1
}
```

### `active_job_postings_by_month`

|  |  |
| --- | --- |
| Description | Count of distinct, active job postings that existed over the course of each month. |
| Data Type | `Object` |

#### Example

JSON

```
"active_job_postings_by_month": {
    "2024-10": 2,
    "2024-11": 3,
    "2024-12": 4,
    "2025-01": 7,
    "2025-02": 4
}
```

### `deactivated_job_postings_by_month`

|  |  |
| --- | --- |
| Description | Count of distinct, active job postings that were removed/no longer captured over the course of each month. |
| Data Type | `Object` |

#### Example

JSON

```
"deactivated_job_postings_by_month": {
    "2024-12": 1,
    "2025-01": 0,
    "2025-02": 4
}
```

Updated 2 months ago

---

* [Company Stats](/docs/company-stats)
* [Example Company Record](/docs/example-company-record)
* [Company Enrichment API](/docs/company-enrichment-api)
* [Company Search API](/docs/company-search-api)

Did this page help you?

Yes

No

---
# https://docs.peopledatalabs.com/docs/email-data-for-outreach

## Overview

PDL provides many email-related fields to support a variety of different use cases, ranging from powering direct outreach to matching profiles for entity resolution.

In this guide weâ€™ll focus specifically on using PDLâ€™s email data for **email outreach**. This includes powering your outreach campaigns, supplying contact info in your platform to your own end users, and any other scenario where the intention is to use PDLâ€™s email data to reach out to a specific target audience.

This page will explain which fields to use, which to avoid, and why.

> ðŸ“˜
>
> **TLDR**
>
> For email outreach, **use only**:
>
> * âœ… [`recommended_personal_email`](/v5.0_email_deliverability_callouts/docs/fields)
> * âœ… [`work_email`](/v5.0_email_deliverability_callouts/docs/fields)
>
> Do **not** use:
>
> * âŒ [`emails`](/v5.0_email_deliverability_callouts/docs/fields)
> * âŒ [`personal_emails`](/v5.0_email_deliverability_callouts/docs/fields)
>
> The latter two fields include historical emails and have lower deliverability rates.

## Which email fields should you use?

The only fields that PDL recommends using for email outreach are the following two fields:

* [`recommended_personal_email`](/v5.0_email_deliverability_callouts/docs/fields)
* [`work_email`](/v5.0_email_deliverability_callouts/docs/fields)

These two fields are intended to represent a personâ€™s **current** personal and work email and are the best-suited fields for connecting with a person. Furthermore, as of October 2025, we have also increased our efforts to validate the deliverability of emails in these two fields ([more details below](#pdl-email-deliverability-improvements)).

[`recommended_personal_email`](/v5.0_email_deliverability_callouts/docs/fields)

* Best available ***personal*** email for outreach
* Ideal for **non-work-related communication**
* Optimized for direct contact and higher deliverability
* Selected from the `personal_emails` field

[`work_email`](/v5.0_email_deliverability_callouts/docs/fields)

* Most up-to-date ***professional*** email address
* Intended for **business-related outreach**
* Optimized to reduce bounces from outdated work emails

### Which to use?

Which you use depends on your specific goals, but a general pattern we see with our users is:

* **Recruiting/Candidate Outreach** use cases tend to leverage the [`recommended_personal_email`](/v5.0_email_deliverability_callouts/docs/fields) field in order to connect with candidates outside of their work inbox
* **Sales/Marketing Outreach** use cases tend to prefer the [`work_email`](/v5.0_email_deliverability_callouts/docs/fields) field in order to reach contacts within their professional work environment.

## What about PDL's other email fields?

In the Person Schema, you will find several other email-related fields alongside the two mentioned above:

* [`emails`](/v5.0_email_deliverability_callouts/docs/fields)
* [`personal_emails`](/v5.0_email_deliverability_callouts/docs/fields)

However, unlike the [`recommended_personal_email`](/v5.0_email_deliverability_callouts/docs/fields) and [`work_email`](/v5.0_email_deliverability_callouts/docs/fields) fields, these fields are meant to track **both current and historical** emails, with the primary goal being entity resolution (e.g. matching data to a profile based on any of the emails ever associated with that individual).

As a result, **we do not make any efforts to ensure the current or deliverability status of the emails in these fields**, and only focus on ensuring that the emails can be confidently associated to a profile at any point in its history.

Therefore, we **strongly discourage** the use of these fields in your outreach efforts, especially without additional effort on your part to ensure the emails are deliverable and active.

> âš ï¸
>
> **What happens if you use historical emails for outreach?**
>
> Using outdated or inactive emails in your outreach can significantly harm both campaign performance and, more importantly, your sender reputation. These addresses increase bounce rates, trigger spam complaints, and waste valuable resources.
>
> A damaged sender reputation - marked by high bounces and low engagement - causes emails to be filtered into spam folders or blocked entirely, making it difficult to reach your audience. Because sender reputation takes a long time to recover, the consequences of poor list hygiene can be long-lasting.

## Email outreach best practices

> ðŸ“˜
>
> **PDL Email Outreach Best Practice Guide**
>
> As a resource for our users, here is an in-depth guide on Email Outreach Best Practices, created by our Solutions Engineering Team:
>
> [A Practical Guide for Effective Email Outreach](https://www.peopledatalabs.com/pdf/email-outreach-guide.pdf)

Apart from using the correct email fields, there are some key best practices that we strongly encourage our users to follow when launching and running their outreach campaigns. These include:

1. Validating Emails to minimize bounce rates
2. Leverage domain warmup strategies to protect sender reputation
3. Ongoing monitoring of campaign performance metrics

These are covered in detail in our email outreach best practice guide linked at the top of this section.

The one we will take a closer look at here is **email validation**

### Email Validation

Whether you are getting your emails from PDL or any other data provider, it is important to always ensure the deliverability of any emails you intend to use in your outreach. As we explained above, any inactive or non-deliverable emails that get included in your outreach can have extremely damaging long-term effects on your ability to send outreach in the future.

> âš ï¸
>
> Emails can become inactive or invalid at any time, and so even previously validated emails should be revalidated immediately before outreach. This is true for any emails you use whether they come from PDL or other providers.

**Recommendations**

Our recommendation is to validate your emails **once a quarter at minimum**, but ideally **immediately before kicking off any large outreach campaigns** or **anytime you begin to notice large drops in deliverability**.

**Email Validation Services**

To validate the deliverability of your emails, there are a variety of trusted validation services available on the market.

PDL customers have access to [discount incentives](https://withlove.usebouncer.com/afiuucaft7je) through our partnership with [Bouncer.com](http://Bouncer.com), but there are many other similar providers available.

The most important thing is that you are able to verify the deliverability status of the emails you intend to use to ensure that you do not include any emails that are no longer active or deliverable.

## PDL Email Deliverability Improvements

In October 2025, PDL kicked off an initiative to revitalize and revamp the way email validation is done on our top-level email fields. In particular, we began validating and removing non-deliverable emails from the [`recommended_personal_email`](/v5.0_email_deliverability_callouts/docs/fields) and [`work_email`](/v5.0_email_deliverability_callouts/docs/fields) fields.

The goal of this initiative is to ensure higher success rates when using these fields for outreach and to help provide ongoing deliverability validation for these emails. This work is expected to continue into the first few couple quarters of 2026.

**Note that this work does not change our recommendation to continue validating any emails you intend to use for outreach since an emailâ€™s deliverability status can change on any given day.**

For more information on these deliverability improvements, please see our [October 2025 (v32.0) Release Notes](/v5.0_email_deliverability_callouts/changelog/october-2025-release-notes-v320) as well as this guide on these changes put together by our Solutions Engineering Team: [PDL Email Deliverability Improvements](https://www.peopledatalabs.com/pdf/email-deliverability-improvements-guide.pdf).

## Wrapping Up

PDLâ€™s email data can be a powerful input for outreach when used correctly. For any email-based outreach use case, always rely on `recommended_personal_email` and `work_email`, as these fields are designed to represent a personâ€™s current contact information and are actively optimized for deliverability.

Avoid using historical email fields like `emails` and `personal_emails` for outreach, as they are intended for entity resolution and can negatively impact campaign performance and sender reputation.

Finally, remember that even high-quality email data requires good hygiene. Regular email validation, ongoing performance monitoring, and adherence to outreach best practices are essential to protecting deliverability and maximizing results. When combined with these practices, PDLâ€™s recommended email fields provide a strong foundation for effective, scalable email outreach.

  
> ðŸ“˜
>
> **Resources**
>
> * [Person Schema](/v5.0_email_deliverability_callouts/docs/person-data-overview)
> * [A Practical Guide for Effective Email Outreach](https://www.peopledatalabs.com/pdf/email-outreach-guide.pdf)
> * [October 2025 (v32.0) Release Notes](/v5.0_email_deliverability_callouts/changelog/october-2025-release-notes-v320)
> * [Email Deliverability Improvements Guide](https://www.peopledatalabs.com/pdf/email-deliverability-improvements-guide.pdf)

Updated 30 days ago

---

Did this page help you?

Yes

No

---
# https://docs.peopledatalabs.com/docs/errors

Our APIs use conventional HTTP response status codes to indicate the success or failure of a request. A `200` means that an API returned a matching record, and a `404` means that an API neither found nor returned a matching record. Any `4xx` code besides a `404` indicates that there was an issue with the request, and `5xx` codes indicate that an internal issue with the API occurred.

## Error & Status Response Fields

When an API call fails (does not return `200` or `404` response code), it will return an error response to help debug what went wrong with the request. The error response will be a JSON object with the following fields:

| Field Name | Type | Description |
| --- | --- | --- |
| `status` | `Integer` | The HTTP response status code. |
| `error` | `Object` | The object containing the error type and message. See [error codes](#error-codes) for examples. |
| `error.type` | `String` | The error type. |
| `error.message` | `String` | The error message. |

### Example 404 Response

JSON

```
{
    "status": 404,
    "error": {
        "type": "not_found",
        "message": "No records were found matching your request"
    }
}
```

### Example 429 Response

JSON

```
{
    "status": 429,
    "error": {
        "type": "rate_limit_error",
        "message": "An error occurred due to requests hitting the API too quick"
    }
}
```

## Error Codes

| Status | Status/ErrorÂ Name | Description |
| --- | --- | --- |
| `400` | `invalid_request_error` | The request contained either missing or invalid parameters. |
| `401` | `authentication_error` | The request contained a missing or invalid key. |
| `402` | `payment_required` | You have reached your account maximum (all matches have been used). |
| `405` | `invalid_request_error` | You cannot use the request method on the requested resource. |
| `429` | `rate_limit_error` | An error occurred due to requests hitting the API too quick. |
| `5xx` | `api_error` | The server encountered an unexpected condition that prevented it from fulfilling the request. |

## Status Codes

| Status | Status/ErrorÂ Name | Description |
| --- | --- | --- |
| `200` | `request successful` | If Search API, your request was successful. If Enrichment API: your request yielded a match. |
| `404` | `not_found` | While technically labeled as an error in the response, this simply means there were no profiles found matching your request. |

## Best Practice

Use proper error handling techniques for all status codes and error codes. This is especially essential for looped Search API requests.

Updated 4 months ago

---

Did this page help you?

Yes

No

---
# https://docs.peopledatalabs.com/docs/canonical-data

# Overview

For several of the field types in our [Person Schema](/docs/fields) and [Company Schema](/docs/company-schema), we have enumerated the standard set of values that they are allowed to take on. For example, we have defined all the degree types that our data can take on with the canonical field values listed in [Education Degrees](/docs/education-degrees).

To see which files correspond to which fields in each schema, see our [person fields](/docs/fields) and [company fields](/docs/company-schema). Please feel free to use any of these that'd be helpful to you.

## Where to Access

Datasets of possible values for many of our fields can be found in this [public Amazon S3 Bucket](https://s3.console.aws.amazon.com/s3/buckets/pdl-prod-schema/). Our current data version is [33.1](https://s3.console.aws.amazon.com/s3/buckets/pdl-prod-schema?region=us-west-2&prefix=33.1/enums/).

We update our canonical data quarterly, either by migrating the same file into a new folder or by updating the file. We will note any updated or changed files in the [Release Notes](/docs/changelog).

Updated 6 days ago

---

Did this page help you?

Yes

No

---
# https://docs.peopledatalabs.com/docs/person-data-field-bundles

## Base

| Field | Bundle |
| --- | --- |
| [birth\_date](/docs/fields#birth_date) | Base |
| [birth\_year](/docs/fields#birth_year) | Base |
| [countries](/docs/fields#countries) | Base |
| [dataset\_version](/docs/fields#dataset_version) | Base |
| [education](/docs/fields#education-1) | Base |
| [education.degrees](/docs/fields#education-1) | Base |
| [education.end\_date](/docs/fields#education-1) | Base |
| [education.gpa](/docs/fields#education-1) | Base |
| [education.majors](/docs/fields#education-1) | Base |
| [education.minors](/docs/fields#education-1) | Base |
| [education.school](/docs/fields#educationschool) | Base |
| [education.school.domain](/docs/fields#educationschool) | Base |
| [education.school.facebook\_url](/docs/fields#educationschool) | Base |
| [education.school.id](/docs/fields#educationschool) | Base |
| [education.school.linkedin\_id](/docs/fields#educationschool) | Base |
| [education.school.linkedin\_url](/docs/fields#educationschool) | Base |
| [education.school.location](/docs/fields#educationschool) | Base |
| [education.school.location.continent](/docs/fields#educationschool) | Base |
| [education.school.location.country](/docs/fields#educationschool) | Base |
| [education.school.location.locality](/docs/fields#educationschool) | Base |
| [education.school.location.name](/docs/fields#educationschool) | Base |
| [education.school.location.region](/docs/fields#educationschool) | Base |
| [education.school.name](/docs/fields#educationschool) | Base |
| [education.school.twitter\_url](/docs/fields#educationschool) | Base |
| [education.school.type](/docs/fields#educationschool) | Base |
| [education.school.website](/docs/fields#educationschool) | Base |
| [education.start\_date](/docs/fields#education-1) | Base |
| [emails](/docs/fields#emails) | Base |
| [emails.address](/docs/fields#emails) | Base |
| [emails.type](/docs/fields#emails) | Base |
| [experience](/docs/fields#experience) | Base |
| [experience.company](/docs/fields#experiencecompany) | Base |
| [experience.company.facebook\_url](/docs/fields#experiencecompany) | Base |
| [experience.company.founded](/docs/fields#experiencecompany) | Base |
| [experience.company.id](/docs/fields#experiencecompany) | Base |
| [experience.company.industry](/docs/fields#experiencecompany) | Base |
| [experience.company.industry\_v2](/docs/fields#experiencecompany) | Base |
| [experience.company.linkedin\_id](/docs/fields#experiencecompany) | Base |
| [experience.company.linkedin\_url](/docs/fields#experiencecompany) | Base |
| [experience.company.location](/docs/fields#experiencecompany) | Base |
| [experience.company.location.address\_line\_2](/docs/fields#experiencecompany) | Base |
| [experience.company.location.continent](/docs/fields#experiencecompany) | Base |
| [experience.company.location.country](/docs/fields#experiencecompany) | Base |
| [experience.company.location.geo](/docs/fields#experiencecompany) | Base |
| [experience.company.location.locality](/docs/fields#experiencecompany) | Base |
| [experience.company.location.metro](/docs/fields#experiencecompany) | Base |
| [experience.company.location.name](/docs/fields#experiencecompany) | Base |
| [experience.company.location.postal\_code](/docs/fields#experiencecompany) | Base |
| [experience.company.location.region](/docs/fields#experiencecompany) | Base |
| [experience.company.location.street\_address](/docs/fields#experiencecompany) | Base |
| [experience.company.name](/docs/fields#experiencecompany) | Base |
| [experience.company.size](/docs/fields#experiencecompany) | Base |
| [experience.company.twitter\_url](/docs/fields#experiencecompany) | Base |
| [experience.company.website](/docs/fields#experiencecompany) | Base |
| [experience.end\_date](/docs/fields#experience) | Base |
| [experience.is\_primary](/docs/fields#experience) | Base |
| [experience.location\_names](/docs/fields#experience) | Base |
| [experience.start\_date](/docs/fields#experience) | Base |
| [experience.title](/docs/fields#experiencetitle) | Base |
| [experience.title.levels](/docs/fields#experiencetitle) | Base |
| [experience.title.name](/docs/fields#experiencetitle) | Base |
| [experience.title.role](/docs/fields#experiencetitle) | Base |
| [experience.title.sub\_role](/docs/fields#experiencetitle) | Base |
| [experience.title.class](/docs/fields#experiencetitle) | Base |
| [facebook\_id](/docs/fields#facebook_id) | Base |
| [facebook\_url](/docs/fields#facebook_url) | Base |
| [facebook\_username](/docs/fields#facebook_username) | Base |
| [first\_name](/docs/fields#first_name) | Base |
| [full\_name](/docs/fields#full_name) | Base |
| [sex](/docs/fields#sex) | Base |
| [github\_url](/docs/fields#github_url) | Base |
| [github\_username](/docs/fields#github_username) | Base |
| [id](/docs/fields#id) | Base |
| [industry](/docs/fields#industry) | Base |
| [interests](/docs/fields#interests) | Base |
| [job\_company\_facebook\_url](/docs/fields#job_company_facebook_url) | Base |
| [job\_company\_founded](/docs/fields#job_company_founded) | Base |
| [job\_company\_id](/docs/fields#job_company_id) | Base |
| [job\_company\_industry](/docs/fields#job_company_industry) | Base |
| [job\_company\_industry\_v2](/docs/fields#job_company_industry_v2) | Base |
| [job\_company\_linkedin\_id](/docs/fields#job_company_linkedin_id) | Base |
| [job\_company\_linkedin\_url](/docs/fields#job_company_linkedin_url) | Base |
| [job\_company\_location\_address\_line\_2](/docs/fields#job_company_location_address_line_2) | Base |
| [job\_company\_location\_continent](/docs/fields#job_company_location_continent) | Base |
| [job\_company\_location\_country](/docs/fields#job_company_location_country) | Base |
| [job\_company\_location\_geo](/docs/fields#job_company_location_geo) | Base |
| [job\_company\_location\_locality](/docs/fields#job_company_location_locality) | Base |
| [job\_company\_location\_metro](/docs/fields#job_company_location_metro) | Base |
| [job\_company\_location\_name](/docs/fields#job_company_location_name) | Base |
| [job\_company\_location\_postal\_code](/docs/fields#job_company_location_postal_code) | Base |
| [job\_company\_location\_region](/docs/fields#job_company_location_region) | Base |
| [job\_company\_location\_street\_address](/docs/fields#job_company_location_street_address) | Base |
| [job\_company\_name](/docs/fields#job_company_name) | Base |
| [job\_company\_size](/docs/fields#job_company_size) | Base |
| [job\_company\_twitter\_url](/docs/fields#job_company_twitter_url) | Base |
| [job\_company\_website](/docs/fields#job_company_website) | Base |
| [job\_last\_changed](/docs/fields#job_last_changed) | Base |
| [job\_last\_verified](/docs/fields#job_last_verified) | Base |
| [job\_start\_date](/docs/fields#job_start_date) | Base |
| [job\_title](/docs/fields#job_title) | Base |
| [job\_title\_levels](/docs/fields#job_title_levels) | Base |
| [job\_title\_role](/docs/fields#job_title_role) | Base |
| [job\_title\_sub\_role](/docs/fields#job_title_sub_role) | Base |
| [job\_title\_class](/docs/fields#job_title_class) | Base |
| [last\_initial](/docs/fields#last_initial) | Base |
| [last\_name](/docs/fields#last_name) | Base |
| [linkedin\_id](/docs/fields#linkedin_id) | Base |
| [linkedin\_url](/docs/fields#linkedin_url) | Base |
| [linkedin\_username](/docs/fields#linkedin_username) | Base |
| [location\_address\_line\_2](/docs/fields#location_address_line_2) | Base |
| [location\_continent](/docs/fields#location_continent) | Base |
| [location\_country](/docs/fields#location_country) | Base |
| [location\_geo](/docs/fields#location_geo) | Base |
| [location\_last\_updated](/docs/fields#location_last_updated) | Base |
| [location\_locality](/docs/fields#location_locality) | Base |
| [location\_metro](/docs/fields#location_metro) | Base |
| [location\_name](/docs/fields#location_name) | Base |
| [location\_names](/docs/fields#location_names) | Base |
| [location\_postal\_code](/docs/fields#location_postal_code) | Base |
| [location\_region](/docs/fields#location_region) | Base |
| [location\_street\_address](/docs/fields#location_street_address) | Base |
| [middle\_initial](/docs/fields#middle_initial) | Base |
| [middle\_name](/docs/fields#middle_name) | Base |
| [mobile\_phone](/docs/fields#mobile_phone) | Base |
| [operation\_id](/docs/fields#operation_id) | Base |
| [personal\_emails](/docs/fields#personal_emails) | Base |
| [phone\_numbers](/docs/fields#phone_numbers) | Base |
| [profiles](/docs/fields#profiles) | Base |
| [profiles.id](/docs/fields#profiles) | Base |
| [profiles.network](/docs/fields#profiles) | Base |
| [profiles.url](/docs/fields#profiles) | Base |
| [profiles.username](/docs/fields#profiles) | Base |
| [recommended\_personal\_email](/docs/fields#recommended_personal_email) | Base |
| [regions](/docs/fields#regions) | Base |
| [skills](/docs/fields#skills) | Base |
| [street\_addresses](/docs/fields#street_addresses) | Base |
| [street\_addresses.address\_line\_2](/docs/fields#street_addresses) | Base |
| [street\_addresses.continent](/docs/fields#street_addresses) | Base |
| [street\_addresses.country](/docs/fields#street_addresses) | Base |
| [street\_addresses.geo](/docs/fields#street_addresses) | Base |
| [street\_addresses.locality](/docs/fields#street_addresses) | Base |
| [street\_addresses.metro](/docs/fields#street_addresses) | Base |
| [street\_addresses.name](/docs/fields#street_addresses) | Base |
| [street\_addresses.postal\_code](/docs/fields#street_addresses) | Base |
| [street\_addresses.region](/docs/fields#street_addresses) | Base |
| [street\_addresses.street\_address](/docs/fields#street_addresses) | Base |
| [twitter\_url](/docs/fields#twitter_url) | Base |
| [twitter\_username](/docs/fields#twitter_username) | Base |
| [work\_email](/docs/fields#work_email) | Base |

## Premium Resume Fields

| Field | Bundle |
| --- | --- |
| [certifications](/docs/fields#certifications) | Premium Resume Fields |
| [certifications.end\_date](/docs/fields#certifications) | Premium Resume Fields |
| [certifications.name](/docs/fields#certifications) | Premium Resume Fields |
| [certifications.organization](/docs/fields#certifications) | Premium Resume Fields |
| [certifications.start\_date](/docs/fields#certifications) | Premium Resume Fields |
| [education.summary](/docs/fields#education-1) | Premium Resume Fields |
| [experience.summary](/docs/fields#experience) | Premium Resume Fields |
| [headline](/docs/fields#headline) | Premium Resume Fields |
| [job\_summary](/docs/fields#job_summary) | Premium Resume Fields |
| [languages](/docs/fields#languages) | Premium Resume Fields |
| [languages.name](/docs/fields#languages) | Premium Resume Fields |
| [languages.proficiency](/docs/fields#languages) | Premium Resume Fields |
| [summary](/docs/fields#summary) | Premium Resume Fields |

## Ticker Information

| Field | Bundle |
| --- | --- |
| [experience.company.ticker](/docs/fields#experiencecompany) | Ticker Information |
| [experience.company.type](/docs/fields#experiencecompany) | Ticker Information |
| [job\_company\_ticker](/docs/fields#job_company_ticker) | Ticker Information |
| [job\_company\_type](/docs/fields#job_company_type) | Ticker Information |

## Raw Fields

| Field | Bundle |
| --- | --- |
| [education.raw](/docs/fields#education-1) | Raw Fields |
| [education.school.raw](/docs/fields#educationschool) | Raw Fields |
| [experience.company.raw](/docs/fields#experiencecompany) | Raw Fields |
| [experience.title.raw](/docs/fields#experiencetitle) | Raw Fields |

## Inferred Salary

| Field | Bundle |
| --- | --- |
| [`inferred_salary`](/docs/fields#inferred_salary) | Inferred Salary |

## Inferred Years Experience

| Field | Bundle |
| --- | --- |
| [`inferred_years_experience`](/docs/fields#inferred_years_experience) | Inferred Years Experience |

## Linkedin Connections

| Field | Bundle |
| --- | --- |
| [`linkedin_connections`](/docs/fields#linkedin_connections) | Linkedin Connections |

## Person Risk Attributes

| Field | Bundle |
| --- | --- |
| [emails.first\_seen](/docs/fields#emails) | Person Risk Attributes |
| [emails.last\_seen](/docs/fields#emails) | Person Risk Attributes |
| [emails.num\_sources](/docs/fields#emails) | Person Risk Attributes |
| [experience.first\_seen](/docs/fields#experience) | Person Risk Attributes |
| [experience.last\_seen](/docs/fields#experience) | Person Risk Attributes |
| [experience.num\_sources](/docs/fields#experience) | Person Risk Attributes |
| [facebook\_friends](/docs/fields#facebook_friends) | Person Risk Attributes |
| [first\_seen](/docs/fields#first_seen) | Person Risk Attributes |
| [job\_history](/docs/fields#job_history) | Person Risk Attributes |
| [job\_history.company\_id](/docs/fields#job_history) | Person Risk Attributes |
| [job\_history.company\_name](/docs/fields#job_history) | Person Risk Attributes |
| [job\_history.first\_seen](/docs/fields#job_history) | Person Risk Attributes |
| [job\_history.last\_seen](/docs/fields#job_history) | Person Risk Attributes |
| [job\_history.num\_sources](/docs/fields#job_history) | Person Risk Attributes |
| [job\_history.title](/docs/fields#job_history) | Person Risk Attributes |
| [name\_aliases](/docs/fields#name_aliases) | Person Risk Attributes |
| [num\_records](/docs/fields#num_records) | Person Risk Attributes |
| [num\_sources](/docs/fields#num_sources) | Person Risk Attributes |
| [phones](/docs/fields#phones) | Person Risk Attributes |
| [phones.first\_seen](/docs/fields#phones) | Person Risk Attributes |
| [phones.last\_seen](/docs/fields#phones) | Person Risk Attributes |
| [phones.num\_sources](/docs/fields#phones) | Person Risk Attributes |
| [phones.number](/docs/fields#phones) | Person Risk Attributes |
| [possible\_birth\_dates](/docs/fields#possible_birth_dates) | Person Risk Attributes |
| [possible\_emails](/docs/fields#possible_emails) | Person Risk Attributes |
| [possible\_emails.address](/docs/fields#possible_emails) | Person Risk Attributes |
| [possible\_emails.first\_seen](/docs/fields#possible_emails) | Person Risk Attributes |
| [possible\_emails.last\_seen](/docs/fields#possible_emails) | Person Risk Attributes |
| [possible\_emails.num\_sources](/docs/fields#possible_emails) | Person Risk Attributes |
| [possible\_emails.type](/docs/fields#possible_emails) | Person Risk Attributes |
| [possible\_location\_names](/docs/fields#possible_location_names) | Person Risk Attributes |
| [possible\_phones](/docs/fields#possible_phones) | Person Risk Attributes |
| [possible\_phones.first\_seen](/docs/fields#possible_phones) | Person Risk Attributes |
| [possible\_phones.last\_seen](/docs/fields#possible_phones) | Person Risk Attributes |
| [possible\_phones.num\_sources](/docs/fields#possible_phones) | Person Risk Attributes |
| [possible\_phones.number](/docs/fields#possible_phones) | Person Risk Attributes |
| [possible\_profiles](/docs/fields#possible_profiles) | Person Risk Attributes |
| [possible\_profiles.first\_seen](/docs/fields#possible_profiles) | Person Risk Attributes |
| [possible\_profiles.id](/docs/fields#possible_profiles) | Person Risk Attributes |
| [possible\_profiles.last\_seen](/docs/fields#possible_profiles) | Person Risk Attributes |
| [possible\_profiles.network](/docs/fields#possible_profiles) | Person Risk Attributes |
| [possible\_profiles.num\_sources](/docs/fields#possible_profiles) | Person Risk Attributes |
| [possible\_profiles.url](/docs/fields#possible_profiles) | Person Risk Attributes |
| [possible\_profiles.username](/docs/fields#possible_profiles) | Person Risk Attributes |
| [possible\_street\_addresses](/docs/fields#possible_street_addresses) | Person Risk Attributes |
| [possible\_street\_addresses.address\_line\_2](/docs/fields#possible_street_addresses) | Person Risk Attributes |
| [possible\_street\_addresses.continent](/docs/fields#possible_street_addresses) | Person Risk Attributes |
| [possible\_street\_addresses.country](/docs/fields#possible_street_addresses) | Person Risk Attributes |
| [possible\_street\_addresses.first\_seen](/docs/fields#possible_street_addresses) | Person Risk Attributes |
| [possible\_street\_addresses.geo](/docs/fields#possible_street_addresses) | Person Risk Attributes |
| [possible\_street\_addresses.last\_seen](/docs/fields#possible_street_addresses) | Person Risk Attributes |
| [possible\_street\_addresses.locality](/docs/fields#possible_street_addresses) | Person Risk Attributes |
| [possible\_street\_addresses.metro](/docs/fields#possible_street_addresses) | Person Risk Attributes |
| [possible\_street\_addresses.name](/docs/fields#possible_street_addresses) | Person Risk Attributes |
| [possible\_street\_addresses.num\_sources](/docs/fields#possible_street_addresses) | Person Risk Attributes |
| [possible\_street\_addresses.postal\_code](/docs/fields#possible_street_addresses) | Person Risk Attributes |
| [possible\_street\_addresses.region](/docs/fields#possible_street_addresses) | Person Risk Attributes |
| [possible\_street\_addresses.street\_address](/docs/fields#possible_street_addresses) | Person Risk Attributes |
| [profiles.first\_seen](/docs/fields#profiles) | Person Risk Attributes |
| [profiles.last\_seen](/docs/fields#profiles) | Person Risk Attributes |
| [profiles.num\_sources](/docs/fields#profiles) | Person Risk Attributes |
| [street\_addresses.first\_seen](/docs/fields#street_addresses) | Person Risk Attributes |
| [street\_addresses.last\_seen](/docs/fields#street_addresses) | Person Risk Attributes |
| [street\_addresses.num\_sources](/docs/fields#street_addresses) | Person Risk Attributes |

## O/\*Net Fields

| Field | Bundle |
| --- | --- |
| [job\_onet\_broad\_occupation](/docs/fields#job_onet_broad_occupation) | O\*Net Fields |
| [job\_onet\_code](/docs/fields#job_onet_code) | O\*Net Fields |
| [job\_onet\_major\_group](/docs/fields#job_onet_major_group) | O\*Net Fields |
| [job\_onet\_minor\_group](/docs/fields#job_onet_minor_group) | O\*Net Fields |
| [job\_onet\_specific\_occupation](/docs/fields#job_onet_specific_occupation) | O\*Net Fields |
| [job\_onet\_specific\_occupation\_detail](/docs/fields#job_onet_specific_occupation_detail) | O\*Net Fields |

## Premium Company Attributes

| Field | Bundle |
| --- | --- |
| [job\_company\_12mo\_employee\_growth\_rate](/docs/fields#job_company_12mo_employee_growth_rate) | Premium Company Attributes |
| [job\_company\_employee\_count](/docs/fields#job_company_employee_count) | Premium Company Attributes |
| [job\_company\_inferred\_revenue](/docs/fields#job_company_inferred_revenue) | Premium Company Attributes |
| [job\_company\_total\_funding\_raised](/docs/fields#job_company_total_funding_raised) | Premium Company Attributes |

## Email Hashes

| Field | Bundle |
| --- | --- |
| [emails.md5\_hash](/docs/fields#emails) | Email Hashes |
| [emails.sha\_256\_hash](/docs/fields#emails) | Email Hashes |

Updated 7 days ago

---

Did this page help you?

Yes

No

---
# https://docs.peopledatalabs.com/docs/education-majors

| Canonical Values for Education Majors |
| --- |
| 3d modelling |
| 3d modelling and animation |
| accountancy |
| accounting |
| acting |
| actuarial science |
| addiction counseling |
| administration |
| administration of justice |
| advertising |
| aerospace and aeronautical engineering |
| aerospace engineering |
| african american studies |
| african culture |
| african language |
| african language and culture |
| african language and literature |
| african language studies |
| african languages |
| african literature |
| african literature and culture |
| african studies |
| africana studies |
| africana study |
| afrikaans |
| afrikaans culture |
| afrikaans language |
| afrikaans language and culture |
| afrikaans language and literature |
| afrikaans language studies |
| afrikaans languages |
| afrikaans literature |
| afrikaans literature and culture |
| afrikaans studies |
| agricultural economics |
| agricultural engineering |
| agriculture |
| agriculture production |
| agriculture production and management |
| agronomy |
| airway science |
| american history |
| american indian studies |
| american literature |
| american sign language |
| american studies |
| anatomy |
| ancient civilizations |
| anesthesiology |
| animal behavior |
| animal bioscience |
| animal science |
| animation |
| anthropology |
| anthropology and archeology |
| apparel and merchandising |
| apparel and textiles |
| apparel design |
| applied digital art |
| applied economics |
| applied graphic design |
| applied linguistics |
| applied mathematics |
| applied physics |
| applied psychology |
| applied science |
| applied statistics |
| aquaculture |
| aquatics |
| arabic |
| arabic culture |
| arabic language |
| arabic language and culture |
| arabic language and literature |
| arabic language studies |
| arabic languages |
| arabic literature |
| arabic literature and culture |
| arabic studies |
| archeology |
| architectural engineering |
| architectural tech |
| architecture |
| architecture and engineering |
| area ethnic and civilization studies |
| art |
| art and design |
| art and music education |
| art education |
| art history |
| art therapy |
| asian american studies |
| asian studies |
| astrology |
| astronomy |
| astronomy and astrophysics |
| astrophysics |
| atmospheric science |
| atmospheric science and meteorology |
| audiology |
| automotive mechanics |
| aviation |
| avionic systems |
| avionics |
| avionics maintenance |
| baking |
| baking and pastry art |
| balkan culture |
| balkan language |
| balkan language and culture |
| balkan language and literature |
| balkan language studies |
| balkan languages |
| balkan literature |
| balkan literature and culture |
| balkan studies |
| ballet |
| baltic culture |
| baltic language |
| baltic language and culture |
| baltic language and literature |
| baltic language studies |
| baltic languages |
| baltic literature |
| baltic literature and culture |
| baltic studies |
| banking |
| behavioral science |
| behavioural science |
| biblical preaching |
| biblical studies |
| biobehavioral health |
| biochemical engineering |
| biochemical science |
| biochemistry |
| bioengineering |
| bioinformatics |
| biological engineering |
| biological science |
| biology |
| biomedical engineering |
| biomedical science |
| biophysics |
| biotechnology |
| botany |
| brass instruments |
| british literature |
| broadcast and cinematic art |
| broadcast journalism |
| broadcasting |
| buddhist studies |
| bulgarian |
| bulgarian culture |
| bulgarian language |
| bulgarian language and culture |
| bulgarian language and literature |
| bulgarian language studies |
| bulgarian languages |
| bulgarian literature |
| bulgarian literature and culture |
| bulgarian studies |
| business |
| business admin |
| business administration |
| business administration and management |
| business and medical administration |
| business economics |
| business finance |
| business law |
| business management |
| business management and administration |
| business marketing |
| business studies |
| celtic studies |
| ceramics |
| chemical engineering |
| chemistry |
| chicano |
| chicano culture |
| chicano studies |
| child and adolescent development |
| child development |
| chinese |
| chinese culture |
| chinese language |
| chinese language and culture |
| chinese language and literature |
| chinese language studies |
| chinese languages |
| chinese literature |
| chinese literature and culture |
| chinese studies |
| choral conducting |
| choral maintenance tech |
| christian administration |
| christian doctorine |
| christian preaching |
| civil engineering |
| classical culture |
| classical language |
| classical language and culture |
| classical language and literature |
| classical language studies |
| classical languages |
| classical literature |
| classical literature and culture |
| classical studies |
| classics |
| clinical nurse |
| clinical nursing |
| clinical psychology |
| coaching |
| cognitive science |
| cognitive science and biopsychology |
| college student affairs |
| commerce |
| commercial art |
| commercial science |
| commercial studies |
| communication |
| communication art |
| communication disorders science and services |
| communication management |
| communication studies |
| communication tech |
| communications |
| communications and media studies |
| community |
| community and public health |
| community development |
| comp lit |
| comp sci |
| comparative literature |
| comparative race and ethnic studies |
| comparative religious studies |
| composition |
| composition and rhetoric |
| computer |
| computer administration management and security |
| computer and information science |
| computer and information systems |
| computer application |
| computer applications |
| computer engineering |
| computer graphics |
| computer information systems |
| computer networking and telecommunications |
| computer programming |
| computer programming and data processing |
| computer science |
| computer science and electrical engineering |
| computer science and engineering |
| computer science and mathematics |
| computer systems |
| computer systems engineering |
| computer systems management |
| computer tech |
| conducting |
| conflict resolution |
| construction |
| construction and land development |
| construction management |
| construction services |
| consulting |
| consulting and sales |
| consumer science |
| corporate finance |
| corporate law |
| corrections |
| cosmetology |
| cosmetology services and culinary art |
| counseling |
| counseling psychology |
| court reporting |
| creative writing |
| criminal justice |
| criminal justice and fire protection |
| criminology |
| culinary art |
| culinary arts |
| curriculum and instruction |
| curriculum supervision |
| customer service |
| customer service management |
| cybersecurity |
| czech |
| czech culture |
| czech language |
| czech language and culture |
| czech language and literature |
| czech language studies |
| czech languages |
| czech literature |
| czech literature and culture |
| czech studies |
| dance |
| dance performance |
| danish |
| danish culture |
| danish language |
| danish language and culture |
| danish language and literature |
| danish language studies |
| danish languages |
| danish literature |
| danish literature and culture |
| danish studies |
| data science |
| demography |
| dental hygiene |
| dental tech |
| dentistry |
| design |
| digital art |
| digital video |
| digital video and cinema |
| digital visual effects |
| disability studies |
| distribution management |
| diversity studies |
| divinity |
| documentary production |
| drama |
| drama and theater art |
| drawing |
| drug development |
| dutch |
| dutch culture |
| dutch language |
| dutch language and culture |
| dutch language and literature |
| dutch language studies |
| dutch languages |
| dutch literature |
| dutch literature and culture |
| dutch studies |
| early childhood education |
| earth science |
| east asian studies |
| ecology |
| economics |
| education |
| educational administration and supervision |
| educational psychology |
| electrical engineering |
| electrical engineering and computer science |
| electrical engineering tech |
| electronics |
| electronics engineering |
| elementary education |
| energy |
| energy and climate policy |
| energy and enviornmental analysis |
| engineering |
| engineering and industrial management |
| engineering mechanics physics and science |
| engineering tech |
| english |
| english as a second language |
| english culture |
| english language |
| english language and culture |
| english language and literature |
| english language arts |
| english language studies |
| english languages |
| english literature |
| english literature and culture |
| english studies |
| entomology |
| entrepreneurial studies |
| entrepreneurship |
| environmental |
| environmental and geotechnical engineering |
| environmental engineering |
| environmental science |
| environmental studies |
| epidemiology |
| ethics |
| european civilization |
| european history |
| european modern languages |
| european studies |
| event planning |
| exercise and sport science |
| exercise science |
| family |
| family and community services |
| family and consumer science |
| family science |
| family therapy |
| fashion |
| fashion design |
| feminine spirituality |
| feminine studies |
| film |
| film and television |
| film directing |
| film photography |
| film photography and visual art |
| film video and photographic art |
| finance |
| finance and marketing |
| financial accounting |
| financial economics |
| financial engineering |
| financial forensics |
| financial forensics and fraud investigation |
| financial management |
| fine |
| fine and studio art |
| fine art |
| fine arts |
| finnish |
| finnish culture |
| finnish language |
| finnish language and culture |
| finnish language and literature |
| finnish language studies |
| finnish languages |
| finnish literature |
| finnish literature and culture |
| finnish studies |
| fisheries |
| fisheries and wildlife science |
| flute |
| flute performance |
| folklore |
| folklore studies |
| food |
| food and nutritional science |
| food preparation |
| food safety |
| food science |
| foreign relations |
| foreign studies |
| forensic chemistry |
| forensic computing |
| forensic science |
| forensics |
| forest science |
| forest tech |
| forestry |
| francophone studies |
| french |
| french culture |
| french language |
| french language and culture |
| french language and literature |
| french language studies |
| french languages |
| french literature |
| french literature and culture |
| french pastry |
| french studies |
| fundraising |
| fundraising and grantmaking |
| game design |
| gay and lesbian studies |
| gay lesbian studies |
| gender and diversity studies |
| gender and womens studies |
| gender studies |
| general agriculture |
| general business |
| general education |
| general engineering |
| general medical and health services |
| general science |
| general social science |
| general studies |
| genetics |
| genomics |
| geochemistry |
| geography |
| geological and geophysical engineering |
| geology |
| geology and earth science |
| geophysics |
| geoscience |
| geosciences |
| geotechnical engineering |
| german |
| german culture |
| german language |
| german language and culture |
| german language and literature |
| german language studies |
| german languages |
| german literature |
| german literature and culture |
| german studies |
| global health |
| global history |
| global studies |
| government |
| government and management |
| government and politics |
| graphic and printing |
| graphic and printing science |
| graphic art |
| graphic design |
| greek |
| greek culture |
| greek language |
| greek language and culture |
| greek language and literature |
| greek language studies |
| greek languages |
| greek literature |
| greek literature and culture |
| greek mythology |
| greek studies |
| gynecology |
| health administration |
| health and medical administrative services |
| health and medical preparatory programs |
| health care |
| health care administration |
| health education |
| health education teaching |
| health medical professions |
| health promotion |
| health science |
| health service administration |
| health services |
| healthcare |
| healthcare administration |
| hebrew |
| hebrew culture |
| hebrew language |
| hebrew language and culture |
| hebrew language and literature |
| hebrew language studies |
| hebrew languages |
| hebrew literature |
| hebrew literature and culture |
| hebrew studies |
| hindi |
| hindi culture |
| hindi language |
| hindi language and culture |
| hindi language and literature |
| hindi language studies |
| hindi languages |
| hindi literature |
| hindi literature and culture |
| hindi studies |
| hindu |
| hindu studies |
| historic preservation |
| history |
| holocaust studies |
| homeland security |
| horticulture |
| hospitality |
| hospitality and tourism |
| hospitality management |
| hotel management |
| human development |
| human physiology |
| human relations |
| human resource development |
| human resource management |
| human resources |
| human resources and personnel management |
| human resources management |
| human services |
| human services and community organization |
| humanities |
| hungarian |
| hungarian culture |
| hungarian language |
| hungarian language and culture |
| hungarian language and literature |
| hungarian language studies |
| hungarian languages |
| hungarian literature |
| hungarian literature and culture |
| hungarian studies |
| illustration |
| illustraton |
| immunology |
| indonesian |
| indonesian and malay languages |
| indonesian culture |
| indonesian language |
| indonesian language and culture |
| indonesian language and literature |
| indonesian language studies |
| indonesian languages |
| indonesian literature |
| indonesian literature and culture |
| indonesian studies |
| industrial administration |
| industrial and manufacturing engineering |
| industrial and organizational psychology |
| industrial design |
| industrial engineering |
| industrial engineering and operations research |
| industrial production tech |
| industrial relations |
| industrial safety |
| industrial sales |
| industrial tech |
| informatics |
| information science |
| information science and agronomy |
| information science and tech |
| information systems |
| information systems management |
| information tech |
| instructional tech |
| interactive media |
| intercultural and international studies |
| interdisciplinary social science |
| interdisciplinary studies |
| international affairs |
| international business |
| international commerce |
| international communications |
| international development |
| international development and conflict management |
| international economic relations |
| international economics |
| international finance |
| international law |
| international relations |
| international studies |
| investment analysis |
| investment banking |
| irish studies |
| islamic culture |
| islamic religion |
| islamic studies |
| italian |
| italian culture |
| italian language |
| italian language and culture |
| italian language and literature |
| italian language studies |
| italian languages |
| italian literature |
| italian literature and culture |
| italian studies |
| japanese |
| japanese culture |
| japanese language |
| japanese language and culture |
| japanese language and literature |
| japanese language studies |
| japanese languages |
| japanese literature |
| japanese literature and culture |
| japanese studies |
| jazz |
| jazz performance |
| journalism |
| judaic studies |
| kinesiology |
| korean |
| korean culture |
| korean language |
| korean language and culture |
| korean language and literature |
| korean language studies |
| korean languages |
| korean literature |
| korean literature and culture |
| korean studies |
| labor relations |
| labor studies |
| landscape architecture |
| landscaping |
| landscaping and groundskeeping |
| language and drama education |
| latin |
| latin american and caribbean studies |
| latin american studies |
| law |
| law enforcement |
| law enforcement executive development |
| leadership |
| legal administration |
| legal studies |
| lgbtq studies |
| liberal art |
| liberal arts |
| liberal studies |
| library science |
| linguistics |
| linguistics and comparative language and literature |
| literature |
| liturgical studies |
| logic |
| logistics |
| management |
| management information systems and statistics |
| management science |
| management studies |
| mandarin |
| mandarin chinese |
| mandarin culture |
| mandarin language |
| mandarin language and culture |
| mandarin language and literature |
| mandarin language studies |
| mandarin languages |
| mandarin literature |
| mandarin literature and culture |
| mandarin studies |
| marine biology |
| marine science |
| marketing |
| masonry |
| mass media |
| materials engineering |
| materials engineering and materials science |
| materials science |
| mathematical modeling |
| mathematical science |
| mathematics |
| mechanical engineering |
| mechanical engineering related tech |
| mechanical tech |
| mechatronics |
| mechatronics and automation |
| mechatronics engineering |
| media art |
| media art and entertainment |
| media management |
| media studies |
| medical assisting services |
| medical biology |
| medical engineering |
| medical insurance |
| medical tech |
| medicine |
| medieval and renaissance studies |
| medieval studies |
| metallurgical engineering |
| metaphysics |
| meteorology |
| microbiology |
| middle eastern studies |
| military science |
| military tech |
| mining |
| mining and mineral engineering |
| mining engineering |
| ministry |
| modern art |
| modern languages |
| molecular biology |
| molecular biophysics |
| multicultural studies |
| multimedia |
| multimedia journalism |
| music |
| music education |
| mythology |
| mythology and folklore |
| nanotechnology |
| native american studies |
| natural resource conservation |
| natural resources conservation |
| natural resources management |
| natural science |
| naval architecture |
| naval architecture and marine engineering |
| naval architecture and ocean engineering |
| near and middle eastern studies |
| near eastern studies |
| network administration |
| network and systems administration |
| neuroscience |
| norwegian |
| norwegian culture |
| norwegian language |
| norwegian language and culture |
| norwegian language and literature |
| norwegian language studies |
| norwegian languages |
| norwegian literature |
| norwegian literature and culture |
| norwegian studies |
| nuclear engineering |
| nuclear propulsion |
| number theory |
| nursing |
| nursing administration |
| nutrition |
| nutrition science |
| nutritional science |
| occupational health |
| occupational health and safety |
| occupational safety |
| occupational safety engineering |
| occupational therapy |
| oceanography |
| operations logistics |
| operations logistics and e-commerce |
| operations management |
| optometry |
| orchestral conducting |
| organ performance |
| organic chemistry |
| organization administration |
| organizational and professional communications |
| organizational communications |
| organizational leadership |
| organizational management |
| orthodontics |
| painting |
| paleontology |
| paralegal |
| paralegal studies |
| parks |
| parks and recreation |
| parks recreation and leisure studies |
| percussion |
| performing art |
| performing arts |
| petroleum engineering |
| petroleum geoscience |
| petroleum tech |
| pharmaceutical administration |
| pharmaceutical development |
| pharmaceutical science |
| pharmacology |
| pharmacy |
| philosophy |
| photography |
| physical |
| physical activity |
| physical and health education teaching |
| physical education |
| physical fitness parks recreation and leisure |
| physical science |
| physical therapy |
| physics |
| physiology |
| physiotherapy |
| piano |
| piano performace |
| piano performance |
| planetary |
| planetary and atmospheric science |
| plant science |
| plant science and agronomy |
| playwriting |
| poetry |
| police science |
| political development |
| political science |
| political science and government |
| politics |
| poly sci |
| portuguese |
| portuguese culture |
| portuguese language |
| portuguese language and culture |
| portuguese language and literature |
| portuguese language studies |
| portuguese languages |
| portuguese literature |
| portuguese literature and culture |
| portuguese studies |
| pre dental |
| pre law |
| pre law and legal studies |
| pre med |
| pre optometry |
| pre orthodontics |
| prelaw |
| premed |
| premedicine |
| product design |
| product marketing |
| production tech |
| project management |
| psychology |
| public admin |
| public administration |
| public affairs |
| public health |
| public law |
| public policy |
| public relations |
| public service |
| public service and administration |
| publishing |
| puppetry |
| quality improvement |
| queer studies |
| rabbinic studies |
| rabbinical studies |
| radio broadcasting |
| radiology |
| real estate |
| recording art |
| recording arts |
| recreation |
| recreation administration |
| regional planning |
| religious education |
| religious studies |
| retail |
| rhetoric |
| robotics |
| russian |
| russian culture |
| russian language |
| russian language and culture |
| russian language and literature |
| russian language studies |
| russian languages |
| russian literature |
| russian literature and culture |
| russian studies |
| scandinavian |
| scandinavian culture |
| scandinavian language |
| scandinavian language and culture |
| scandinavian language and literature |
| scandinavian language studies |
| scandinavian languages |
| scandinavian literature |
| scandinavian literature and culture |
| scandinavian studies |
| school student counseling |
| science and computer teacher education |
| science information |
| science tech |
| science tech and society |
| screen art and cultures |
| screen writing |
| screenwriting |
| sculpture |
| secondary teacher education |
| semiconductor manufacturing |
| serbian |
| serbian culture |
| serbian language |
| serbian language and culture |
| serbian language and literature |
| serbian language studies |
| serbian languages |
| serbian literature |
| serbian literature and culture |
| serbian studies |
| slavic culture |
| slavic language |
| slavic language and culture |
| slavic language and literature |
| slavic language studies |
| slavic languages |
| slavic literature |
| slavic literature and culture |
| slavic studies |
| social psychology |
| social science |
| social sciences |
| social services |
| social studies |
| social work |
| sociology |
| software development |
| software engineering |
| soil science |
| sommelier |
| spanish |
| spanish culture |
| spanish language |
| spanish language and culture |
| spanish language and literature |
| spanish language studies |
| spanish languages |
| spanish literature |
| spanish literature and culture |
| spanish studies |
| special education |
| special needs education |
| speech and hearing science |
| speech communications |
| speech language pathology |
| speech pathology |
| speech science |
| sport administration |
| sport communications |
| sport management |
| sport philosophy |
| sport psychology |
| sports and fitness |
| sports management |
| statistics |
| statistics and decision science |
| stringed instruments |
| studio art |
| studio arts |
| supply chain management |
| sustainability |
| sustainability management |
| sustainability studies |
| swedish |
| swedish culture |
| swedish language |
| swedish language and culture |
| swedish language and literature |
| swedish language studies |
| swedish languages |
| swedish literature |
| swedish literature and culture |
| swedish studies |
| talmudic studies |
| taxidermy |
| teacher education |
| teaching |
| telecom |
| telecom and electronics |
| telecommunications |
| television |
| television broadcasting |
| theater |
| theater art |
| theater arts |
| theatre |
| theological studies |
| theology |
| theology and religious vocations |
| tibetan |
| tibetan culture |
| tibetan language |
| tibetan language and culture |
| tibetan language and literature |
| tibetan language studies |
| tibetan languages |
| tibetan literature |
| tibetan literature and culture |
| tibetan studies |
| tourism |
| tourism management |
| toxicology |
| transportation science and tech |
| travel |
| travel and tourism management |
| travel services management |
| treatment therapy professions |
| trial advocacy |
| turfgrass science |
| turkish |
| turkish culture |
| turkish language |
| turkish language and culture |
| turkish language and literature |
| turkish language studies |
| turkish languages |
| turkish literature |
| turkish literature and culture |
| turkish studies |
| ukrainian |
| ukrainian culture |
| ukrainian language |
| ukrainian language and culture |
| ukrainian language and literature |
| ukrainian language studies |
| ukrainian languages |
| ukrainian literature |
| ukrainian literature and culture |
| ukrainian studies |
| united states history |
| urban planning |
| urban schooling |
| urban social studies |
| urban sociology |
| urban studies |
| veterinary pathology |
| veterinary science |
| veterinary studies |
| vietnamese |
| vietnamese culture |
| vietnamese language |
| vietnamese language and culture |
| vietnamese language and literature |
| vietnamese language studies |
| vietnamese languages |
| vietnamese literature |
| vietnamese literature and culture |
| vietnamese studies |
| virology |
| visual |
| visual and performing art |
| visual art |
| visual communications |
| visual effects |
| viticulture |
| vlsi design |
| vlsi engineer |
| vocal performance |
| vocational counseling |
| vocational rehabilitation |
| voice |
| voice and opera |
| web development |
| welding |
| welding engineering |
| wellness management |
| wildlife and fisheries science |
| wildlife and fishery science |
| wildlife science |
| wildlife tech |
| womens studies |
| writing |
| writing and culture |
| zoology |

*Contents of this table were sourced from the following file on our public S3 bucket:[education.majors.txt](https://pdl-prod-schema.s3.us-west-2.amazonaws.com/28.0/enums/education.majors.txt)*

## Relevant fields

* [`education.majors`](/docs/fields#education-1)

Updated 4 months ago

---

Did this page help you?

Yes

No

---
# https://docs.peopledatalabs.com/docs/company-types

| Canonical Values for Company Types |
| --- |
| educational |
| government |
| nonprofit |
| private |
| public |
| public\_subsidiary |

*Contents of this table were sourced from the following file on our public S3 bucket:[job\_company\_type.txt](https://pdl-prod-schema.s3.us-west-2.amazonaws.com/28.0/enums/job_company_type.txt)*

## Relevant fields

* [`experience.company.type`](/docs/fields#experiencecompany)
* [`job_company_type`](/docs/fields#job_company_type)
* [`type`](/docs/company-schema#type)

Updated 4 months ago

---

Did this page help you?

Yes

No

---
# https://docs.peopledatalabs.com/docs/location-countries

> ðŸš§
>
> ### Updated in v28.0 (October 2024)
>
> We have updated the list of canonical country values in v28.0 (October 2024). The specific updates that have been implemented are shown in the table below.
>
> | Country (pre-v28.0) | Change | Country (post-v28.0) |
> | --- | --- | --- |
> | swaziland | `renamed` | eswatini |
> | antarctica | `deleted` | -- |
> | macedonia | `renamed` | north macedonia |
> | pitcairn | `renamed` | pitcairn islands |
> | gambia | `renamed` | the gambia |
> | ivory coast | `deleted` | -- |
>
> Please see our [October 2024 Release Announcement (v28.0)](/changelog/october-2024-release-announcement-v280) for further information.

| Canonical Values for Location Countries |
| --- |
| afghanistan |
| albania |
| algeria |
| american samoa |
| andorra |
| angola |
| anguilla |
| antigua and barbuda |
| argentina |
| armenia |
| aruba |
| australia |
| austria |
| azerbaijan |
| bahamas |
| bahrain |
| bangladesh |
| barbados |
| belarus |
| belgium |
| belize |
| benin |
| bermuda |
| bhutan |
| bolivia |
| bosnia and herzegovina |
| botswana |
| bouvet island |
| brazil |
| british indian ocean territory |
| british virgin islands |
| brunei |
| bulgaria |
| burkina faso |
| burundi |
| cambodia |
| cameroon |
| canada |
| cape verde |
| caribbean netherlands |
| cayman islands |
| central african republic |
| chad |
| chile |
| china |
| christmas island |
| cocos (keeling) islands |
| colombia |
| comoros |
| cook islands |
| costa rica |
| croatia |
| cuba |
| curaÃ§ao |
| cyprus |
| czechia |
| cÃ´te d'ivoire |
| democratic republic of the congo |
| denmark |
| djibouti |
| dominica |
| dominican republic |
| ecuador |
| egypt |
| el salvador |
| equatorial guinea |
| eritrea |
| estonia |
| eswatini |
| ethiopia |
| falkland islands |
| faroe islands |
| fiji |
| finland |
| france |
| french guiana |
| french polynesia |
| french southern territories |
| gabon |
| georgia |
| germany |
| ghana |
| gibraltar |
| greece |
| greenland |
| grenada |
| guadeloupe |
| guam |
| guatemala |
| guernsey |
| guinea |
| guinea-bissau |
| guyana |
| haiti |
| heard island and mcdonald islands |
| honduras |
| hong kong |
| hungary |
| iceland |
| india |
| indonesia |
| iran |
| iraq |
| ireland |
| isle of man |
| israel |
| italy |
| jamaica |
| japan |
| jersey |
| jordan |
| kazakhstan |
| kenya |
| kiribati |
| kosovo |
| kuwait |
| kyrgyzstan |
| laos |
| latvia |
| lebanon |
| lesotho |
| liberia |
| libya |
| liechtenstein |
| lithuania |
| luxembourg |
| macau |
| madagascar |
| malawi |
| malaysia |
| maldives |
| mali |
| malta |
| marshall islands |
| martinique |
| mauritania |
| mauritius |
| mayotte |
| mexico |
| micronesia |
| moldova |
| monaco |
| mongolia |
| montenegro |
| montserrat |
| morocco |
| mozambique |
| myanmar |
| namibia |
| nauru |
| nepal |
| netherlands |
| new caledonia |
| new zealand |
| nicaragua |
| niger |
| nigeria |
| niue |
| norfolk island |
| north korea |
| north macedonia |
| northern mariana islands |
| norway |
| oman |
| pakistan |
| palau |
| palestine |
| panama |
| papua new guinea |
| paraguay |
| peru |
| philippines |
| pitcairn islands |
| poland |
| portugal |
| puerto rico |
| qatar |
| republic of the congo |
| romania |
| russia |
| rwanda |
| rÃ©union |
| saint barthÃ©lemy |
| saint helena |
| saint kitts and nevis |
| saint lucia |
| saint martin |
| saint pierre and miquelon |
| saint vincent and the grenadines |
| samoa |
| san marino |
| saudi arabia |
| senegal |
| serbia |
| seychelles |
| sierra leone |
| singapore |
| sint maarten |
| slovakia |
| slovenia |
| solomon islands |
| somalia |
| south africa |
| south georgia and the south sandwich islands |
| south korea |
| south sudan |
| spain |
| sri lanka |
| sudan |
| suriname |
| svalbard and jan mayen |
| sweden |
| switzerland |
| syria |
| sÃ£o tomÃ© and prÃ­ncipe |
| taiwan |
| tajikistan |
| tanzania |
| thailand |
| the gambia |
| timor-leste |
| togo |
| tokelau |
| tonga |
| trinidad and tobago |
| tunisia |
| turkey |
| turkmenistan |
| turks and caicos islands |
| tuvalu |
| u.s. virgin islands |
| uganda |
| ukraine |
| united arab emirates |
| united kingdom |
| united states |
| united states minor outlying islands |
| uruguay |
| uzbekistan |
| vanuatu |
| vatican city |
| venezuela |
| vietnam |
| wallis and futuna |
| western sahara |
| yemen |
| zambia |
| zimbabwe |
| Ã¥land islands |

*Contents of this table were sourced from the following file on our public S3 bucket:[location\_country.txt](https://pdl-prod-schema.s3.us-west-2.amazonaws.com/29.0/enums/location_country.txt)*

## Relevant fields

* [`education.school.location.country`](/docs/fields#educationschool)
* [`experience.company.location.country`](/docs/fields#experiencecompany)
* [`job_company_location_country`](/docs/fields#job_company_location_country)
* [`location.country`](/docs/company-schema#location) (Company)
* [`location_country`](/docs/fields#location_country) (Person)
* [`possible_street_addresses.country`](/docs/fields#possible_street_addresses)
* [`street_addresses.country`](/docs/fields#street_addresses)

Updated 4 months ago

---

Did this page help you?

Yes

No

---
# https://docs.peopledatalabs.com/docs/person-data-overview

The following table contains an overview of each person-related field in our dataset. Click the field name to go to the corresponding section in our [Person Schema](/docs/fields) to see additional details about each field.

> ðŸ“˜
>
> ### Field Availability
>
> Please note: Not all fields are available in all packages.
>
> For more details about the fields we offer, including fill rates and which fields are included in the base vs premium packages, check out our [Person Data Field Bundles](/docs/person-data-field-bundles).

  

| Field | Type | Short Description | Requires add-on | Searchable | Bundle |
| --- | --- | --- | --- | --- | --- |
| [`birth_date`](/docs/fields#birth_date) | [`String (Date)`](/docs/data-types#dates) | The day the person was born |  | T | [Base](/docs/person-data-field-bundles#base) |
| [`birth_year`](/docs/fields#birth_year) | `Integer` | The year the person was born |  | T | [Base](/docs/person-data-field-bundles#base) |
| [`certifications`](/docs/fields#certifications) | `Array [Object]` | Any certifications the person has | T | T | [Premium Resume Fields](/docs/person-data-field-bundles#premium-resume-fields) |
| [`certifications.end_date`](/docs/fields#certifications) | [`String (Date)`](/docs/data-types#dates) | The expiration date of the certification | T | T | [Premium Resume Fields](/docs/person-data-field-bundles#premium-resume-fields) |
| [`certifications.name`](/docs/fields#certifications) | `String` | Certification name | T | T | [Premium Resume Fields](/docs/person-data-field-bundles#premium-resume-fields) |
| [`certifications.organization`](/docs/fields#certifications) | `String` | The organization awarding the certification | T | T | [Premium Resume Fields](/docs/person-data-field-bundles#premium-resume-fields) |
| [`certifications.start_date`](/docs/fields#certifications) | [`String (Date)`](/docs/data-types#dates) | The date the certification was awarded | T | T | [Premium Resume Fields](/docs/person-data-field-bundles#premium-resume-fields) |
| [`countries`](/docs/fields#countries) | [`Array [Enum (String)]`](/docs/location-countries) | AllÂ countriesÂ associated with the person |  | T | [Base](/docs/person-data-field-bundles#base) |
| [`dataset_version`](/docs/fields#dataset_version) | `String` | The major or minor release number. |  | T | [Base](/docs/person-data-field-bundles#base) |
| [`education`](/docs/fields#education-1) | `Array [Object]` | The person's education information |  | T | [Base](/docs/person-data-field-bundles#base) |
| [`education.degrees`](/docs/fields#education-1) | [`Array [Enum (String)]`](/docs/education-degrees) | The degrees the person earned at the school |  | T | [Base](/docs/person-data-field-bundles#base) |
| [`education.end_date`](/docs/fields#education-1) | [`String (Date)`](/docs/data-types#dates) | The date the person left the school |  | T | [Base](/docs/person-data-field-bundles#base) |
| [`education.gpa`](/docs/fields#education-1) | `Float` | The GPA the person earned at the school |  | T | [Base](/docs/person-data-field-bundles#base) |
| [`education.majors`](/docs/fields#education-1) | [`Array [Enum (String)]`](/docs/education-majors) | All majors the person earned at the school |  | T | [Base](/docs/person-data-field-bundles#base) |
| [`education.minors`](/docs/fields#education-1) | [`Array [Enum (String)]`](/docs/education-majors) | All minors the person earned at the school |  | T | [Base](/docs/person-data-field-bundles#base) |
| [`education.raw`](/docs/fields#education-1) | `String` | Raw education data | T |  | [Raw Fields](/docs/person-data-field-bundles#raw-fields) |
| [`education.school`](/docs/fields#educationschool) | `Object` | The school the person attended |  | T | [Base](/docs/person-data-field-bundles#base) |
| [`education.school.domain`](/docs/fields#educationschool) | `String` | The primary website domain associated with the school |  | T | [Base](/docs/person-data-field-bundles#base) |
| [`education.school.facebook_url`](/docs/fields#educationschool) | `String` | The school's Facebook URL |  | T | [Base](/docs/person-data-field-bundles#base) |
| [`education.school.id`](/docs/fields#educationschool) | `String` | The non-persistent ID for the school in our records |  | T | [Base](/docs/person-data-field-bundles#base) |
| [`education.school.linkedin_id`](/docs/fields#educationschool) | `String` | The school's LinkedIn ID |  | T | [Base](/docs/person-data-field-bundles#base) |
| [`education.school.location`](/docs/fields#educationschool) | `Object` | The location of the school |  | T | [Base](/docs/person-data-field-bundles#base) |
| [`education.school.location.continent`](/docs/fields#educationschool) | [`Enum (String)`](/docs/location-continents) | The continent the school is in |  | T | [Base](/docs/person-data-field-bundles#base) |
| [`education.school.location.country`](/docs/fields#educationschool) | [`Enum (String)`](/docs/location-countries) | The country the school is in |  | T | [Base](/docs/person-data-field-bundles#base) |
| [`education.school.location.locality`](/docs/fields#educationschool) | `String` | The locality the school is in |  | T | [Base](/docs/person-data-field-bundles#base) |
| [`education.school.location.name`](/docs/fields#educationschool) | `String` | Our cleaned values for the school location in the formatÂ "locality, region, country" |  | T | [Base](/docs/person-data-field-bundles#base) |
| [`education.school.location.region`](/docs/fields#educationschool) | `String` | The region the school is in |  | T | [Base](/docs/person-data-field-bundles#base) |
| [`education.school.name`](/docs/fields#educationschool) | `String` | The name of the school |  | T | [Base](/docs/person-data-field-bundles#base) |
| [`education.school.raw`](/docs/fields#educationschool) | `String` | Raw school name | T | T | [Raw Fields](/docs/person-data-field-bundles#raw-fields) |
| [`education.school.twitter_url`](/docs/fields#educationschool) | `String` | The school's Twitter URL |  | T | [Base](/docs/person-data-field-bundles#base) |
| [`education.school.type`](/docs/fields#educationschool) | [`Enum (String)`](/docs/education-school-types) | The school type |  | T | [Base](/docs/person-data-field-bundles#base) |
| [`education.school.website`](/docs/fields#educationschool) | `String` | The website URL associated with the school |  | T | [Base](/docs/person-data-field-bundles#base) |
| [`education.start_date`](/docs/fields#education-1) | [`String (Date)`](/docs/data-types#dates) | The date the person started at the school |  | T | [Base](/docs/person-data-field-bundles#base) |
| [`education.summary`](/docs/fields#education-1) | `String` | User-inputted summary of their education | T |  | [Premium Resume Fields](/docs/person-data-field-bundles#premium-resume-fields) |
| [`emails`](/docs/fields#emails) | `Array [Object]` | Email addresses associated with the person  âš ï¸ **Note** This array contains historical email addresses and should **not** directly be used for email outreach. [Recommended Alternatives](/docs/email-data-for-outreach) |  | T | [Base](/docs/person-data-field-bundles#base) |
| [`emails.address`](/docs/fields#emails) | `String` | The fully parsed email address |  | T | [Base](/docs/person-data-field-bundles#base) |
| [`emails.first_seen`](/docs/fields#emails) | [`String (Date)`](/docs/data-types#dates) | The date that this entity was first associated with the Person record | T | T | [Person Risk Attributes](/docs/person-data-field-bundles#person-risk-attributes) |
| [`emails.last_seen`](/docs/fields#emails) | [`String (Date)`](/docs/data-types#dates) | The date that this entity was last associated with the Person record | T | T | [Person Risk Attributes](/docs/person-data-field-bundles#person-risk-attributes) |
| [`emails.md5_hash`](/docs/fields#emails) | `String` | A 128-bit hash of an email in md5 format. | T |  | [Email Hashes](/docs/person-data-field-bundles#email_hash) |
| [`emails.num_sources`](/docs/fields#emails) | `Integer (> 0)` | The number of sources that have contributed to the association of this entity with the Person record | T | T | [Person Risk Attributes](/docs/person-data-field-bundles#person-risk-attributes) |
| [`emails.sha_256_hash`](/docs/fields#emails) | `String` | A 256-bit hash of an email in sha256 format. | T |  | [Email Hashes](/docs/person-data-field-bundles#email_hash) |
| [`emails.type`](/docs/fields#emails) | [`Enum (String)`](/docs/email-types) | The type of email |  | T | [Base](/docs/person-data-field-bundles#base) |
| [`experience`](/docs/fields#experience) | `Array [Object]` | The person's work experience |  | T | [Base](/docs/person-data-field-bundles#base) |
| [`experience.company`](/docs/fields#experiencecompany) | `Object` | The company where the person worked |  | T | [Base](/docs/person-data-field-bundles#base) |
| [`experience.company.facebook_url`](/docs/fields#experiencecompany) | `String` | The company'sÂ Facebook URL |  | T | [Base](/docs/person-data-field-bundles#base) |
| [`experience.company.founded`](/docs/fields#experiencecompany) | `Integer (> 0)` | The founding year of the company |  | T | [Base](/docs/person-data-field-bundles#base) |
| [`experience.company.id`](/docs/fields#experiencecompany) | `String` | The company's PDL ID |  | T | [Base](/docs/person-data-field-bundles#base) |
| [`experience.company.industry`](/docs/fields#experiencecompany) | [`Enum (String)`](/docs/industries) | The self-identified industry of the company |  | T | [Base](/docs/person-data-field-bundles#base) |
| [`experience.company.industry_v2`](/docs/fields#experiencecompany) | [`Enum (String)`](/docs/industries-v2) | The self-identified V2 industry of the company |  | T | [Base](/docs/person-data-field-bundles#base) |
| [`experience.company.linkedin_id`](/docs/fields#experiencecompany) | `String` | The company's LinkedIn ID |  | T | [Base](/docs/person-data-field-bundles#base) |
| [`experience.company.linkedin_url`](/docs/fields#experiencecompany) | `String` | The company's LinkedIn URL |  | T | [Base](/docs/person-data-field-bundles#base) |
| [`experience.company.location`](/docs/fields#experiencecompany) | `Object` | The location of the company's headquarters |  | T | [Base](/docs/person-data-field-bundles#base) |
| [`experience.company.location.address_line_2`](/docs/fields#experiencecompany) | `String` | The street address line 2 of the company HQ address |  | T | [Base](/docs/person-data-field-bundles#base) |
| [`experience.company.location.continent`](/docs/fields#experiencecompany) | [`Enum (String)`](/docs/location-continents) | The continent the company HQ is in |  | T | [Base](/docs/person-data-field-bundles#base) |
| [`experience.company.location.country`](/docs/fields#experiencecompany) | [`Enum (String)`](/docs/location-countries) | The country the company HQ is in |  | T | [Base](/docs/person-data-field-bundles#base) |
| [`experience.company.location.geo`](/docs/fields#experiencecompany) | `String` | City-center geo code of the company HQ, in the formatÂ "latitude, longitude" |  | T | [Base](/docs/person-data-field-bundles#base) |
| [`experience.company.location.locality`](/docs/fields#experiencecompany) | `String` | The locality the company HQ is in |  | T | [Base](/docs/person-data-field-bundles#base) |
| [`experience.company.location.metro`](/docs/fields#experiencecompany) | [`Enum (String)`](/docs/location-metros) | The metro area the company HQ is in |  | T | [Base](/docs/person-data-field-bundles#base) |
| [`experience.company.location.name`](/docs/fields#experiencecompany) | `String` | Our cleaned values for the company HQ location in the formatÂ "locality, region, country" |  | T | [Base](/docs/person-data-field-bundles#base) |
| [`experience.company.location.postal_code`](/docs/fields#experiencecompany) | `String` | The postal code of the company HQ address |  | T | [Base](/docs/person-data-field-bundles#base) |
| [`experience.company.location.region`](/docs/fields#experiencecompany) | `String` | The region the company HQ is in |  | T | [Base](/docs/person-data-field-bundles#base) |
| [`experience.company.location.street_address`](/docs/fields#experiencecompany) | `String` | The street address of the company HQ |  | T | [Base](/docs/person-data-field-bundles#base) |
| [`experience.company.name`](/docs/fields#experiencecompany) | `String` | TheÂ company name, cleaned and standardized |  | T | [Base](/docs/person-data-field-bundles#base) |
| [`experience.company.raw`](/docs/fields#experiencecompany) | `String` | Raw company name | T | T | [Raw Fields](/docs/person-data-field-bundles#raw-fields) |
| [`experience.company.size`](/docs/fields#experiencecompany) | [`Enum (String)`](/docs/company-sizes) | The self-reportedÂ company size range |  | T | [Base](/docs/person-data-field-bundles#base) |
| [`experience.company.ticker`](/docs/fields#experiencecompany) | `String` | The company ticker | T | T | [Ticker Information](/docs/person-data-field-bundles#ticker-information) |
| [`experience.company.twitter_url`](/docs/fields#experiencecompany) | `String` | The company's Twitter URL |  | T | [Base](/docs/person-data-field-bundles#base) |
| [`experience.company.type`](/docs/fields#experiencecompany) | [`Enum (String)`](/docs/company-types) | The company type | T | T | [Ticker Information](/docs/person-data-field-bundles#ticker-information) |
| [`experience.company.website`](/docs/fields#experiencecompany) | `String` | The company's primary website, cleaned and standardized |  | T | [Base](/docs/person-data-field-bundles#base) |
| [`experience.end_date`](/docs/fields#experience) | [`String (Date)`](/docs/data-types#dates) | The date the person left the company |  | T | [Base](/docs/person-data-field-bundles#base) |
| [`experience.first_seen`](/docs/fields#experience) | [`String (Date)`](/docs/data-types#dates) | The date that this entity was first associated with the Person record | T | T | [Person Risk Attributes](/docs/person-data-field-bundles#person-risk-attributes) |
| [`experience.is_primary`](/docs/fields#experience) | `Boolean` | Whether this is the person's current job or not |  | T | [Base](/docs/person-data-field-bundles#base) |
| [`experience.last_seen`](/docs/fields#experience) | [`String (Date)`](/docs/data-types#dates) | The date that this entity was last associated with the Person record | T | T | [Person Risk Attributes](/docs/person-data-field-bundles#person-risk-attributes) |
| [`experience.location_names`](/docs/fields#experience) | `Array [String]` | Locations where the person has worked while with this company |  | T | [Base](/docs/person-data-field-bundles#base) |
| [`experience.num_sources`](/docs/fields#experience) | `Integer (> 0)` | The number of sources that have contributed to the association of this entity with the Person record | T | T | [Person Risk Attributes](/docs/person-data-field-bundles#person-risk-attributes) |
| [`experience.start_date`](/docs/fields#experience) | [`String (Date)`](/docs/data-types#dates) | The date the person started at the company |  | T | [Base](/docs/person-data-field-bundles#base) |
| [`experience.summary`](/docs/fields#experience) | `String` | User-inputted summary of their work experience | T | T | [Premium Resume Fields](/docs/person-data-field-bundles#premium-resume-fields) |
| [`experience.title`](/docs/fields#experiencetitle) | `Object` | The person's job title while at the company |  | T | [Base](/docs/person-data-field-bundles#base) |
| [`experience.title.levels`](/docs/fields#experiencetitle) | [`Array [Enum (String)]`](/docs/job-title-levels) | The level(s) of the job title |  | T | [Base](/docs/person-data-field-bundles#base) |
| [`experience.title.name`](/docs/fields#experiencetitle) | `String` | The cleaned job title |  | T | [Base](/docs/person-data-field-bundles#base) |
| [`experience.title.raw`](/docs/fields#experiencetitle) | `String` | Raw job title input | T | T | [Raw Fields](/docs/person-data-field-bundles#raw-fields) |
| [`experience.title.role`](/docs/fields#experiencetitle) | [`Enum (String)`](/docs/job-title-roles) | One of the Canonical Job Roles |  | T | [Base](/docs/person-data-field-bundles#base) |
| [`experience.title.sub_role`](/docs/fields#experiencetitle) | [`Enum (String)`](/docs/job-title-subroles) | One of the Canonical Job Sub Roles |  | T | [Base](/docs/person-data-field-bundles#base) |
| [`experience.title.class`](/docs/fields#experiencetitle) | [`Enum (String)`](/docs/job-title-class) | The expense line item category this employee would fall into |  | T | [Base](/docs/person-data-field-bundles#base) |
| [`facebook_friends`](/docs/fields#facebook_friends) | `Integer (>= 0)` | The number of Facebook friends the person has | T | T | [Person Risk Attributes](/docs/person-data-field-bundles#person-risk-attributes) |
| [`facebook_id`](/docs/fields#facebook_id) | `String` | The person's Facebook profile ID based on source agreement |  | T | [Base](/docs/person-data-field-bundles#base) |
| [`facebook_url`](/docs/fields#facebook_url) | `String` | The person's Facebook profile URL based on source agreement |  | T | [Base](/docs/person-data-field-bundles#base) |
| [`facebook_username`](/docs/fields#facebook_username) | `String` | The person's Facebook profile username based on source agreement |  | T | [Base](/docs/person-data-field-bundles#base) |
| [`first_name`](/docs/fields#first_name) | `String` | The person's first name |  | T | [Base](/docs/person-data-field-bundles#base) |
| [`first_seen`](/docs/fields#first_seen) | [`String (Date)`](/docs/data-types#dates) | The date when this record was first created in our data | T | T | [Person Risk Attributes](/docs/person-data-field-bundles#person-risk-attributes) |
| [`full_name`](/docs/fields#full_name) | `String` | The person's full name |  | T | [Base](/docs/person-data-field-bundles#base) |
| [`sex`](/docs/fields#sex) | [`Enum (String)`](/docs/genders) | The person's sex |  | T | [Base](/docs/person-data-field-bundles#base) |
| [`github_url`](/docs/fields#github_url) | `String` | The person's GitHub profile URL based on source agreement |  | T | [Base](/docs/person-data-field-bundles#base) |
| [`github_username`](/docs/fields#github_username) | `String` | The person's GitHub profile username based on source agreement |  | T | [Base](/docs/person-data-field-bundles#base) |
| [`headline`](/docs/fields#headline) | `String` | The brief headline associated with a person profile. | T | T | [Premium Resume Fields](/docs/person-data-field-bundles#premium-resume-fields) |
| [`id`](/docs/fields#id) | `String` | A unique persistent identifier for the person |  | T | [Base](/docs/person-data-field-bundles#base) |
| [`industry`](/docs/fields#industry) | [`Enum (String)`](/docs/industries) | The most relevant industry for this person based on their work history |  | T | [Base](/docs/person-data-field-bundles#base) |
| [`inferred_salary`](/docs/fields#inferred_salary) | [`Enum (String)`](/docs/inferred-salaries) | The inferred salary range (USD) for the person's current job | T | T | [Inferred Salary](/docs/person-data-field-bundles#inferred-salary) |
| [`inferred_years_experience`](/docs/fields#inferred_years_experience) | `Integer (0 - 100)` | The person's inferred years of total work experience | T | T | Inferred Years Experience |
| [`interests`](/docs/fields#interests) | `Array [String]` | The person's self-reported interests |  | T | [Base](/docs/person-data-field-bundles#base) |
| [`job_company_12mo_employee_growth_rate`](/docs/fields#job_company_12mo_employee_growth_rate) | `Float` | The personâ€™s current companyâ€™s percentage increase in total headcount over the past twelve months. | T | T | [Premium Company Attributes](/docs/person-data-field-bundles#premium-company-attributes) |
| [`job_company_employee_count`](/docs/fields#job_company_employee_count) | `Integer (>= 0)` | The total number of PDL profiles associated with the personâ€™s current company. | T | T | [Premium Company Attributes](/docs/person-data-field-bundles#premium-company-attributes) |
| [`job_company_facebook_url`](/docs/fields#job_company_facebook_url) | `String` | The person's current company'sÂ Facebook URL |  | T | [Base](/docs/person-data-field-bundles#base) |
| [`job_company_founded`](/docs/fields#job_company_founded) | `Integer (> 0)` | The person's current company'sÂ founding year |  | T | [Base](/docs/person-data-field-bundles#base) |
| [`job_company_id`](/docs/fields#job_company_id) | `String` | The person's current company'sÂ PDL ID |  | T | [Base](/docs/person-data-field-bundles#base) |
| [`job_company_industry`](/docs/fields#job_company_industry) | [`Enum (String)`](/docs/industries) | The person's current company'sÂ industry |  | T | [Base](/docs/person-data-field-bundles#base) |
| [`job_company_industry_v2`](/docs/fields#job_company_industry_v2) | [`Enum (String)`](/docs/industries-v2) | The v2 industry for the personâ€™s current company. |  | T | [Base](/docs/person-data-field-bundles#base) |
| [`job_company_inferred_revenue`](/docs/fields#job_company_inferred_revenue) | [`Enum (String)`](/docs/inferred-revenue-ranges) | The estimated annual revenue range in USD of the personâ€™s current company. | T | T | [Premium Company Attributes](/docs/person-data-field-bundles#premium-company-attributes) |
| [`job_company_linkedin_id`](/docs/fields#job_company_linkedin_id) | `String` | The person's current company'sÂ LinkedIn ID |  | T | [Base](/docs/person-data-field-bundles#base) |
| [`job_company_linkedin_url`](/docs/fields#job_company_linkedin_url) | `String` | The person's current company'sÂ LinkedIn URL |  | T | [Base](/docs/person-data-field-bundles#base) |
| [`job_company_location_address_line_2`](/docs/fields#job_company_location_address_line_2) | `String` | The person's current company's headquarters'Â street address line 2 |  | T | [Base](/docs/person-data-field-bundles#base) |
| [`job_company_location_continent`](/docs/fields#job_company_location_continent) | [`Enum (String)`](/docs/location-continents) | The person's current company's headquarters'Â continent |  | T | [Base](/docs/person-data-field-bundles#base) |
| [`job_company_location_country`](/docs/fields#job_company_location_country) | [`Enum (String)`](/docs/location-countries) | The person's current company's headquarters'Â country |  | T | [Base](/docs/person-data-field-bundles#base) |
| [`job_company_location_geo`](/docs/fields#job_company_location_geo) | `String` | The person's current company's headquarters'Â city-center geographic coordinates |  | T | [Base](/docs/person-data-field-bundles#base) |
| [`job_company_location_locality`](/docs/fields#job_company_location_locality) | `String` | The person's current company's headquarters'Â locality |  | T | [Base](/docs/person-data-field-bundles#base) |
| [`job_company_location_metro`](/docs/fields#job_company_location_metro) | [`Enum (String)`](/docs/location-metros) | The person's current company's headquarters'Â metro area |  | T | [Base](/docs/person-data-field-bundles#base) |
| [`job_company_location_name`](/docs/fields#job_company_location_name) | `String` | The person's current company's headquarters' location name |  | T | [Base](/docs/person-data-field-bundles#base) |
| [`job_company_location_postal_code`](/docs/fields#job_company_location_postal_code) | `String` | The person's current company's headquarters'Â postal code |  | T | [Base](/docs/person-data-field-bundles#base) |
| [`job_company_location_region`](/docs/fields#job_company_location_region) | `String` | The person's current company's headquarters' region |  | T | [Base](/docs/person-data-field-bundles#base) |
| [`job_company_location_street_address`](/docs/fields#job_company_location_street_address) | `String` | The person's current company's headquarters' street address |  | T | [Base](/docs/person-data-field-bundles#base) |
| [`job_company_name`](/docs/fields#job_company_name) | `String` | The person's current company'sÂ name |  | T | [Base](/docs/person-data-field-bundles#base) |
| [`job_company_size`](/docs/fields#job_company_size) | [`Enum (String)`](/docs/company-sizes) | The person's current company's size range |  | T | [Base](/docs/person-data-field-bundles#base) |
| [`job_company_ticker`](/docs/fields#job_company_ticker) | `String` | The company ticker for the person's current job | T | T | [Ticker Information](/docs/person-data-field-bundles#ticker-information) |
| [`job_company_total_funding_raised`](/docs/fields#job_company_total_funding_raised) | `Integer (> 0)` | The cumulative amount of money raised in USD by the personâ€™s current company during all publicly disclosed funding rounds. | T | T | [Premium Company Attributes](/docs/person-data-field-bundles#premium-company-attributes) |
| [`job_company_twitter_url`](/docs/fields#job_company_twitter_url) | `String` | The person's current company's Twitter URL |  | T | [Base](/docs/person-data-field-bundles#base) |
| [`job_company_type`](/docs/fields#job_company_type) | [`Enum (String)`](/docs/company-types) | The company type for the person's current job | T | T | [Ticker Information](/docs/person-data-field-bundles#ticker-information) |
| [`job_company_website`](/docs/fields#job_company_website) | `String` | The person's current company's website |  | T | [Base](/docs/person-data-field-bundles#base) |
| [`job_history`](/docs/fields#job_history) | `Array [Object]` | Additional professional positions that may have been removed or changed on resumes | T | T | [Person Risk Attributes](/docs/person-data-field-bundles#person-risk-attributes) |
| [`job_history.company_id`](/docs/fields#job_history) | `String` | PDL Company ID | T | T | [Person Risk Attributes](/docs/person-data-field-bundles#person-risk-attributes) |
| [`job_history.company_name`](/docs/fields#job_history) | `String` | Company name | T | T | [Person Risk Attributes](/docs/person-data-field-bundles#person-risk-attributes) |
| [`job_history.first_seen`](/docs/fields#job_history) | [`String (Date)`](/docs/data-types#dates) | The date that this experience was first associated with this record | T | T | [Person Risk Attributes](/docs/person-data-field-bundles#person-risk-attributes) |
| [`job_history.last_seen`](/docs/fields#job_history) | [`String (Date)`](/docs/data-types#dates) | The date that this experience was last associated with this record | T | T | [Person Risk Attributes](/docs/person-data-field-bundles#person-risk-attributes) |
| [`job_history.num_sources`](/docs/fields#job_history) | `Integer (> 0)` | The number of sources that have contributed to the association of this profile with this record | T | T | [Person Risk Attributes](/docs/person-data-field-bundles#person-risk-attributes) |
| [`job_history.title`](/docs/fields#job_history) | `String` | Job Title | T | T | [Person Risk Attributes](/docs/person-data-field-bundles#person-risk-attributes) |
| [`job_last_changed`](/docs/fields#job_last_changed) | [`String (Date)`](/docs/data-types#dates) | The timestamp that reflects when the top-level job information changed. |  | T | [Base](/docs/person-data-field-bundles#base) |
| [`job_last_verified`](/docs/fields#job_last_verified) | [`String (Date)`](/docs/data-types#dates) | The timestamp that reflects when the top level job information was last validated by a data source. |  | T | [Base](/docs/person-data-field-bundles#base) |
| [`job_onet_broad_occupation`](/docs/fields#job_onet_broad_occupation) | `String` | The O\*NET Broad Occupation associated with the personâ€™s current job title | T | T | [O\*Net Fields](/docs/person-data-field-bundles#onet-fields) |
| [`job_onet_code`](/docs/fields#job_onet_code) | `String` | The 8-digit O\*NET code for the personâ€™s current job title | T | T | [O\*Net Fields](/docs/person-data-field-bundles#onet-fields) |
| [`job_onet_major_group`](/docs/fields#job_onet_major_group) | `String` | The O\*NET Major Group associated with the personâ€™s current job title | T | T | [O\*Net Fields](/docs/person-data-field-bundles#onet-fields) |
| [`job_onet_minor_group`](/docs/fields#job_onet_minor_group) | `String` | The O\*NET Minor Group associated with the personâ€™s current job title | T | T | [O\*Net Fields](/docs/person-data-field-bundles#onet-fields) |
| [`job_onet_specific_occupation`](/docs/fields#job_onet_specific_occupation) | `String` | The O\*NET Specific Occupation associated with the personâ€™s current job title | T | T | [O\*Net Fields](/docs/person-data-field-bundles#onet-fields) |
| [`job_onet_specific_occupation_detail`](/docs/fields#job_onet_specific_occupation_detail) | `String` | A more detailed job title classification than O\*NET Specific Occupation | T | T | [O\*Net Fields](/docs/person-data-field-bundles#onet-fields) |
| [`job_start_date`](/docs/fields#job_start_date) | [`String (Date)`](/docs/data-types#dates) | The date the person started their current job |  | T | [Base](/docs/person-data-field-bundles#base) |
| [`job_summary`](/docs/fields#job_summary) | `String` | User-inputted summary of their current job | T | T | [Premium Resume Fields](/docs/person-data-field-bundles#premium-resume-fields) |
| [`job_title`](/docs/fields#job_title) | `String` | The person's current job title |  | T | [Base](/docs/person-data-field-bundles#base) |
| [`job_title_levels`](/docs/fields#job_title_levels) | [`Array [Enum (String)]`](/docs/job-title-levels) | The derived level(s) of the person's current job title |  | T | [Base](/docs/person-data-field-bundles#base) |
| [`job_title_role`](/docs/fields#job_title_role) | [`Enum (String)`](/docs/job-title-roles) | The derived role of the person's current job title |  | T | [Base](/docs/person-data-field-bundles#base) |
| [`job_title_sub_role`](/docs/fields#job_title_sub_role) | [`Enum (String)`](/docs/job-title-subroles) | The derived subrole of the person's current job title |  | T | [Base](/docs/person-data-field-bundles#base) |
| [`job_title_class`](/docs/fields#job_title_class) | [`Enum (String)`](/docs/job-title-class) | The expense line item category this employee would fall into |  | T | [Base](/docs/person-data-field-bundles#base) |
| [`languages`](/docs/fields#languages) | `Array [Object]` | Languages the person knows | T | T | [Premium Resume Fields](/docs/person-data-field-bundles#premium-resume-fields) |
| [`languages.name`](/docs/fields#languages) | [`Enum (String)`](/docs/language-names) | The language | T | T | [Premium Resume Fields](/docs/person-data-field-bundles#premium-resume-fields) |
| [`languages.proficiency`](/docs/fields#languages) | `Integer (1-5)` | Self-ranked language proficiency from 1 (limited) to 5 (fluent) | T | T | [Premium Resume Fields](/docs/person-data-field-bundles#premium-resume-fields) |
| [`last_initial`](/docs/fields#last_initial) | `String (1 character)` | The first letter of the person's last name |  | T | [Base](/docs/person-data-field-bundles#base) |
| [`last_name`](/docs/fields#last_name) | `String` | The person's last name |  | T | [Base](/docs/person-data-field-bundles#base) |
| [`linkedin_connections`](/docs/fields#linkedin_connections) | `Integer (>= 0)` | The number of LinkedIn connections the person has | T | T | [Linkedin Connections](/docs/person-data-field-bundles#linkedin-connections) |
| [`linkedin_id`](/docs/fields#linkedin_id) | `String` | The person's LinkedIn profile ID. This is null when no values in the "profiles" array are active |  | T | [Base](/docs/person-data-field-bundles#base) |
| [`linkedin_url`](/docs/fields#linkedin_url) | `String` | The person's current LinkedIn profile URL. This is null when no values in the "profiles" array are active |  | T | [Base](/docs/person-data-field-bundles#base) |
| [`linkedin_username`](/docs/fields#linkedin_username) | `String` | The person's LinkedIn profile username. This is null when no values in the "profiles" array are active |  | T | [Base](/docs/person-data-field-bundles#base) |
| [`location_address_line_2`](/docs/fields#location_address_line_2) | `String` | The person's current street address line 2 |  | T | [Base](/docs/person-data-field-bundles#base) |
| [`location_continent`](/docs/fields#location_continent) | [`Enum (String)`](/docs/location-continents) | TheÂ continent of the person's current address |  | T | [Base](/docs/person-data-field-bundles#base) |
| [`location_country`](/docs/fields#location_country) | [`Enum (String)`](/docs/location-countries) | TheÂ country of the person's current address |  | T | [Base](/docs/person-data-field-bundles#base) |
| [`location_geo`](/docs/fields#location_geo) | `String` | TheÂ geo codeÂ of the city center of the person's current address |  | T | [Base](/docs/person-data-field-bundles#base) |
| [`location_last_updated`](/docs/fields#location_last_updated) | [`String (Date)`](/docs/data-types#dates) | The timestamp that a new data source contributed to the record for the person's current address |  | T | [Base](/docs/person-data-field-bundles#base) |
| [`location_locality`](/docs/fields#location_locality) | `String` | The locality of the person's current address |  | T | [Base](/docs/person-data-field-bundles#base) |
| [`location_metro`](/docs/fields#location_metro) | [`Enum (String)`](/docs/location-metros) | TheÂ metroÂ of the person's current address |  | T | [Base](/docs/person-data-field-bundles#base) |
| [`location_name`](/docs/fields#location_name) | `String` | TheÂ locationÂ of the person's current address |  | T | [Base](/docs/person-data-field-bundles#base) |
| [`location_names`](/docs/fields#location_names) | `Array [String]` | All location names associated with the person |  | T | [Base](/docs/person-data-field-bundles#base) |
| [`location_postal_code`](/docs/fields#location_postal_code) | `String` | TheÂ postal codeÂ of the person's current address |  | T | [Base](/docs/person-data-field-bundles#base) |
| [`location_region`](/docs/fields#location_region) | `String` | The region of the person's current address |  | T | [Base](/docs/person-data-field-bundles#base) |
| [`location_street_address`](/docs/fields#location_street_address) | `String` | The person's currentÂ street address |  | T | [Base](/docs/person-data-field-bundles#base) |
| [`middle_initial`](/docs/fields#middle_initial) | `String (1 character)` | The first letter of the person's middle name |  | T | [Base](/docs/person-data-field-bundles#base) |
| [`middle_name`](/docs/fields#middle_name) | `String` | The person's middle name |  | T | [Base](/docs/person-data-field-bundles#base) |
| [`mobile_phone`](/docs/fields#mobile_phone) | [`String (Phone)`](/docs/data-types#phone-numbers) | The personal mobile phone associated with this individual. Mobile phones can only be associated with 1 person in the PDL data. |  | T | [Base](/docs/person-data-field-bundles#base) |
| [`name_aliases`](/docs/fields#name_aliases) | `Array [String]` | Any other names the person goes by | T | T | [Person Risk Attributes](/docs/person-data-field-bundles#person-risk-attributes) |
| [`num_records`](/docs/fields#num_records) | `Integer (> 0)` | The number of unique raw records contributing to this specific PDL profile | T | T | [Person Risk Attributes](/docs/person-data-field-bundles#person-risk-attributes) |
| [`num_sources`](/docs/fields#num_sources) | `Integer (> 0)` | The number of unique sources contributing to this specific PDL profile | T | T | [Person Risk Attributes](/docs/person-data-field-bundles#person-risk-attributes) |
| [`operation_id`](/docs/fields#operation_id) | `String` | An identifier for an operation in a Data License delivery, used for troubleshooting. |  |  | [Base](/docs/person-data-field-bundles#base) |
| [`personal_emails`](/docs/fields#personal_emails) | `Array [String]` | All personal emails associated with the person |  | T | [Base](/docs/person-data-field-bundles#base) |
| [`phone_numbers`](/docs/fields#phone_numbers) | [`Array [String (Phone)]`](/docs/data-types#phone-numbers) | All phone numbers associated with the person |  | T | [Base](/docs/person-data-field-bundles#base) |
| [`phones`](/docs/fields#phones) | `Array [Object]` | The list of phone numbers associated with this record | T | T | [Person Risk Attributes](/docs/person-data-field-bundles#person-risk-attributes) |
| [`phones.first_seen`](/docs/fields#phones) | [`String (Date)`](/docs/data-types#dates) | The date that this number was first associated with this record | T | T | [Person Risk Attributes](/docs/person-data-field-bundles#person-risk-attributes) |
| [`phones.last_seen`](/docs/fields#phones) | [`String (Date)`](/docs/data-types#dates) | The date that this number was last associated with this record | T | T | [Person Risk Attributes](/docs/person-data-field-bundles#person-risk-attributes) |
| [`phones.num_sources`](/docs/fields#phones) | `Integer (> 0)` | The number of sources that have contributed to the association of this profile with this record | T | T | [Person Risk Attributes](/docs/person-data-field-bundles#person-risk-attributes) |
| [`phones.number`](/docs/fields#phones) | [`String (Phone)`](/docs/data-types#phone-numbers) | The phone number | T | T | [Person Risk Attributes](/docs/person-data-field-bundles#person-risk-attributes) |
| [`possible_birth_dates`](/docs/fields#possible_birth_dates) | [`Array [String (Date)]`](/docs/data-types#dates) | Birthdays associated with this person that have a lower level of confidence | T |  | [Person Risk Attributes](/docs/person-data-field-bundles#person-risk-attributes) |
| [`possible_emails`](/docs/fields#possible_emails) | `Array [Object]` | Email addresses associated with this person that have a lower level of confidence | T | T | [Person Risk Attributes](/docs/person-data-field-bundles#person-risk-attributes) |
| [`possible_emails.address`](/docs/fields#possible_emails) | `String` | The fully parsed email address | T | T | [Person Risk Attributes](/docs/person-data-field-bundles#person-risk-attributes) |
| [`possible_emails.first_seen`](/docs/fields#possible_emails) | [`String (Date)`](/docs/data-types#dates) | The date that this entity was first associated with the Person record | T | T | [Person Risk Attributes](/docs/person-data-field-bundles#person-risk-attributes) |
| [`possible_emails.last_seen`](/docs/fields#possible_emails) | [`String (Date)`](/docs/data-types#dates) | The date that this entity was last associated with the Person record | T | T | [Person Risk Attributes](/docs/person-data-field-bundles#person-risk-attributes) |
| [`possible_emails.num_sources`](/docs/fields#possible_emails) | `Integer (> 0)` | The number of sources that have contributed to the association of this entity with the Person record | T | T | [Person Risk Attributes](/docs/person-data-field-bundles#person-risk-attributes) |
| [`possible_emails.type`](/docs/fields#possible_emails) | [`Enum (String)`](/docs/email-types) | The type of email | T | T | [Person Risk Attributes](/docs/person-data-field-bundles#person-risk-attributes) |
| [`possible_location_names`](/docs/fields#possible_location_names) | `Array [String]` | Locations associated with this person that have a lower level of confidence | T | T | [Person Risk Attributes](/docs/person-data-field-bundles#person-risk-attributes) |
| [`possible_phones`](/docs/fields#possible_phones) | `Array [Object]` | Phone numbers associated with this person that have a lower level of confidence | T | T | [Person Risk Attributes](/docs/person-data-field-bundles#person-risk-attributes) |
| [`possible_phones.first_seen`](/docs/fields#possible_phones) | [`String (Date)`](/docs/data-types#dates) | The date that this number was first associated with this record | T | T | [Person Risk Attributes](/docs/person-data-field-bundles#person-risk-attributes) |
| [`possible_phones.last_seen`](/docs/fields#possible_phones) | [`String (Date)`](/docs/data-types#dates) | The date that this number was last associated with this record | T | T | [Person Risk Attributes](/docs/person-data-field-bundles#person-risk-attributes) |
| [`possible_phones.num_sources`](/docs/fields#possible_phones) | `Integer (> 0)` | The number of sources that have contributed to the association of this profile with this record | T | T | [Person Risk Attributes](/docs/person-data-field-bundles#person-risk-attributes) |
| [`possible_phones.number`](/docs/fields#possible_phones) | [`String (Phone)`](/docs/data-types#phone-numbers) | The phone number | T | T | [Person Risk Attributes](/docs/person-data-field-bundles#person-risk-attributes) |
| [`possible_profiles`](/docs/fields#possible_profiles) | `Array [Object]` | Social profiles associated with this person that have a lower level of confidence | T | T | [Person Risk Attributes](/docs/person-data-field-bundles#person-risk-attributes) |
| [`possible_profiles.first_seen`](/docs/fields#possible_profiles) | [`String (Date)`](/docs/data-types#dates) | The date that this entity was first associated with the Person record | T | T | [Person Risk Attributes](/docs/person-data-field-bundles#person-risk-attributes) |
| [`possible_profiles.id`](/docs/fields#possible_profiles) | `String` | The profile ID | T | T | [Person Risk Attributes](/docs/person-data-field-bundles#person-risk-attributes) |
| [`possible_profiles.last_seen`](/docs/fields#possible_profiles) | [`String (Date)`](/docs/data-types#dates) | The date that this entity was last associated with the Person record | T | T | [Person Risk Attributes](/docs/person-data-field-bundles#person-risk-attributes) |
| [`possible_profiles.network`](/docs/fields#possible_profiles) | [`Enum (String)`](/docs/profile-networks) | The social network the profile is on | T | T | [Person Risk Attributes](/docs/person-data-field-bundles#person-risk-attributes) |
| [`possible_profiles.num_sources`](/docs/fields#possible_profiles) | `Integer (> 0)` | The number of sources that have contributed to the association of this entity with the Person record | T | T | [Person Risk Attributes](/docs/person-data-field-bundles#person-risk-attributes) |
| [`possible_profiles.url`](/docs/fields#possible_profiles) | `String` | The profile URL | T | T | [Person Risk Attributes](/docs/person-data-field-bundles#person-risk-attributes) |
| [`possible_profiles.username`](/docs/fields#possible_profiles) | `String` | The profile username | T | T | [Person Risk Attributes](/docs/person-data-field-bundles#person-risk-attributes) |
| [`possible_street_addresses`](/docs/fields#possible_street_addresses) | `Array [Object]` | Addresses associated with this person that have a lower level of confidence | T | T | [Person Risk Attributes](/docs/person-data-field-bundles#person-risk-attributes) |
| [`possible_street_addresses.address_line_2`](/docs/fields#possible_street_addresses) | `String` | TheÂ street address line 2 | T |  | [Person Risk Attributes](/docs/person-data-field-bundles#person-risk-attributes) |
| [`possible_street_addresses.continent`](/docs/fields#possible_street_addresses) | [`Enum (String)`](/docs/location-continents) | The continent the address is in | T |  | [Person Risk Attributes](/docs/person-data-field-bundles#person-risk-attributes) |
| [`possible_street_addresses.country`](/docs/fields#possible_street_addresses) | [`Enum (String)`](/docs/location-countries) | The country the address is in | T |  | [Person Risk Attributes](/docs/person-data-field-bundles#person-risk-attributes) |
| [`possible_street_addresses.first_seen`](/docs/fields#possible_street_addresses) | [`String (Date)`](/docs/data-types#dates) | The date that this entity was first associated with the Person record | T | T | [Person Risk Attributes](/docs/person-data-field-bundles#person-risk-attributes) |
| [`possible_street_addresses.geo`](/docs/fields#possible_street_addresses) | `String` | The city-center geographic coordinates of the address | T |  | [Person Risk Attributes](/docs/person-data-field-bundles#person-risk-attributes) |
| [`possible_street_addresses.last_seen`](/docs/fields#possible_street_addresses) | [`String (Date)`](/docs/data-types#dates) | The date that this entity was last associated with the Person record | T | T | [Person Risk Attributes](/docs/person-data-field-bundles#person-risk-attributes) |
| [`possible_street_addresses.locality`](/docs/fields#possible_street_addresses) | `String` | The locality the address is in | T |  | [Person Risk Attributes](/docs/person-data-field-bundles#person-risk-attributes) |
| [`possible_street_addresses.metro`](/docs/fields#possible_street_addresses) | [`Enum (String)`](/docs/location-metros) | The metro area the address is in | T |  | [Person Risk Attributes](/docs/person-data-field-bundles#person-risk-attributes) |
| [`possible_street_addresses.name`](/docs/fields#possible_street_addresses) | `String` | The location of the address | T | T | [Person Risk Attributes](/docs/person-data-field-bundles#person-risk-attributes) |
| [`possible_street_addresses.num_sources`](/docs/fields#possible_street_addresses) | `Integer (> 0)` | The number of sources that have contributed to the association of this entity with the Person record | T | T | [Person Risk Attributes](/docs/person-data-field-bundles#person-risk-attributes) |
| [`possible_street_addresses.postal_code`](/docs/fields#possible_street_addresses) | `String` | The postal code of the address | T |  | [Person Risk Attributes](/docs/person-data-field-bundles#person-risk-attributes) |
| [`possible_street_addresses.region`](/docs/fields#possible_street_addresses) | `String` | The region of the address | T |  | [Person Risk Attributes](/docs/person-data-field-bundles#person-risk-attributes) |
| [`possible_street_addresses.street_address`](/docs/fields#possible_street_addresses) | `String` | The street address | T |  | [Person Risk Attributes](/docs/person-data-field-bundles#person-risk-attributes) |
| [`profiles`](/docs/fields#profiles) | `Array [Object]` | Social profiles associated with the person |  | T | [Base](/docs/person-data-field-bundles#base) |
| [`profiles.first_seen`](/docs/fields#profiles) | [`String (Date)`](/docs/data-types#dates) | The date that this entity was first associated with the Person record | T | T | [Person Risk Attributes](/docs/person-data-field-bundles#person-risk-attributes) |
| [`profiles.id`](/docs/fields#profiles) | `String` | The profile ID |  | T | [Base](/docs/person-data-field-bundles#base) |
| [`profiles.last_seen`](/docs/fields#profiles) | [`String (Date)`](/docs/data-types#dates) | The date that this entity was last associated with the Person record | T | T | [Person Risk Attributes](/docs/person-data-field-bundles#person-risk-attributes) |
| [`profiles.network`](/docs/fields#profiles) | [`Enum (String)`](/docs/profile-networks) | The social network the profile is on |  | T | [Base](/docs/person-data-field-bundles#base) |
| [`profiles.num_sources`](/docs/fields#profiles) | `Integer (> 0)` | The number of sources that have contributed to the association of this entity with the Person record | T | T | [Person Risk Attributes](/docs/person-data-field-bundles#person-risk-attributes) |
| [`profiles.url`](/docs/fields#profiles) | `String` | The profile URL |  | T | [Base](/docs/person-data-field-bundles#base) |
| [`profiles.username`](/docs/fields#profiles) | `String` | The profile username |  | T | [Base](/docs/person-data-field-bundles#base) |
| [`recommended_personal_email`](/docs/fields#recommended_personal_email) | `String` | The best available email to reach a person |  | T | [Base](/docs/person-data-field-bundles#base) |
| [`regions`](/docs/fields#regions) | `Array [String]` | AllÂ regionsÂ associated with the person |  | T | [Base](/docs/person-data-field-bundles#base) |
| [`skills`](/docs/fields#skills) | `Array [String]` | The person's self-reported skills |  | T | [Base](/docs/person-data-field-bundles#base) |
| [`street_addresses`](/docs/fields#street_addresses) | `Array [Object]` | AllÂ street addressesÂ associated with the person |  | T | [Base](/docs/person-data-field-bundles#base) |
| [`street_addresses.address_line_2`](/docs/fields#street_addresses) | `String` | TheÂ street address line 2 |  | T | [Base](/docs/person-data-field-bundles#base) |
| [`street_addresses.continent`](/docs/fields#street_addresses) | [`Enum (String)`](/docs/location-continents) | The continent the address is in |  | T | [Base](/docs/person-data-field-bundles#base) |
| [`street_addresses.country`](/docs/fields#street_addresses) | [`Enum (String)`](/docs/location-countries) | The country the address is in |  | T | [Base](/docs/person-data-field-bundles#base) |
| [`street_addresses.first_seen`](/docs/fields#street_addresses) | [`String (Date)`](/docs/data-types#dates) | The date that this entity was first associated with the Person record | T | T | [Person Risk Attributes](/docs/person-data-field-bundles#person-risk-attributes) |
| [`street_addresses.geo`](/docs/fields#street_addresses) | `String` | The city-center geographic coordinates of the address |  | T | [Base](/docs/person-data-field-bundles#base) |
| [`street_addresses.last_seen`](/docs/fields#street_addresses) | [`String (Date)`](/docs/data-types#dates) | The date that this entity was last associated with the Person record | T | T | [Person Risk Attributes](/docs/person-data-field-bundles#person-risk-attributes) |
| [`street_addresses.locality`](/docs/fields#street_addresses) | `String` | The locality the address is in |  | T | [Base](/docs/person-data-field-bundles#base) |
| [`street_addresses.metro`](/docs/fields#street_addresses) | [`Enum (String)`](/docs/location-metros) | The metro area the address is in |  | T | [Base](/docs/person-data-field-bundles#base) |
| [`street_addresses.name`](/docs/fields#street_addresses) | `String` | The location of the address |  | T | [Base](/docs/person-data-field-bundles#base) |
| [`street_addresses.num_sources`](/docs/fields#street_addresses) | `Integer (> 0)` | The number of sources that have contributed to the association of this entity with the Person record | T | T | [Person Risk Attributes](/docs/person-data-field-bundles#person-risk-attributes) |
| [`street_addresses.postal_code`](/docs/fields#street_addresses) | `String` | The postal code of the address |  | T | [Base](/docs/person-data-field-bundles#base) |
| [`street_addresses.region`](/docs/fields#street_addresses) | `String` | The region of the address |  | T | [Base](/docs/person-data-field-bundles#base) |
| [`street_addresses.street_address`](/docs/fields#street_addresses) | `String` | The street address |  | T | [Base](/docs/person-data-field-bundles#base) |
| [`summary`](/docs/fields#summary) | `String` | User-inputted personal summary | T | T | [Premium Resume Fields](/docs/person-data-field-bundles#premium-resume-fields) |
| [`twitter_url`](/docs/fields#twitter_url) | `String` | The person's Twitter profile URL based on source agreement |  | T | [Base](/docs/person-data-field-bundles#base) |
| [`twitter_username`](/docs/fields#twitter_username) | `String` | The person's Twitter profile username based on source agreement |  | T | [Base](/docs/person-data-field-bundles#base) |
| [`work_email`](/docs/fields#work_email) | `String` | The person's current work email |  | T | [Base](/docs/person-data-field-bundles#base) |

---



*Know someone whoâ€™d thrive building data products and helping us launch whatâ€™s next? Weâ€™d love to meet!*

*Check out our[open roles](https://www.peopledatalabs.com/company?utm_source=docs&utm_medium=footer&utm_campaign=cta#jobs) â†’*

Updated about 11 hours ago

---

Did this page help you?

Yes

No

---
# https://docs.peopledatalabs.com/docs/enrichment-api

## Overview

The Person Enrichment API enables you to enrich data on a person by performing a one-to-one match of this person with the nearly three billion individual profiles that are hosted in our dataset. Once matched, you have access to all the fields in our [Person Schema](/docs/fields), which can include names, addresses, employment information and social media accounts.

## What's Next

Please check out the following pages for more information on the Person Enrichment API:

| Page | Description |
| --- | --- |
| [Quickstart](/docs/quickstart-person-enrichment-api) | A quick hands-on introduction to the API with simple code examples. |
| [Reference](/docs/reference-person-enrichment-api) | Detailed descriptions of the technical specifications and usage constraints. |
| [Input Parameters](/docs/input-parameters-person-enrichment-api) | In-depth explanations of the input parameters that the API supports. |
| [Output Response](/docs/output-response-person-enrichment-api) | In-depth explanations of the output response object that the API returns. |
| [Examples](/docs/examples-person-enrichment-api) | A collection of functional code examples and walkthroughs that illustrate various use cases and applications of the API. |
| [FAQs](/docs/faqs-person-enrichment-api) | Answers to commonly asked questions and other good-to-know information. |
| [Bulk Person Enrichment API](/docs/bulk-enrichment-api) | A supporting functionality to enrich multiple profiles in the same request. |
| [Preview Enrichment API](/docs/preview-enrichment-api) | A supporting functionality to preview which fields have non-null data for a particular person. |

---



*Know someone whoâ€™d thrive building data products and helping us launch whatâ€™s next? Weâ€™d love to meet!*

*Check out our[open roles](https://www.peopledatalabs.com/company?utm_source=docs&utm_medium=footer&utm_campaign=cta#jobs) â†’*

Updated 4 months ago

---

Did this page help you?

Yes

No

---
# https://docs.peopledatalabs.com/docs/naics-codes

| Canonical Values for NAICS Codes |
| --- |
| abrasive product manufacturing |
| adhesive manufacturing |
| administration of air and water resource and solid waste management programs |
| administration of conservation programs |
| administration of education programs |
| administration of general economic programs |
| administration of housing programs |
| administration of human resource programs (except education, public health, and veterans' affairs programs) |
| administration of public health programs |
| administration of urban planning and community and rural development |
| administration of veterans' affairs |
| administrative management and general management consulting services |
| advertising agencies |
| advertising material distribution services |
| agents and managers for artists, athletes, entertainers, and other public figures |
| air and gas compressor manufacturing |
| air traffic control |
| air-conditioning and warm air heating equipment and commercial and industrial refrigeration equipment manufacturing |
| aircraft engine and engine parts manufacturing |
| aircraft manufacturing |
| all other amusement and recreation industries |
| all other animal production |
| all other automotive repair and maintenance |
| all other basic organic chemical manufacturing |
| all other business support services |
| all other consumer goods rental |
| all other converted paper product manufacturing |
| all other general merchandise stores |
| all other grain farming |
| all other health and personal care stores |
| all other home furnishings stores |
| all other information services |
| all other insurance related activities |
| all other leather good and allied product manufacturing |
| all other legal services |
| all other metal ore mining |
| all other miscellaneous ambulatory health care services |
| all other miscellaneous chemical product and preparation manufacturing |
| all other miscellaneous crop farming |
| all other miscellaneous electrical equipment and component manufacturing |
| all other miscellaneous fabricated metal product manufacturing |
| all other miscellaneous food manufacturing |
| all other miscellaneous general purpose machinery manufacturing |
| all other miscellaneous manufacturing |
| all other miscellaneous nonmetallic mineral product manufacturing |
| all other miscellaneous schools and instruction |
| all other miscellaneous store retailers (except tobacco stores) |
| all other miscellaneous textile product mills |
| all other miscellaneous waste management services |
| all other miscellaneous wood product manufacturing |
| all other nondepository credit intermediation |
| all other nonmetallic mineral mining |
| all other outpatient care centers |
| all other personal services |
| all other petroleum and coal products manufacturing |
| all other pipeline transportation |
| all other plastics product manufacturing |
| all other professional, scientific, and technical services |
| all other publishers |
| all other rubber product manufacturing |
| all other specialty food stores |
| all other specialty trade contractors |
| all other support activities for transportation |
| all other support services |
| all other telecommunications |
| all other transit and ground passenger transportation |
| all other transportation equipment manufacturing |
| all other travel arrangement and reservation services |
| all other traveler accommodation |
| alumina refining and primary aluminum production |
| aluminum foundries (except die-casting) |
| aluminum sheet, plate, and foil manufacturing |
| ambulance services |
| american indian and alaska native tribal governments |
| ammunition (except small arms) manufacturing |
| amusement and theme parks |
| amusement arcades |
| analytical laboratory instrument manufacturing |
| animal (except poultry) slaughtering |
| anthracite mining |
| apiculture |
| apparel accessories and other apparel manufacturing |
| apple orchards |
| appliance repair and maintenance |
| apprenticeship training |
| architectural services |
| armored car services |
| art dealers |
| artificial and synthetic fibers and filaments manufacturing |
| asphalt paving mixture and block manufacturing |
| asphalt shingle and coating materials manufacturing |
| assisted living facilities for the elderly |
| audio and video equipment manufacturing |
| automatic environmental control manufacturing for residential, commercial, and appliance use |
| automobile and other motor vehicle merchant wholesalers |
| automobile driving schools |
| automobile manufacturing |
| automotive body, paint, and interior repair and maintenance |
| automotive exhaust system repair |
| automotive glass replacement shops |
| automotive oil change and lubrication shops |
| automotive parts and accessories stores |
| automotive transmission repair |
| baked goods stores |
| ball and roller bearing manufacturing |
| barber shops |
| bare printed circuit board manufacturing |
| beauty salons |
| bed-and-breakfast inns |
| beef cattle ranching and farming |
| beer and ale merchant wholesalers |
| beer, wine, and liquor stores |
| beet sugar manufacturing |
| berry (except strawberry) farming |
| biological product (except diagnostic) manufacturing |
| biomass electric power generation |
| bituminous coal and lignite surface mining |
| bituminous coal underground mining |
| blank magnetic and optical recording media manufacturing |
| blind and shade manufacturing |
| blood and organ banks |
| boat building |
| boat dealers |
| bolt, nut, screw, rivet, and washer manufacturing |
| book publishers |
| book stores |
| book, periodical, and newspaper merchant wholesalers |
| books printing |
| bottled water manufacturing |
| bowling centers |
| breakfast cereal manufacturing |
| breweries |
| brick, stone, and related construction material merchant wholesalers |
| broadwoven fabric mills |
| broilers and other meat type chicken production |
| broom, brush, and mop manufacturing |
| building inspection services |
| burial casket manufacturing |
| bus and other motor vehicle transit systems |
| business and secretarial schools |
| business associations |
| business to business electronic markets |
| cable and other subscription programming |
| cafeterias, grill buffets, and buffets |
| cane sugar manufacturing |
| capacitor, resistor, coil, transformer, and other inductor manufacturing |
| car washes |
| carbon and graphite product manufacturing |
| carpet and rug mills |
| carpet and upholstery cleaning services |
| casino hotels |
| casinos (except casino hotels) |
| caterers |
| cattle feedlots |
| cement manufacturing |
| cemeteries and crematories |
| charter bus industry |
| cheese manufacturing |
| chicken egg production |
| child and youth services |
| child day care services |
| children's and infants' clothing stores |
| chocolate and confectionery manufacturing from cacao beans |
| citrus (except orange) groves |
| civic and social organizations |
| claims adjusting |
| clay and ceramic and refractory minerals mining |
| clay building material and refractories manufacturing |
| clothing accessories stores |
| coal and other mineral and ore merchant wholesalers |
| coastal and great lakes freight transportation |
| coastal and great lakes passenger transportation |
| coffee and tea manufacturing |
| coin-operated laundries and drycleaners |
| collection agencies |
| colleges, universities, and professional schools |
| commercial air, rail, and water transportation equipment rental and leasing |
| commercial and industrial machinery and equipment (except automotive and electronic) repair and maintenance |
| commercial and institutional building construction |
| commercial bakeries |
| commercial banking |
| commercial photography |
| commercial printing (except screen and books) |
| commercial screen printing |
| commercial, industrial, and institutional electric lighting fixture manufacturing |
| commodity contracts brokerage |
| commodity contracts dealing |
| communication equipment repair and maintenance |
| community food services |
| commuter rail systems |
| computer and computer peripheral equipment and software merchant wholesalers |
| computer and office machine repair and maintenance |
| computer facilities management services |
| computer storage device manufacturing |
| computer systems design services |
| computer terminal and other computer peripheral equipment manufacturing |
| computer training |
| concrete block and brick manufacturing |
| concrete pipe manufacturing |
| confectionery and nut stores |
| confectionery manufacturing from purchased chocolate |
| confectionery merchant wholesalers |
| construction and mining (except oil well) machinery and equipment merchant wholesalers |
| construction machinery manufacturing |
| construction sand and gravel mining |
| construction, mining, and forestry machinery and equipment rental and leasing |
| consumer electronics and appliances rental |
| consumer electronics repair and maintenance |
| consumer lending |
| continuing care retirement communities |
| convenience stores |
| convention and trade show organizers |
| convention and visitors bureaus |
| conveyor and conveying equipment manufacturing |
| cookie and cracker manufacturing |
| copper rolling, drawing, extruding, and alloying |
| copper, nickel, lead, and zinc mining |
| corn farming |
| corporate, subsidiary, and regional managing offices |
| correctional institutions |
| corrugated and solid fiber box manufacturing |
| cosmetics, beauty supplies, and perfume stores |
| cosmetology and barber schools |
| cotton farming |
| cotton ginning |
| couriers and express delivery services |
| court reporting and stenotype services |
| courts |
| creamery butter manufacturing |
| credit bureaus |
| credit card issuing |
| credit unions |
| crop harvesting, primarily by machine |
| crude petroleum extraction |
| crushed and broken granite mining and quarrying |
| crushed and broken limestone mining and quarrying |
| current-carrying wiring device manufacturing |
| curtain and linen mills |
| custom architectural woodwork and millwork manufacturing |
| custom compounding of purchased resins |
| custom computer programming services |
| custom roll forming |
| cut and sew apparel contractors |
| cut stock, resawing lumber, and planing |
| cut stone and stone product manufacturing |
| cutting tool and machine tool accessory manufacturing |
| cyclic crude, intermediate, and gum and wood chemical manufacturing |
| dairy cattle and milk production |
| dairy product (except dried or canned) merchant wholesalers |
| dance companies |
| data processing, hosting, and related services |
| deep sea freight transportation |
| deep sea passenger transportation |
| dental equipment and supplies manufacturing |
| dental laboratories |
| department stores |
| diagnostic imaging centers |
| diet and weight reducing centers |
| dimension stone mining and quarrying |
| direct health and medical insurance carriers |
| direct life insurance carriers |
| direct mail advertising |
| direct property and casualty insurance carriers |
| direct title insurance carriers |
| directory and mailing list publishers |
| distilleries |
| document preparation services |
| dog and cat food manufacturing |
| doll, toy, and game manufacturing |
| drafting services |
| dried and dehydrated food manufacturing |
| drilling oil and gas wells |
| drinking places (alcoholic beverages) |
| drive-in motion picture theaters |
| drugs and druggists' sundries merchant wholesalers |
| dry pasta, dough, and flour mixes manufacturing from purchased flour |
| dry pea and bean farming |
| dry, condensed, and evaporated dairy product manufacturing |
| drycleaning and laundry services (except coin-operated) |
| drywall and insulation contractors |
| dual-purpose cattle ranching and farming |
| educational support services |
| electric bulk power transmission and control |
| electric lamp bulb and part manufacturing |
| electric power distribution |
| electrical apparatus and equipment, wiring supplies, and related equipment merchant wholesalers |
| electrical contractors and other wiring installation contractors |
| electromedical and electrotherapeutic apparatus manufacturing |
| electronic computer manufacturing |
| electronic connector manufacturing |
| electronic shopping and mail-order houses |
| electronics stores |
| electroplating, plating, polishing, anodizing, and coloring |
| elementary and secondary schools |
| elevator and moving stairway manufacturing |
| emergency and other relief services |
| employment placement agencies |
| engineered wood member (except truss) manufacturing |
| engineering services |
| environment, conservation and wildlife organizations |
| environmental consulting services |
| ethyl alcohol manufacturing |
| exam preparation and tutoring |
| executive and legislative offices, combined |
| executive offices |
| executive search services |
| explosives manufacturing |
| exterminating and pest control services |
| fabric coating mills |
| fabricated pipe and pipe fitting manufacturing |
| fabricated structural metal manufacturing |
| facilities support services |
| family clothing stores |
| family planning centers |
| farm and garden machinery and equipment merchant wholesalers |
| farm labor contractors and crew leaders |
| farm machinery and equipment manufacturing |
| farm management services |
| farm product warehousing and storage |
| farm supplies merchant wholesalers |
| fastener, button, needle, and pin manufacturing |
| fats and oils refining and blending |
| fertilizer (mixing only) manufacturing |
| fiber optic cable manufacturing |
| fiber, yarn, and thread mills |
| financial transactions processing, reserve, and clearinghouse activities |
| fine arts schools |
| finfish farming and fish hatcheries |
| finfish fishing |
| finish carpentry contractors |
| fire protection |
| fish and seafood markets |
| fish and seafood merchant wholesalers |
| fitness and recreational sports centers |
| flat glass manufacturing |
| flavoring syrup and concentrate manufacturing |
| flight training |
| floor covering stores |
| flooring contractors |
| floriculture production |
| florists |
| flour milling |
| flower, nursery stock, and florists' supplies merchant wholesalers |
| fluid milk manufacturing |
| fluid power cylinder and actuator manufacturing |
| fluid power pump and motor manufacturing |
| fluid power valve and hose fitting manufacturing |
| folding paperboard box manufacturing |
| food (health) supplement stores |
| food product machinery manufacturing |
| food service contractors |
| footwear and leather goods repair |
| footwear manufacturing |
| footwear merchant wholesalers |
| forest nurseries and gathering of forest products |
| formal wear and costume rental |
| fossil fuel electric power generation |
| framing contractors |
| freestanding ambulatory surgical and emergency centers |
| freight transportation arrangement |
| fresh fruit and vegetable merchant wholesalers |
| frozen cakes, pies, and other pastries manufacturing |
| frozen fruit, juice, and vegetable manufacturing |
| frozen specialty food manufacturing |
| fruit and tree nut combination farming |
| fruit and vegetable canning |
| fruit and vegetable markets |
| fuel dealers |
| full-service restaurants |
| funeral homes and funeral services |
| fur-bearing animal and rabbit production |
| furniture merchant wholesalers |
| furniture stores |
| gasket, packing, and sealing device manufacturing |
| gasoline stations with convenience stores |
| general automotive repair |
| general freight trucking, local |
| general freight trucking, long-distance, less than truckload |
| general freight trucking, long-distance, truckload |
| general line grocery merchant wholesalers |
| general medical and surgical hospitals |
| general rental centers |
| general warehousing and storage |
| geophysical surveying and mapping services |
| geothermal electric power generation |
| gift, novelty, and souvenir stores |
| glass and glazing contractors |
| glass container manufacturing |
| glass product manufacturing made of purchased glass |
| goat farming |
| gold ore mining |
| golf courses and country clubs |
| grain and field bean merchant wholesalers |
| grantmaking foundations |
| grape vineyards |
| graphic design services |
| greeting card publishers |
| ground or treated mineral and earth manufacturing |
| guided missile and space vehicle manufacturing |
| guided missile and space vehicle propulsion unit and propulsion unit parts manufacturing |
| gypsum product manufacturing |
| hardware manufacturing |
| hardware merchant wholesalers |
| hardware stores |
| hardwood veneer and plywood manufacturing |
| hay farming |
| hazardous waste collection |
| hazardous waste treatment and disposal |
| health and welfare funds |
| heating equipment (except warm air furnaces) manufacturing |
| heavy duty truck manufacturing |
| highway, street, and bridge construction |
| historical sites |
| hmo medical centers |
| hobby, toy, and game stores |
| hog and pig farming |
| home and garden equipment repair and maintenance |
| home centers |
| home furnishing merchant wholesalers |
| home health care services |
| home health equipment rental |
| horses and other equine production |
| hosiery and sock mills |
| hotels (except casino hotels) and motels |
| household appliance stores |
| household appliances, electric housewares, and consumer electronics merchant wholesalers |
| household furniture (except wood and metal) manufacturing |
| human resources consulting services |
| human rights organizations |
| hunting and trapping |
| hydroelectric power generation |
| ice cream and frozen dessert manufacturing |
| ice manufacturing |
| in-vitro diagnostic substance manufacturing |
| independent artists, writers, and performers |
| industrial and commercial fan and blower and air purification equipment manufacturing |
| industrial and personal service paper merchant wholesalers |
| industrial building construction |
| industrial design services |
| industrial gas manufacturing |
| industrial launderers |
| industrial machinery and equipment merchant wholesalers |
| industrial mold manufacturing |
| industrial process furnace and oven manufacturing |
| industrial sand mining |
| industrial supplies merchant wholesalers |
| industrial truck, tractor, trailer, and stacker machinery manufacturing |
| industrial valve manufacturing |
| inland water freight transportation |
| inland water passenger transportation |
| institutional furniture manufacturing |
| instrument manufacturing for measuring and testing electricity and electrical signals |
| instruments and related products manufacturing for measuring, displaying, and controlling industrial process variables |
| insurance agencies and brokerages |
| interior design services |
| international affairs |
| international trade financing |
| internet publishing and broadcasting and web search portals |
| interurban and rural bus transportation |
| investigation services |
| investment advice |
| investment banking and securities dealing |
| iron and steel forging |
| iron and steel mills and ferroalloy manufacturing |
| iron and steel pipe and tube manufacturing from purchased steel |
| iron foundries |
| iron ore mining |
| irradiation apparatus manufacturing |
| janitorial services |
| jewelry and silverware manufacturing |
| jewelry stores |
| jewelry, watch, precious stone, and precious metal merchant wholesalers |
| junior colleges |
| kaolin and ball clay mining |
| kidney dialysis centers |
| knit fabric mills |
| labor unions and similar labor organizations |
| laminated plastics plate, sheet (except packaging), and shape manufacturing |
| land subdivision |
| landscape architectural services |
| landscaping services |
| language schools |
| lawn and garden tractor and home lawn and garden equipment manufacturing |
| leather and hide tanning and finishing |
| legal counsel and prosecution |
| legislative bodies |
| lessors of miniwarehouses and self-storage units |
| lessors of nonfinancial intangible assets (except copyrighted works) |
| lessors of nonresidential buildings (except miniwarehouses) |
| lessors of other real estate property |
| lessors of residential buildings and dwellings |
| libraries and archives |
| light truck and utility vehicle manufacturing |
| lime manufacturing |
| limited-service restaurants |
| limousine service |
| line-haul railroads |
| linen supply |
| livestock merchant wholesalers |
| local messengers and local delivery |
| locksmiths |
| logging |
| luggage and leather goods stores |
| lumber, plywood, millwork, and wood panel merchant wholesalers |
| machine shops |
| machine tool manufacturing |
| major household appliance manufacturing |
| malt manufacturing |
| manufactured (mobile) home dealers |
| manufactured home (mobile home) manufacturing |
| marinas |
| marine cargo handling |
| marketing consulting services |
| marketing research and public opinion polling |
| masonry contractors |
| materials recovery facilities |
| mattress manufacturing |
| mayonnaise, dressing, and other prepared sauce manufacturing |
| measuring, dispensing, and other pumping equipment manufacturing |
| meat and meat product merchant wholesalers |
| meat markets |
| meat processed from carcasses |
| mechanical power transmission equipment manufacturing |
| media buying agencies |
| media representatives |
| medical laboratories |
| medical, dental, and hospital equipment and supplies merchant wholesalers |
| medicinal and botanical manufacturing |
| men's and boys' clothing and furnishings merchant wholesalers |
| men's clothing stores |
| menâ€™s and boysâ€™ cut and sew apparel manufacturing |
| metal can manufacturing |
| metal coating, engraving (except jewelry and silverware), and allied services to manufacturers |
| metal crown, closure, and other metal stamping (except automotive) |
| metal heat treating |
| metal household furniture manufacturing |
| metal kitchen cookware, utensil, cutlery, and flatware (except precious) manufacturing |
| metal service centers and other metal merchant wholesalers |
| metal tank (heavy gauge) manufacturing |
| metal window and door manufacturing |
| military armored vehicle, tank, and tank component manufacturing |
| mineral wool manufacturing |
| mining machinery and equipment manufacturing |
| miscellaneous financial investment activities |
| miscellaneous intermediation |
| mixed mode transit systems |
| mobile food services |
| monetary authorities-central bank |
| mortgage and nonmortgage loan brokers |
| motion picture and video distribution |
| motion picture and video production |
| motion picture theaters (except drive-ins) |
| motor and generator manufacturing |
| motor home manufacturing |
| motor vehicle body manufacturing |
| motor vehicle brake system manufacturing |
| motor vehicle electrical and electronic equipment manufacturing |
| motor vehicle gasoline engine and engine parts manufacturing |
| motor vehicle metal stamping |
| motor vehicle parts (used) merchant wholesalers |
| motor vehicle seating and interior trim manufacturing |
| motor vehicle steering and suspension components (except spring) manufacturing |
| motor vehicle supplies and new parts merchant wholesalers |
| motor vehicle towing |
| motor vehicle transmission and power train parts manufacturing |
| motorcycle, atv, and all other motor vehicle dealers |
| motorcycle, bicycle, and parts manufacturing |
| museums |
| mushroom production |
| music publishers |
| musical groups and artists |
| musical instrument and supplies stores |
| musical instrument manufacturing |
| nail salons |
| narrow fabric mills and schiffli machine embroidery |
| national security |
| natural gas distribution |
| natural gas extraction |
| nature parks and other similar institutions |
| navigational services to shipping |
| new car dealers |
| new housing for-sale builders |
| new multifamily housing construction (except for-sale builders) |
| new single-family housing construction (except for-sale builders) |
| news dealers and newsstands |
| news syndicates |
| newspaper publishers |
| newsprint mills |
| nitrogenous fertilizer manufacturing |
| nonchocolate confectionery manufacturing |
| noncurrent-carrying wiring device manufacturing |
| nonferrous forging |
| nonferrous metal (except aluminum) smelting and refining |
| nonferrous metal (except copper and aluminum) rolling, drawing, and extruding |
| nonferrous metal die-casting foundries |
| nonresidential property managers |
| nonscheduled chartered freight air transportation |
| nonscheduled chartered passenger air transportation |
| nonupholstered wood household furniture manufacturing |
| nonwoven fabric mills |
| nuclear electric power generation |
| nursery and tree production |
| nursery, garden center, and farm supply stores |
| nursing care facilities (skilled nursing facilities) |
| office administrative services |
| office equipment merchant wholesalers |
| office furniture (except wood) manufacturing |
| office machinery and equipment rental and leasing |
| office supplies (except paper) manufacturing |
| office supplies and stationery stores |
| offices of all other miscellaneous health practitioners |
| offices of bank holding companies |
| offices of certified public accountants |
| offices of chiropractors |
| offices of dentists |
| offices of lawyers |
| offices of mental health practitioners (except physicians) |
| offices of notaries |
| offices of optometrists |
| offices of other holding companies |
| offices of physical, occupational and speech therapists, and audiologists |
| offices of physicians (except mental health specialists) |
| offices of physicians, mental health specialists |
| offices of podiatrists |
| offices of real estate agents and brokers |
| offices of real estate appraisers |
| oil and gas field machinery and equipment manufacturing |
| oil and gas pipeline and related structures construction |
| oilseed (except soybean) farming |
| oilseed and grain combination farming |
| one-hour photofinishing |
| open-end investment funds |
| ophthalmic goods manufacturing |
| ophthalmic goods merchant wholesalers |
| optical goods stores |
| optical instrument and lens manufacturing |
| orange groves |
| ornamental and architectural metal work manufacturing |
| other accounting services |
| other activities related to credit intermediation |
| other activities related to real estate |
| other aircraft parts and auxiliary equipment manufacturing |
| other airport operations |
| other aluminum rolling, drawing, and extruding |
| other animal food manufacturing |
| other apparel knitting mills |
| other aquaculture |
| other automotive mechanical and electrical repair and maintenance |
| other basic inorganic chemical manufacturing |
| other building equipment contractors |
| other building finishing contractors |
| other building material dealers |
| other business service centers (including copy shops) |
| other chemical and allied products merchant wholesalers |
| other chemical and fertilizer mineral mining |
| other clothing stores |
| other commercial and industrial machinery and equipment rental and leasing |
| other commercial and service industry machinery manufacturing |
| other commercial equipment merchant wholesalers |
| other communication and energy wire manufacturing |
| other communications equipment manufacturing |
| other community housing services |
| other computer related services |
| other concrete product manufacturing |
| other construction material merchant wholesalers |
| other crushed and broken stone mining and quarrying |
| other cut and sew apparel manufacturing |
| other depository credit intermediation |
| other direct insurance (except life, health, and medical) carriers |
| other direct selling establishments |
| other electric power generation |
| other electronic and precision equipment repair and maintenance |
| other electronic component manufacturing |
| other electronic parts and equipment merchant wholesalers |
| other engine equipment manufacturing |
| other fabricated wire product manufacturing |
| other farm product raw material merchant wholesalers |
| other financial vehicles |
| other food crops grown under cover |
| other foundation, structure, and building exterior contractors |
| other gambling industries |
| other gasoline stations |
| other general government support |
| other grantmaking and giving services |
| other grocery and related products merchant wholesalers |
| other guided missile and space vehicle parts and auxiliary equipment manufacturing |
| other heavy and civil engineering construction |
| other individual and family services |
| other industrial machinery manufacturing |
| other insurance funds |
| other justice, public order, and safety activities |
| other lighting equipment manufacturing |
| other management consulting services |
| other marine fishing |
| other measuring and controlling device manufacturing |
| other metal container manufacturing |
| other metal valve and pipe fitting manufacturing |
| other millwork (including flooring) |
| other miscellaneous durable goods merchant wholesalers |
| other miscellaneous nondurable goods merchant wholesalers |
| other motion picture and video industries |
| other motor vehicle parts manufacturing |
| other noncitrus fruit farming |
| other nonferrous metal foundries (except die-casting) |
| other nonhazardous waste treatment and disposal |
| other nonscheduled air transportation |
| other paperboard container manufacturing |
| other performing arts companies |
| other personal and household goods repair and maintenance |
| other personal care services |
| other poultry production |
| other pressed and blown glass and glassware manufacturing |
| other professional equipment and supplies merchant wholesalers |
| other residential care facilities |
| other scientific and technical consulting services |
| other services related to advertising |
| other services to buildings and dwellings |
| other similar organizations (except business, professional, labor, and political organizations) |
| other snack food manufacturing |
| other social advocacy organizations |
| other sound recording industries |
| other specialized design services |
| other spectator sports |
| other support activities for air transportation |
| other support activities for road transportation |
| other support activities for water transportation |
| other technical and trade schools |
| other urban transit systems |
| other vegetable (except potato) and melon farming |
| other warehousing and storage |
| other waste collection |
| outdoor advertising |
| outdoor power equipment stores |
| outpatient mental health and substance abuse centers |
| overhead traveling crane, hoist, and monorail system manufacturing |
| packaged frozen food merchant wholesalers |
| packaging and labeling services |
| packaging machinery manufacturing |
| packing and crating |
| paint and coating manufacturing |
| paint and wallpaper stores |
| paint, varnish, and supplies merchant wholesalers |
| painting and wall covering contractors |
| paper (except newsprint) mills |
| paper bag and coated and treated paper manufacturing |
| paperboard mills |
| parking lots and garages |
| parole offices and probation offices |
| passenger car leasing |
| passenger car rental |
| payroll services |
| peanut farming |
| pension funds |
| periodical publishers |
| perishable prepared food manufacturing |
| pesticide and other agricultural chemical manufacturing |
| pet and pet supplies stores |
| pet care (except veterinary) services |
| petrochemical manufacturing |
| petroleum and petroleum products merchant wholesalers (except bulk stations and terminals) |
| petroleum bulk stations and terminals |
| petroleum lubricating oil and grease manufacturing |
| petroleum refineries |
| pharmaceutical preparation manufacturing |
| pharmacies and drug stores |
| phosphate rock mining |
| phosphatic fertilizer manufacturing |
| photofinishing laboratories (except one-hour) |
| photographic and photocopying equipment manufacturing |
| photographic equipment and supplies merchant wholesalers |
| photographic film, paper, plate, and chemical manufacturing |
| photography studios, portrait |
| piece goods, notions, and other dry goods merchant wholesalers |
| pipeline transportation of crude oil |
| pipeline transportation of natural gas |
| pipeline transportation of refined petroleum products |
| plastics bag and pouch manufacturing |
| plastics bottle manufacturing |
| plastics material and resin manufacturing |
| plastics materials and basic forms and shapes merchant wholesalers |
| plastics packaging film and sheet (including laminated) manufacturing |
| plastics pipe and pipe fitting manufacturing |
| plastics plumbing fixture manufacturing |
| plate work manufacturing |
| plumbing and heating equipment and supplies (hydronics) merchant wholesalers |
| plumbing fixture fitting and trim manufacturing |
| plumbing, heating, and air-conditioning contractors |
| police protection |
| polish and other sanitation good manufacturing |
| political organizations |
| polystyrene foam product manufacturing |
| port and harbor operations |
| portfolio management |
| postal service |
| postharvest crop activities (except cotton ginning) |
| potash, soda, and borate mineral mining |
| potato farming |
| pottery, ceramics, and plumbing fixture manufacturing |
| poultry and poultry product merchant wholesalers |
| poultry hatcheries |
| poultry processing |
| poured concrete foundation and structure contractors |
| powder metallurgy part manufacturing |
| power and communication line and related structures construction |
| power boiler and heat exchanger manufacturing |
| power, distribution, and specialty transformer manufacturing |
| power-driven handtool manufacturing |
| precision turned product manufacturing |
| prefabricated metal building and component manufacturing |
| prefabricated wood building manufacturing |
| primary battery manufacturing |
| printed circuit assembly (electronic assembly) manufacturing |
| printing and writing paper merchant wholesalers |
| printing ink manufacturing |
| printing machinery and equipment manufacturing |
| private households |
| private mail centers |
| process, physical distribution, and logistics consulting services |
| professional and management development training |
| professional employer organizations |
| professional organizations |
| promoters of performing arts, sports, and similar events with facilities |
| promoters of performing arts, sports, and similar events without facilities |
| psychiatric and substance abuse hospitals |
| public finance activities |
| public relations agencies |
| pulp mills |
| racetracks |
| radio and television broadcasting and wireless communications equipment manufacturing |
| radio networks |
| radio stations |
| railroad rolling stock manufacturing |
| ready-mix concrete manufacturing |
| real estate credit |
| reconstituted wood product manufacturing |
| record production and distribution |
| recreational and vacation camps (except campgrounds) |
| recreational goods rental |
| recreational vehicle dealers |
| recyclable material merchant wholesalers |
| refrigerated warehousing and storage |
| refrigeration equipment and supplies merchant wholesalers |
| regulation and administration of communications, electric, gas, and other utilities |
| regulation and administration of transportation programs |
| regulation of agricultural marketing and commodities |
| regulation, licensing, and inspection of miscellaneous commercial sectors |
| reinsurance carriers |
| relay and industrial control manufacturing |
| religious organizations |
| remediation services |
| rendering and meat byproduct processing |
| repossession services |
| research and development in biotechnology (except nanobiotechnology) |
| research and development in nanotechnology |
| research and development in the physical, engineering, and life sciences (except nanotechnology and biotechnology) |
| research and development in the social sciences and humanities |
| residential electric lighting fixture manufacturing |
| residential intellectual and developmental disability facilities |
| residential mental health and substance abuse facilities |
| residential property managers |
| residential remodelers |
| retail bakeries |
| reupholstery and furniture repair |
| rice farming |
| rice milling |
| roasted nuts and peanut butter manufacturing |
| rolled steel shape manufacturing |
| rolling mill and other metalworking machinery manufacturing |
| roofing contractors |
| roofing, siding, and insulation material merchant wholesalers |
| rooming and boarding houses, dormitories, and workers' camps |
| rope, cordage, twine, tire cord, and tire fabric mills |
| rubber and plastics hoses and belting manufacturing |
| rubber product manufacturing for mechanical use |
| rv (recreational vehicle) parks and campgrounds |
| sales financing |
| sanitary paper product manufacturing |
| satellite telecommunications |
| savings institutions |
| saw blade and handtool manufacturing |
| sawmill, woodworking, and paper machinery manufacturing |
| sawmills |
| scale and balance manufacturing |
| scenic and sightseeing transportation, land |
| scenic and sightseeing transportation, other |
| scenic and sightseeing transportation, water |
| scheduled freight air transportation |
| scheduled passenger air transportation |
| school and employee bus transportation |
| seafood product preparation and packaging |
| search, detection, navigation, guidance, aeronautical, and nautical system and instrument manufacturing |
| secondary market financing |
| secondary smelting and alloying of aluminum |
| secondary smelting, refining, and alloying of nonferrous metal (except copper and aluminum) |
| securities and commodity exchanges |
| securities brokerage |
| security guards and patrol services |
| security systems services (except locksmiths) |
| semiconductor and related device manufacturing |
| semiconductor machinery manufacturing |
| septic tank and related services |
| service establishment equipment and supplies merchant wholesalers |
| services for the elderly and persons with disabilities |
| sewage treatment facilities |
| sewing, needlework, and piece goods stores |
| sheep farming |
| sheet metal work manufacturing |
| shellfish farming |
| shellfish fishing |
| ship building and repairing |
| shoe stores |
| short line railroads |
| showcase, partition, shelving, and locker manufacturing |
| siding contractors |
| sign manufacturing |
| silver ore mining |
| site preparation contractors |
| skiing facilities |
| small arms ammunition manufacturing |
| small arms, ordnance, and ordnance accessories manufacturing |
| small electrical appliance manufacturing |
| snack and nonalcoholic beverage bars |
| soap and other detergent manufacturing |
| soft drink manufacturing |
| software and other prerecorded compact disc, tape, and record reproducing |
| software publishers |
| softwood veneer and plywood manufacturing |
| soil preparation, planting, and cultivating |
| solar electric power generation |
| solid waste collection |
| solid waste combustors and incinerators |
| solid waste landfill |
| sound recording studios |
| soybean and other oilseed processing |
| soybean farming |
| space research and technology |
| special die and tool, die set, jig, and fixture manufacturing |
| special needs transportation |
| specialized freight (except used goods) trucking, local |
| specialized freight (except used goods) trucking, long-distance |
| specialty (except psychiatric and substance abuse) hospitals |
| specialty canning |
| speed changer, industrial high-speed drive, and gear manufacturing |
| spice and extract manufacturing |
| sporting and athletic goods manufacturing |
| sporting and recreational goods and supplies merchant wholesalers |
| sporting goods stores |
| sports and recreation instruction |
| sports teams and clubs |
| spring manufacturing |
| stationery and office supplies merchant wholesalers |
| stationery product manufacturing |
| steam and air-conditioning supply |
| steel foundries (except investment) |
| steel investment foundries |
| steel wire drawing |
| storage battery manufacturing |
| strawberry farming |
| structural steel and precast concrete contractors |
| sugar beet farming |
| sugarcane farming |
| supermarkets and other grocery (except convenience) stores |
| support activities for animal production |
| support activities for coal mining |
| support activities for forestry |
| support activities for metal mining |
| support activities for nonmetallic minerals (except fuels) mining |
| support activities for oil and gas operations |
| support activities for printing |
| support activities for rail transportation |
| surface active agent manufacturing |
| surgical and medical instrument manufacturing |
| surgical appliance and supplies manufacturing |
| surveying and mapping (except geophysical) services |
| switchgear and switchboard apparatus manufacturing |
| synthetic dye and pigment manufacturing |
| synthetic rubber manufacturing |
| tax preparation services |
| taxi service |
| telecommunications resellers |
| telemarketing bureaus and other contact centers |
| telephone answering services |
| telephone apparatus manufacturing |
| teleproduction and other postproduction services |
| television broadcasting |
| temporary help services |
| temporary shelters |
| testing laboratories |
| textile and fabric finishing mills |
| textile bag and canvas mills |
| theater companies and dinner theaters |
| third party administration of insurance and pension funds |
| tile and terrazzo contractors |
| timber tract operations |
| tire and tube merchant wholesalers |
| tire dealers |
| tire manufacturing (except retreading) |
| tire retreading |
| title abstract and settlement offices |
| tobacco and tobacco product merchant wholesalers |
| tobacco farming |
| tobacco manufacturing |
| tobacco stores |
| toilet preparation manufacturing |
| tortilla manufacturing |
| totalizing fluid meter and counting device manufacturing |
| tour operators |
| toy and hobby goods and supplies merchant wholesalers |
| translation and interpretation services |
| transportation equipment and supplies (except motor vehicle) merchant wholesalers |
| travel agencies |
| travel trailer and camper manufacturing |
| tree nut farming |
| truck trailer manufacturing |
| truck, utility trailer, and rv (recreational vehicle) rental and leasing |
| truss manufacturing |
| trust, fiduciary, and custody activities |
| trusts, estates, and agency accounts |
| turbine and turbine generator set units manufacturing |
| turkey production |
| unlaminated plastics film and sheet (except packaging) manufacturing |
| unlaminated plastics profile shape manufacturing |
| upholstered household furniture manufacturing |
| uranium-radium-vanadium ore mining |
| urethane and other foam product (except polystyrene) manufacturing |
| used car dealers |
| used household and office goods moving |
| used merchandise stores |
| vending machine operators |
| veterinary services |
| video tape and disc rental |
| vocational rehabilitation services |
| voluntary health organizations |
| warehouse clubs and supercenters |
| warm air heating and air-conditioning equipment and supplies merchant wholesalers |
| water and sewer line and related structures construction |
| water supply and irrigation systems |
| welding and soldering equipment manufacturing |
| wet corn milling |
| wheat farming |
| wholesale trade agents and brokers |
| wind electric power generation |
| window treatment stores |
| wine and distilled alcoholic beverage merchant wholesalers |
| wineries |
| wired telecommunications carriers |
| wireless telecommunications carriers (except satellite) |
| women's clothing stores |
| women's handbag and purse manufacturing |
| women's, children's, and infants' clothing and accessories merchant wholesalers |
| womenâ€™s, girlsâ€™, and infantsâ€™ cut and sew apparel manufacturing |
| wood container and pallet manufacturing |
| wood kitchen cabinet and countertop manufacturing |
| wood office furniture manufacturing |
| wood preservation |
| wood window and door manufacturing |
| zoos and botanical gardens |

*Contents of this table were sourced from the following file on our public S3 bucket:[naics\_code.txt](https://pdl-prod-schema.s3.us-west-2.amazonaws.com/28.0/enums/naics_code.txt)*

## Relevant fields

* [`naics.naics_code`](/docs/company-schema#naics)

Updated 4 months ago

---

Did this page help you?

Yes

No

---
# https://docs.peopledatalabs.com/docs/data-formatting

# No Data

Every response object will contain every field listed in the Schema page that the customer has paid for.

If we do not have data for a field, its value will be `null` unless the field is an Array type, in which case its value will be an empty list `[]`.

# Phone Numbers

All phone numbers will be in in [E164 format](https://en.wikipedia.org/wiki/E.164) with a leading `+` and country code. For example, `"+15558675309"`.

# Currencies

Unless otherwise stated in the Schema page for a field, all currency values are in USD.

# Locations

### Localities

We match locations using a strict/fuzzy logic. Our goal is match as many locations as possible to our Location Data entity, linking them based on `location.name`. To tap into our location matching logic, use our [Location Cleaner API](/docs/cleaner-apis) or retrieve possible location values using our [Autocomplete API](/docs/autocomplete-api).

### Addresses

We standardize addresses in the US and Canada using an internal address parser. We do not conform to any standards such as [CASS](https://en.wikipedia.org/wiki/Coding_Accuracy_Support_System), although we try to imitate them as much as possible.

### Common Location Fields

We break location data into the following fields. These names are used throughout our data to refer to location information.

| Field | Data Type | Description |
| --- | --- | --- |
| `name` | `String` | Our cleaned values for locations in the format `locality, region, country`. |
| `locality` | `String` | The locality of the address |
| `region` | `String` | The region of the address |
| `metro` | `Enum (String)` | **US ONLY.** These are generated based on the census-designated MSAs and maps. Will be one of our [Canonical Metros](/docs/location-metros). |
| `country` | `Enum (String)` | Standardized format for country. Will be one of our [Canonical Countries](/docs/location-countries). |
| `continent` | `Enum (String)` | Standardized format for continent. Will be one of our [Canonical Continents](/docs/location-continents). |
| `street_address` | `String` | The street address |
| `address_line_2` | `String` | The street address line 2 |
| `postal_code` | `String` | The postal code of the address |
| `geo` | `String` | City-center geo code of a locality, in the format `latitude, longitude` |

Updated 4 months ago

---

Did this page help you?

Yes

No

---
# https://docs.peopledatalabs.com/docs/job-title-levels

| Canonical Values for Job Title Levels |
| --- |
| cxo |
| director |
| entry |
| manager |
| owner |
| partner |
| senior |
| training |
| unpaid |
| vp |

*Contents of this table were sourced from the following file on our public S3 bucket:[job\_title\_levels.txt](https://pdl-prod-schema.s3.us-west-2.amazonaws.com/28.0/enums/job_title_levels.txt)*

## Relevant fields

* [`average_tenure_by_level`](/docs/company-schema#average_tenure_by_level)
* [`employee_count_by_month_by_level`](/docs/company-schema#employee_count_by_month_by_level)
* [`experience.title.levels`](/docs/fields#experiencetitle)
* [`job_title_levels`](/docs/fields#job_title_levels)
* [`recent_exec_departures.job_title_levels`](/docs/company-schema#recent_exec_departures)
* [`recent_exec_departures.new_company_job_title_levels`](/docs/company-schema#recent_exec_departures)
* [`recent_exec_hires.job_title_levels`](/docs/company-schema#recent_exec_hires)
* [`recent_exec_hires.previous_company_job_title_levels`](/docs/company-schema#recent_exec_hires)

Updated 4 months ago

---

Did this page help you?

Yes

No

---
# https://docs.peopledatalabs.com/docs/genders

| Canonical Values for Sex |
| --- |
| female |
| male |

*Contents of this table were sourced from the following file on our public S3 bucket:[sex.txt](https://pdl-prod-schema.s3.us-west-2.amazonaws.com/28.0/enums/sex.txt)*

## Relevant fields

* [`sex`](/docs/fields#sex)

Updated 4 months ago

---

Did this page help you?

Yes

No

---
# https://docs.peopledatalabs.com/docs/company-data-overview

The following table contains an overview of each company-related field in our dataset. Click the field name to go to the corresponding section in our [Company Schema](/docs/company-schema) to see additional details about each field.

> ðŸ“˜
>
> ### Field Availability
>
> Please note: Not all fields are available in all packages.
>
> For more details about the fields we offer, including fill rates and which fields are included in the base vs premium packages, check out our [Company Data Field Bundles](/docs/company-data-field-bundles).

  

| Field | Type | Short Description | Requires add-on | Searchable | Bundle |
| --- | --- | --- | --- | --- | --- |
| [`affiliated_entities`](/docs/company-schema#affiliated_entities) | `Array [Object]` | Object containing information on related company profiles. | T |  | [Premium](/docs/company-data-field-bundles#premium) |
| [`affiliated_entities.affiliated_id`](/docs/company-schema#affiliated_entities) | `String` | PDL Company ID of the affiliated company record. | T |  | [Premium](/docs/company-data-field-bundles#premium) |
| [`affiliated_entities.display_name`](/docs/company-schema#affiliated_entities) | `String` | display\_name of the affiliated company record. | T |  | [Premium](/docs/company-data-field-bundles#premium) |
| [`affiliated_entities.relationship`](/docs/company-schema#affiliated_entities) | [`Enum (String)`](/docs/relationship_types) | Categorization of the relationship type to the affiliated company record. | T |  | [Premium](/docs/company-data-field-bundles#premium) |
| [`affiliated_entities.relationship_catalyst`](/docs/company-schema#affiliated_entities) | [`Enum (String)`](/docs/relationship_catalysts) | Categorization of the event that formed the relationship to the affiliated company record. | T |  | [Premium](/docs/company-data-field-bundles#premium) |
| [`affiliated_entities.relationship_status`](/docs/company-schema#affiliated_entities) | [`Enum (String)`](/docs/relationship_statuses) | Whether the relationship is active, pending, or inactive. | T |  | [Parent Subsidiary Details](/docs/company-data-field-bundles#parent-subsidiary-details) |
| [`affiliated_entities.start_date`](/docs/company-schema#affiliated_entities) | `String (Date)` | Date when the affiliated company became related. For mergers or acquisitions, this will be the date that the transaction is closed (when that information is available); otherwise, this will be the date announced. | T |  | [Parent Subsidiary Details](/docs/company-data-field-bundles#parent-subsidiary-details) |
| [`affiliated_entities.end_date`](/docs/company-schema#affiliated_entities) | `String (Date)` | When applicable, the date when the the affiliated company was divested or otherwise no longer affiliated. | T |  | [Parent Subsidiary Details](/docs/company-data-field-bundles#parent-subsidiary-details) |
| [`affiliated_entities.relationship_citations`](/docs/company-schema#affiliated_entities) | `Array [String]` | List of URL links to news articles, press releases, or company webpages that describe the business relationship. | T |  | [Parent Subsidiary Details](/docs/company-data-field-bundles#parent-subsidiary-details) |
| [`affiliated_profiles`](/docs/company-schema#affiliated_profiles) | `Array [String]` | Additional Company IDsÂ that are affiliated with the queried company |  | T | [Base](/docs/company-data-field-bundles#base) |
| [`all_subsidiaries`](/docs/company-schema#all_subsidiaries) | `Array [String]` | Full hierarchy chain of Company IDs for all downstream entities | T | T | [Premium](/docs/company-data-field-bundles#premium) |
| [`alternative_domains`](/docs/company-schema#alternative_domains) | `Array [String]` | A list of alternate domains associated with this company |  | T | [Base](/docs/company-data-field-bundles#base) |
| [`alternative_names`](/docs/company-schema#alternative_names) | `Array [String]` | A list of names associated with this company, including past profile names |  | T | [Base](/docs/company-data-field-bundles#base) |
| [`average_employee_tenure`](/docs/company-schema#average_employee_tenure) | `Float (> 0)` | The average years of experience at the company | T |  | [Premium](/docs/company-data-field-bundles#premium) |
| [`average_tenure_by_level`](/docs/company-schema#average_tenure_by_level) | `Object` | The average years of experience at the company by job level | T |  | [Premium](/docs/company-data-field-bundles#premium) |
| [`average_tenure_by_role`](/docs/company-schema#average_tenure_by_role) | [`Object`](/docs/job-title-roles) | The average years of experience at the company by job role | T |  | [Premium](/docs/company-data-field-bundles#premium) |
| [`dataset_version`](/docs/company-schema#dataset_version) | `String` | The major or minor release number |  | T | [Base](/docs/company-data-field-bundles#base) |
| [`direct_subsidiaries`](/docs/company-schema#direct_subsidiaries) | `Array [String]` | The CompanyÂ IDsÂ of each company that the queried company directly owns | T | T | [Premium](/docs/company-data-field-bundles#premium) |
| [`display_name`](/docs/company-schema#display_name) | `String` | The company name, capitalized using the companyâ€™s self-reported name |  |  | [Base](/docs/company-data-field-bundles#base) |
| [`employee_churn_rate`](/docs/company-schema#employee_churn_rate) | `Object` | The rate of change in employee headcount from N months prior | T | T | [Premium](/docs/company-data-field-bundles#premium) |
| [`employee_churn_rate.3_month`](/docs/company-schema#employee_churn_rate) | `Float (>= 0)` | The rate of change in employee headcount from 3 months prior | T | T | [Comprehensive](/docs/company-data-field-bundles#comprehensive) |
| [`employee_churn_rate.6_month`](/docs/company-schema#employee_churn_rate) | `Float (>= 0)` | The rate of change in employee headcount from 6 months prior | T | T | [Comprehensive](/docs/company-data-field-bundles#comprehensive) |
| [`employee_churn_rate.12_month`](/docs/company-schema#employee_churn_rate) | `Float (>= 0)` | The rate of change in employee headcount from 12 months prior | T | T | [Premium](/docs/company-data-field-bundles#premium) |
| [`employee_churn_rate.24_month`](/docs/company-schema#employee_churn_rate) | `Float (>= 0)` | The rate of change in employee headcount from 24 months prior | T | T | [Comprehensive](/docs/company-data-field-bundles#comprehensive) |
| [`employee_count`](/docs/company-schema#employee_count) | `Integer (>= 0)` | The current number of employees working at the company, derived from PDL's resume data |  | T | [Base](/docs/company-data-field-bundles#base) |
| [`employee_count_by_class`](/docs/company-schema#employee_count_by_class) | [`Object`](/docs/job-title-roles) | The number of current employees broken down by [Job Title Class](/docs/job-title-class) | T |  | [Premium](/docs/company-data-field-bundles#premium) |
| [`employee_count_by_country`](/docs/company-schema#employee_count_by_country) | [`Object`](/docs/location-countries) | The number of current employees broken out by country |  |  | [Base](/docs/company-data-field-bundles#base) |
| [`employee_count_by_month`](/docs/company-schema#employee_count_by_month) | `Object` | The number of employees at the end of each month | T |  | [Premium](/docs/company-data-field-bundles#premium) |
| [`employee_count_by_month_by_level`](/docs/company-schema#employee_count_by_month_by_level) | [`Object`](/docs/job-title-levels) | The number of employees at the end of each month, broken down by job level | T |  | [Comprehensive](/docs/company-data-field-bundles#comprehensive) |
| [`employee_count_by_month_by_role`](/docs/company-schema#employee_count_by_month_by_role) | [`Object`](/docs/job-title-roles) | The number of employees at the end of each month, broken down by job role | T |  | [Comprehensive](/docs/company-data-field-bundles#comprehensive) |
| [`employee_count_by_role`](/docs/company-schema#employee_count_by_role) | [`Object`](/docs/job-title-roles) | The number of current employees broken down by job role | T |  | [Premium](/docs/company-data-field-bundles#premium) |
| [`employee_count_by_sub_role`](/docs/company-schema#employee_count_by_sub_role) | [`Object`](/docs/job-title-roles) | The number of current employees broken down by [Job Title Sub Role](/docs/job-title-subroles) . | T |  | [Comprehensive](/docs/company-data-field-bundles#comprehensive) |
| [`employee_growth_rate`](/docs/company-schema#employee_growth_rate) | `Object` | The percentage increase in total headcount from N months prior | T | T | [Premium](/docs/company-data-field-bundles#premium) |
| [`employee_growth_rate.3_month`](/docs/company-schema#employee_growth_rate) | `Float` | The percentage increase in total headcount from 3 months prior | T | T | [Comprehensive](/docs/company-data-field-bundles#comprehensive) |
| [`employee_growth_rate.6_month`](/docs/company-schema#employee_growth_rate) | `Float` | The percentage increase in total headcount from 6 months prior | T | T | [Comprehensive](/docs/company-data-field-bundles#comprehensive) |
| [`employee_growth_rate.12_month`](/docs/company-schema#employee_growth_rate) | `Float` | The percentage increase in total headcount from 12 months prior | T | T | [Premium](/docs/company-data-field-bundles#premium) |
| [`employee_growth_rate.24_month`](/docs/company-schema#employee_growth_rate) | `Float` | The percentage increase in total headcount from 24 months prior | T | T | [Comprehensive](/docs/company-data-field-bundles#comprehensive) |
| [`employee_growth_rate_12_month_by_class`](/docs/company-schema#employee_growth_rate_12_month_by_class) | `Object` | The twelve month rate of change by [Job Title Class](/docs/job-title-class) | T |  | [Premium](/docs/company-data-field-bundles#premium) |
| [`employee_growth_rate_12_month_by_role`](/docs/company-schema#employee_growth_rate_12_month_by_role) | `Object` | The twelve month rate of change by Job Role on the final day of the most recent month. | T | T | [Premium](/docs/company-data-field-bundles#premium) |
| [`employee_growth_rate_12_month_by_sub_role`](/docs/company-schema#employee_growth_rate_12_month_by_sub_role) | `Object` | The twelve month rate of change by [Job Title Sub Role](/docs/job-title-subroles) | T |  | [Comprehensive](/docs/company-data-field-bundles#comprehensive) |
| [`facebook_url`](/docs/company-schema#facebook_url) | `String` | The main Facebook profile URL for the company based on source agreement |  | T | [Base](/docs/company-data-field-bundles#base) |
| [`founded`](/docs/company-schema#founded) | `Integer (> 0)` | The self-reported founding year of the company |  | T | [Base](/docs/company-data-field-bundles#base) |
| [`funding_details`](/docs/company-schema#funding_details) | `Array [Object]` | Array of all funding events associated with the company, with corresponding details | T |  | [Funding Details](/docs/company-data-field-bundles#funding-details) |
| [`funding_details.funding_currency`](/docs/company-schema#funding_details) | [`Enum (String)`](/docs/currency-codes) | The currency code for the `funding_raised` value | T |  | [Funding Details](/docs/company-data-field-bundles#funding-details) |
| [`funding_details.funding_raised`](/docs/company-schema#funding_details) | `Float (> 0)` | The total amount raised during the funding event | T |  | [Funding Details](/docs/company-data-field-bundles#funding-details) |
| [`funding_details.funding_round_date`](/docs/company-schema#funding_details) | [`String (Date)`](/docs/data-types#dates) | The publicly disclosed date of the closing of the financing event | T |  | [Funding Details](/docs/company-data-field-bundles#funding-details) |
| [`funding_details.funding_type`](/docs/company-schema#funding_details) | [`Enum (String)`](/docs/funding-rounds) | The funding stage of the funding event | T |  | [Funding Details](/docs/company-data-field-bundles#funding-details) |
| [`funding_details.investing_companies`](/docs/company-schema#funding_details) | `Array [String]` | The company names of the investing companies participating in the funding event | T |  | [Funding Details](/docs/company-data-field-bundles#funding-details) |
| [`funding_details.investing_individuals`](/docs/company-schema#funding_details) | `Array [String]` | Name strings of any separate investing individuals that participated in the funding event | T |  | [Funding Details](/docs/company-data-field-bundles#funding-details) |
| [`funding_stages`](/docs/company-schema#funding_stages) | [`Array [Enum (String)]`](/docs/funding-rounds) | All disclosed funding stages for the company |  | T | [Base](/docs/company-data-field-bundles#base) |
| [`gross_additions_by_month`](/docs/company-schema#gross_additions_by_month) | `Object` | The total number of employees that joined the company each month | T |  | [Premium](/docs/company-data-field-bundles#premium) |
| [`gross_departures_by_month`](/docs/company-schema#gross_departures_by_month) | `Object` | The total number of employees that left the company each month | T |  | [Premium](/docs/company-data-field-bundles#premium) |
| [`headline`](/docs/company-schema#headline) | `String` | The companyâ€™s headline summary |  | T | [Base](/docs/company-data-field-bundles#base) |
| [`id`](/docs/company-schema#id) | `String` | The identifier for the company |  | T | [Base](/docs/company-data-field-bundles#base) |
| [`immediate_parent`](/docs/company-schema#immediate_parent) | `String` | The ID of the company that directly owns the queried company | T | T | [Premium](/docs/company-data-field-bundles#premium) |
| [`industry`](/docs/company-schema#industry) | [`Enum (String)`](/docs/industries) | The self-reported industry of the company |  | T | [Base](/docs/company-data-field-bundles#base) |
| [`inferred_revenue`](/docs/company-schema#inferred_revenue) | [`Enum (String)`](/docs/inferred-revenue-ranges) | Company's estimated annual revenue in US dollars ($) | T | T | [Premium](/docs/company-data-field-bundles#premium) |
| [`last_funding_date`](/docs/company-schema#last_funding_date) | [`String (Date)`](/docs/data-types#dates) | The date of the companyâ€™s most recent funding event |  | T | [Base](/docs/company-data-field-bundles#base) |
| [`latest_funding_stage`](/docs/company-schema#latest_funding_stage) | [`Enum (String)`](/docs/funding-rounds) | The stage of the companyâ€™s most recent funding event |  | T | [Base](/docs/company-data-field-bundles#base) |
| [`linkedin_follower_count`](/docs/company-schema#linkedin_follower_count) | `Integer (>= 0)` | The number of followers on a companyâ€™s LinkedIn profile | T |  | [Premium](/docs/company-data-field-bundles#premium) |
| [`linkedin_id`](/docs/company-schema#linkedin_id) | `String` | The main LinkedIn profile ID for the company |  | T | [Base](/docs/company-data-field-bundles#base) |
| [`linkedin_slug`](/docs/company-schema#linkedin_slug) | `String` | The company-specific name/text directly from its LinkedIn URL |  | T | [Base](/docs/company-data-field-bundles#base) |
| [`linkedin_url`](/docs/company-schema#linkedin_url) | `String` | The main LinkedIn profile URL for the company based on source agreement |  | T | [Base](/docs/company-data-field-bundles#base) |
| [`location`](/docs/company-schema#location) | `Object` | The location of the company's headquarters |  |  | [Base](/docs/company-data-field-bundles#base) |
| [`location.address_line_2`](/docs/company-schema#location) | `String` | The street address line 2 of the company HQ address |  | T | [Base](/docs/company-data-field-bundles#base) |
| [`location.continent`](/docs/company-schema#location) | [`Enum (String)`](/docs/location-continents) | The continent of the company HQ |  | T | [Base](/docs/company-data-field-bundles#base) |
| [`location.country`](/docs/company-schema#location) | [`Enum (String)`](/docs/location-countries) | The country of company HQ |  | T | [Base](/docs/company-data-field-bundles#base) |
| [`location.geo`](/docs/company-schema#location) | `String` | City-center geo code of the company HQ, in the formatÂ "latitude, longitude" |  | T | [Base](/docs/company-data-field-bundles#base) |
| [`location.locality`](/docs/company-schema#location) | `String` | The locality the company HQ is in |  | T | [Base](/docs/company-data-field-bundles#base) |
| [`location.metro`](/docs/company-schema#location) | [`Enum (String)`](/docs/location-metros) | The metro area of company HQ |  | T | [Base](/docs/company-data-field-bundles#base) |
| [`location.name`](/docs/company-schema#location) | `String` | Our cleaned values for the company HQ location in the formatÂ "locality, region, country" |  | T | [Base](/docs/company-data-field-bundles#base) |
| [`location.postal_code`](/docs/company-schema#location) | `String` | The postal code of the company HQ address |  | T | [Base](/docs/company-data-field-bundles#base) |
| [`location.region`](/docs/company-schema#location) | `String` | The region of company HQ |  | T | [Base](/docs/company-data-field-bundles#base) |
| [`location.street_address`](/docs/company-schema#location) | `String` | The street address of the company HQ |  | T | [Base](/docs/company-data-field-bundles#base) |
| [`locations`](/docs/company-schema#locations) | `Object` | An object containing increasingly granular information about all locations associated to the company. |  |  | [Location Details](/docs/company-data-field-bundles#location-details) |
| [`locations.address_line_2`](/docs/company-schema#locations) | `String` | The street address line 2 for the given company location. |  | T | [Location Details](/docs/company-data-field-bundles#location-details) |
| [`locations.continent`](/docs/company-schema#locations) | [`Enum (String)`](/docs/location-continents) | The canonical continent for the given company location. |  | T | [Location Details](/docs/company-data-field-bundles#location-details) |
| [`locations.country`](/docs/company-schema#locations) | [`Enum (String)`](/docs/location-countries) | The canonical country for the given company location. |  | T | [Location Details](/docs/company-data-field-bundles#location-details) |
| [`locations.first_seen`](/docs/company-schema#locations) | `String` | The date that this location was first observed in association with the company record. |  | T | [Location Details](/docs/company-data-field-bundles#location-details) |
| [`locations.last_seen`](/docs/company-schema#locations) | `String` | The date that this location was last observed in association with the company record. |  | T | [Location Details](/docs/company-data-field-bundles#location-details) |
| [`locations.geo`](/docs/company-schema#locations) | `String` | The city-center geographic coordinates for the given company location. |  | T | [Location Details](/docs/company-data-field-bundles#location-details) |
| [`locations.is_active`](/docs/company-schema#locations) | `Boolean` | Whether this location was active (â€œtrueâ€) or inactive (â€œfalseâ€). |  | T | [Location Details](/docs/company-data-field-bundles#location-details) |
| [`locations.is_primary`](/docs/company-schema#locations) | `Boolean` | Whether this is the primary HQ location for the company or not. If true, this location will be used to populate the location fields. |  | T | [Location Details](/docs/company-data-field-bundles#location-details) |
| [`locations.locality`](/docs/company-schema#locations) | `String` | The canonical locality for the given company location. |  | T | [Location Details](/docs/company-data-field-bundles#location-details) |
| [`locations.metro`](/docs/company-schema#locations) | [`Enum (String)`](/docs/location-metros) | The canonical metro for the given company location. |  | T | [Location Details](/docs/company-data-field-bundles#location-details) |
| [`locations.name`](/docs/company-schema#locations) | `String` | The canonical location name for the given location. |  | T | [Location Details](/docs/company-data-field-bundles#location-details) |
| [`locations.postal_code`](/docs/company-schema#locations) | `String` | The postal code for the given company location. |  | T | [Location Details](/docs/company-data-field-bundles#location-details) |
| [`locations.region`](/docs/company-schema#locations) | `String` | The canonical region for the given company location. |  | T | [Location Details](/docs/company-data-field-bundles#location-details) |
| [`locations.street_address`](/docs/company-schema#locations) | `String` | The street address for the given company location. |  | T | [Location Details](/docs/company-data-field-bundles#location-details) |
| [`mic_exchange`](/docs/company-schema#mic_exchange) | [`Enum (String)`](/docs/mic-codes) | The MIC code representing the stock exchange of the company's primary ticker |  | T | [Base](/docs/company-data-field-bundles#base) |
| [`naics`](/docs/company-schema#naics) | `Array [Object]` | An array containing the company's self-reported NAICS the industry classifications |  | T | [Base](/docs/company-data-field-bundles#base) |
| [`naics.industry_group`](/docs/company-schema#naics) | `String` | The industry classification according to the first four digits in the NAICS code |  | T | [Base](/docs/company-data-field-bundles#base) |
| [`naics.naics_code`](/docs/company-schema#naics) | `String` | The NAICS code associated with a companyâ€™s industry classification, specific to as many digits available from the self-reported data |  | T | [Base](/docs/company-data-field-bundles#base) |
| [`naics.naics_industry`](/docs/company-schema#naics) | `String` | The industry classification according to the first five digits in the NAICS code |  | T | [Base](/docs/company-data-field-bundles#base) |
| [`naics.national_industry`](/docs/company-schema#naics) | `String` | The industry classification according to all six digits in the NAICS code |  | T | [Base](/docs/company-data-field-bundles#base) |
| [`naics.sector`](/docs/company-schema#naics) | `String` | The industry classification according to the first two digits in the NAICS code |  | T | [Base](/docs/company-data-field-bundles#base) |
| [`naics.sub_sector`](/docs/company-schema#naics) | `String` | The industry classification according to the first three digits in the NAICS code |  | T | [Base](/docs/company-data-field-bundles#base) |
| [`name`](/docs/company-schema#name) | `String` | The company's primary common name |  | T | [Base](/docs/company-data-field-bundles#base) |
| [`num_active_locations`](/docs/company-schema#num_active_locations) | `Integer` | Count of all active locations associated with the company record. |  | T | [Location Details](/docs/company-data-field-bundles#location-details) |
| [`num_total_locations`](/docs/company-schema#num_total_locations) | `Integer` | Count of distinct, active job postings that existed over the course of the most recent month. |  | T | [Location Details](/docs/company-data-field-bundles#location-details) |
| [`number_funding_rounds`](/docs/company-schema#number_funding_rounds) | `Integer (> 0)` | The number of funding rounds announced by the company |  | T | [Base](/docs/company-data-field-bundles#base) |
| [`profiles`](/docs/company-schema#profiles) | `Array [String]` | A list of all associated social profile URLs for the company |  | T | [Base](/docs/company-data-field-bundles#base) |
| [`recent_exec_departures`](/docs/company-schema#recent_exec_departures) | `Array [Object]` | The profiles of all of CXOs, owners and VPs that have left the company in the prior three months | T |  | [Comprehensive](/docs/company-data-field-bundles#comprehensive) |
| [`recent_exec_hires`](/docs/company-schema#recent_exec_hires) | `Array [Object]` | The profiles of all of CXOs, owners and VPs that have joined the company in the prior three months | T |  | [Comprehensive](/docs/company-data-field-bundles#comprehensive) |
| [`sic`](/docs/company-schema#sic) | `Array [Object]` | An array containing the company's self-reported SIC industry classifications, specific to as many digits available from the self-reported data |  | T | [Base](/docs/company-data-field-bundles#base) |
| [`sic.industry_group`](/docs/company-schema#sic) | `String` | The industry classification according to the first three digits in the SIC code |  | T | [Base](/docs/company-data-field-bundles#base) |
| [`sic.industry_sector`](/docs/company-schema#sic) | `String` | The industry classification according to all four digits in the SIC code |  | T | [Base](/docs/company-data-field-bundles#base) |
| [`sic.major_group`](/docs/company-schema#sic) | `String` | The industry classification according to the first two digits in the SIC code |  | T | [Base](/docs/company-data-field-bundles#base) |
| [`sic.sic_code`](/docs/company-schema#sic) | `String` | The SIC code associated with a companyâ€™s industry classification |  | T | [Base](/docs/company-data-field-bundles#base) |
| [`size`](/docs/company-schema#size) | [`Enum (String)`](/docs/company-sizes) | The user-selected size range representing the number of people at the company; may disagree with [`employee_count`](#employee_count) |  | T | [Base](/docs/company-data-field-bundles#base) |
| [`summary`](/docs/company-schema#summary) | `String` | A description of the company |  | T | [Base](/docs/company-data-field-bundles#base) |
| [`tags`](/docs/company-schema#tags) | `Array [String]` | Tags associated with the company |  | T | [Base](/docs/company-data-field-bundles#base) |
| [`ticker`](/docs/company-schema#ticker) | `String (Uppercase)` | The company's primary stock ticker (only for public companies) |  | T | [Base](/docs/company-data-field-bundles#base) |
| [`top_next_employers`](/docs/company-schema#top_next_employers) | [`Object`](/docs/job-title-roles) | The top ten companies employees moved to, and how many employees moved there, across all time periods | T |  | [Comprehensive](/docs/company-data-field-bundles#comprehensive) |
| [`top_next_employers_12_month`](/docs/company-schema#top_next_employers_12_month) | `Object` | The top ten next employers, counting only employee changes within the last 12 months | T |  | [Comprehensive](/docs/company-data-field-bundles#comprehensive) |
| [`top_next_employers_by_role`](/docs/company-schema#top_next_employers_by_role) | [`Object`](/docs/job-title-roles) | (**DEPRECATED**) The top ten companies employees moved to, and how many employees moved there, across all time periods | T |  | [Comprehensive](/docs/company-data-field-bundles#comprehensive) |
| [`top_previous_employers`](/docs/company-schema#top_previous_employers) | [`Object`](/docs/job-title-roles) | The top ten previous companies employees worked for previously, and how many current employees were previously employed by them, across all time periods | T |  | [Comprehensive](/docs/company-data-field-bundles#comprehensive) |
| [`top_previous_employers_12_month`](/docs/company-schema#top_previous_employers_12_month) | `Object` | The top ten previous employers, counting only employee changes within the last 12 months | T |  | [Comprehensive](/docs/company-data-field-bundles#comprehensive) |
| [`top_previous_employers_by_role`](/docs/company-schema#top_previous_employers_by_role) | [`Object`](/docs/job-title-roles) | (**DEPRECATED**) The top ten previous companies employees worked for previously, and how many current employees were previously employed by them, across all time periods | T |  | [Comprehensive](/docs/company-data-field-bundles#comprehensive) |
| [`top_us_employee_metros`](/docs/company-schema#top_us_employee_metros) | [`Object`](/docs/location-metros) | The top ten US metros where employees are based | T |  | [Comprehensive](/docs/company-data-field-bundles#comprehensive) |
| [`total_funding_raised`](/docs/company-schema#total_funding_raised) | `Float (> 0)` | The cumulative amount raised by the company in USD |  | T | [Base](/docs/company-data-field-bundles#base) |
| [`twitter_url`](/docs/company-schema#twitter_url) | `String` | The primary Twitter profile URL associated with the record |  | T | [Base](/docs/company-data-field-bundles#base) |
| [`type`](/docs/company-schema#type) | [`Enum (String)`](/docs/company-types) | The value from a canonical list describing the companies organizational type/structure |  | T | [Base](/docs/company-data-field-bundles#base) |
| [`ultimate_parent`](/docs/company-schema#ultimate_parent) | `String` | The Company ID of the ultimate organizational entity that owns the queried company | T | T | [Premium](/docs/company-data-field-bundles#premium) |
| [`ultimate_parent_ticker`](/docs/company-schema#ultimate_parent_ticker) | `String` | Stock symbol of the company's ultimate parent, if applicable | T | T | [Premium](/docs/company-data-field-bundles#premium) |
| [`ultimate_parent_mic_exchange`](/docs/company-schema#ultimate_parent_mic_exchange) | `String` | MIC exchange code of the company's ultimate parent, if applicable | T | T | [Premium](/docs/company-data-field-bundles#premium) |
| [`website`](/docs/company-schema#website) | `String` | The company's primary website |  | T | [Base](/docs/company-data-field-bundles#base) |

---



*Know someone whoâ€™d thrive building data products and helping us launch whatâ€™s next? Weâ€™d love to meet!*

*Check out our[open roles](https://www.peopledatalabs.com/company?utm_source=docs&utm_medium=footer&utm_campaign=cta#jobs) â†’*

Updated 2 months ago

---

Did this page help you?

Yes

No

---
# https://docs.peopledatalabs.com/docs/sandbox-apis

The Sandbox APIs let you query our APIs to access synthetic data without consuming credits. The primary purpose of these endpoints are for testing and evaluating use cases in support of tasks such as:

* Performing integration testing to ensure compatibility with our endpoints and data structures
* Evaluating our APIs without revealing proprietary or regulated data

The Sandbox API endpoints mirror our production API endpoints, meaning that each public API endpoint will eventually have a corresponding sandbox endpoint. Each sandbox endpoint has **identical functionality** as its corresponding production endpoint. However, the records that each sandbox endpoint return contain only **artificial data**, which follows the same object structure as records from our production datasets.

Here is the current status of our Sandbox API endpoints:

| Data Schema | API Endpoint | Sandbox API Endpoint |
| --- | --- | --- |
| [Person](/docs/fields) | [Person Enrichment API](/docs/person-enrichment-api) | `https://sandbox.api.peopledatalabs.com/v5/person/enrich` |
| [Person](/docs/fields) | [Person Search API](/docs/person-search-api) | `https://sandbox.api.peopledatalabs.com/v5/person/search` |
| [Person](/docs/fields) | [Person Identify API](/docs/identify-api) | `https://sandbox.api.peopledatalabs.com/v5/person/identify` |
| [Company](/docs/company-schema) | [Company Enrichment API](/docs/company-enrichment-api) | `https://sandbox.api.peopledatalabs.com/v5/company/enrich` |
| [Company](/docs/company-schema) | [Company Search API](/docs/company-search-api) | `https://sandbox.api.peopledatalabs.com/v5/company/search` |
| [Company](/docs/company-schema) | [Company Cleaner API](/docs/cleaner-apis) | âŒ |
| Location | [Location Cleaner API](/docs/cleaner-apis) | âŒ |
| Schools | [School Cleaner API](/docs/cleaner-apis) | âŒ |
| [Skills](/docs/skill-schema) | [Skill Enrichment API](/docs/skill-enrichment-api) | âŒ |
| [Job Titles](/docs/job-title-schema) | [Job Title Enrichment API](/docs/job-title-enrichment-api) | âŒ |

## What's Next

Please checkout the following pages for more information on the Sandbox APIs:

| Page | Description |
| --- | --- |
| [Reference](/docs/sandbox-apis-reference) | Detailed descriptions of the technical specifications and usage constraints. |
| [Examples](/docs/sandbox-apis-examples) | A collection of functional code examples and walkthroughs illustrating various use cases and applications of the APIs. |

---



*Know someone whoâ€™d thrive building data products and helping us launch whatâ€™s next? Weâ€™d love to meet!*

*Check out our[open roles](https://www.peopledatalabs.com/company?utm_source=docs&utm_medium=footer&utm_campaign=cta#jobs) â†’*

Updated 4 months ago

---

Did this page help you?

Yes

No

---
# https://docs.peopledatalabs.com/docs/social-networks

These aggregations relate to our [Full API Dataset](/docs/datasets#all-dataset), which has a rate of duplication. For stats relating to specific license slices, feel free to [contact us](https://www.peopledatalabs.com/talk-to-sales).

| Social Network | Count | Numeric |
| --- | --- | --- |
| `facebook` | 1,025,430,124 | 1025430124 |
| `linkedin` | 819,660,531 | 819660531 |
| `twitter` | 55,981,475 | 55981475 |
| `xing` | 7,290,307 | 7290307 |
| `indeed` | 6,799,348 | 6799348 |
| `meetup` | 3,782,749 | 3782749 |
| `github` | 3,528,906 | 3528906 |
| `instagram` | 2,962,499 | 2962499 |
| `quora` | 2,456,717 | 2456717 |
| `stackoverflow` | 987,317 | 987317 |
| `gravatar` | 691,270 | 691270 |
| `angellist` | 665,400 | 665400 |
| `youtube` | 606,747 | 606747 |
| `klout` | 475,271 | 475271 |
| `foursquare` | 288,121 | 288121 |
| `crunchbase` | 247,788 | 247788 |
| `pinterest` | 237,980 | 237980 |
| `dribbble` | 207,754 | 207754 |
| `vimeo` | 199,929 | 199929 |
| `flickr` | 188,161 | 188161 |
| `aboutme` | 182,515 | 182515 |
| `google` | 84,391 | 84391 |
| `wordpress` | 82,933 | 82933 |
| `myspace` | 32,580 | 32580 |
| `behance` | 28,317 | 28317 |
| `soundcloud` | 12,595 | 12595 |
| `reddit` | 5,832 | 5832 |
| `gitlab` | 717 | 717 |
| `ello` | 2 | 2 |
| `medium` | 0 | 0 |

*Stats shown are accurate as of data version 33.1*

Updated 6 days ago

---

Did this page help you?

Yes

No

---
# https://docs.peopledatalabs.com/docs/naics-subsectors

| Canonical Values for NAICS Subsectors |
| --- |
| accommodation |
| administration of economic programs |
| administration of environmental quality programs |
| administration of housing programs, urban planning, and community development |
| administration of human resource programs |
| administrative and support services |
| air transportation |
| ambulatory health care services |
| amusement, gambling, and recreation industries |
| animal production and aquaculture |
| apparel manufacturing |
| beverage and tobacco product manufacturing |
| broadcasting (except internet) |
| building material and garden equipment and supplies dealers |
| chemical manufacturing |
| clothing and clothing accessories stores |
| computer and electronic product manufacturing |
| construction of buildings |
| couriers and messengers |
| credit intermediation and related activities |
| crop production |
| data processing, hosting, and related services |
| educational services |
| electrical equipment, appliance, and component manufacturing |
| electronics and appliance stores |
| executive, legislative, and other general government support |
| fabricated metal product manufacturing |
| fishing, hunting and trapping |
| food and beverage stores |
| food manufacturing |
| food services and drinking places |
| forestry and logging |
| funds, trusts, and other financial vehicles |
| furniture and home furnishings stores |
| furniture and related product manufacturing |
| gasoline stations |
| general merchandise stores |
| health and personal care stores |
| heavy and civil engineering construction |
| hospitals |
| insurance carriers and related activities |
| justice, public order, and safety activities |
| leather and allied product manufacturing |
| lessors of nonfinancial intangible assets (except copyrighted works) |
| machinery manufacturing |
| management of companies and enterprises |
| merchant wholesalers, durable goods |
| merchant wholesalers, nondurable goods |
| mining (except oil and gas) |
| miscellaneous manufacturing |
| miscellaneous store retailers |
| monetary authorities-central bank |
| motion picture and sound recording industries |
| motor vehicle and parts dealers |
| museums, historical sites, and similar institutions |
| national security and international affairs |
| nonmetallic mineral product manufacturing |
| nonstore retailers |
| nursing and residential care facilities |
| oil and gas extraction |
| other information services |
| paper manufacturing |
| performing arts, spectator sports, and related industries |
| personal and laundry services |
| petroleum and coal products manufacturing |
| pipeline transportation |
| plastics and rubber products manufacturing |
| postal service |
| primary metal manufacturing |
| printing and related support activities |
| private households |
| professional, scientific, and technical services |
| publishing industries (except internet) |
| rail transportation |
| real estate |
| religious, grantmaking, civic, professional, and similar organizations |
| rental and leasing services |
| repair and maintenance |
| scenic and sightseeing transportation |
| securities, commodity contracts, and other financial investments and related activities |
| social assistance |
| space research and technology |
| specialty trade contractors |
| sporting goods, hobby, musical instrument, and book stores |
| support activities for agriculture and forestry |
| support activities for mining |
| support activities for transportation |
| telecommunications |
| textile mills |
| textile product mills |
| transit and ground passenger transportation |
| transportation equipment manufacturing |
| truck transportation |
| utilities |
| warehousing and storage |
| waste management and remediation services |
| water transportation |
| wholesale electronic markets and agents and brokers |
| wood product manufacturing |

*Contents of this table were sourced from the following file on our public S3 bucket:[naics\_sub\_sector.txt](https://pdl-prod-schema.s3.us-west-2.amazonaws.com/28.0/enums/naics_sub_sector.txt)*

## Relevant fields

* [`naics.sub_sector`](/docs/company-schema#naics)

Updated 4 months ago

---

Did this page help you?

Yes

No

---
# https://docs.peopledatalabs.com/docs/company-stats

# Overview:

This page provides field-level summary statistics for our Company Data.

## Field Availability

| Field | Count | Numeric | Fill Percentage |
| --- | --- | --- | --- |
| `Total` | 74,679,887 | 74679887 | 100.0% |
| `active_job_postings` | 46,685 | 46685 | 0.1% |
| `active_job_postings_by_class` | 27,579,867 | 27579867 | 36.9% |
| `active_job_postings_by_country` | 27,579,867 | 27579867 | 36.9% |
| `active_job_postings_by_metro` | 27,579,867 | 27579867 | 36.9% |
| `active_job_postings_by_month` | 27,579,867 | 27579867 | 36.9% |
| `active_job_postings_by_role` | 27,579,867 | 27579867 | 36.9% |
| `active_job_postings_by_sub_role` | 27,579,867 | 27579867 | 36.9% |
| `affiliated_entities` | 164,991 | 164991 | 0.2% |
| `affiliated_entities.affiliated_id` | 164,991 | 164991 | 0.2% |
| `affiliated_entities.display_name` | 164,991 | 164991 | 0.2% |
| `affiliated_entities.end_date` | 2,986 | 2986 | 0.0% |
| `affiliated_entities.relationship` | 164,991 | 164991 | 0.2% |
| `affiliated_entities.relationship_catalyst` | 164,991 | 164991 | 0.2% |
| `affiliated_entities.relationship_citations` | 89,433 | 89433 | 0.1% |
| `affiliated_entities.relationship_status` | 164,991 | 164991 | 0.2% |
| `affiliated_entities.start_date` | 65,501 | 65501 | 0.1% |
| `affiliated_profiles` | 171,601 | 171601 | 0.2% |
| `all_subsidiaries` | 48,436 | 48436 | 0.1% |
| `alternative_domains` | 6,048,623 | 6048623 | 8.1% |
| `alternative_names` | 2,118,839 | 2118839 | 2.8% |
| `average_employee_tenure` | 27,579,867 | 27579867 | 36.9% |
| `average_tenure_by_level` | 27,579,867 | 27579867 | 36.9% |
| `average_tenure_by_role` | 27,579,867 | 27579867 | 36.9% |
| `dataset_version` | 74,679,887 | 74679887 | 100.0% |
| `deactivated_job_postings` | 46,685 | 46685 | 0.1% |
| `deactivated_job_postings_by_class` | 27,579,867 | 27579867 | 36.9% |
| `deactivated_job_postings_by_month` | 27,579,867 | 27579867 | 36.9% |
| `deactivated_job_postings_by_role` | 27,579,867 | 27579867 | 36.9% |
| `deactivated_job_postings_by_sub_role` | 27,579,867 | 27579867 | 36.9% |
| `direct_subsidiaries` | 48,256 | 48256 | 0.1% |
| `display_name` | 74,679,887 | 74679887 | 100.0% |
| `employee_churn_rate` | 19,479,921 | 19479921 | 26.1% |
| `employee_count` | 27,579,867 | 27579867 | 36.9% |
| `employee_count_by_class` | 27,579,867 | 27579867 | 36.9% |
| `employee_count_by_country` | 27,579,867 | 27579867 | 36.9% |
| `employee_count_by_month` | 27,579,867 | 27579867 | 36.9% |
| `employee_count_by_month_by_level` | 27,579,867 | 27579867 | 36.9% |
| `employee_count_by_month_by_role` | 27,579,867 | 27579867 | 36.9% |
| `employee_count_by_role` | 27,579,867 | 27579867 | 36.9% |
| `employee_count_by_sub_role` | 27,579,867 | 27579867 | 36.9% |
| `employee_growth_rate` | 19,479,921 | 19479921 | 26.1% |
| `employee_growth_rate_12_month_by_class` | 27,579,867 | 27579867 | 36.9% |
| `employee_growth_rate_12_month_by_role` | 27,579,867 | 27579867 | 36.9% |
| `employee_growth_rate_12_month_by_sub_role` | 27,579,867 | 27579867 | 36.9% |
| `facebook_url` | 2,162,553 | 2162553 | 2.9% |
| `founded` | 16,676,091 | 16676091 | 22.3% |
| `funding_details` | 279,493 | 279493 | 0.4% |
| `funding_details.funding_currency` | 203,756 | 203756 | 0.3% |
| `funding_details.funding_raised` | 27,579,867 | 27579867 | 36.9% |
| `funding_details.funding_round_date` | 279,493 | 279493 | 0.4% |
| `funding_details.funding_type` | 279,493 | 279493 | 0.4% |
| `funding_details.investing_companies` | 200,320 | 200320 | 0.3% |
| `funding_details.investing_individuals` | 42,135 | 42135 | 0.1% |
| `funding_stages` | 279,493 | 279493 | 0.4% |
| `gross_additions_by_month` | 27,579,867 | 27579867 | 36.9% |
| `gross_departures_by_month` | 27,579,867 | 27579867 | 36.9% |
| `headline` | 15,840,952 | 15840952 | 21.2% |
| `id` | 74,679,887 | 74679887 | 100.0% |
| `immediate_parent` | 125,470 | 125470 | 0.2% |
| `industry` | 56,076,393 | 56076393 | 75.1% |
| `industry_v2` | 55,115,937 | 55115937 | 73.8% |
| `inferred_revenue` | 27,579,867 | 27579867 | 36.9% |
| `last_funding_date` | 279,493 | 279493 | 0.4% |
| `latest_funding_stage` | 279,493 | 279493 | 0.4% |
| `linkedin_follower_count` | 33,207,782 | 33207782 | 44.5% |
| `linkedin_id` | 74,679,887 | 74679887 | 100.0% |
| `linkedin_slug` | 74,679,887 | 74679887 | 100.0% |
| `linkedin_url` | 74,679,887 | 74679887 | 100.0% |
| `location` | 67,214,464 | 67214464 | 90.0% |
| `location.address_line_2` | 3,104,027 | 3104027 | 4.2% |
| `location.continent` | 67,214,438 | 67214438 | 90.0% |
| `location.country` | 67,213,874 | 67213874 | 90.0% |
| `location.geo` | 62,750,994 | 62750994 | 84.0% |
| `location.locality` | 63,192,529 | 63192529 | 84.6% |
| `location.metro` | 14,723,076 | 14723076 | 19.7% |
| `location.name` | 67,214,464 | 67214464 | 90.0% |
| `location.postal_code` | 55,677,266 | 55677266 | 74.6% |
| `location.region` | 63,704,889 | 63704889 | 85.3% |
| `location.street_address` | 43,990,533 | 43990533 | 58.9% |
| `locations` | 67,214,533 | 67214533 | 90.0% |
| `locations.address_line_2` | 3,518,798 | 3518798 | 4.7% |
| `locations.continent` | 67,214,533 | 67214533 | 90.0% |
| `locations.country` | 67,214,257 | 67214257 | 90.0% |
| `locations.first_seen` | 67,214,533 | 67214533 | 90.0% |
| `locations.geo` | 63,120,257 | 63120257 | 84.5% |
| `locations.is_active` | 67,214,533 | 67214533 | 90.0% |
| `locations.last_seen` | 67,214,533 | 67214533 | 90.0% |
| `locations.locality` | 63,499,990 | 63499990 | 85.0% |
| `locations.metro` | 14,908,654 | 14908654 | 20.0% |
| `locations.name` | 67,214,533 | 67214533 | 90.0% |
| `locations.postal_code` | 56,738,512 | 56738512 | 76.0% |
| `locations.region` | 63,931,743 | 63931743 | 85.6% |
| `locations.street_address` | 45,524,758 | 45524758 | 61.0% |
| `mic_exchange` | 28,689 | 28689 | 0.0% |
| `naics` | 8,228,461 | 8228461 | 11.0% |
| `name` | 74,679,790 | 74679790 | 100.0% |
| `num_active_locations` | 74,679,887 | 74679887 | 100.0% |
| `num_total_locations` | 74,679,887 | 74679887 | 100.0% |
| `number_funding_rounds` | 279,493 | 279493 | 0.4% |
| `profiles` | 74,679,887 | 74679887 | 100.0% |
| `recent_exec_departures` | 27,579,867 | 27579867 | 36.9% |
| `recent_exec_hires` | 27,579,867 | 27579867 | 36.9% |
| `sic` | 7,245,038 | 7245038 | 9.7% |
| `size` | 74,679,887 | 74679887 | 100.0% |
| `summary` | 23,573,052 | 23573052 | 31.6% |
| `tags` | 9,935,121 | 9935121 | 13.3% |
| `ticker` | 28,689 | 28689 | 0.0% |
| `top_next_employers` | 27,579,867 | 27579867 | 36.9% |
| `top_next_employers_12_month` | 27,579,867 | 27579867 | 36.9% |
| `top_previous_employers` | 27,579,867 | 27579867 | 36.9% |
| `top_previous_employers_12_month` | 27,579,867 | 27579867 | 36.9% |
| `top_us_employee_metros` | 27,579,867 | 27579867 | 36.9% |
| `total_funding_raised` | 279,493 | 279493 | 0.4% |
| `twitter_url` | 1,167,648 | 1167648 | 1.6% |
| `type` | 74,679,887 | 74679887 | 100.0% |
| `ultimate_parent` | 125,258 | 125258 | 0.2% |
| `ultimate_parent_mic_exchange` | 37,354 | 37354 | 0.1% |
| `ultimate_parent_ticker` | 37,354 | 37354 | 0.1% |
| `website` | 35,483,125 | 35483125 | 47.5% |

*Stats shown are accurate as of data version 33.1*

Updated 6 days ago

---

Did this page help you?

Yes

No

---
# https://docs.peopledatalabs.com/docs/company-data-field-bundles

## Base

| Field | Bundle |
| --- | --- |
| [affiliated\_profiles](/docs/company-schema#affiliated_profiles) | Base |
| [alternative\_domains](/docs/company-schema#alternative_domains) | Base |
| [alternative\_names](/docs/company-schema#alternative_names) | Base |
| [dataset\_version](/docs/company-schema#dataset_version) | Base |
| [display\_name](/docs/company-schema#display_name) | Base |
| [employee\_count](/docs/company-schema#employee_count) | Base |
| [employee\_count\_by\_country](/docs/company-schema#employee_count_by_country) | Base |
| [facebook\_url](/docs/company-schema#facebook_url) | Base |
| [founded](/docs/company-schema#founded) | Base |
| [funding\_stages](/docs/company-schema#funding_stages) | Base |
| [headline](/docs/company-schema#headline) | Base |
| [id](/docs/company-schema#id) | Base |
| [industry](/docs/company-schema#industry) | Base |
| [industry\_v2](/docs/company-schema#industry_v2) | Base |
| [last\_funding\_date](/docs/company-schema#last_funding_date) | Base |
| [latest\_funding\_stage](/docs/company-schema#latest_funding_stage) | Base |
| [linkedin\_id](/docs/company-schema#linkedin_id) | Base |
| [linkedin\_slug](/docs/company-schema#linkedin_slug) | Base |
| [linkedin\_url](/docs/company-schema#linkedin_url) | Base |
| [location](/docs/company-schema#location) | Base |
| [location.address\_line\_2](/docs/company-schema#location) | Base |
| [location.continent](/docs/company-schema#location) | Base |
| [location.country](/docs/company-schema#location) | Base |
| [location.geo](/docs/company-schema#location) | Base |
| [location.locality](/docs/company-schema#location) | Base |
| [location.metro](/docs/company-schema#location) | Base |
| [location.name](/docs/company-schema#location) | Base |
| [location.postal\_code](/docs/company-schema#location) | Base |
| [location.region](/docs/company-schema#location) | Base |
| [location.street\_address](/docs/company-schema#location) | Base |
| [mic\_exchange](/docs/company-schema#mic_exchange) | Base |
| [naics](/docs/company-schema#naics) | Base |
| [naics.industry\_group](/docs/company-schema#naics) | Base |
| [naics.naics\_code](/docs/company-schema#naics) | Base |
| [naics.naics\_industry](/docs/company-schema#naics) | Base |
| [naics.national\_industry](/docs/company-schema#naics) | Base |
| [naics.sector](/docs/company-schema#naics) | Base |
| [naics.sub\_sector](/docs/company-schema#naics) | Base |
| [name](/docs/company-schema#name) | Base |
| [number\_funding\_rounds](/docs/company-schema#number_funding_rounds) | Base |
| [profiles](/docs/company-schema#profiles) | Base |
| [sic](/docs/company-schema#sic) | Base |
| [sic.industry\_group](/docs/company-schema#sic) | Base |
| [sic.industry\_sector](/docs/company-schema#sic) | Base |
| [sic.major\_group](/docs/company-schema#sic) | Base |
| [sic.sic\_code](/docs/company-schema#sic) | Base |
| [size](/docs/company-schema#size) | Base |
| [summary](/docs/company-schema#summary) | Base |
| [tags](/docs/company-schema#tags) | Base |
| [ticker](/docs/company-schema#ticker) | Base |
| [total\_funding\_raised](/docs/company-schema#total_funding_raised) | Base |
| [twitter\_url](/docs/company-schema#twitter_url) | Base |
| [type](/docs/company-schema#type) | Base |
| [website](/docs/company-schema#website) | Base |

## Premium

| Field | Bundle |
| --- | --- |
| [affiliated\_entities](/docs/company-schema#affiliated_entities) | Premium |
| [affiliated\_entities.affiliated\_id](/docs/company-schema#affiliated_entities) | Premium |
| [affiliated\_entities.display\_name](/docs/company-schema#affiliated_entities) | Premium |
| [affiliated\_entities.relationship](/docs/company-schema#affiliated_entities) | Premium |
| [all\_subsidiaries](/docs/company-schema#all_subsidiaries) | Premium |
| [average\_employee\_tenure](/docs/company-schema#average_employee_tenure) | Premium |
| [average\_tenure\_by\_level](/docs/company-schema#average_tenure_by_level) | Premium |
| [average\_tenure\_by\_role](/docs/company-schema#average_tenure_by_role) | Premium |
| [direct\_subsidiaries](/docs/company-schema#direct_subsidiaries) | Premium |
| [employee\_churn\_rate](/docs/company-schema#employee_churn_rate) | Premium |
| [employee\_churn\_rate.12\_month](/docs/company-schema#employee_churn_rate) | Premium |
| [employee\_count\_by\_class](/docs/company-schema#employee_count_by_class) | Premium |
| [employee\_count\_by\_month](/docs/company-schema#employee_count_by_month) | Premium |
| [employee\_count\_by\_role](/docs/company-schema#employee_count_by_role) | Premium |
| [employee\_growth\_rate](/docs/company-schema#employee_growth_rate) | Premium |
| [employee\_growth\_rate.12\_month](/docs/company-schema#employee_growth_rate) | Premium |
| [employee\_growth\_rate\_12\_month\_by\_class](/docs/company-schema#employee_growth_rate_12_month_by_class) | Premium |
| [employee\_growth\_rate\_12\_month\_by\_role](/docs/company-schema#employee_growth_rate_12_month_by_role) | Premium |
| [gross\_additions\_by\_month](/docs/company-schema#gross_additions_by_month) | Premium |
| [gross\_departures\_by\_month](/docs/company-schema#gross_departures_by_month) | Premium |
| [immediate\_parent](/docs/company-schema#immediate_parent) | Premium |
| [inferred\_revenue](/docs/company-schema#inferred_revenue) | Premium |
| [linkedin\_follower\_count](/docs/company-schema#linkedin_follower_count) | Premium |
| [ultimate\_parent](/docs/company-schema#ultimate_parent) | Premium |
| [ultimate\_parent\_ticker](/docs/company-schema#ultimate_parent_ticker) | Premium |
| [ultimate\_parent\_mic\_exchange](/docs/company-schema#ultimate_parent_mic_exchange) | Premium |

## Comprehensive

| Field | Bundle |
| --- | --- |
| [employee\_churn\_rate.3\_month](/docs/company-schema#employee_churn_rate) | Comprehensive |
| [employee\_churn\_rate.6\_month](/docs/company-schema#employee_churn_rate) | Comprehensive |
| [employee\_churn\_rate.24\_month](/docs/company-schema#employee_churn_rate) | Comprehensive |
| [employee\_count\_by\_month\_by\_level](/docs/company-schema#employee_count_by_month_by_level) | Comprehensive |
| [employee\_count\_by\_month\_by\_role](/docs/company-schema#employee_count_by_month_by_role) | Comprehensive |
| [employee\_count\_by\_sub\_role](/docs/company-schema#employee_count_by_sub_role) | Comprehensive |
| [employee\_growth\_rate.3\_month](/docs/company-schema#employee_growth_rate) | Comprehensive |
| [employee\_growth\_rate.6\_month](/docs/company-schema#employee_growth_rate) | Comprehensive |
| [employee\_growth\_rate.24\_month](/docs/company-schema#employee_growth_rate) | Comprehensive |
| [employee\_growth\_rate\_12\_month\_by\_sub\_role](/docs/company-schema#employee_growth_rate_12_month_by_sub_role) | Comprehensive |
| [recent\_exec\_departures](/docs/company-schema#recent_exec_departures) | Comprehensive |
| [recent\_exec\_hires](/docs/company-schema#recent_exec_hires) | Comprehensive |
| [top\_next\_employers](/docs/company-schema#top_next_employers) | Comprehensive |
| [top\_next\_employers\_12\_month](/docs/company-schema#top_next_employers_12_month) | Comprehensive |
| [top\_next\_employers\_by\_role](/docs/company-schema#top_next_employers_by_role) | Comprehensive |
| [top\_previous\_employers](/docs/company-schema#top_previous_employers) | Comprehensive |
| [top\_previous\_employers\_12\_month](/docs/company-schema#top_previous_employers_12_month) | Comprehensive |
| [top\_previous\_employers\_by\_role](/docs/company-schema#top_previous_employers_by_role) | Comprehensive |
| [top\_us\_employee\_metros](/docs/company-schema#top_us_employee_metros) | Comprehensive |

## Funding Details

| Field | Bundle |
| --- | --- |
| [funding\_details](/docs/company-schema#funding_details) | Funding Details |
| [funding\_details.funding\_currency](/docs/company-schema#funding_details) | Funding Details |
| [funding\_details.funding\_raised](/docs/company-schema#funding_details) | Funding Details |
| [funding\_details.funding\_round\_date](/docs/company-schema#funding_details) | Funding Details |
| [funding\_details.funding\_type](/docs/company-schema#funding_details) | Funding Details |
| [funding\_details.investing\_companies](/docs/company-schema#funding_details) | Funding Details |
| [funding\_details.investing\_individuals](/docs/company-schema#funding_details) | Funding Details |

## Location Details

| Field | Bundle |
| --- | --- |
| [locations](/docs/company-schema#locations) | Location Details |
| [locations.first\_seen](/docs/company-schema#locations) | Location Details |
| [locations.last\_seen](/docs/company-schema#locations) | Location Details |
| [locations.is\_active](/docs/company-schema#locations) | Location Details |
| [num\_active\_locations](/docs/company-schema#num_active_locations) | Location Details |
| [num\_total\_locations](/docs/company-schema#num_total_locations) | Location Details |

## Job Posting Details

| Field | Bundle |
| --- | --- |
| [active\_job\_postings](/docs/company-schema#active_job_postings) | Job Posting Details |
| [deactivated\_job\_postings](/docs/company-schema#deactivated_job_postings) | Job Posting Details |
| [active\_job\_postings\_by\_role](/docs/company-schema#active_job_postings_by_role) | Job Posting Details |
| [deactivated\_job\_postings\_by\_role](/docs/company-schema#deactivated_job_postings_by_role) | Job Posting Details |
| [active\_job\_postings\_by\_class](/docs/company-schema#active_job_postings_by_class) | Job Posting Details |
| [deactivated\_job\_postings\_by\_class](/docs/company-schema#deactivated_job_postings_by_class) | Job Posting Details |
| [active\_job\_postings\_by\_sub\_role](/docs/company-schema#active_job_postings_by_sub_role) | Job Posting Details |
| [deactivated\_job\_postings\_by\_sub\_role](/docs/company-schema#deactivated_job_postings_by_sub_role) | Job Posting Details |
| [active\_job\_postings\_by\_country](/docs/company-schema#active_job_postings_by_country) | Job Posting Details |
| [active\_job\_postings\_by\_metro](/docs/company-schema#active_job_postings_by_metro) | Job Posting Details |
| [active\_job\_postings\_by\_month](/docs/company-schema#active_job_postings_by_month) | Job Posting Details |
| [deactivated\_job\_postings\_by\_month](/docs/company-schema#deactivated_job_postings_by_month) | Job Posting Details |

## Parent Subsidiary Details

| Field | Bundle |
| --- | --- |
| [affiliated\_entities.relationship\_catalyst](/docs/company-schema#affiliated_entities) | Parent Subsidiary Details |
| [affiliated\_entities.relationship\_status](/docs/company-schema#affiliated_entities) | Parent Subsidiary Details |
| [affiliated\_entities.start\_date](/docs/company-schema#affiliated_entities) | Parent Subsidiary Details |
| [affiliated\_entities.end\_date](/docs/company-schema#affiliated_entities) | Parent Subsidiary Details |
| [affiliated\_entities.relationship\_citations](/docs/company-schema#affiliated_entities) | Parent Subsidiary Details |

Updated 2 months ago

---

Did this page help you?

Yes

No

---
# https://docs.peopledatalabs.com/docs/data-build

Bringing in data from [thousands of sources](/docs/data-sources) surfaces many complicated issues such as standardization, de-duplication and time-stamping data. Here we discuss many of these core product questions in detail.

Additionally, you can access our white paper about our data building process and approach [here](https://www.peopledatalabs.com/resource-lab/datafication/our-data-build-process).

## Standardization

Standardization comes in two forms: ensuring general formatting standards and canonicalizing data.

We lowercase all data and strip leading and trailing whitespace. This ensures normalization across all our data sources since raw data comes in a variety of capitalization formats. We also strip any leading or trailing punctuation that we have deemed non-essential.

Many of our fields are canonicalized into standardized values.

* For some fields, such as for majors and minors, this allows for standardized output and queryability
* For other fields our canonicalized data provides extra information (schools, companies and locations all are enhanced by our canonicalization techniques)
* For job titles in particular, we will attempt to map out acronyms to their full form
  + For example, "ceo" becomes "chief executive officer"
  + "MD" becomes "medical doctor" unless they are in a non-medical industry in which case "MD" becomes "managing director"

## De-Duplication

We de-duplicate our data using both deterministic and probabilistic methods that stem from a blocking/matching logic. We group records on similar values "keys," such as a common email, common name and so forth, and then we compare all records within a "blocking group" to verify if they are in fact a match.

This process is intentionally strict as our primary goal is to avoid false positive merges. Our general philosophy is that false positive merges have significantly more detrimental effects than missing out on a potential match of two largely different values. This philosophy helps define our [datasets](/docs/datasets), ensuring that we minimize the possibility of duplication and that our APIs return as much information as we can confidently provide for any given input.

## Quality Assurance

At the tail end of each [data build](/docs/data-updates), we conduct quality assurance on our data. Our QA process involves hand checking, running aggregations, and significant unit testing to ensure that we have not decreased the quality of data in any way.

Updated 4 months ago

---

Did this page help you?

Yes

No

---
# https://docs.peopledatalabs.com/docs/relationship_status

| Canonical Values for Affiliated Entity Relationship Statuses |
| --- |
| active |
| inactive |
| pending |
| unknown |

  

## Relevant fields

* [`affiliated_entities`](/docs/company-schema#affiliated_entities)

Updated 2 months ago

---

Did this page help you?

Yes

No

---
# https://docs.peopledatalabs.com/docs/title-subroles-to-roles

> ðŸ“˜
>
> ### Launched in v28.0 (October 2024)
>
> The classes, roles and sub roles on this page are the officially supported set of canonical values used across all datasets for all PDL customers. **Support for the previous (legacy) taxonomy has now fully ended.**
>
> To view the previous role values, see: [Legacy Mapping Title Subroles to Roles (pre-v27.1)](/docs/legacy-mapping-title-subroles-to-roles-prev-v271).
>
> For additional information, please see the [February 2025 Release Notes (v29.1)](/changelog/february-2025-release-notes-v291).

| Job Title Class | Job Title Role | Job Title Subrole |
| --- | --- | --- |
| services | creative | artist |
| services | creative | entertainment |
| services | creative | fashion |
| services | creative | graphic\_design |
| services | creative | hair\_stylist |
| services | creative | journalism |
| services | education | curation |
| services | education | primary\_and\_secondary |
| services | education | professor |
| services | education | student |
| services | education | tour\_and\_travel |
| services | fulfillment | logistics |
| services | fulfillment | project\_management |
| services | fulfillment | transport |
| services | fulfillment | warehouse |
| services | health | dental |
| services | health | doctor |
| services | health | fitness |
| services | health | nursing |
| services | health | pharmacy |
| services | health | therapy |
| services | health | veterinarian |
| services | health | wellness |
| services | hospitality | restaurants |
| services | hospitality | retail |
| services | manufacturing | health\_and\_safety |
| services | manufacturing | machinist |
| services | manufacturing | quality\_assurance |
| services | public\_service | emergency\_services |
| services | public\_service | judicial |
| services | public\_service | military |
| services | public\_service | political |
| services | public\_service | protective\_service |
| services | public\_service | social\_service |
| services | support | account\_management |
| services | support | customer\_success |
| services | support | customer\_support |
| services | support | fraud |
| services | trade | agriculture |
| services | trade | construction |
| services | trade | electric |
| services | trade | mechanic |
| services | trade | plumbing |
| services | professional\_service | accounting\_services |
| services | professional\_service | architecture |
| services | professional\_service | consulting |
| services | professional\_service | investment\_banking |
| services | professional\_service | legal\_services |
| services | professional\_service | marketing\_services |
| services | professional\_service | translation |
| general\_and\_administrative | analyst | business\_analyst |
| general\_and\_administrative | analyst | data\_analyst |
| general\_and\_administrative | analyst | revenue\_operations |
| general\_and\_administrative | advisory | advisor |
| general\_and\_administrative | advisory | board\_member |
| general\_and\_administrative | advisory | investor |
| general\_and\_administrative | finance | accounting |
| general\_and\_administrative | finance | bookkeeping |
| general\_and\_administrative | finance | procurement |
| general\_and\_administrative | finance | planning\_and\_analysis |
| general\_and\_administrative | finance | risk |
| general\_and\_administrative | human\_resources | human\_resources |
| general\_and\_administrative | human\_resources | recruiting |
| general\_and\_administrative | human\_resources | talent\_analytics |
| general\_and\_administrative | human\_resources | training |
| general\_and\_administrative | legal | compliance |
| general\_and\_administrative | legal | legal |
| general\_and\_administrative | operations | administrative |
| general\_and\_administrative | operations | aides |
| general\_and\_administrative | operations | building\_and\_grounds |
| general\_and\_administrative | operations | corporate\_development |
| general\_and\_administrative | operations | executive |
| general\_and\_administrative | operations | investor\_relations |
| general\_and\_administrative | operations | strategy |
| research\_and\_development | engineering | chemical |
| research\_and\_development | engineering | data\_engineering |
| research\_and\_development | engineering | data\_science |
| research\_and\_development | engineering | devops |
| research\_and\_development | engineering | electrical |
| research\_and\_development | engineering | hardware |
| research\_and\_development | engineering | industrial |
| research\_and\_development | engineering | information\_technology |
| research\_and\_development | engineering | mechanical |
| research\_and\_development | engineering | network |
| research\_and\_development | engineering | qa\_engineering |
| research\_and\_development | engineering | security |
| research\_and\_development | engineering | software |
| research\_and\_development | engineering | web |
| research\_and\_development | product | product\_design |
| research\_and\_development | product | product\_management |
| research\_and\_development | research | academic |
| research\_and\_development | research | financial |
| research\_and\_development | research | scientific |
| sales\_and\_marketing | marketing | brand |
| sales\_and\_marketing | marketing | content |
| sales\_and\_marketing | marketing | growth |
| sales\_and\_marketing | marketing | marketing\_design |
| sales\_and\_marketing | partnerships | business\_development |
| sales\_and\_marketing | partnerships | partnerships |
| sales\_and\_marketing | sales | account\_executive |
| sales\_and\_marketing | sales | insurance |
| sales\_and\_marketing | sales | realtor |
| sales\_and\_marketing | sales | sales\_development |
| sales\_and\_marketing | sales\_engineering | implementation |
| sales\_and\_marketing | sales\_engineering | solutions\_engineer |
| unemployed | unemployed | unemployed |

*Contents of this table were sourced from the following file on our public S3 bucket:[sub\_roles.txt](https://pdl-prod-schema.s3.us-west-2.amazonaws.com/30.0/enums/sub_roles.txt)*

## Relevant fields

* [`job_title_class`](/docs/fields#job_title_class)
* [`experience.title.class`](/docs/fields#experiencetitle)

## See Also

* [Job Title Class](/docs/job-title-class)
* [Job Title Roles](/docs/job-title-roles)
* [Job Title Subroles](/docs/job-title-subroles)

Updated 4 months ago

---

Did this page help you?

Yes

No

---
# https://docs.peopledatalabs.com/docs/funding-rounds

| Canonical Values for Funding Rounds |
| --- |
| angel |
| convertible\_note |
| corporate\_round |
| debt\_financing |
| equity\_crowdfunding |
| funding\_round |
| grant |
| initial\_coin\_offering |
| non\_equity\_assistance |
| post\_ipo\_debt |
| post\_ipo\_equity |
| post\_ipo\_secondary |
| pre\_seed |
| private\_equity |
| product\_crowdfunding |
| secondary\_market |
| seed |
| series\_a |
| series\_b |
| series\_c |
| series\_d |
| series\_e |
| series\_f |
| series\_g |
| series\_h |
| series\_i |
| series\_j |
| series\_unknown |
| undisclosed |

*Contents of this table were sourced from the following file on our public S3 bucket:[funding\_stage.txt](https://pdl-prod-schema.s3.us-west-2.amazonaws.com/28.0/enums/funding_stage.txt)*

## Relevant fields

* [`funding_stages`](/docs/company-schema#funding_stages)

Updated 4 months ago

---

Did this page help you?

Yes

No

---
# https://docs.peopledatalabs.com/docs/company-fields

# Overview

This page details the company-related fields that we provide through the [Company Enrichment](/docs/company-enrichment-api) and [Company Search](/docs/company-search-api) APIs.

* [Base Company Fields](#base-company-fields): Common fields available to all customers by default
* [Company Insights Fields](#company-insights-fields): Premium fields presenting summaries of the employee headcount and trends, built by aggregating data from our Person dataset
* [Premium Company Fields](#premium-company-fields): Premium company fields such as related companies, subsidiaries, acquisitions and more

> ðŸ“˜
>
> ### Field Availability
>
> Please note: Not all fields are available in all bundles.

* For more information about data formatting, see [Data Types](/docs/data-types).
* For a full example record, see [Example Company Record](/docs/example-company-record).
* For a simplified overview of our company fields, check out the [Company Data Overview](/docs/company-data-overview).
* For more details about our company fields, including fill rates and which fields are included in the base vs premium [field bundles](/docs/data-field-bundles), check out our [Company Stats](/docs/company-stats) pages.
* For a full data ingestion JSON schema, check out [this page](/docs/receiving-and-updating-data#data-ingestion-schemas).
* If you'd like access to premium fields or have questions about which fields are included in your specific field bundle(s), please [speak to one of our data consultants](https://peopledatalabs.com/talk-to-sales).

---

# Base Company Fields

These fields are available to all customers by default.

## Identifiers

### `id`

|  |  |
| --- | --- |
| Description | The identifier for the company. |
| Data Type | `String` |

#### Field Details

The ID is a unique, hashed value that represents a specific company record.

#### Example

JSON

```
"id": "tnHcNHbCv8MKeLh92946LAkX6PKg"
```

### `name`

|  |  |
| --- | --- |
| Description | The company's main common name. |
| Data Type | `String` |

#### Field Details

The company name will be lowercase with any leading/trailing whitespace removed. It is **not** guaranteed to be unique.

For the correct capitalization of the company name, see [`display_name`](#display_name).

The name value returned here does not undergo much cleaning or standardization. However, we clean and tokenize company names behind the scenes so they can be found using the [Company Search API](/docs/company-search-api). To see how company name cleaning works, check out the [Company Cleaner API](/docs/cleaner-apis#companyclean).

#### Example

JSON

```
"name": "people data labs"
```

### `display_name`

|  |  |
| --- | --- |
| Description | The company name, capitalized using the companyâ€™s self-reported name. |
| Data Type | `String` |

#### Field Details

The `display_name` field preserves the capitalization of the company name (unlike [`name`](#name) which is always lowercase). `display_name` is set using the companyâ€™s self-reported name, so it should be accurate even for companies with non-standard capitalization (such as VMware, FedEx, or Dell EMC).

Use this field to display properly capitalized company names in a UI or other customer-facing project or product.

#### Example

JSON

```
"display_name": "VMware"
```

## Company Information

### `affiliated_profiles`

|  |  |
| --- | --- |
| Description | [Company IDs](#id) that are affiliated with the queried company (parents and subsidiaries.) |
| Data Type | `Array [String]` |

#### Field Details

A list of [Company IDs](#id) that we have flagged as having an association to this company (either a parent or a subsidiary.) See [Parents and Subsidiaries](#parents-and-subsidiaries) for fields based on specific company associations.

#### Example

JSON

```
"affiliated_profiles": [
    "a1cpOkL4SHp0wSAKjbCeuwtAlno0",
    "3WBa1kollMtBbib5DoiCwwhyD9ks"
  ]
```

### `alternative_domains`

|  |  |
| --- | --- |
| Description | A list of alternate domains associated with this company. |
| Data Type | `Array [String]` |

#### Field Details

If a company rebrands or otherwise changes its primary domain, old company websites will be kept in this list.

See [`website`](#website) for how we handle domains.

#### Example

JSON

```
"alternative_domains": [
    "peopledatalabs.com",
    "talentiq.co",
    "peopledatalabs.co"
  ]
```

### `alternative_names`

|  |  |
| --- | --- |
| Description | A list of names associated with this company. |
| Data Type | `Array [String]` |

#### Field Details

A list of [names](#name) associated with the company filtered to ensure data quality.

#### Example

JSON

```
"alternative_names": [
    "people data labs",
    "people data labs inc",
    "talentiq"
  ]
```

### `employee_count`

|  |  |
| --- | --- |
| Description | The current number of employees working at the company based on our number of profiles. |
| Data Type | `Integer (>= 0)` |

#### Field Details

`employee_count` is an integer greater than or equal to zero. We calculate it by finding the number of profiles whose `experience.company.id`  matches the company with a non-null `job_start_date` and no end date.

For the company's self-reported size range, use the [`size`](#size) field instead. For more information about the different types of employee count data we provide, see [Employee Count Fields](/docs/employee-count-fields).

This number may be higher or lower than a company's real employee count depending on how many false positives and false negatives we have in our data as well as missing or duplicate individuals.

#### Example

JSON

```
"employee_count": 78
```

### `employee_count_by_country`

|  |  |
| --- | --- |
| Description | The number of current employees broken out by country. |
| Data Type | `Object` |

#### Field Details

Each country will be one of our [Canonical Countries](/docs/location-countries). For more information about how each count is calculated, see [Employee Count Breakdowns](/docs/company-schema#employee-count-breakdowns).

Beginning in v25.0, this field will also contain an `other_uncategorized` subfield. Profiles that we have associated with the company but do not have enough information to assign a location to will be included in this field. For more information, see [Employee Count Fields](/docs/employee-count-fields).

#### Example

JSON

```
"employee_count_by_country": {
    "united states": 67,
    "canada": 2,
    "india": 1,
    "bangladesh": 1,
    "other_uncategorized": 2
  }
```

### `founded`

|  |  |
| --- | --- |
| Description | The founding year of the company. |
| Data Type | `Integer (> 0)` |

#### Field Details

The founding year will be an integer greater than zero. If no year is found, it will be `null`.

If different sources list different founding years, we will choose the year that appears in the most sources. If multiple years appear in the same number of sources, we will use the latest year.

#### Example

JSON

```
"founded": 2015
```

### `headline`

|  |  |
| --- | --- |
| Description | The companyâ€™s headline summary. |
| Data Type | `String` |

#### Field Details

`headline` is a short description of the company, limited to 300 characters.

#### Example

JSON

```
"headline": "Your Single Source of Truth"
```

### `size`

|  |  |
| --- | --- |
| Description | A range representing the number of people working at the company. |
| Data Type | `Enum (String)` |

#### Field Details

The value of this field will be one of our canonical [Company Sizes](/docs/company-sizes). We derive it from the company's self-reported size on their social media profile.

For the true number of employees, use the [`employee_count`](#employee_count) field.

#### Example

JSON

```
"size": "11-50"
```

### `summary`

|  |  |
| --- | --- |
| Description | A description of the company. |
| Data Type | `String` |

#### Field Details

The company summary is a lowercase string and can contain escape characters such as `\n`. The string is limited to a maximum of 1000 characters.

#### Example

```
  "summary": "people data labs builds people data. \n\nuse our dataset
              of 1.5 billion unique person profiles to build products,
              enrich person profiles, power predictive modeling/ai,
              analysis, and more. we work with technical teams as their
              engineering focused people data partner. \n\nwe work with
              thousands of data science teams as their engineering focused
              people data partner. these include enterprises like adidas,
              ebay, and acxiom, as well as startups like madison logic,
              zoho, and workable. we are a deeply technical company, and
              are backed by two leading engineering venture capital firms
              - founders fund and 8vc.",
```

### `tags`

|  |  |
| --- | --- |
| Description | Tags associated with the company. |
| Data Type | `Array [String]` |

#### Field Details

Each tag is a lowercase string.

There may be tags that seem to overlap (for example: `"data"`, `"analytics"` and `"data and analytics"`). This is intentional so that it is easier to search for companies matching a tag.

#### Example

JSON

```
"tags": [
    "data",
    "people data",
    "data science",
    "artificial intelligence",
    "data and analytics",
    "machine learning",
    "analytics",
    "database",
    "software",
    "developer apis"
   ]
```

### `website`

|  |  |
| --- | --- |
| Description | The primary company website. |
| Data Type | `String` |

#### Field Details

This field contains the address of the primary company website associated with the record.

We standardize websites by removing `https://www.` and any additional subdomains and paths (with certain exceptions). Popular hosting platforms (like Facebook, Blogspot, Wix, etc.) will retain their subdomains and paths. For example, `samspizza.blogspot.com` or `etsy.com/sams-pizza`.

Websites using link shortening services (like Bit.ly, TinyURL, ShortURL, etc.) will appear in full.

We have a list of invalid URL items (domains, subdomains and TLDs) that we check against. We also check if an iteration of the company name appears in the website address as a simple validation.

Ideally, this is the website address that people commonly use when accessing a company's site (such as `facebook.com`) and not an alias (such as `fb.com`).

As with [Social Presence](#social-presence), we do **not** verify that the website is valid.

#### Example

JSON

```
"website": "peopledatalabs.com"
```

## Funding Data

### `funding_stages`

|  |  |
| --- | --- |
| Description | All disclosed funding stages for the company. |
| Data Type | `Array [Enum (String)]` |

#### Field Details

An unordered list of all funding stages for funding events announced by the company.

This is generated from the separate events in [`funding_details.funding_type`](#funding_details).

All values in the list must be [Canonical Funding Rounds](/docs/funding-rounds). If there are multiple events tied to the same round (ex: Series A), that label will only appear once in the list.

#### Example

JSON

```
"funding_stages": [
    "series_b",
    "series_a",
    "seed"
  ]
```

### `last_funding_date`

|  |  |
| --- | --- |
| Description | The date of the companyâ€™s most recent funding event. |
| Data Type | [`String (Date)`](https://docs.peopledatalabs.com/docs/data-types#dates) |

#### Field Details

The date of the companyâ€™s most recent funding event. This represents the publicly disclosed date of the closing of the financing, and will be independent of any prior dates associated with that same funding round.

#### Example

JSON

```
"last_funding_date": "2021-11-16"
```

### `latest_funding_stage`

|  |  |
| --- | --- |
| Description | The stage of the companyâ€™s most recent funding event. |
| Data Type | `Enum (String)` |

#### Field Details

Must be one of the [Canonical Funding Rounds](/docs/funding-rounds).

#### Example

JSON

```
"latest_funding_stage": "series_b"
```

### `number_funding_rounds`

|  |  |
| --- | --- |
| Description | The number of funding rounds announced by the company. |
| Data Type | `Integer (> 0)` |

#### Field Details

The number of separate funding events for the company. This is the total number of events in [`funding_details`](#funding_details).

If multiple events are tied to the same funding round, they will each be counted toward the total (ex: 3 Series A events will add 3 to the total count).

#### Example

JSON

```
"number_funding_rounds": 7
```

### `total_funding_raised`

|  |  |
| --- | --- |
| Description | The cumulative amount raised by the company in USD. |
| Data Type | `Float (> 0)` |

#### Field Details

The cumulative amount raised by the company during all publicly disclosed funding rounds.

The value for this field is represented in USD. It is the sum of all known values from individual funding rounds (each of which is represented in $ USD using â€œthen-currentâ€ currency exchange rates).

#### Example

JSON

```
"total_funding_raised": 55250000.0
```

## Industry Types

### `industry`

|  |  |
| --- | --- |
| Description | The self-reported industry of the company. |
| Data Type | `Enum (String)` |

#### Field Details

Industry is self-reported and will be one of our [Canonical Industries](/docs/industries). If no industry is found, the field will be `null`.

#### Example

JSON

```
"industry": "animation"
```

  

### `industry_v2`

|  |  |
| --- | --- |
| Description | Industry v2 is the self-reported industry from an expanded list of [Canonical v2 Industries](https://docs.peopledatalabs.com/docs/industries-v2). If no industry is found, the field will be `null` |
| Data Type | [`Enum (String)`](https://docs.peopledatalabs.com/docs/industries-v2) |

#### Field Details

Industry is self-reported and will be one of our [Canonical V2 Industries](/docs/industries-v2). If no industry is found, the field will be `null`.

#### Example

JSON

```
"industry": "textile manufacturing"
```

### `naics`

|  |  |
| --- | --- |
| Description | An array of objects containing the industry classifications for a company according to the North American Industry Classification System (NAICS). A company can (and frequently does) have multiple NAICS codes. |
| Data Type | `Array [Object]` |

#### Field Details

Each NAICS code associated with the company will be included in the list. For each NAICS code, we provide the actual six-digit code as well as the official description for each level of the NAICS code.

PDL uses [NAICS 2017 industry categorization](https://www.bls.gov/cew/classifications/industry/home.htm).

PDL offers self-reported NAICS industry categorizations within the company data, where this data serves as an alternative to Industry and SIC for users to categorize or segment companies. Because the data PDL publishes represents self-reported data where the industry values were selected by employees of those companies prior to the 2022 revision, we have not bulk converted to, or inferred, NAICS 2022 categories for our existing NAICS values.

A NAICS code doesnâ€™t have to use all six digits. Any unspecified field(s) in our data will have a `null` value.

| Field | Data Type | Description |
| --- | --- | --- |
| `naics_code` | `String` | The NAICS code associated with a companyâ€™s industry classification. [See canonical values](/docs/naics-codes). |
| `sector` | `String` | The industry classification according to the first two digits in the NAICS code. [See canonical values](/docs/naics-sectors). |
| `sub_sector` | `String` | The industry classification according to the first three digits in the NAICS code. [See canonical values](/docs/naics-subsectors). |
| `industry_group` | `String` | The industry classification according to the first four digits in the NAICS code. [See canonical values](/docs/naics-industry-groups). |
| `naics_industry` | `String` | The industry classification according to the first five digits in the NAICS code. [See canonical values](/docs/naics-industries). |
| `national_industry` | `String` | The industry classification according to all six digits in the NAICS code. [See canonical values.](/docs/naics-national-industries) |

#### Example

JSON

```
"naics": [
    {
      "naics_code": "423920",
      "sector": "wholesale trade",
      "sub_sector": "merchant wholesalers, durable goods",
      "industry_group": "miscellaneous durable goods merchant wholesalers",
      "naics_industry": "toy and hobby goods and supplies merchant wholesalers",
      "national_industry": "toy and hobby goods and supplies merchant wholesalers"
    },
    ...
  ]
```

### `sic`

|  |  |
| --- | --- |
| Description | An array of objects containing the industry classifications for a company according to the Standard Industrial Classification (SIC) system. A company can (and frequently does) have multiple SIC codes. |
| Data Type | `Array [Object]` |

#### Field Details

Each SIC code associated with the company will be included in the list. For each SIC code, we provide the actual four-digit code as well as the official description for each level of the SIC code.

A SIC code doesnâ€™t have to use all four digits. Any unspecified field(s) in our data will have a `null` value.

| Field | Data Type | Description |
| --- | --- | --- |
| `sic_code` | `String` | The SIC code associated with a companyâ€™s industry classification. |
| `major_group` | `String` | The industry classification according to the first two digits in the SIC code. |
| `industry_group` | `String` | The industry classification according to the first three digits in the SIC code. |
| `industry_sector` | `String` | The industry classification according to all four digits in the SIC code. |

#### Example

JSON

```
"sic": [
    {
      "sic_code": "7372",
      "major_group": "business services",
      "industry_group": "computer programming, data processing, and other computer related services",
      "industry_sector": "prepackaged software"
    },
    ...
   ]
```

## Primary Location

### `location`

|  |  |
| --- | --- |
| Description | An object containing increasingly granular information about the location of the companyâ€™s current headquarters. |
| Data Type | `Object` |

#### Field Details

A company's location is the location of its Headquarters (HQ). We determine a companyâ€™s current Headquarters/primary office based on the location that we see most often in our sources.

For more information on our standard location fields, see [Data Formatting: Locations](/docs/data-formatting#locations).

#### Example

JSON

```
"location": {
    "name": "san francisco, california, united states",
    "locality": "san francisco",
    "region": "california",
    "metro": "san francisco, california",
    "country": "united states",
    "continent": "north america",
    "street_address": "455 market street",
    "address_line_2": "suite 1670",
    "postal_code": "94105",
    "geo": "37.77,-122.41"
  }
```

## Stock Information

### `mic_exchange`

|  |  |
| --- | --- |
| Description | The MIC code for the stock exchange that the company's [ticker](#ticker) is listed on. |
| Data Type | `Enum (String)` |

#### Field Details

`mic_exchange` represents the Market Identified Code (MIC) standard exchange code corresponding to the stock exchange of the company.

The value of `mic_exchange` will always be one of our [Canonical MIC Codes](/docs/mic-codes) or `null` if there is no [ticker](#ticker).

#### Example

JSON

```
"mic_exchange": "xnams"
```

### `ticker`

|  |  |
| --- | --- |
| Description | The company ticker (only for public companies.) |
| Data Type | `String (Uppercase)` |

#### Field Details

`ticker` is the uppercase string of the companyâ€™s stock symbol.

If a company is not public (as listed in its [`type`](#type)), its ticker will be `null`.

#### Example

JSON

```
"ticker": "MOO"
```

### `type`

|  |  |
| --- | --- |
| Description | The company type. |
| Data Type | `Enum (String)` |

#### Field Details

`type` will be one of the Canonical [Company Types](/docs/company-types). If a company has a known [`ticker`](#ticker), then its `type` is public. If a company does not have a ticker and its ultimate parent company does, then its type is public\_subsidiary.

#### Example

JSON

```
"type": "private"
```

## Social Presence

We currently include company social profiles for LinkedIn, Yellow Pages, Xing, Twitter, Facebook and Crunchbase. Any profiles that we find for the company from these sources will be added to the [`profiles`](#profiles) list.

Each social profile URL has one or more standard formats that we parse and turn into a standard PDL format for that social URL. We invalidate profiles that have non-valid company stubs (for example, `linkedin.com/in`), and we also have a blacklist of usernames that we know are invalid.

We do **not** validate if a URL is valid (that is, whether you can access it) because doing this at scale is considered a Direct Denial of Service (DDoS) attack and/or a form of crawling. This is highly discouraged! We try to mitigate invalid URLs as much as possible by using Entity Resolution (Merging) to link URLs together and then tagging the primary URL at the top level for key networks.

### `linkedin_id`

|  |  |
| --- | --- |
| Description | The main LinkedIn profile ID for the company based on source agreement. |
| Data Type | `String` |

#### Example

JSON

```
"linkedin_id": "18170482"
```

### `linkedin_slug`

|  |  |
| --- | --- |
| Description | The companyâ€™s LinkedIn URL slug. |
| Data Type | `String` |

#### Field Details

To support our [upcoming change to PDL Company IDs](/changelog/january-2024-release-notes-v25#company-id), we are adding the new `linkedin_slug` field. This field is generated in the same way as our [current company `id` field](/docs/company-schema#id).

For new company records that do not have associated LinkedIn pages, this field will be null.

#### Example

JSON

```
"linkedin_slug": "peopledatalabs"
```

### `linkedin_url`

|  |  |
| --- | --- |
| Description | The main LinkedIn profile URL for the company based on source agreement. |
| Data Type | `String` |

#### Example

JSON

```
"linkedin_url": "linkedin.com/company/peopledatalabs"
```

### `facebook_url`

|  |  |
| --- | --- |
| Description | The main Facebook profile URL for the company based on source agreement. |
| Data Type | `String` |

#### Example

JSON

```
"facebook_url": "facebook.com/peopledatalabs"
```

### `twitter_url`

|  |  |
| --- | --- |
| Description | The main Twitter profile URL for the company based on source agreement. |
| Data Type | `String` |

#### Example

JSON

```
"twitter_url": "twitter.com/peopledatalabs"
```

### `profiles`

|  |  |
| --- | --- |
| Description | A list of all known social profile URLs for the company from [our known sources](#social-presence). |
| Data Type | `Array [String]` |

#### Example

JSON

```
"profiles": [
    "linkedin.com/company/peopledatalabs",
    "linkedin.com/company/18170482",
    "facebook.com/peopledatalabs",
    "twitter.com/peopledatalabs",
    "crunchbase.com/organization/talentiq"
  ]
```

## PDL Record Information & Metadata

### `dataset_version`

|  |  |
| --- | --- |
| Description | The major or minor release number. |
| Data Type | `String` |

#### Field Details

Note: This number corresponds to the [data release number](/changelog), not the API release number.

#### Example

JSON

```
"dataset_version": "19.2"
```

---

# Company Insights Fields

Premium fields presenting summaries of the employee headcount and trends, built by aggregating data from from our [Person Dataset](/docs/fields).

## Average Employee Tenure

Average employee tenure is the average number of years employees work for the company. It is represented by a floating number greater than zero and rounded to the nearest thousandth. It could skew lower if there have been a lot of recent hires.

The average is calculated using `experience.start_date` and `experience.end_date` for each employee found in our Person records.

If no start date is given or if a date only contains a year but no month, then the experience is not counted toward the average.

### `average_employee_tenure`

|  |  |
| --- | --- |
| Description | The average years of experience at the company. |
| Data Type | `Float (> 0)` |

#### Field Details

This insight shows the average number of years that employees at the company have worked based on `experience.start_date` and `experience.end_date`.

#### Example

JSON

```
"average_employee_tenure": 2.75
```

### `average_tenure_by_level`

|  |  |
| --- | --- |
| Description | The average years of experience at the company by job level. |
| Data Type | `Object` |

#### Field Details

This insight shows the average number of years that employees at the company have worked broken out by their level at the company. The average for each level is calculated using the same logic as [`average_employee_tenure`](#average_employee_tenure).

The level names come from `experience.title.levels`, meaning they will always be one of the [Canonical Job Levels](/docs/job-title-levels).

#### Example

JSON

```
"average_tenure_by_level": {
    "entry": 0.3,
    "unpaid": 2.0,
    "senior": 6.0,
    "director": 3.0,
    "vp": 2.4,
    "training": 0.2,
    "manager": 4.0,
    "owner": 3.2,
    "partner": 2.4,
    "cxo": 8.1
  }
```

### `average_tenure_by_role`

|  |  |
| --- | --- |
| Description | The average years of experience at the company by job role. |
| Data Type | `Object` |

#### Field Details

This insight shows the average number of years that employees at the company have worked broken out by their role at the company. The average for each role is calculated using the same logic as [`average_employee_tenure`](#average_employee_tenure).

The role names come from `experience.title.role`, meaning they will always be one of the [Canonical Job Roles](/docs/job-title-roles).

#### Example

JSON

```
"average_tenure_by_role": {
    "real_estate": 4.5,
    "design": 2.0,
    "trades": 3.2,
    "marketing": 0.1,
    "education": 6.5,
    "legal": 8.0,
    "customer_service": 4.0,
    "finance": 5.0,
    "public_relations": 8.1,
    "engineering": 2.1,
    "human_resources": 0.5,
    "media": 0.4,
    "sales": 0.6,
    "operations": 0.1,
    "health": 2.0
  }
```

## Employee Count Breakdowns

The count for each category will always be an integer value greater than or equal to zero.

This number may be higher or lower than a company's real employee count depending on how many false positives and false negatives we have in our data, missing and duplicate individuals, and missing information on start dates and job roles.

If no start date is given, then the experience is not counted.

For the overall employee count, see [`employee_count`](#employee_count). For the company's self-reported size, see [`size`](#size).

Note that discrepancies between the [`employee_count`](#employee_count), the most recent [`employee_count_by_month`](#employee_count_by_month), and aggregated[`employee_count_by_month_by_role`](#employee_count_by_month_by_role) and [`employee_count_by_month_by_level`](#employee_count_by_month_by_level) counts are expected. For more information about the logic used to calculate these values, see [this page](/docs/employee-count-fields).

### `employee_count_by_month`

|  |  |
| --- | --- |
| Description | The number of employees at the end of each month. |
| Data Type | `Object` |

#### Field Details

The total number of profiles associated with this company at the end of each month in the format `YYYY-MM`. The date range begins at the start date of the first associated employee or January 1, 2010, whichever is most recent. The final month in the range will be the last full month before the last monthly [Data Build](/docs/data-build). Most often this is the month before request was submitted. For example, if you make a request mid-March, the response will contain all data up to that February.

#### Example

JSON

```
"employee_count_by_month": {
    "2021-07": 84,
    "2021-08": 86,
    "2021-09": 84
  }
```

### `employee_count_by_month_by_level`

|  |  |
| --- | --- |
| Description | The number of employees at the end of each month, broken down by job level. |
| Data Type | `Object` |

#### Field Details

The total number of profiles associated with this company at the end of each month in the format `YYYY-MM` broken down by `experience.title.levels`. The level names will always be one of the [Canonical Job Levels](/docs/job-title-levels).

The date range begins at the start date of the first associated employee or January 1, 2010, whichever is most recent. The final month in the range will be the last full month before the last monthly [Data Build](/docs/data-build). Most often this is the month before request was submitted. For example, if you make a request mid-March, the response will contain all data up to that February.

If a person changes levels within a company during the same month, they will be counted in the same month towards both levels. An individual may have more than a single level for the same experience object, in which case they will contribute towards multiple levels.

#### Example

JSON

```
"employee_count_by_month_by_level": {
    "2015-03": {
      "partner": 0,
      "vp": 0,
      "owner": 1,
      "entry": 0,
      "director": 0,
      "unpaid": 0,
      "senior": 0,
      "cxo": 1,
      "manager": 0,
      "training": 0
    },
    ...
    "2021-06": {
      "partner": 0,
      "vp": 3,
      "owner": 1,
      "entry": 10,
      "director": 2,
      "unpaid": 2,
      "senior": 5,
      "cxo": 1,
      "manager": 3,
      "training": 0
    }
  }
```

### `employee_count_by_month_by_role`

|  |  |
| --- | --- |
| Description | The number of employees at the end of each month, broken down by job role. |
| Data Type | `Object` |

#### Field Details

The total number of profiles associated with this company at the end of each month in the format `YYYY-MM` broken down by `experience.title.role`. The role names will always be one of the [Canonical Job Roles](/docs/job-title-roles).

The date range begins at the start date of the first associated employee or January 1, 2010, whichever is most recent. The final month in the range will be the last full month before the last monthly [Data Build](/docs/data-build). Most often this is the month before request was submitted. For example, if you make a request mid-March, the response will contain all data up to that February.

If a person changes roles with a company during the same month, they will only be counted for a single role.

Beginning in v25.0, each month will also contain an `other_uncategorized` subfield. Profiles that we have associated with the company but do not have enough information to assign a role to will be included in this field. For more information, see [Employee Count Fields](/docs/employee-count-fields).

#### Example

JSON

```
"employee_count_by_month_by_role": {
    "2015-03": {
      "engineering": 0,
      "education": 0,
      "media": 0,
      "design": 0,
      "trades": 0,
      "health": 0,
      "real_estate": 0,
      "customer_service": 0,
      "legal": 0,
      "human_resources": 0,
      "finance": 0,
      "public_relations": 0,
      "marketing": 0,
      "sales": 0,
      "operations": 0,
      "other_uncategorized": 1
    },
    ...
    "2021-06": {
      "engineering": 1,
      "education": 0,
      "media": 0,
      "design": 0,
      "trades": 0,
      "health": 0,
      "real_estate": 0,
      "customer_service": 0,
      "legal": 0,
      "human_resources": 0,
      "finance": 0,
      "public_relations": 0,
      "marketing": 0,
      "sales": 0,
      "operations": 0,
      "other_uncategorized": 8
    }
  }
```

### `employee_count_by_class`

|  |  |
| --- | --- |
| Description | The number of current employees broken down by [Job Title Class](https://docs.peopledatalabs.com/docs/job-title-class). |
| Data Type | `Object` |

#### Field Details

The total number of profiles associated with this company at the end of the most recent month, broken down by `experience.title.class`. The role names will always be one of the [Canonical Job Title Class](/docs/job-title-class) labels. This field will also contain an `other_uncategorized` subfield that contains profiles we have associated with the company but do not have enough information to assign a role to.

#### Example

JSON

```
"employee_count_by_class": {
    "other_uncategorized": 16,
    "general_and_administrative": 12,
    "research_and_development": 29,
    "sales_and_marketing": 22,
    "services": 14,
  }
```

### `employee_count_by_role`

|  |  |
| --- | --- |
| Description | The number of employees (`INT`) by Job Role on the final day of the most recent month. |
| Data Type | `Object` |

#### Field Details

The total number of profiles associated with this company at the end of the most recent month, broken down by `experience.title.role`. The role names will always be one of the [Canonical Job Roles](/docs/job-title-roles). This field will also contain an `other_uncategorized` subfield that contains profiles we have associated with the company but do not have enough information to assign a role to.

This field is equivalent to the final month in the [`employee_count_by_month_by_role`](/docs/company-schema#employee_count_by_month_by_role) field.

#### Example

JSON

```
"employee_count_by_role": {
    "real_estate": 0,
    "design": 2,
    "trades": 0,
    "marketing": 4,
    "education": 4,
    "legal": 0,
    "customer_service": 10,
    "finance": 6,
    "public_relations": 1,
    "engineering": 24,
    "human_resources": 3,
    "media": 1,
    "sales": 12,
    "operations": 10,
    "health": 0,
    "other_uncategorized": 10
  }
```

### `employee_count_by_sub_role`

|  |  |
| --- | --- |
| Description | The number of current employees broken down by [Job Title Sub Role](https://docs.peopledatalabs.com/docs/job-title-subroles). |
| Data Type | `Object` |

#### Field Details

The total number of profiles associated with this company at the end of the most recent month, broken down by `experience.title.sub_role`. The role names will always be one of the [Canonical Job Title Subroles](/docs/job-title-subroles). This field will also contain an `other_uncategorized` subfield that contains profiles we have associated with the company but do not have enough information to assign a role to.

#### Example

JSON

```
{
  "employee_count_by_sub_role": {
    "other_uncategorized": 19,
    "health_and_safety": 0,
    "graphic_design": 1,
    "veterinarian": 0,
    "data_science": 2,
    "restaurants": 0,
    "marketing_services": 2,
    "planning_and_analysis": 1,
...
    "mechanical": 0
  }
}
```

## Employee Growth and Churn Rates

All calculation time frames are based on the month that you make the request. If you make the request in April, the three-month rate will use data from January onward.

If no start date is given, then the experience is not counted.

Additionally, if a date only contains a year but no month, it is assumed to be to be January for start dates and December (or the current month if December is in the future) for end dates.

### `employee_churn_rate`

|  |  |
| --- | --- |
| Description | The rate of change in employee headcount from N months prior. |
| Data Type | `Object` |

#### Field Details

This is a representation of net employee turnover. The churn rate is rounded to four decimal points and is always greater than or equal to 0. If the company had 0 employees or did not exist at the start time for a specific window, then the churn rate is `null`.

Churn rate is calculated as `max(employee_count_n_months_ago - employee_count_current, 0)/employee_count_n_months_ago`. For example, if a company has 200 employees at the beginning of the month, and at the end of the month 100 leave and 100 remain then its churn rate = 100 / 200 = 0.5.

| Field | Data Type |
| --- | --- |
| `3_month` | `Float (>= 0)` |
| `6_month` | `Float (>= 0)` |
| `12_month` | `Float (>= 0)` |
| `24_month` | `Float (>= 0)` |

#### Example

JSON

```
"employee_churn_rate": {
    "3_month": 0.015,
    "6_month": 0.02,
    "12_month": 0.035,
    "24_month": 0.155
  }
```

### `employee_growth_rate`

|  |  |
| --- | --- |
| Description | The percentage increase in total headcount from N months prior. |
| Data Type | `Object` |

#### Field Details

The growth rate is rounded to four decimal points and can be negative if the current number of employees is less than in the past. If the company had zero employees or did not exist at the start time for a specific window, then the growth rate is `null`.

Growth rate is calculated as `(current_employee_count / previous_employee_count) - 1`. For example, if a company has 100 employees at the beginning of the month, and at the end of the month has grown to 200 employees then its growth rate = (200 / 100) - 1 = 1.0.

| Field | Data Type |
| --- | --- |
| `3_month` | `Float` |
| `6_month` | `Float` |
| `12_month` | `Float` |
| `24_month` | `Float` |

#### Example

JSON

```
"employee_growth_rate": {
    "3_month": 0.0595,
    "6_month": 0.0723,
    "12_month": 0.8542,
    "24_month": 1.4722
  }
```

### `employee_growth_rate_12_month_by_class`

|  |  |
| --- | --- |
| Description | The twelve month rate of change by [Job Title Class](https://docs.peopledatalabs.com/docs/job-title-class). |
| Data Type | `Object` |

#### Field Details

The 12 month growth rate of the total number of profiles associated with this company at the end of the most recent month in the format `YYYY-MM` broken down by `experience.title.class`. The role names will always be one of the [Canonical Job Title Class](/docs/job-title-class) labels. This field will also contain an `other_uncategorized` subfield that contains profiles we have associated with the company but do not have enough information to assign a role to.

The growth rate is rounded to four decimal points and can be negative if the current number of employees is less than in the past. If the company had zero employees or did not exist at the start time for a specific window, then the growth rate is `null`.

Growth rate is calculated as `(current_employee_count / previous_employee_count) - 1`. For example, if a company has 100 employees at the beginning of the month 12 months ago, and at the end of the most recent month has grown to 200 employees then its growth rate = (200 / 100) - 1 = 1.0.

The 12 month growth rate will be computed using the last full month before the last monthly Data Build. Most often this is the month before request was submitted. For example, if you make a request mid-March, the response will contain the 12 month growth rate from February."

#### Example

JSON

```
"employee_growth_rate_12_month_by_class": {
    "other_uncategorized": 0.2,
    "general_and_administrative": -0.167,
    "research_and_development": 0.1,
    "sales_and_marketing": -0.333,
    "services": 0.0,
  }
```

### `employee_growth_rate_12_month_by_role`

|  |  |
| --- | --- |
| Description | The twelve month rate of change (`FLOAT`) by Job Role on the final day of the most recent month. |
| Data Type | `Object` |

#### Field Details

The 12 month growth rate of the total number of profiles associated with this company at the end of the most recent month in the format `YYYY-MM` broken down by `experience.title.role`. The role names will always be one of the [Canonical Job Roles](/docs/job-title-roles). This field will also contain an `other_uncategorized` subfield that contains profiles we have associated with the company but do not have enough information to assign a role to.

The growth rate is rounded to four decimal points and can be negative if the current number of employees is less than in the past. If the company had zero employees or did not exist at the start time for a specific window, then the growth rate is `null`.

Growth rate is calculated as `(current_employee_count / previous_employee_count) - 1`. For example, if a company has 100 employees at the beginning of the month 12 months ago, and at the end of the most recent month has grown to 200 employees then its growth rate = (200 / 100) - 1 = 1.0.

The 12 month growth rate will be computed using the last full month before the last monthly Data Build. Most often this is the month before request was submitted. For example, if you make a request mid-March, the response will contain the 12 month growth rate from February.

#### Example

JSON

```
"employee_count_12_month_growth_by_role": {
    "real_estate": null,
    "design": -0.2500,
    "trades": null,
    "marketing": -0.5000,
    "education": 0.0000,
    "legal": null,
    "customer_service": -0.4545,
    "finance": -0.2500,
    "public_relations": null,
    "engineering": -0.1220,
    "human_resources": -0.1667,
    "media": 0.0000,
    "sales": -0.1852,
    "operations": 0.000,
    "health": null,
    "other_uncategorized": 0.1471
  }
```

### `employee_growth_rate_12_month_by_sub_role`

|  |  |
| --- | --- |
| Description | The twelve month rate of change by [Job Title Sub Role](https://docs.peopledatalabs.com/docs/job-title-subroles). |
| Data Type | `Object` |

#### Field Details

The 12 month growth rate of the total number of profiles associated with this company at the end of the most recent month in the format `YYYY-MM` broken down by `experience.title.sub_role`. The role names will always be one of the [Canonical Job Title Subroles](/docs/job-title-subroles). This field will also contain an `other_uncategorized` subfield that contains profiles we have associated with the company but do not have enough information to assign a role to.

The growth rate is rounded to four decimal points and can be negative if the current number of employees is less than in the past. If the company had zero employees or did not exist at the start time for a specific window, then the growth rate is `null`.

Growth rate is calculated as `(current_employee_count / previous_employee_count) - 1`. For example, if a company has 100 employees at the beginning of the month 12 months ago, and at the end of the most recent month has grown to 200 employees then its growth rate = (200 / 100) - 1 = 1.0.

The 12 month growth rate will be computed using the last full month before the last monthly Data Build. Most often this is the month before request was submitted. For example, if you make a request mid-March, the response will contain the 12 month growth rate from February.

#### Example

JSON

```
"employee_growth_rate_12_month_by_sub_role": {
    "other_uncategorized": -0.2667,
    "advisory": 0.0,
    "analyst": null,
    "creative": null,
    "education": 0.2,
    "engineering": -0.069,
    "finance": 0.0,
    "health": null,
    "hospitality": null,
    "product_design": -0.675,
    "recruiting": 0.0,
    "manufacturing": null,
    "marketing": 0.0,
    "solutions_engineer": -0.2667,
	...
    "retail": null
  }
```

## Gross Additions and Departures

This insight shows the total number of employees that joined or left the company each month.

The count for each month will always be an integer greater than or equal to zero. The month range begins at the start date of the first associated employee or January 1, 2010, whichever is most recent. The final month in the range will be the last full month before the last monthly [Data Build](/docs/data-build). Most often this is the month before request was submitted. For example, if you make a request mid-March, the response will contain all data up to that February.

This number may be higher or lower than a company's real employee count depending on how many false positives and false negatives we have in our data, missing and duplicate individuals, and missing information on start/end dates.

If a start or end date is not given or only contains a year but no month, it is not counted. This differs from [`employee_count_by_month`](#employee_count_by_month) that assumes January if there is no month.

### `gross_additions_by_month`

|  |  |
| --- | --- |
| Description | The total number of profiles that joined the company each month. |
| Data Type | `Object` |

#### Field Details

The total number of profiles that joined the company each month in the format `YYYY-MM` based on `experience.start_date`.

#### Example

JSON

```
"gross_additions_by_month": {
    "2015-03": 1,
    "2015-04": 1,
    ...
    "2021-05": 2,
    "2021-06": 2
  }
```

### `gross_departures_by_month`

|  |  |
| --- | --- |
| Description | The total number of profiles that left the company each month. |
| Data Type | `Object` |

#### Field Details

The total number of profiles that left the company each month in the format `YYYY-MM` based on `experience.end_date`.

#### Example

JSON

```
"gross_departures_by_month": {
    "2015-03": 1,
    "2015-04": 1,
    ...
    "2021-05": 2,
    "2021-06": 2
  }
```

## Inferred Revenue

### `inferred_revenue`

|  |  |
| --- | --- |
| Description | Company's estimated annual revenue range in US dollars. |
| Data Type | `Enum (String)` |

#### Field Details

A company's inferred revenue is an estimated range of its annual revenue in US dollars and can be used as a filter in [Company Search queries](/docs/company-search-api).

The revenue estimate is calculated using a predictive model that factors in details generated for our [Company Insights Fields](#company-insights-fields) (for example, [employee\_count\_by\_month\_by\_role](#employee_count_by_month_by_role)) as well as for other inputs that have been shown to be highly correlative.

The range will be one of our [Canonical Inferred Revenue Ranges](/docs/inferred-revenue-ranges).

#### Example

JSON

```
"inferred_revenue": "$10M-$25M"
```

## Recent Executive Changes

These insights provide details on executives that have joined or left the company in the past three months at the time you make the request.

There is no limit on the number of executives that can be in either list. To determine if someone is an executive, we check if their `experience.title.levels` in the company matches `CXO`, `owner` or `VP`. If no level is specified, then the experience is not counted.

If a start or end date is not given for an executive, then the experience is not counted. If the date only contains a year, the month is assumed to be January.

### `recent_exec_departures`

|  |  |
| --- | --- |
| Description | The profiles of all of CXOs, owners and VPs that have left the company in the last three months. |
| Data Type | `Array [Object]` |

#### Field Details

For each executive that has left the company in the past three months, we provide the following information:

| Field | Data Type | Description |
| --- | --- | --- |
| `departed_date` | `String (Date: YYYY-MM)` | The month the executive left the company. |
| `pdl_id` | `String` | The ID of the executive in our [Person Dataset](/docs/fields). |
| `job_title` | `String` | The executive's previous job title at the company. |
| `job_title_role` | `Enum (String)` | The executive's previous job role at the company. This will be one of the [Canonical Job Roles](/docs/job-title-roles). |
| `job_title_sub_role` | `Enum (String)` | The executive's previous job subrole at the company. This will be one of the [Canonical Job Subroles](/docs/job-title-subroles). |
| `job_title_class` | `Enum (String)` | The expense line item category this executive would fall into. This will be one of the [Canonical Job Classes](/docs/job-title-class) . |
| `job_title_levels` | `Array [Enum (String)]` | The executive's previous job levels at the company. This will be in the [Canonical Job Levels](/docs/job-title-levels). |
| `new_company_id` | `String` | The [ID](#id) of the new company the executive joined. |
| `new_company_job_title` | `String` | The executive's current job title at the new company. |
| `new_company_job_title_role` | `Enum (String)` | The executive's current job role at the new company. This will be one of the [Canonical Job Roles](/docs/job-title-roles). |
| `new_company_job_title_sub_role` | `Enum (String)` | The executive's current job subrole at the new company. This will be one of the [Canonical Job Classes](/docs/job-title-class) . |
| `new_company_job_title_class` | `Enum (String)` | The executive's current job class at the new company. This will be one of the [Canonical Job Subroles](/docs/job-title-subroles) . |
| `new_company_job_title_levels` | `Array [Enum (String)]` | The executive's current job levels at the new company. This will be in the [Canonical Job Levels](/docs/job-title-levels). |

#### Example

JSON

```
"recent_exec_departures": [
    {
      "departed_date": "2024-06",
      "pdl_id": "sosPKkiBABHsppzWEYyqgg_0000",
      "job_title": "vice president of revenue operations",
      "job_title_role": "analyst",
      "job_title_sub_role": "revenue_operations",
      "job_title_class": "general_and_administrative",
      "job_title_levels": ["vp"],
      "new_company_id": "ZFOfaDnanwu1hrtXsyfFEw521uw0",
      "new_company_job_title": "senior vice president, revenue operations",
      "new_company_job_title_role": "analyst",
      "new_company_job_title_sub_role": "revenue_operations",
      "new_company_job_title_class": "general_and_administrative",
      "new_company_job_title_levels": ["senior", "vp"]
    },
    ...
  ]
```

### `recent_exec_hires`

|  |  |
| --- | --- |
| Description | The profiles of all of CXOs, owners and VPs that have joined the company in the last three months. |
| Data Type | `Array [Object]` |

#### Field Details

For each executive that has joined the company in the past three months, we provide the following information:

| Field | Data Type | Description |
| --- | --- | --- |
| `joined_date` | `String (Date: YYYY-MM)` | The month the executive joined the company. |
| `pdl_id` | `String` | The ID of the executive in our [Person Dataset](/docs/fields). |
| `job_title` | `String` | The executive's current job title at the company. |
| `job_title_role` | `Enum (String)` | The executive's current job role at the company. This will be one of the [Canonical Job Roles](/docs/job-title-roles). |
| `job_title_sub_role` | `Enum (String)` | The executive's current job subrole at the company. This will be one of the [Canonical Job Subroles](/docs/job-title-subroles). |
| `job_title_class` | `Enum (String)` | The expense line item category this executive would fall into. This will be one of the [Canonical Job Classes](/docs/job-title-class) . |
| `job_title_levels` | `Array [Enum (String)]` | The executive's current job level at the company. This will be in the [Canonical Job Levels](/docs/job-title-levels). |
| `previous_company_id` | `String` | The [ID](#id) of the company the executive left. |
| `previous_company_job_title` | `String` | The executive's previous job title at the old company. |
| `previous_company_job_title_role` | `Enum (String)` | The executive's previous job role at the old company. This will be one of the [Canonical Job Roles](/docs/job-title-roles). |
| `previous_company_job_title_sub_role` | `Enum (String)` | The executive's previous job subrole at the old company. This will be one of the [Canonical Job Subroles](/docs/job-title-subroles). |
| `previous_company_job_title_class` | `Enum (String)` | The executive's previous job class at the old company. This will be one of the [Canonical Job Classes](/docs/job-title-class) . |
| `previous_company_job_title_levels` | `Array [Enum (String)]` | The executive's previous job levels at the old company. This will be in the [Canonical Job Levels](/docs/job-title-levels). |

#### Example

JSON

```
"recent_exec_hires": [
  {
    "joined_date": "2024-06",
    "pdl_id": "un-fsOccjHy1yElqJObW6g_0000",
    "job_title": "chief of staff to the chief executive officer and founder",
    "job_title_role": "operations",
    "job_title_sub_role": "aides",
    "job_title_class": "general_and_administrative",
    "job_title_levels": ["owner"],
    "previous_company_id": "RjhjJnYUCiAfXFyxCHLDQQ5opPrK",
    "previous_company_job_title": "business operations manager, reality labs",
    "previous_company_job_title_role": "professional_service",
    "previous_company_job_title_sub_role": "investment_banking",
    "previous_company_job_title_class": null,
    "previous_company_job_title_levels": ["manager"]
  },
    ...
  ]
```

## Top Next and Previous Employers

The top ten next and previous companies employees are broken down by job role.

Companies are listed using their [PDL Company ID](#id).

The first list of companies will be under the `"all"` key. This represents the top 10 companies for any role.

The roles are based on the employeeâ€™s role at the company queried. Each role listed in the break down will come from the [Canonical Job Roles](/docs/job-title-roles).

If no start date is given or no role exists, then the experience is not counted.

If there are fewer than ten next/previous employers for a role, it will return as many as there are.

### `top_next_employers`

|  |  |
| --- | --- |
| Description | The top ten companies employees moved to, and how many employees moved there, across all time periods. |
| Data Type | `Object` |

#### Field Details

This field uses `experience.title.role` and `experience.start_date` to find the top next employers. Companies are ranked by the number of previous employees currently employed there.

A company is considered to be a ""next employer"" if the employee has a start date after their start date for the company being queried.

This field is functionally identical to the legacy `top_next_employers_by_role field`, but adds a displayable company name to the response structure.

#### Example

JSON

```
"top_next_employers": {
  "finance": [
    {
      "id": "3kgY1DOS3BewEUBVRyl5Lg3tl13v",
      "count": 1,
      "display_name": "Essex Property Trust"
    },
    {
      "id": "OCuR0U1nT6kt66YfnUVKlQaeEYUr",
      "count": 1,
      "display_name": "Green Street"
    }
  ],
  "education": [
    {
      "id": "69IOeBijO7bNzClSGs6bxg4Dt7Ge",
      "count": 1,
      "display_name": "DoorDash"
    }
  ],
  "all": [
    {
      "id": "gbzAHmeUyu5rJyy4eUrPPgtM5jdC",
      "count": 5,
      "display_name": "Five by Five"
    },
    {
      "id": "Dn0GAueIRsYzwepbYEGIAQVi7Qyl",
      "count": 3,
      "display_name": "Anaconda"
    },
    ...
  ]
...
}
```

### `top_next_employers_12_month`

|  |  |
| --- | --- |
| Description | The top ten next employers, counting only employee changes within the last 12 months. |
| Data Type | `Object` |

#### Field Details

This field modifies the top\_next\_employers field, with a filter to only count for employees with job changes that have occurred within the last 12 months

#### Example

JSON

```
"top_next_employers_12_month": {
  "education": [
    {
      "id": "69IOeBijO7bNzClSGs6bxg4Dt7Ge",
      "count": 1,
      "display_name": "DoorDash"
    }
  ],
  "all": [
    {
      "id": "gbzAHmeUyu5rJyy4eUrPPgtM5jdC",
      "count": 4,
      "display_name": "Five by Five"
    },
    {
      "id": "Dn0GAueIRsYzwepbYEGIAQVi7Qyl",
      "count": 2,
      "display_name": "Anaconda"
    },
    ...
  ]
...
}
```

### `top_next_employers_by_role`

> âš ï¸
>
> ### Deprecated Field
>
> As of April 2025, the `top_next_employer_by_role` field is deprecated and no longer recommended for use. It will be fully replaced in July 2025 (v31.0) by the new [`top_next_employers`](#top_next_employers) field which is now available in beta. We encourage all users to transition to this new field before the final sunset in July.
>
> For more information please see our [April 2025 Release Notes (v30.0)](/changelog/april-2025-release-notes-v300).

|  |  |
| --- | --- |
| Description | The top ten companies employees moved to and how many employees moved there. |
| Data Type | `Object` |

#### Field Details

This insight uses `experience.title.role` and `experience.start_date` to find the top next employers. Companies are ranked by the number of previous employees currently employed there.

A company is considered to be a "next employer" if the employee has a start date after their start date for the company being queried.

#### Example

JSON

```
"top_next_employers_by_role": {
    "all": {
      "aKCIYBNF9ey6o5CjHCCO4goHYKlf" : 573,
      "RjhjJnYUCiAfXFyxCHLDQQ5opPrK" : 498,
      ...
    },
    "finance": {
      "RZOFiRjw26VpLObnwmYXGgRyn3aW" : 294,
      "BWiTKOBgRTsSttn62R7EBQvww4gF" : 112,
      ...
    },
    ...
  }
```

### `top_previous_employers`

|  |  |
| --- | --- |
| Description | The top ten previous companies employees worked for previously, and how many current employees were previously employed by them, across all time periods. |
| Data Type | `Object` |

#### Field Details

This field uses `experience.title.role` and `experience.start_date` to find the top previous employers. Companies are ranked by the number of current employees previously employed there.

A company is considered to be a "previous employer" if the employee has a start date before their start date for the company being queried.

This field is functionally identical to the legacy `top_previous_employers_by_role field`, but adds a displayable company name to the response structure."

#### Example

JSON

```
"top_previous_employers": {
  "finance": [
    {
      "id": "7L0SglhytLJVj2JOx3PqVgDa2lnM",
      "count": 1,
      "display_name": "MineralTree, Inc."
    },
    {
      "id": "HKCBzjcdUhVPHCmb246CSAYwkTC1",
      "count": 1,
      "display_name": "Center for Effective Government"
    },
    {
      "id": "Pt8QqdHiI5swPLyB4kwkWAnYh66C",
      "count": 1,
      "display_name": "University of Massachusetts Dartmouth"
    }
  ],
  "education": [
    {
      "id": "CKHJ5P60N4XW4oZXB8BdmgKL8vvO",
      "count": 1,
      "display_name": "US Army"
    },
    {
      "id": "DCD55P9HCbJ6EkJhEdPp0AFqPzf3",
      "count": 1,
      "display_name": "Oracle"
    }
  ],
  "all": [
    {
      "id": "aubMfPvUgxL09C7OTtPqqQFVuAR9",
      "count": 11,
      "display_name": "Pipl"
    },
    {
      "id": "Cw9vt7WFFRbhLDnoCeRbswn15Qhi",
      "count": 6,
      "display_name": "Intel Corporation"
    },
    ...
  ]
...
}
```

### `top_previous_employers_12_month`

|  |  |
| --- | --- |
| Description | The top ten previous employers, counting only employee changes within the last 12 months. |
| Data Type | `Object` |

#### Field Details

This field modifies the `top_previous_employers` field, with a filter to only count for employees with job changes that have occurred within the last 12 months

#### Example

JSON

```
"top_previous_employers_12_month": {
  "education": [
    {
      "id": "DCD55P9HCbJ6EkJhEdPp0AFqPzf3",
      "count": 1,
      "display_name": "Oracle"
    }
  ],
  "all": [
    {
      "id": "aubMfPvUgxL09C7OTtPqqQFVuAR9",
      "count": 3,
      "display_name": "Pipl"
    },
    {
      "id": "Cw9vt7WFFRbhLDnoCeRbswn15Qhi",
      "count": 2,
      "display_name": "Intel Corporation"
    },
    ...
  ]
...
}
```

### `top_previous_employers_by_role`

> âš ï¸
>
> ### Deprecated Field
>
> As of April 2025, the `top_previous_employer_by_role` field is deprecated and no longer recommended for use. It will be fully replaced in July 2025 (v31.0) by the new [`top_previous_employers`](#top_previous_employers) field which is now available in beta. We encourage all users to transition to this new field before the final sunset in July.
>
> For more information please see our [April 2025 Release Notes (v30.0)](/changelog/april-2025-release-notes-v300).

|  |  |
| --- | --- |
| Description | The top ten previous companies employees worked for and how many current employees were previously employed by them. |
| Data Type | `Object` |

#### Field Details

This insight uses `experience.title.role` and `experience.start_date` to find the top previous employers. Companies are ranked by the number of current employees previously employed there.

A company is considered to be a "previous employer" if the employee has a start date before their start date for the company being queried.

#### Example

JSON

```
"top_previous_employers_by_role": {
    "all": {
      "aKCIYBNF9ey6o5CjHCCO4goHYKlf" : 573,
      "RjhjJnYUCiAfXFyxCHLDQQ5opPrK" : 498,
      ...
    },
    "finance": {
      "RZOFiRjw26VpLObnwmYXGgRyn3aW" : 294,
      "BWiTKOBgRTsSttn62R7EBQvww4gF" : 112,
      ...
    },
    ...
  }
```

## Top US Metros

### `top_us_employee_metros`

|  |  |
| --- | --- |
| Description | The top ten US metros where employees are based. |
| Data Type | `Object` |

#### Field Details

This insight contains the top ten US metros for the company, ordered by the current headcount at each location. For each metro, we also provide the current headcount and the growth rate in that metro over the last twelve months.

Each metro listed is one of our [Canonical Metros](/docs/location-metros).

To determine the headcount at each location, we use our Person Data to find the location where each current employee works. If an employee does not have location data or they are not based in the US, they are not included in the count.

| Field | Data Type | Description |
| --- | --- | --- |
| `current_headcount` | `Integer (> 0)` | The number of employees in the metro. |
| `12_month_growth_rate` | `Float` | The [growth rate](#employee_growth_rate) in the metro over the last twelve months, precise to fourth decimal place. |

#### Example

JSON

```
"top_us_employee_metros": {
    "san francisco, california, united states" : {
      "current_headcount" : 1207,
      "12_month_growth_rate" : .0040
    },
    "austin, texas, united states" : {
      "current_headcount" : 532,
      "12_month_growth_rate" : .0900
    },
    ...
  }
```

---

# Premium Company Fields

These high-value fields are available through our premium offerings.

## Premium Company Information

### `linkedin_follower_count`

|  |  |
| --- | --- |
| Description | The number of followers on a companyâ€™s LinkedIn profile. |
| Data Type | `Integer (>= 0)` |

#### Field Details

The number of followers on a companyâ€™s LinkedIn profile.

#### Example

JSON

```
"linkedin_follower_count": 5880
```

## Funding Details

### `funding_details`

|  |  |
| --- | --- |
| Description | List of all funding events associated with the company, with corresponding details. |
| Data Type | `Array [Object]` |

#### Field Details

Each publicly disclosed funding event will be added to the `funding_details` list as an Object with the following fields:

| Field | Data Type | Description |
| --- | --- | --- |
| `funding_round_date` | [`String (Date)`](/docs/data-types#dates) | The publicly disclosed date of the closing of the financing event. |
| `funding_raised` | `Float (> 0)` | The total amount raised during the funding event. |
| `funding_currency` | `Enum (String)` | The currency code for the `funding_raised` value. Currently, this will always be `usd`. |
| `funding_type` | `Enum (String)` | The funding stage of the funding event. Must be one of our [Canonical Funding Rounds](/docs/funding-rounds). |
| `investing_companies` | `Array [String]` | The [PDL Company IDs](/docs/company-schema#id) of the investing companies participating in the funding event. |
| `investing_individuals` | `Array [String (Titlecase)]` | The names of any other investing individuals participating in the funding event. |

#### Example

JSON

```
"funding_details": [
    {
      "funding_round_date": "2021-11-16",
      "funding_raised": 45000000.0,
      "funding_currency": "usd",
      "funding_type": "series_b",
      "investing_companies": [
        "UHKkwjzET0f4c2FLBt5BOgB7eZH9",
        "s5O9wCcVnokBzzvX4TQwEwg07z1L"
      ],
      "investing_individuals": [
        "Guillaume \"G\" Cabane"
      ]
    },
    ...
  ]
```

## Parents and Subsidiaries

These insights provide the [company IDs](#id) of the queried company's parent and subsidiary companies.

### `all_subsidiaries`

|  |  |
| --- | --- |
| Description | The [IDs](#id) of every company owned by the queried company. |
| Data Type | `Array [String]` |

#### Field Details

The subsidiary company values will be the [ID](#id) of the company. If no subsidiaries are found, the value will be `null`.

#### Example

JSON

```
"all_subsidiaries" : [
    "HwrPqD6yDTnKmmPQFCgIeQ5hOn8j",
    "xhI4e4JvjGZF4SprW5hhCgmLfVjB",
    "niEc7rpuQ1GXwpuDPeeN2QWYggDC",
    "2BrnzFlEfHtRXJUakLCQYQuO0JnJ",
    "uBF8GihqobELnphsfR9ppwQbM9x7",
    "N7iFUv1vUYWF8t0JXHmL5gvFy4XE",
    "97JIBSIC059vdTevziAFJA7qSRNZ",
    "amtMwZGXmNDYoqBCSQBXQAxXVeWV"
  ]
```

### `direct_subsidiaries`

|  |  |
| --- | --- |
| Description | The [IDs](#id) of each company that the queried company directly owns. |
| Data Type | `Array [String]` |

#### Field Details

The subsidiary company values will be the [ID](#id) of the company. If no subsidiaries are found, the value will be `null`.

#### Example

JSON

```
"direct_subsidiaries" : [
    "HwrPqD6yDTnKmmPQFCgIeQ5hOn8j",
    "2BrnzFlEfHtRXJUakLCQYQuO0JnJ",
    "uBF8GihqobELnphsfR9ppwQbM9x7",
    "N7iFUv1vUYWF8t0JXHmL5gvFy4XE",
    "97JIBSIC059vdTevziAFJA7qSRNZ",
    "amtMwZGXmNDYoqBCSQBXQAxXVeWV"
  ]
```

### `immediate_parent`

|  |  |
| --- | --- |
| Description | The [ID](#id) of the company that directly owns the queried company. |
| Data Type | `String` |

#### Field Details

The parent company value will be the [ID](#id) of the company. If no parents are found, the value will be `null`.

#### Example

JSON

```
"immediate_parent": "amtMwZGXmNDYoqBCSQBXQAxXVeWV"
```

### `ultimate_parent`

|  |  |
| --- | --- |
| Description | The [ID](#id) of the ultimate organizational entity that owns the queried company. |
| Data Type | `String` |

#### Field Details

The parent company value will be the [ID](#id) of the company. If no parents are found, the value will be `null`.

#### Example

JSON

```
"ultimate_parent": "0XQ1XCKrHIFF3H6tBVRdzAIknJNS"
```

### `ultimate_parent_ticker`

|  |  |
| --- | --- |
| Description | Stock symbol of the company's ultimate parent (only for subsidiaries of public companies) |
| Data Type | `String` |

#### Field Details

The `ultimate_parent_ticker` field will be populated for records where the company is a subsidiary of a public company. These companies will also have a [`type`](/docs/company-schema#type) value of `public_subsidiary` following the v28.0 release in October 2024.

#### Example

JSON

```
"ultimate_parent_ticker": "CRM",
```

### `ultimate_parent_mic_exchange`

|  |  |
| --- | --- |
| Description | MIC exchange code that corresponds to the stock exchange of the company's ultimate parent (only for subsidiaries of public companies) |
| Data Type | `String` |

#### Field Details

The `ultimate_parent_mic_exchange` field will be populated for records where the company is a subsidiary of a public company. These companies will also have a [`type`](/docs/company-schema#type) value of `public_subsidiary` following the v28.0 release in October 2024.

#### Example

JSON

```
"ultimate_parent_mic_exchange": "XNYS"
```

## Affiliated Entities

### `affiliated_entities`

|  |  |
| --- | --- |
| Description | An object containing information on related company profiles. |
| Data Type | `Object` |

#### Field Details

| Field | Data Type | Description |
| --- | --- | --- |
| `affiliated_id` | `String` | PDL Company ID of the affiliated company record. |
| `display_name` | `String` | display\_name of the affiliated company record. |
| `relationship` | `Enum (String)` | Categorization of the relationship type to the affiliated company record. The value of this field will be one of our canonical [Relationship Types](/docs/relationship_types) |
| `relationship_catalyst` | `Enum (String)` | Categorization of the event that formed the relationship to the affiliated company record. The value of this field will be one of our canonical [Relationship Catalysts](/docs/relationship_catalysts) |
| `relationship_status` | `Enum (String)` | Whether the relationship is active, pending, or inactive. The value of this field will be one of our canonical [Relationship Statuses](/docs/relationship_status). |
| `start_date` | `String (Date)` | Date when the affiliated company became related. For mergers or acquisitions, this will be the date that the transaction is closed (when that information is available); otherwise, this will be the date announced. |
| `end_date` | `String (Date)` | When applicable, the date when the the affiliated company was divested or otherwise no longer affiliated. |
| `relationship_citations` | `Array [String]` | List of URL links to news articles, press releases, or company webpages that describe the business relationship. |

#### Example

JSON

```
"affiliated_entities": [
    {
      "affiliated_id": "es7LgyqRNsFDLcWXC3WAvACHVh9g",
      "display_name": "Salesforce",
      "relationship": "ultimate_parent"
    }
  ]
```

  

## Office Insights

### `locations`

|  |  |
| --- | --- |
| Description | An object containing increasingly granular information about all locations associated to the company. |
| Data Type | `Object` |

#### Field Details

In addition to a company's location of its Headquarters (HQ) we provide a list of known offices. As of v31.1 (August 2025 Release) we are also tagging offices as active or inactive and the date it was first and last observed in our data sources:

| Field | Data Type | Description |
| --- | --- | --- |
| `first_seen` | `String` | The date that this location was first observed in association with the company record. |
| `last_seen` | `String` | The date that this location was last observed in association with the company record. |
| `is_active` | `Boolean` | Denotes whether this location was active (â€œtrueâ€) or inactive (â€œfalseâ€) as of the last observation. |

For more information on our standard location fields, see [Data Formatting: Locations](/docs/data-formatting#locations).

#### Example

JSON

```
"locations": [
  {
    "name": "palo alto, california, united states",
    "locality": "palo alto",
    "region": "california",
    "metro": "san jose, california",
    "country": "united states",
    "continent": "north america",
    "street_address": "1455 3rd street",
    "address_line_2": null,
    "postal_code": "94304",
    "geo": "37.44,-122.14",
    "first_seen": "2022-06-11",
    "last_seen": "2024-03-12",
    "is_primary": false,
    "is_active": true
  },
  {
    "name": "san francisco, california, united states",
    "locality": "san francisco",
    "region": "california",
    "metro": "san francisco, california",
    "country": "united states",
    "continent": "north america",
    "street_address": "1455 3rd street",
    "address_line_2": null,
    "postal_code": "94108",
    "geo": "37.77,-122.41",
    "first_seen": "2022-06-11",
    "last_seen": "2024-03-12",
    "is_primary": false,
    "is_active": true
  },
  {
    "name": "san francisco, california, united states",
    "locality": "san francisco",
    "region": "california",
    "metro": "san francisco, california",
    "country": "united states",
    "continent": "north america",
    "street_address": "1725 3rd street",
    "address_line_2": null,
    "postal_code": "94158",
    "geo": "37.77,-122.41",
    "first_seen": "2022-06-11",
    "last_seen": "2024-03-12",
    "is_primary": true,
    "is_active": true
  },
```

  

### `num_active_locations`

|  |  |
| --- | --- |
| Description | Count of all active locations associated to the company record. |
| Data Type | `Integer > 0` |

#### Example

JSON

```
"num_active_locations": 20
```

  

### `num_total_locations`

|  |  |
| --- | --- |
| Description | Count of all locations associated with the company record. |
| Data Type | `Integer > 0` |

#### Example

JSON

```
"num_total_locations": 30
```

## Job Posting Insights

These fields provide an aggregate summary of the open and filled job postings at a company.

### `active_job_postings`

|  |  |
| --- | --- |
| Description | Count of distinct, active job postings that existed over the course of the most recent month. |
| Data Type | `Integer` |

#### Example

JSON

```
"active_job_postings": 4
```

### `deactivated_job_postings`

|  |  |
| --- | --- |
| Description | Count of distinct job postings that were removed/no longer captured over the course of the most recent month. |
| Data Type | `Integer` |

#### Example

JSON

```
"deactivated_job_postings": 3
```

### `active_job_postings_by_role`

|  |  |
| --- | --- |
| Description | Count of distinct, active job postings that existed over the course of the most recent month, categorized by Job Title Role. |
| Data Type | `Object` |

#### Example

JSON

```
"active_job_postings_by_role": {
    "support": 1,
    "product": 1,
    "engineering": 2
}
```

### `deactivated_job_postings_by_role`

|  |  |
| --- | --- |
| Description | Count of distinct, active job postings that were removed/no longer captured over the course of the most recent month, categorized by Job Title Role. |
| Data Type | `Object` |

#### Example

JSON

```
"deactivated_job_postings_by_role": {
    "other_uncategorized": 1,
    "product": 1,
    "engineering": 1
}
```

### `active_job_postings_by_class`

|  |  |
| --- | --- |
| Description | Count of distinct, active job postings that existed over the course of the most recent month, categorized by Job Title Class. |
| Data Type | `Object` |

#### Example

JSON

```
"active_job_postings_by_class": {
    "general_and_administrative": 1,
    "research_and_development": 2,
    "services": 1
}
```

### `deactivated_job_postings_by_class`

|  |  |
| --- | --- |
| Description | Count of distinct, active job postings that existed over the course of the most recent month, categorized by Job Title Class. |
| Data Type | `Object` |

#### Example

JSON

```
"deactivated_job_postings_by_class": {
    "other_uncategorized": 1,
    "general_and_administrative": 1,
    "research_and_development": 2
}
```

### `active_job_postings_by_sub_role`

|  |  |
| --- | --- |
| Description | Count of distinct, active job postings that existed over the course of the most recent month, categorized by Job Title Subrole. |
| Data Type | `Object` |

#### Example

JSON

```
"active_job_postings_by_sub_role": {
  "other_uncategorized": 1,
  "product_management" : 1,
  "data_engineering" : 2   
}
```

### `deactivated_job_postings_by_sub_role`

|  |  |
| --- | --- |
| Description | Count of distinct, active job postings that were removed/no longer captured over the course of the most recent month, categorized by Job Title Subrole. |
| Data Type | `Object` |

#### Example

JSON

```
"deactivated_job_postings_by_sub_role": {
  "other_uncategorized": 1,
  "product_management" : 1,
  "data_engineering" : 1   
}
```

### `active_job_postings_by_country`

|  |  |
| --- | --- |
| Description | Count of distinct, active job postings that existed over the course of the most recent month, categorized by the Country of the job posting. |
| Data Type | `Object` |

#### Example

JSON

```
"active_job_postings_by_country": {
    "other_uncategorized": 1,
    "remote_location": 8,
    "brazil": 36,
    "united states": 331,
    "canada": 84,
    "netherlands": 2
}
```

### `active_job_postings_by_metro`

|  |  |
| --- | --- |
| Description | Count of distinct, active job postings that existed over the course of the most recent month, categorized by the Metro of the job posting. |
| Data Type | `Object` |

#### Example

JSON

```
"active_job_postings_by_metro": {
    "other_uncategorized": 142,
    "remote_location": 8,
    "denver, colorado, united states": 1,
    "san francisco, california, united states": 127,
    "seattle, washington, united states": 35,
    "atlanta, georgia, united states": 1,        
    "new york, new york, united states": 100,
    "salt lake city, utah, united states": 54,
    "austin, texas, united states": 1,
    "san diego, california, united states": 1
}
```

### `active_job_postings_by_month`

|  |  |
| --- | --- |
| Description | Count of distinct, active job postings that existed over the course of each month. |
| Data Type | `Object` |

#### Example

JSON

```
"active_job_postings_by_month": {
    "2024-10": 2,
    "2024-11": 3,
    "2024-12": 4,
    "2025-01": 7,
    "2025-02": 4
}
```

### `deactivated_job_postings_by_month`

|  |  |
| --- | --- |
| Description | Count of distinct, active job postings that were removed/no longer captured over the course of each month. |
| Data Type | `Object` |

#### Example

JSON

```
"deactivated_job_postings_by_month": {
    "2024-12": 1,
    "2025-01": 0,
    "2025-02": 4
}
```

Updated 2 months ago

---

* [Company Stats](/docs/company-stats)
* [Example Company Record](/docs/example-company-record)
* [Company Enrichment API](/docs/company-enrichment-api)
* [Company Search API](/docs/company-search-api)

Did this page help you?

Yes

No

---
# https://docs.peopledatalabs.com/docs/data-updates

We update our data consistently to make iterative improvements, add new sources and fields, and ensure our fields stay up-to-date.

# Update Frequency

Depending on how our customers access our data, our update frequency changes. For more information or questions, please reach out to your Customer Success team.

## Data Updates

| Data Access Type | Monthly | Quarterly |
| --- | --- | --- |
| API | âœ… | âŒ |
| Data License Flat Files | âœ… | âœ… |

As of the [May 2024 Release (v26.1)](/changelog/may-2024-release-announcement-v26-1), we offer [Delta Files](/docs/delta-file-deliveries) as a streamlined delivery format.

> ðŸ’¡
>
> ### Need faster updates?
>
> Our goal is to push towards faster and faster updates and develop new mechanisms for updating flat files. Visit our [public roadmap](https://feedback.peopledatalabs.com) to provide us with feedback on new mechanisms for data updates for your ideal workflow.

## Product Releases

### Major Changes: **Quarterly**

Major breaking changes to our products such as new data fields, new canonicalized field values, new APIs, or significant changes to our existing APIs will be rolled out quarterly and documented in our [Release Notes](/docs/changelog).

### Minor Bug Fixes & Improvements: **Monthly**

Data updates (including new data sources), bug fixes, and improvements will be rolled out monthly. These updates will only be available through our APIs.

### Beta Fields & New Products: **Monthly**

New products and field bundles will be rolled out monthly on an invite-only basis. We wonâ€™t be rolling out major changes that impact the wider customer base in our monthly releases. As such, we will not be providing monthly release notes at this time. However, you can track iterative product releases in our [public roadmap](https://feedback.peopledatalabs.com/) by voting on cards to subscribe to updates.

# Data Goals

1. To ensure that we have current job title, company, and location information for as many profiles as possible.

* While we value the accuracy of all fields, we value the accuracy of these fields the most, as they provide the most flexible utilization across all use cases.
* The [`job_last_verified`](/docs/fields#job_last_verified) and [`location_last_updated`](/docs/fields#location_last_updated) fields indicate when our "current" job and location data last appeared in a data source.

2. To increase the total volume of data through our [Data Union](/docs/data-sources).

* By increasing the number of values we have in each field, we can improve match rates and the value of each profile to the end user.
* Our most highly-valued data partners provide linkages that cannot be found elsewhere. By taking advantage of these, we are often able to merge what would be multiple "sides" of our data together.
* Adding new data fields allows our customers to power new products and create new features. We typically aim to have relatively strong coverage of a new field before we add it to the production data. However, some fields are valued enough that we provide them as "restricted" fields to our license customers and don't expose them in the APIs.

3. To improve our [data build process](/docs/data-build).

* While we are relatively strict with our merging logic, finding new ways to increase the number of profiles that we merge without creating new errors allows us to increase the total volume of data without needing to acquire new sources of linkages.
* Improved standardization results in cleaner profiles with better field-level de-duplication. Improved standardization also allows us to successfully merge more profiles.

# Communicating Updates

The `data_version` field in API [responses](/docs/response) reflect the current version.

Our goal is to make persistence commitments regarding how each field will evolve between data releases. We aim to do this in order to help our customers build applications around our data that are sustainable. We will announce any possible breaking changes within 90 days in advance of any release.

Updated 4 months ago

---

Did this page help you?

Yes

No

---
# https://docs.peopledatalabs.com/docs/naics-sectors

| Canonical Values for NAICS Sectors |
| --- |
| accommodation and food services |
| administrative and support and waste management and remediation services |
| agriculture, forestry, fishing and hunting |
| arts, entertainment, and recreation |
| construction |
| educational services |
| finance and insurance |
| health care and social assistance |
| information |
| management of companies and enterprises |
| manufacturing |
| mining, quarrying, and oil and gas extraction |
| other services (except public administration) |
| professional, scientific, and technical services |
| public administration |
| real estate and rental and leasing |
| retail trade |
| transportation and warehousing |
| utilities |
| wholesale trade |

*Contents of this table were sourced from the following file on our public S3 bucket:[naics\_sector.txt](https://pdl-prod-schema.s3.us-west-2.amazonaws.com/28.0/enums/naics_sector.txt)*

  

## Relevant fields

* [`naics.sector`](/docs/company-schema#naics)

Updated 4 months ago

---

Did this page help you?

Yes

No

---
# https://docs.peopledatalabs.com/docs/employee-count-fields

Our [Company Schema](/docs/company-schema) contains many different fields to represent the number of employees associated with the company record. These fields are calculated using different methods, which can result in different counts for the same company.

As of [v25.0](/changelog/january-2024-release-notes-v25#insights-logic), we've made some improvements to keep counts consistent across the following fields:

* [`employee_count`](/docs/company-schema#employee_count)
* Sum of values for [`employee_count_by_country`](/docs/company-schema#employee_count_by_country)
* The last month in [`employee_count_by_month`](/docs/company-schema#employee_count_by_month)
* Sum of values in the last month in [`employee_count_by_month_by_role`](/docs/company-schema#employee_count_by_month_by_role)

There can still be some discrepancies, the most common are explained below.

**[`size`](/docs/company-schema#size)Field**  
This information comes from a **user-selected** dropdown value obtained from the companyâ€™s primary social media profile, such as LinkedIn or Facebook. Sometimes this range is far from the real count of employees, however the function of this field is to preserve the raw selected value as selected on those platforms.

  

**Multiple Job Levels**  
The [`employee_count_by_month_by_level`](/docs/company-schema#employee_count_by_month_by_level) field presents a summary of the [`job_title_levels`](/docs/fields#job_title_levels), which is itself a â€œone-to-manyâ€ field highlighting the seniority levels for a personâ€™s job title. If a person role has multiple levels (ex: the job title â€œfounder and ceoâ€ would have tags for both "cxo" and "owner"), that person is counted multiple times (once for each level).

  

**Comparisons to LinkedIn Employee Counts**  
Because we generate our counts bottom-up as aggregations of the underlying person record data associated with company record, you can expect a slight discrepancy between PDLâ€™s employee counts and those represented on LinkedIn company pages.

Specifically, weâ€™ve incorporated additional profile cleaning and data validation steps that we believe make our counts more accurate representations of the true workforces of represented companies. For example, favorable discrepancies can emerge from a reduced rate of person profile and work experience duplication, stricter fuzzy matching on work experience to corresponding canonical companies, and separate accounting for subsidiary company records for corporate conglomerates.

Updated 13 days ago

---

Did this page help you?

Yes

No

---
# https://docs.peopledatalabs.com/docs/skill-schema

> â—ï¸
>
> ### The Skill Enrichment API is now fully removed
>
> This endpoint was removed in our April 2025 (v30.0) Release and is no longer available. This page is retained for historical documentation purposes.
>
> For more information, please see our [April 2025 Release Notes (v30.0)](/changelog/april-2025-release-notes-v300).

## Response Data Structure

Here is the structure of an example response from the Skill Enrichment API:

JSON

```
{
  "cleaned_skill": "ai",
  "similar_skills": [
    "machine learning",
    "artificial intelligence",
    "deep learning",
    "data science",
    "iot"
  ],
  "relevant_job_titles": [
    "data scientist",
    "software engineer",
    "senior data scientist",
    "chief technology officer",
    "senior software engineer"
  ]
}
```

## Response Fields

### `cleaned_skill`

| Type | Description |
| --- | --- |
| `String` | The skill that matches the API input `skill` after passing it through our internal skill cleaner. |

  

### `similar_skills`

| Type | Description |
| --- | --- |
| `Array [String]` | A list of to five of the most contextually-similar skills to the `cleaned_skill`, determined using our global resume data. |

  

### `relevant_job_titles`

| Type | Description |
| --- | --- |
| `Array [String]` | A list of up to five of the most contextually-similar job titles to the `cleaned_skill`, determined using our global resume data. |

Updated 4 months ago

---

Did this page help you?

Yes

No

---
# https://docs.peopledatalabs.com/docs/relationship_types

| Canonical Values for Affiliated Entity Relationship Statuses |
| --- |
| direct\_subsidiary |
| immediate\_parent |
| indirect\_subsidiary |
| ultimate\_parent |

  

## Relevant fields

* [`affiliated_entities`](/docs/company-schema#affiliated_entities)

Updated 2 months ago

---

Did this page help you?

Yes

No

---
# https://docs.peopledatalabs.com/docs/relationship_catalysts

| Canonical Values for Affiliated Entity Relationship Catalysts |
| --- |
| direct\_acquisition |
| indirect\_acquisition |
| other |
| unknown |

  

## Relevant fields

* [`affiliated_entities`](/docs/company-schema#affiliated_entities)

Updated 2 months ago

---

Did this page help you?

Yes

No

---
# https://docs.peopledatalabs.com/docs/skill-enrichment-api

> â—ï¸
>
> ### The Skill Enrichment API is now fully removed
>
> This endpoint was removed in our April 2025 (v30.0) Release and is no longer available. This page is retained for historical documentation purposes.
>
> For more information, please see our [April 2025 Release Notes (v30.0)](/changelog/april-2025-release-notes-v300).

## Overview

The Skill Enrichment API lets you enrich data on a skill by performing a one-to-one match of this skill with those included in our [Skill](/docs/skill-schema) Dataset. Once matched, you can search for profiles with less context. For example, instead of explicitly searching for "engineers who know spark, mapreduce or hadoop" you can search for "engineers who know spark or have similar skills."

**Note**: Our current Skill Dataset only contains skills seen at least 250 times across our global resume data.

## Expected Usage

This API functions primarily as a support for our [Person Search API](/docs/person-search-api). Once you enhance a skill, you can use the returned information in your Person Search query to find better matches in our Person Dataset.

We expect the flow for using the Skill Enrichment and Person Search APIs to broadly follow one of the two patterns shown in the diagrams below:

Flow 1: Using the Skill Enrichment API to search for people with similar skills.



Flow 2: Using the Skill Enrichment API to search for people with job titles relevant to the skill.

  
  

## What's Next

Please check out the following pages for more information on the Skill Enrichment API:

| Page | Description |
| --- | --- |
| [Quickstart](/docs/quickstart-skill-enrichment-api) | A quick hands-on introduction to the API with simple code examples. |
| [Reference](/docs/reference-skill-enrichment-api) | Detailed descriptions of the technical specifications and usage constraints. |
| [Input Parameters](/docs/input-parameters-skill-enrichment-api) | In-depth explanations of the input parameters thaat the API supports. |
| [Output Response](/docs/output-response-skill-enrichment-api) | In-depth explanations of the output response object that the API returns. |
| [Examples](/docs/examples-skill-enrichment-api) | A collection of functional code examples and walkthroughs that illustrate various use cases and applications of the API. |

Updated 4 months ago

---

Did this page help you?

Yes

No

---
# https://docs.peopledatalabs.com/docs/faqs-person-enrichment-api

> â“
>
> ### Have a Question You Want Answered? Ask Us!
>
> Head over to the [Help Center](https://support.peopledatalabs.com) and search for your question. If you still can't find what you're looking for, create a support ticket and we will get it answered for you!

---

## What is the difference between the various Person APIs?

See [this section](/docs/person-endpoints#the-differences-between-our-person-related-apis) for a detailed breakdown of the differences between our Person APIs.

## If I submit a blank parameter in the request will the results be affected? e.g. profile=linkedin.com/in/seanthorne&name=Sean Thorne&company=

Submitting a blank value for a parameter will not affect the quality of the results. Any parameter with an empty value will not be considered when providing you with a match.

## Will I be charged for retrieving the same profile multiple times?

Yes. PDL will charge for the retrieval of the same profile.

**Example**  
You enrich for a profile with the LinkedIn URL: linkedin.com/in/linfluencer. A day later you enrich a profile with the same LinkedIn URL. You will be charged two credits, one for each successful response.

To handle for situations demonstrated in the above example , PDL recommends duplicate call detection. You can use methods like unique key constraints. For example, you can hash the request, storing the hash, and check for a duplicate call before sending it to the API.

Updated 4 months ago

---

Did this page help you?

Yes

No

---
# https://docs.peopledatalabs.com/docs/naics-industry-groups

| Canonical Values for NAICS Industry Groups |
| --- |
| accounting, tax preparation, bookkeeping, and payroll services |
| activities related to credit intermediation |
| activities related to real estate |
| administration of economic programs |
| administration of environmental quality programs |
| administration of housing programs, urban planning, and community development |
| administration of human resource programs |
| advertising, public relations, and related services |
| aerospace product and parts manufacturing |
| agencies, brokerages, and other insurance related activities |
| agents and managers for artists, athletes, entertainers, and other public figures |
| agriculture, construction, and mining machinery manufacturing |
| alumina and aluminum production and processing |
| amusement parks and arcades |
| animal food manufacturing |
| animal slaughtering and processing |
| apparel accessories and other apparel manufacturing |
| apparel knitting mills |
| apparel, piece goods, and notions merchant wholesalers |
| aquaculture |
| architectural and structural metals manufacturing |
| architectural, engineering, and related services |
| audio and video equipment manufacturing |
| automobile dealers |
| automotive equipment rental and leasing |
| automotive parts, accessories, and tire stores |
| automotive repair and maintenance |
| bakeries and tortilla manufacturing |
| basic chemical manufacturing |
| beer, wine, and distilled alcoholic beverage merchant wholesalers |
| beer, wine, and liquor stores |
| beverage manufacturing |
| boiler, tank, and shipping container manufacturing |
| book stores and news dealers |
| building equipment contractors |
| building finishing contractors |
| building material and supplies dealers |
| business schools and computer and management training |
| business support services |
| business, professional, labor, political, and similar organizations |
| cable and other subscription programming |
| cattle ranching and farming |
| cement and concrete product manufacturing |
| charter bus industry |
| chemical and allied products merchant wholesalers |
| child day care services |
| civic and social organizations |
| clay product and refractory manufacturing |
| clothing stores |
| coal mining |
| coating, engraving, heat treating, and allied activities |
| colleges, universities, and professional schools |
| commercial and industrial machinery and equipment (except automotive and electronic) repair and maintenance |
| commercial and industrial machinery and equipment rental and leasing |
| commercial and service industry machinery manufacturing |
| communications equipment manufacturing |
| community food and housing, and emergency and other relief services |
| computer and peripheral equipment manufacturing |
| computer systems design and related services |
| consumer goods rental |
| continuing care retirement communities and assisted living facilities for the elderly |
| converted paper product manufacturing |
| couriers and express delivery services |
| cut and sew apparel manufacturing |
| cutlery and handtool manufacturing |
| dairy product manufacturing |
| data processing, hosting, and related services |
| death care services |
| deep sea, coastal, and great lakes water transportation |
| department stores |
| depository credit intermediation |
| direct selling establishments |
| drinking places (alcoholic beverages) |
| drugs and druggists' sundries merchant wholesalers |
| drycleaning and laundry services |
| educational support services |
| electric lighting equipment manufacturing |
| electric power generation, transmission and distribution |
| electrical equipment manufacturing |
| electronic and precision equipment repair and maintenance |
| electronic shopping and mail-order houses |
| electronics and appliance stores |
| elementary and secondary schools |
| employment services |
| engine, turbine, and power transmission equipment manufacturing |
| executive, legislative, and other general government support |
| fabric mills |
| facilities support services |
| farm product raw material merchant wholesalers |
| fiber, yarn, and thread mills |
| fishing |
| florists |
| footwear manufacturing |
| forest nurseries and gathering of forest products |
| forging and stamping |
| foundation, structure, and building exterior contractors |
| foundries |
| freight transportation arrangement |
| fruit and tree nut farming |
| fruit and vegetable preserving and specialty food manufacturing |
| furniture and home furnishing merchant wholesalers |
| furniture stores |
| gambling industries |
| gasoline stations |
| general freight trucking |
| general medical and surgical hospitals |
| general merchandise stores, including warehouse clubs and supercenters |
| general rental centers |
| glass and glass product manufacturing |
| grain and oilseed milling |
| grantmaking and giving services |
| greenhouse, nursery, and floriculture production |
| grocery and related product merchant wholesalers |
| grocery stores |
| hardware manufacturing |
| hardware, and plumbing and heating equipment and supplies merchant wholesalers |
| health and personal care stores |
| highway, street, and bridge construction |
| hog and pig farming |
| home furnishings stores |
| home health care services |
| household and institutional furniture and kitchen cabinet manufacturing |
| household appliance manufacturing |
| household appliances and electrical and electronic goods merchant wholesalers |
| hunting and trapping |
| independent artists, writers, and performers |
| individual and family services |
| industrial machinery manufacturing |
| inland water transportation |
| insurance and employee benefit funds |
| insurance carriers |
| interurban and rural bus transportation |
| investigation and security services |
| iron and steel mills and ferroalloy manufacturing |
| jewelry, luggage, and leather goods stores |
| junior colleges |
| justice, public order, and safety activities |
| land subdivision |
| lawn and garden equipment and supplies stores |
| leather and hide tanning and finishing |
| legal services |
| lessors of nonfinancial intangible assets (except copyrighted works) |
| lessors of real estate |
| lime and gypsum product manufacturing |
| local messengers and local delivery |
| logging |
| lumber and other construction materials merchant wholesalers |
| machine shops; turned product; and screw, nut, and bolt manufacturing |
| machinery, equipment, and supplies merchant wholesalers |
| management of companies and enterprises |
| management, scientific, and technical consulting services |
| manufacturing and reproducing magnetic and optical media |
| medical and diagnostic laboratories |
| medical equipment and supplies manufacturing |
| metal and mineral (except petroleum) merchant wholesalers |
| metal ore mining |
| metalworking machinery manufacturing |
| miscellaneous durable goods merchant wholesalers |
| miscellaneous nondurable goods merchant wholesalers |
| monetary authorities-central bank |
| motion picture and video industries |
| motor vehicle and motor vehicle parts and supplies merchant wholesalers |
| motor vehicle body and trailer manufacturing |
| motor vehicle manufacturing |
| motor vehicle parts manufacturing |
| museums, historical sites, and similar institutions |
| national security and international affairs |
| natural gas distribution |
| navigational, measuring, electromedical, and control instruments manufacturing |
| newspaper, periodical, book, and directory publishers |
| nondepository credit intermediation |
| nonferrous metal (except aluminum) production and processing |
| nonmetallic mineral mining and quarrying |
| nonresidential building construction |
| nonscheduled air transportation |
| nursing care facilities (skilled nursing facilities) |
| office administrative services |
| office furniture (including fixtures) manufacturing |
| office supplies, stationery, and gift stores |
| offices of dentists |
| offices of other health practitioners |
| offices of physicians |
| offices of real estate agents and brokers |
| oil and gas extraction |
| oilseed and grain farming |
| other ambulatory health care services |
| other amusement and recreation industries |
| other animal production |
| other chemical product and preparation manufacturing |
| other crop farming |
| other electrical equipment and component manufacturing |
| other fabricated metal product manufacturing |
| other financial investment activities |
| other food manufacturing |
| other furniture related product manufacturing |
| other general purpose machinery manufacturing |
| other heavy and civil engineering construction |
| other information services |
| other investment pools and funds |
| other leather and allied product manufacturing |
| other miscellaneous manufacturing |
| other miscellaneous store retailers |
| other motor vehicle dealers |
| other nonmetallic mineral product manufacturing |
| other personal services |
| other pipeline transportation |
| other professional, scientific, and technical services |
| other residential care facilities |
| other schools and instruction |
| other specialty trade contractors |
| other support activities for transportation |
| other support services |
| other telecommunications |
| other textile product mills |
| other transit and ground passenger transportation |
| other transportation equipment manufacturing |
| other wood product manufacturing |
| outpatient care centers |
| paint, coating, and adhesive manufacturing |
| paper and paper product merchant wholesalers |
| performing arts companies |
| personal and household goods repair and maintenance |
| personal care services |
| pesticide, fertilizer, and other agricultural chemical manufacturing |
| petroleum and coal products manufacturing |
| petroleum and petroleum products merchant wholesalers |
| pharmaceutical and medicine manufacturing |
| pipeline transportation of crude oil |
| pipeline transportation of natural gas |
| plastics product manufacturing |
| postal service |
| poultry and egg production |
| printing and related support activities |
| private households |
| professional and commercial equipment and supplies merchant wholesalers |
| promoters of performing arts, sports, and similar events |
| psychiatric and substance abuse hospitals |
| pulp, paper, and paperboard mills |
| radio and television broadcasting |
| rail transportation |
| railroad rolling stock manufacturing |
| religious organizations |
| remediation and other waste management services |
| residential building construction |
| residential intellectual and developmental disability, mental health, and substance abuse facilities |
| resin, synthetic rubber, and artificial and synthetic fibers and filaments manufacturing |
| restaurants and other eating places |
| rooming and boarding houses, dormitories, and workers' camps |
| rubber product manufacturing |
| rv (recreational vehicle) parks and recreational camps |
| satellite telecommunications |
| sawmills and wood preservation |
| scenic and sightseeing transportation, land |
| scenic and sightseeing transportation, other |
| scenic and sightseeing transportation, water |
| scheduled air transportation |
| school and employee bus transportation |
| scientific research and development services |
| seafood product preparation and packaging |
| securities and commodity contracts intermediation and brokerage |
| securities and commodity exchanges |
| semiconductor and other electronic component manufacturing |
| services to buildings and dwellings |
| sheep and goat farming |
| ship and boat building |
| shoe stores |
| soap, cleaning compound, and toilet preparation manufacturing |
| social advocacy organizations |
| software publishers |
| sound recording industries |
| space research and technology |
| special food services |
| specialized design services |
| specialized freight trucking |
| specialty (except psychiatric and substance abuse) hospitals |
| specialty food stores |
| spectator sports |
| sporting goods, hobby, and musical instrument stores |
| spring and wire product manufacturing |
| steel product manufacturing from purchased steel |
| sugar and confectionery product manufacturing |
| support activities for air transportation |
| support activities for animal production |
| support activities for crop production |
| support activities for forestry |
| support activities for mining |
| support activities for rail transportation |
| support activities for road transportation |
| support activities for water transportation |
| taxi and limousine service |
| technical and trade schools |
| textile and fabric finishing and fabric coating mills |
| textile furnishings mills |
| timber tract operations |
| tobacco manufacturing |
| travel arrangement and reservation services |
| traveler accommodation |
| urban transit systems |
| used merchandise stores |
| utility system construction |
| vegetable and melon farming |
| vending machine operators |
| veneer, plywood, and engineered wood product manufacturing |
| ventilation, heating, air-conditioning, and commercial refrigeration equipment manufacturing |
| vocational rehabilitation services |
| warehousing and storage |
| waste collection |
| waste treatment and disposal |
| water, sewage and other systems |
| wholesale electronic markets and agents and brokers |
| wired and wireless telecommunications carriers |

*Contents of this table were sourced from the following file on our public S3 bucket:[naics\_industry\_group.txt](https://pdl-prod-schema.s3.us-west-2.amazonaws.com/28.0/enums/naics_industry_group.txt)*

## Relevant fields

* [`naics.industry_group`](/docs/company-schema#naics)

Updated 4 months ago

---

Did this page help you?

Yes

No

---
# https://docs.peopledatalabs.com/docs/sandbox-apis-reference

## Endpoints

URLs for our Sandbox APIs follow this structure: `https://sandbox.api.peopledatalabs.com/<path>`, where `<path>` is one of the following:

| API | Sandbox Endpoint Path |
| --- | --- |
| [Person Enrichment](/docs/reference-person-enrichment-api#endpoint) | `v5/person/enrich` |
| [Person Search](/docs/reference-person-search-api#endpoint) | `v5/person/search` |
| [Person Identify](/docs/identify-api-reference#endpoint) | `v5/person/identify` |
| [Bulk Person Enrichment API](/docs/bulk-enrichment-api) | `v5/person/bulk` |
| [Company Enrichment](/docs/reference-company-enrichment-api) | `v5/company/enrich` |
| [Company Search](/docs/reference-company-search-api) | `v5/company/search` |

For example, the endpoint for the Sandbox Person Enrichment API is `https://sandbox.api.peopledatalabs.com/v5/person/enrich`.

## SDK Usage

To access the Sandbox API endpoints within our SDKs, use any of the following language-specific strategies:

Python3 SDKJavaScriptRubyGo

```
# Set sandbox to True when creating a client
CLIENT = PDLPY(
    api_key="YOUR API KEY",
    # Use Sandbox API
    sandbox=True,
)
```

```
// Set sandbox to true in the parameters JSON object
const params = {
  email: "irussell@example.org",
  min_likelihood: 6,
  // Use Sandbox API
  sandbox: true
}
```

```
# Use Sandbox API
Peopledatalabs.sandbox = true
```

```
// Include extra imports
import (
    pdl "github.com/peopledatalabs/peopledatalabs-go"
    "github.com/peopledatalabs/peopledatalabs-go/api"
    pdlmodel "github.com/peopledatalabs/peopledatalabs-go/model"
)

// Set Sandbox to true in ClientOptions() when creating a client
client := pdl.New(apiKey,
                      api.ClientOptions(func(c *api.Client) {
                                    c.Sandbox = true
                      }))
```

See [Sandbox examples](/docs/sandbox-apis-examples) for specific usage.

## Billing and Access

The Sandbox APIs are free endpoints and do not consume credits. All plans have access.

## Rate Limiting

The default rate limit for all customers is five calls per minute.

## Input Parameters

The input parameters for each Sandbox API endpoint are identical to the input parameters for the corresponding production endpoint. Here are the input parameters that each Sandbox endpoint supports:

| Sandbox API Endpoint | Input Parameters | Detailed Reference |
| --- | --- | --- |
| Person Enrichment | [Input Parameters](/docs/reference-person-enrichment-api#input-parameters) | [Detailed Reference](/docs/input-parameters-person-enrichment-api) |
| Person Search | [Input Parameters](/docs/reference-person-search-api#input-parameters) | [Detailed Reference](/docs/input-parameters-person-search-api) |
| Person Identify | [Input Parameters](/docs/identify-api-reference#input-parameters) | [Detailed Reference](/docs/identify-api-input-parameters) |
| Bulk Person Enrichment | [Input Parameters](/docs/bulk-enrichment-api#request-format) | [Detailed Reference](/docs/input-parameters-person-enrichment-api) |
| Company Enrichment | [Input Parameters](/docs/input-parameters-company-enrichment-api) | [Detailed Reference](/docs/reference-company-enrichment-api#input-parameters) |
| Company Search | [Input Parameters](/docs/input-parameters-company-search-api) | [Detailed Reference](/docs/reference-company-search-api#input-parameters) |

## Output Response

All Sandbox API endpoints return data that follows the same response structure as the corresponding production endpoint. Here are the output responses that each Sandbox endpoint supports:

> ðŸš§
>
> ### Synthetic data only!
>
> All Sandbox API endpoints return only artificial data in their responses. For more information, see the Full Sandbox Datasets listed below.

| Sandbox API Endpoint | Output Response | Detailed Reference |
| --- | --- | --- |
| Person Enrichment | [Output Response](/docs/reference-person-enrichment-api#response) | [Detailed Reference](/docs/output-response-person-enrichment-api) |
| Person Search | [Output Response](/docs/reference-person-search-api#response) | [Detailed Reference](/docs/output-response-person-search-api) |
| Person Identify | [Output Response](/docs/identify-api-reference#output-response) | [Detailed Reference](/docs/identify-api-output-response) |
| Bulk Person Enrichment | [Output Response](/docs/bulk-enrichment-api#response-format) | [Detailed Reference](/docs/output-response-person-enrichment-api) |
| Company Enrichment | [Output Response](/docs/output-response-company-enrichment-api) | [Detailed Reference](/docs/reference-company-enrichment-api#output-response) |
| Company Search | [Output Response](/docs/output-response-company-search-api) | [Detailed Reference](/docs/reference-company-search-api#output-response) |

  

| Full Sandbox Datasets |
| --- |
| [Person Sandbox Dataset](https://s3.console.aws.amazon.com/s3/buckets/pdl-prod-schema?prefix=33.1/sandbox/person/&region=us-west-2&bucketType=general) |
| [Company Sandbox Dataset](https://s3.console.aws.amazon.com/s3/buckets/pdl-prod-schema?prefix=33.1/sandbox/company/&region=us-west-2&bucketType=general) |

*Updated as of 33.1*

Updated 6 days ago

---

Did this page help you?

Yes

No

---
# https://docs.peopledatalabs.com/docs/industries-v2

| Canonical Values for Industries (V2) |
| --- |
| abrasives and nonmetallic minerals manufacturing |
| accessible architecture and design |
| accessible hardware manufacturing |
| accommodation services |
| accounting |
| administration of justice |
| administrative and support services |
| advertising services |
| agricultural chemical manufacturing |
| agriculture, construction, mining machinery manufacturing |
| air, water, and waste program management |
| airlines and aviation |
| alternative dispute resolution |
| alternative fuel vehicle manufacturing |
| alternative medicine |
| ambulance services |
| amusement parks and arcades |
| animal feed manufacturing |
| animation and post-production |
| apparel manufacturing |
| appliances, electrical, and electronics manufacturing |
| architectural and structural metal manufacturing |
| architecture and planning |
| armed forces |
| artificial rubber and synthetic fiber manufacturing |
| artists and writers |
| audio and video equipment manufacturing |
| automation machinery manufacturing |
| aviation and aerospace component manufacturing |
| baked goods manufacturing |
| banking |
| bars, taverns, and nightclubs |
| bed-and-breakfasts, hostels, homestays |
| beverage manufacturing |
| biomass electric power generation |
| biotechnology research |
| blockchain services |
| blogs |
| boilers, tanks, and shipping container manufacturing |
| book and periodical publishing |
| book publishing |
| breweries |
| broadcast media production and distribution |
| building construction |
| building equipment contractors |
| building finishing contractors |
| building structure and exterior contractors |
| business consulting and services |
| business content |
| business intelligence platforms |
| cable and satellite programming |
| capital markets |
| caterers |
| chemical manufacturing |
| chemical raw materials manufacturing |
| child day care services |
| chiropractors |
| circuses and magic shows |
| civic and social organizations |
| civil engineering |
| claims adjusting, actuarial services |
| clay and refractory products manufacturing |
| climate data and analytics |
| climate technology product manufacturing |
| coal mining |
| collection agencies |
| commercial and industrial equipment rental |
| commercial and industrial machinery maintenance |
| commercial and service industry machinery manufacturing |
| communications equipment manufacturing |
| community development and urban planning |
| community services |
| computer and network security |
| computer games |
| computer hardware manufacturing |
| computer networking products |
| computers and electronics manufacturing |
| conservation programs |
| construction |
| construction hardware manufacturing |
| consumer goods rental |
| consumer services |
| correctional institutions |
| cosmetology and barber schools |
| courts of law |
| credit intermediation |
| cutlery and handtool manufacturing |
| dairy product manufacturing |
| dance companies |
| data infrastructure and analytics |
| data security software products |
| defense and space manufacturing |
| dentists |
| design services |
| desktop computing software products |
| digital accessibility services |
| distilleries |
| e-learning providers |
| economic programs |
| education |
| education administration programs |
| electric lighting equipment manufacturing |
| electric power generation |
| electric power transmission, control, and distribution |
| electrical equipment manufacturing |
| electronic and precision equipment maintenance |
| embedded software products |
| emergency and relief services |
| engineering services |
| engines and power transmission equipment manufacturing |
| entertainment providers |
| environmental quality programs |
| environmental services |
| equipment rental services |
| events services |
| executive offices |
| executive search services |
| fabricated metal products |
| facilities services |
| family planning centers |
| farming |
| farming, ranching, forestry |
| fashion accessories manufacturing |
| financial services |
| fine arts schools |
| fire protection |
| fisheries |
| flight training |
| food and beverage manufacturing |
| food and beverage retail |
| food and beverage services |
| footwear and leather goods repair |
| footwear manufacturing |
| forestry and logging |
| fossil fuel electric power generation |
| freight and package transportation |
| fruit and vegetable preserves manufacturing |
| fuel cell manufacturing |
| fundraising |
| funds and trusts |
| furniture and home furnishings manufacturing |
| gambling facilities and casinos |
| geothermal electric power generation |
| glass product manufacturing |
| glass, ceramics and concrete manufacturing |
| golf courses and country clubs |
| government administration |
| government relations services |
| graphic design |
| ground passenger transportation |
| health and human services |
| higher education |
| highway, street, and bridge construction |
| historical sites |
| holding companies |
| home health care services |
| horticulture |
| hospitality |
| hospitals |
| hospitals and health care |
| hotels and motels |
| household and institutional furniture manufacturing |
| household appliance manufacturing |
| household services |
| housing and community development |
| housing programs |
| human resources services |
| hvac and refrigeration equipment manufacturing |
| hydroelectric power generation |
| individual and family services |
| industrial machinery manufacturing |
| industry associations |
| information services |
| insurance |
| insurance agencies and brokerages |
| insurance and employee benefit funds |
| insurance carriers |
| interior design |
| international affairs |
| international trade and development |
| internet marketplace platforms |
| internet news |
| internet publishing |
| interurban and rural bus services |
| investment advice |
| investment banking |
| investment management |
| it services and it consulting |
| it system custom software development |
| it system data services |
| it system design services |
| it system installation and disposal |
| it system operations and maintenance |
| it system testing and evaluation |
| it system training and support |
| janitorial services |
| landscaping services |
| language schools |
| laundry and drycleaning services |
| law enforcement |
| law practice |
| leasing non-residential real estate |
| leasing residential real estate |
| leather product manufacturing |
| legal services |
| legislative offices |
| libraries |
| lime and gypsum products manufacturing |
| loan brokers |
| machinery manufacturing |
| magnetic and optical media manufacturing |
| manufacturing |
| maritime transportation |
| market research |
| marketing services |
| mattress and blinds manufacturing |
| measuring and control instrument manufacturing |
| meat products manufacturing |
| media and telecommunications |
| media production |
| medical and diagnostic laboratories |
| medical equipment manufacturing |
| medical practices |
| mental health care |
| metal ore mining |
| metal treatments |
| metal valve, ball, and roller manufacturing |
| metalworking machinery manufacturing |
| military and international affairs |
| mining |
| mobile computing software products |
| mobile food services |
| mobile gaming apps |
| motor vehicle manufacturing |
| motor vehicle parts manufacturing |
| movies and sound recording |
| movies, videos and sound |
| museums |
| museums, historical sites, and zoos |
| musicians |
| nanotechnology research |
| natural gas distribution |
| natural gas extraction |
| newspaper publishing |
| non-profit organizations |
| nonmetallic mineral mining |
| nonresidential building construction |
| nuclear electric power generation |
| nursing homes and residential care facilities |
| office administration |
| office furniture and fixtures manufacturing |
| oil and coal product manufacturing |
| oil and gas |
| oil extraction |
| oil, gas, and mining |
| online and mail order retail |
| online audio and video media |
| operations consulting |
| optometrists |
| outpatient care centers |
| outsourcing and offshoring consulting |
| packaging and containers manufacturing |
| paint, coating, and adhesive manufacturing |
| paper and forest product manufacturing |
| pension funds |
| performing arts |
| performing arts and spectator sports |
| periodical publishing |
| personal and laundry services |
| personal care product manufacturing |
| personal care services |
| pet services |
| pharmaceutical manufacturing |
| philanthropic fundraising services |
| photography |
| physical, occupational and speech therapists |
| physicians |
| pipeline transportation |
| plastics and rubber product manufacturing |
| plastics manufacturing |
| political organizations |
| postal services |
| primary and secondary education |
| primary metal manufacturing |
| printing services |
| professional organizations |
| professional services |
| professional training and coaching |
| public assistance programs |
| public health |
| public policy offices |
| public relations and communications services |
| public safety |
| racetracks |
| radio and television broadcasting |
| rail transportation |
| railroad equipment manufacturing |
| ranching |
| ranching and fisheries |
| real estate |
| real estate agents and brokers |
| real estate and equipment rental services |
| recreational facilities |
| regenerative design |
| religious institutions |
| renewable energy equipment manufacturing |
| renewable energy power generation |
| renewable energy semiconductor manufacturing |
| repair and maintenance |
| research services |
| residential building construction |
| restaurants |
| retail |
| retail apparel and fashion |
| retail appliances, electrical, and electronic equipment |
| retail art dealers |
| retail art supplies |
| retail books and printed news |
| retail building materials and garden equipment |
| retail florists |
| retail furniture and home furnishings |
| retail gasoline |
| retail groceries |
| retail health and personal care products |
| retail luxury goods and jewelry |
| retail motor vehicles |
| retail musical instruments |
| retail office equipment |
| retail office supplies and gifts |
| retail pharmacies |
| retail recyclable materials and used merchandise |
| reupholstery and furniture repair |
| robot manufacturing |
| robotics engineering |
| rubber products manufacturing |
| satellite telecommunications |
| savings institutions |
| school and employee bus services |
| seafood product manufacturing |
| secretarial schools |
| securities and commodity exchanges |
| security and investigations |
| security guards and patrol services |
| security systems services |
| semiconductor manufacturing |
| services for renewable energy |
| services for the elderly and disabled |
| sheet music publishing |
| shipbuilding |
| shuttles and special needs transportation services |
| sightseeing transportation |
| skiing facilities |
| smart meter manufacturing |
| soap and cleaning product manufacturing |
| social networking platforms |
| software development |
| solar electric power generation |
| sound recording |
| space research and technology |
| specialty trade contractors |
| spectator sports |
| sporting goods manufacturing |
| sports and recreation instruction |
| sports teams and clubs |
| spring and wire product manufacturing |
| staffing and recruiting |
| steam and air-conditioning supply |
| strategic management services |
| subdivision of land |
| sugar and confectionery product manufacturing |
| surveying and mapping services |
| taxi and limousine services |
| technical and vocational training |
| technology, information and internet |
| technology, information and media |
| telecommunications |
| telecommunications carriers |
| telephone call centers |
| temporary help services |
| textile manufacturing |
| theater companies |
| think tanks |
| tobacco manufacturing |
| translation and localization |
| transportation equipment manufacturing |
| transportation programs |
| transportation, logistics, supply chain and storage |
| travel arrangements |
| truck transportation |
| trusts and estates |
| turned products and fastener manufacturing |
| urban transit services |
| utilities |
| utilities administration |
| utility system construction |
| vehicle repair and maintenance |
| venture capital and private equity principals |
| veterinary services |
| vocational rehabilitation services |
| warehousing and storage |
| waste collection |
| waste treatment and disposal |
| water supply and irrigation systems |
| water, waste, steam, and air conditioning services |
| wellness and fitness services |
| wholesale |
| wholesale alcoholic beverages |
| wholesale apparel and sewing supplies |
| wholesale appliances, electrical, and electronics |
| wholesale building materials |
| wholesale chemical and allied products |
| wholesale computer equipment |
| wholesale drugs and sundries |
| wholesale food and beverage |
| wholesale footwear |
| wholesale furniture and home furnishings |
| wholesale hardware, plumbing, heating equipment |
| wholesale import and export |
| wholesale luxury goods and jewelry |
| wholesale machinery |
| wholesale metals and minerals |
| wholesale motor vehicles and parts |
| wholesale paper products |
| wholesale petroleum and petroleum products |
| wholesale photography equipment and supplies |
| wholesale raw farm products |
| wholesale recyclable materials |
| wind electric power generation |
| wineries |
| wireless services |
| women's handbag manufacturing |
| wood product manufacturing |
| writing and editing |
| zoos and botanical gardens |

  

## Relevant fields

* [`industry_v2`](/docs/company-schema#industry_v2)

Updated 4 months ago

---

Did this page help you?

Yes

No

---
# https://docs.peopledatalabs.com/docs/output-response-person-enrichment-api

## Response Data Structure

The response from the Person Enrichment API will be in this format:

JSON

```
{
    "status": 200,
    "likelihood": 10,
    "data":  {
            "id": "qEnOZ5Oh0poWnQ1luFBfVw_0000",
            "full_name": "sean thorne",
            ...
     }
}
```

See [Example Person Record](/docs/example-record) for a full example of the fields included in the `data` object.

## Response Fields

### `data.*`

| Type | Description |
| --- | --- |
| `Object` | The matched profile record that contains fields from our [Person Schema](/docs/fields). Any fields in the profile record that do not contain any data will have a `null` value. |

The `data` object contains the entire [PDL profile](/docs/fields) for the person that matches the Enrichment API request. Any profile field that we do not have data for will have a `null` value.

  

### `status`

| Type | Description |
| --- | --- |
| `Integer` | The [API response code](/docs/errors). |

  

### `likelihood`

| Type | Description |
| --- | --- |
| `Integer` | How confident we are that the returned profile is the same as the person you requested. Will be an integer between `1` and `10`.  You can control the minimum likelihood score that a response must have in order to count as a match by setting the [`min_likelihood` parameter](/docs/input-parameters-person-enrichment-api#min_likelihood) in the API request. |

We assign every match that the API finds during the enrichment process a likelihood score, to represent our confidence that the profile returned is the same as the profile requested. A score of `1` represents a very low confidence level while a score of `10` represents the highest degree of confidence. The likelihood score is logarithmic, so a response that returns a likelihood score of `2` will have roughly a 10-30% chance of being the person requested.

For example, enriching "John Smith" in "New York" is too vague for us to confidently say which of our profiles is the exact John Smith that you requested. However, if you were to attach an email, phone number, and street address to the request and they matched our data, we would be highly confident that we are returning the correct John Smith.

  

### `matched`

| Type | Description |
| --- | --- |
| `Array (String)` | Every query input from the request that matched this profile.   * \*IMPORTANT:\*\* This field will only be included in the response if the [`include_if_matched` flag](/docs/input-parameters-person-enrichment-api#include_if_matched) is set to `true`. |

See the [`include_if_matched` input parameter](/docs/input-parameters-person-enrichment-api#include_if_matched) for more details.

Updated 4 months ago

---

Did this page help you?

Yes

No

---
# https://docs.peopledatalabs.com/docs/sex

| Canonical Values for Sex |
| --- |
| female |
| male |

*Contents of this table were sourced from the following file on our public S3 bucket:[sex.txt](https://pdl-prod-schema.s3.us-west-2.amazonaws.com/28.0/enums/sex.txt)*

## Relevant fields

* [`sex`](/docs/fields#sex)

Updated 4 months ago

---

Did this page help you?

Yes

No

---
# https://docs.peopledatalabs.com/docs/company-search-api

## Overview

The Company Search API gives you access to every record in our full [Company Dataset](/docs/company-stats), which you can filter and segment using a search query. You can build a search query using fields in the [Company Schema](/docs/company-schema) to target the company profiles that you are interested in (see the [full field mapping](/docs/elasticsearch-mapping-company) for the exact list of query-supported fields).

## What's Next

Please check out the following pages for more information on the Company Search API:

| Page | Description |
| --- | --- |
| [Quickstart](/docs/quickstart-company-search-api) | A quick hands-on introduction to the API with simple code examples. |
| [Reference](/docs/reference-company-search-api) | Detailed descriptions of the technical specifications and usage constraints. |
| [Input Parameters](/docs/input-parameters-company-search-api) | In-depth explanations of the input parameters that the API supports. |
| [Output Response](/docs/output-response-company-search-api) | In-depth explanations of the output response object that the API returns. |
| [Examples](/docs/examples-company-search-api) | A collection of functional code examples and walkthroughs that illustrate various use cases and applications of the API. |
| [FAQs](/docs/faqs-company-search-api) | Answers to commonly asked questions and other good-to-know informatio |

---



*Know someone whoâ€™d thrive building data products and helping us launch whatâ€™s next? Weâ€™d love to meet!*

*Check out our[open roles](https://www.peopledatalabs.com/company?utm_source=docs&utm_medium=footer&utm_campaign=cta#jobs) â†’*

Updated 4 months ago

---

Did this page help you?

Yes

No

---
# https://docs.peopledatalabs.com/docs/input-parameters-skill-enrichment-api

> â—ï¸
>
> ### The Skill Enrichment API is now fully removed

> This endpoint was removed in our April 2025 (v30.0) Release and is no longer available. This page is retained for historical documentation purposes.

> For more information, please see our [April 2025 Release Notes (v30.0)](/changelog/april-2025-release-notes-v300).

## Required Parameters

### `api_key`

| Type | Description | Default | Example |
| --- | --- | --- | --- |
| `String` | Your secret API key. |  |  |

Your API Key **must** be included in either the request header or the api\_key parameter. For more information about request authentication, see the [Authentication](/docs/authentication) page.

  

### `skill`

| Type | Description | Example |
| --- | --- | --- |
| `String` | The skill that you are enriching. | `pyspark` |

If the provided `skill` does not represent one from our [Skill](/docs/skill-schema) Dataset, then the Skill Enrichment API will not return a matching record.

---

## Optional Parameters

### `pretty`

| Type | Description | Default | Example |
| --- | --- | --- | --- |
| `Boolean` | Whether the output should have [human-readable](http://jsonprettyprint.net/) indentation. | `false` | `true` |

  

### `titlecase`

| Type | Description | Default | Example |
| --- | --- | --- | --- |
| `Boolean` | All text in API responses returns as lowercase by default. Setting `titlecase` to `true` will titlecase response data instead. | `false` | `true` |

Updated 4 months ago

---

Did this page help you?

Yes

No

---
# https://docs.peopledatalabs.com/docs/quickstart-skill-enrichment-api

> â—ï¸
>
> ### The Skill Enrichment API is now fully removed
>
> This endpoint was removed in our April 2025 (v30.0) Release and is no longer available. This page is retained for historical documentation purposes.
>
> For more information, please see our [April 2025 Release Notes (v30.0)](/changelog/april-2025-release-notes-v300).

## Getting Started

In order to use our Skill Enrichment API, you must have an active API key. You can look up your API key by logging into our [self-serve dashboard](https://www.peopledatalabs.com/main/api-keys) and going to the **API Keys** section.

> ðŸ‘
>
> ### Need an API Key?
>
> If you don't have an API key, you can easily create one by [signing up](https://peopledatalabs.com/signup) for a self-serve account. Check out our [Self-Serve Quickstart Guide](https://blog.peopledatalabs.com/post/self-signup-api-quickstart), which walks you through the sign-up process as well as shows you how to use the self-serve API dashboard.

## Simple Example

As mentioned in the [Overview](/docs/skill-enrichment-api#overview), the Skill Enrichment API is a means of performing a one-to-one match of a skill with those included in our [Skill](/docs/skill-schema) Dataset. In order to use the Skill Enrichment API, **you will need the[skill](/docs/input-parameters-skill-enrichment-api#skill) that you want to look up**.

Here's a quick example that demonstrates retrieving a record with a `skill` of `ai`:

Python3 SDKcURLJavaScriptRubyGoPython3

```
# See https://github.com/peopledatalabs/peopledatalabs-python
from peopledatalabs import PDLPY

# Create a client, specifying your API key
CLIENT = PDLPY(
    api_key="YOUR API KEY",
)

# Create a parameters JSON object
QUERY_STRING = {"skill": "ai"}

# Pass the parameters object to the Skill Enrichment API
response = CLIENT.skill(**QUERY_STRING)

# Print the API response
print(response.text)
```

```
curl -X GET -G \
  'https://api.peopledatalabs.com/v5/skill/enrich' \
  -H 'X-Api-Key: YOUR API KEY' \
  --data-urlencode 'skill=ai'
```

```
// See https://github.com/peopledatalabs/peopledatalabs-js
import PDLJS from 'peopledatalabs';

// Create a client, specifying your API key
const PDLJSClient = new PDLJS({ apiKey: "YOUR API KEY" });

// Create a parameters JSON object
const queryString = {skill: "ai"}

// Pass the parameters object to the Skill API
PDLJSClient.skill(queryString).then((data) => {
    // Print the API response
    console.log(data);
}).catch((error) => {
    console.log(error);
});
```

```
# See https://github.com/peopledatalabs/peopledatalabs-ruby
require 'peopledatalabs'

# Set your API key
Peopledatalabs.api_key = 'YOUR API KEY'

# Pass parameters to the Skill API
response = Peopledatalabs::Skill.retrieve("skill": "ai")

# Print the API response
puts response
```

```
package main

import (
    "fmt"
    "context"
)

// See https://github.com/peopledatalabs/peopledatalabs-go
import (
    pdl "github.com/peopledatalabs/peopledatalabs-go"
    pdlmodel "github.com/peopledatalabs/peopledatalabs-go/model"
)

func main() {
    // Set your API key
    apiKey := "YOUR API KEY"
    // Set API key as environmental variable
    // apiKey := os.Getenv("API_KEY")

    // Create a client, specifying your API key
    client := pdl.New(apiKey)
    
    // Create a parameters JSON object
    queryString := pdlmodel.SkillBaseParams{Skill: "ai"}
    
    params := pdlmodel.SkillParams{
        SkillBaseParams: queryString,
    }
    
    // Pass the parameters object to the Skill API
    response, err := client.Skill(context.Background(), params)
    // Check for successful response
    if err == nil {
        // Print the API response
        fmt.Println(response)
    }  
}
```

```
import requests

# Set your API key
API_KEY = "YOUR API KEY"

# Set the Skill Enrichment API URL
PDL_URL = "https://api.peopledatalabs.com/v5/skill/enrich"

# Create a parameters JSON object
QUERY_STRING = {"skill": "ai"}

# Set headers
HEADERS = {
    'accept': "application/json",
    'content-type': "application/json",
    'x-api-key': API_KEY
}

# Pass the parameters object to the Skill Enrichment API
response = requests.request("GET", PDL_URL, headers=HEADERS, params=QUERY_STRING)

# Print the API response
print(response.text)
```

The API returns a record like the one below if the `skill` that you passed it exists in our dataset:

JSON

```
{
  "cleaned_skill": "ai",
  "similar_skills": [
    "machine learning",
    "artificial intelligence",
    "deep learning",
    "data science",
    "iot"
  ],
  "relevant_job_titles": [
    "data scientist",
    "software engineer",
    "senior data scientist",
    "chief technology officer",
    "senior software engineer"
  ]
}
```

If you don't get this response, check out our [Errors](/docs/errors) page for more information.

---

Updated 4 months ago

---

Did this page help you?

Yes

No

---
# https://docs.peopledatalabs.com/docs/job-title-subroles

> ðŸ“˜
>
> ### Launched in v28.0 (October 2024)
>
> The sub roles on this page are the officially supported set of canonical values used across all datasets for all PDL customers. **Support for the previous (legacy) taxonomy has now fully ended.**
>
> To view the previous sub role values, see: [Legacy Job Title Subroles (pre-v27.1)](/docs/job-title-subroles-legacy-v271).
>
> For additional information, please see the [February 2025 Release Notes (v29.1)](/changelog/february-2025-release-notes-v291).

| Canonical Values for Job Title Subroles |
| --- |
| academic |
| account\_executive |
| account\_management |
| accounting |
| accounting\_services |
| administrative |
| advisor |
| agriculture |
| aides |
| architecture |
| artist |
| board\_member |
| bookkeeping |
| brand |
| building\_and\_grounds |
| business\_analyst |
| business\_development |
| chemical |
| compliance |
| construction |
| consulting |
| content |
| corporate\_development |
| curation |
| customer\_success |
| customer\_support |
| data\_analyst |
| data\_engineering |
| data\_science |
| dental |
| devops |
| doctor |
| electric |
| electrical |
| emergency\_services |
| entertainment |
| executive |
| fashion |
| financial |
| fitness |
| fraud |
| graphic\_design |
| growth |
| hair\_stylist |
| hardware |
| health\_and\_safety |
| human\_resources |
| implementation |
| industrial |
| information\_technology |
| insurance |
| investment\_banking |
| investor |
| investor\_relations |
| journalism |
| judicial |
| legal |
| legal\_services |
| logistics |
| machinist |
| marketing\_design |
| marketing\_services |
| mechanic |
| mechanical |
| military |
| network |
| nursing |
| partnerships |
| pharmacy |
| planning\_and\_analysis |
| plumbing |
| political |
| primary\_and\_secondary |
| procurement |
| product\_design |
| product\_management |
| professor |
| project\_management |
| protective\_service |
| qa\_engineering |
| quality\_assurance |
| realtor |
| recruiting |
| restaurants |
| retail |
| revenue\_operations |
| risk |
| sales\_development |
| scientific |
| security |
| social\_service |
| software |
| solutions\_engineer |
| strategy |
| student |
| talent\_analytics |
| therapy |
| tour\_and\_travel |
| training |
| translation |
| transport |
| unemployed |
| veterinarian |
| warehouse |
| web |
| wellness |

*Contents of this table were sourced from the following file on our public S3 bucket:[job\_title\_sub\_role.txt](https://pdl-prod-schema.s3.us-west-2.amazonaws.com/30.0/enums/job_title_sub_role.txt)*

## Relevant fields

* [`experience.title.sub_role`](/docs/fields#experiencetitle)
* [`job_title_sub_role`](/docs/fields#job_title_sub_role)
* [`recent_exec_departures.job_title_sub_role`](/docs/company-schema#recent_exec_departures)
* [`recent_exec_departures.new_company_job_title_sub_role`](/docs/company-schema#recent_exec_departures)
* [`recent_exec_hires.job_title_sub_role`](/docs/company-schema#recent_exec_hires)
* [`recent_exec_hires.previous_company_job_title_sub_role`](/docs/company-schema#recent_exec_hires)

  

## See Also

* [Job Title Class](/docs/job-title-class)
* [Job Title Roles](/docs/job-title-roles)
* [Mapping Title Subroles to Roles](/docs/title-subroles-to-roles)

Updated 4 months ago

---

Did this page help you?

Yes

No

---
# https://docs.peopledatalabs.com/docs/profile-networks

| Canonical Values for Profile Networks |
| --- |
| aboutme |
| angellist |
| behance |
| crunchbase |
| dribbble |
| ello |
| facebook |
| flickr |
| foursquare |
| github |
| gitlab |
| google |
| gravatar |
| indeed |
| instagram |
| klout |
| linkedin |
| medium |
| meetup |
| myspace |
| pinterest |
| quora |
| reddit |
| soundcloud |
| stackoverflow |
| twitter |
| vimeo |
| wordpress |
| xing |
| youtube |

*Contents of this table were sourced from the following file on our public S3 bucket:[profiles.network.txt](https://pdl-prod-schema.s3.us-west-2.amazonaws.com/28.0/enums/profiles.network.txt)*

## Relevant fields

* [`possible_profiles.network`](/docs/fields#possible_profiles)
* [`profiles.network`](/docs/fields#profiles)

Updated 4 months ago

---

Did this page help you?

Yes

No

---
# https://docs.peopledatalabs.com/docs/person-search-api

## Overview

The Person Search API gives you access to every profile in our full [Person Dataset](/docs/datasets#api-dataset), which you can filter and segment using a search query. You can build a search query from any fields in the [Person Schema](/docs/fields) to target only the person profiles that you are interested in.

## What's Next

Please check out the following pages for more information on the Person Search API:

| Page | Description |
| --- | --- |
| [Quickstart](/docs/quickstart-person-search-api) | A quick hands-on introduction to the API with simple code examples. |
| [Reference](/docs/reference-person-search-api) | Detailed descriptions of the technical specifications and usage constraints. |
| [Input Parameters](/docs/input-parameters-person-search-api) | In-depth explanations of the input parameters that the API supports. |
| [Output Response](/docs/output-response-person-search-api) | In-depth explanations of the output response object that the API returns. |
| [Examples](/docs/examples-person-search-api) | A collection of functional code examples and walkthroughs that illustrate various use cases and applications of the API. |
| [FAQs](/docs/faqs-person-search-api) | Answers to commonly asked questions and other good-to-know information. |
| [Preview Search API](/docs/preview-search-api) | A supporting functionality to preview which fields have non-null data for a particular search. |

---



*Know someone whoâ€™d thrive building data products and helping us launch whatâ€™s next? Weâ€™d love to meet!*

*Check out our[open roles](https://www.peopledatalabs.com/company?utm_source=docs&utm_medium=footer&utm_campaign=cta#jobs) â†’*

Updated 4 months ago

---

Did this page help you?

Yes

No

---
# https://docs.peopledatalabs.com/docs/identify-api

## Overview

The Person Identify API allows you to use broad search inputs to retrieve multiple records from our person dataset. In particular, this endpoint enables functionality such as searching through a single identifying attribute, such as name, email, phone number, company, school or location, in addition to using any combination of these attributes [and more](/docs/reference-person-identify-api#input-parameters). The API then scores and sorts all matching records that it returns based on the [strength of their association with the input parameters](/docs/output-response-person-identify-api#matchesmatch_score).

> ðŸ“˜
>
> ### How Does the Person Identify API Compare with Other Person-Related Endpoints?
>
> See our [Introduction](/docs/introduction#the-differences-between-our-person-related-apis) for a detailed breakdown regarding the differences between the Person Identify API and our other person-related products.

## Use Cases

A key use case for this endpoint is building comprehensive profiles for specific individuals, such as in the areas of:

* Investigations and forensics
* Fraud risk modeling
* Identity modeling for customer onboarding and other [KYC](https://en.wikipedia.org/wiki/Know_your_customer) applications

## How it Works

At a high level, the Person Identify API works as follows:

1. You specify some characteristics about the identity that you are interested in and pass these as [input parameters](/docs/identify-api-input-parameters) to the API.
2. The API [cleans](/docs/cleaner-apis) the input parameter values and searches our Person Dataset for matching profiles using fuzzy-matching logic.
3. The API returns up to 20 of the the best matching profiles in its response while ranking them by their [match score](/docs/identify-api-output-response#matchesmatch_score).

## What's Next

Please check out the following pages for more information on the Person Identify API:

| Page | Description |
| --- | --- |
| [Quickstart](/docs/quickstart-person-identify-api) | A quick hands-on introduction to the API with simple code examples. |
| [Reference](/docs/reference-person-identify-api) | Detailed descriptions of the technical specifications and usage constraints. |
| [Input Parameters](/docs/input-parameters-person-identify-api) | In-depth explanations of the input parameters that the API supports. |
| [Output Response](/docs/output-response-person-identify-api) | In-depth explanations of the output response object that the API returns. |
| [Examples](/docs/examples-person-identify-api) | A collection of functional code examples and walkthroughs that illustrate various use cases and applications of the API. |
| [FAQs](/docs/faqs-person-identify-api) | Answers to commonly asked questions and other good-to-know information. |

---



*Know someone whoâ€™d thrive building data products and helping us launch whatâ€™s next? Weâ€™d love to meet!*

*Check out our[open roles](https://www.peopledatalabs.com/company?utm_source=docs&utm_medium=footer&utm_campaign=cta#jobs) â†’*

Updated 4 months ago

---

Did this page help you?

Yes

No

---
# https://docs.peopledatalabs.com/docs/datasets

## Terminology

**Person (All) Dataset**: Our collection of every profile record that we have published and made available for use. These records can contain null values for any of their fields.

**Field**: The attributes associated with each record in our dataset, as listed in the [Person Schema](/docs/fields). Each record in our Person Dataset contains all the fields in the Person Schema. However, in general, these records can have null values for their fields.

**Dataset**: A subset of our Person Dataset that contains every record with non-null value for a specific field. For example, our [Email Dataset](/docs/datasets#email-slice) contains every record from our Person Dataset with at least one non-null email address.

## Description

We refer to our full dataset of person profiles as our **Person Dataset** or our **All Dataset**. This dataset contains every person record that we have been able to confidently produce through our [data ingestion and build process](/docs/data-build). However, records in our dataset are not guaranteed to have every **field** populated, and, in general, can contain null values. This is due to our high confidence requirement for merging and inferring missing field values and that we want to present the data as authentically as possible with a minimal amount of modification.

> ðŸ“˜
>
> ### Null Values and Frankenstein Profiles
>
> Given the volume of data we take in, we often have many raw records with data on the same person. While we spend significant engineering resources working on linkages, it's not unusual to end up with 3-4 profiles of disparate information that relate to the same person.
>
> While we could link these together (for example, based on name), this would create many false positive linkages. We call these **Frankenstein profiles**, where data on multiple people has been combined, making that record unusable, even application-breaking. Frankenstein profiles are bad, and we are extremely vigilant to the presence of them in our datasets.

In opting to have a strict linkage algorithm in our [data build process](/docs/data-build), we also decided to define multiple use-case-specific subsets of the All Dataset data called Datasets. For example, our Email Dataset is a subset of our All Dataset containing every record that has a non-null email address.

This approach means that we are not forced to merge and infer missing information where we have low confidence in the original data while also helping to ensure a lower rate of duplication in the data as compared to using the All Dataset. Customers interested accessing the unmerged records still have the option do so through using the All Dataset instead of one of subset datasets.

# List of Datasets

## All Dataset

*All Records Have: Name AND One Other Piece of PII*

**Number of Profiles**: 2,453,435,765
**Main Use Cases**: Enrichment  
[Detailed Stats](/docs/stats)

## Consumer Social Dataset

*All Records Have: Facebook URL*

**Number of Profiles**: 703,540,454  
**Main Use Cases**: Contact Info Enrichment, Sales and Marketing, Fraud, Background Checks // People Search  
[Detailed Stats](/docs/consumer-social-stats)

## Developer Dataset

*All Records Have: GitHub URL*

**Number of Profiles**: 3,058,252  
**Main Use Cases**: Recruiting, Investment Sourcing  
[Detailed Stats](/docs/developer-stats)

## Email Dataset

*All Records Have: Email*

**Number of Profiles**: 587,237,067  
**Main Use Cases**: Email Enrichment, Sales Lead Generation, Candidate Outreach  
[Detailed Stats](/docs/email-stats)

## Mobile Phone Dataset

*All Records Have: Mobile Phone Number*

**Number of Profiles**: 479,855,809  
**Main Use Cases**: Direct Dial Outreach, Caller ID  
[Detailed Stats](/docs/mobile-phone-stats)

## Phone Dataset

*All Records Have: Any Phone Number*

**Number of Profiles**: 770,761,928  
**Main Use Cases**: Background Checks // People Search  
[Detailed Stats](/docs/phone-stats)

## Resume Dataset

*All Records Have: LinkedIn URL in the Profiles Array*

**Number of Profiles**: 798,953,930  
**Main Use Cases**: Candidate Search, Prospect Search, Custom Audiences, Career Path Prediction/Labor Force Modeling, Investment Sourcing  
[Detailed Stats](/docs/resume-stats)

## Street Address Dataset

*All Records Have: Street Address*

**Number of Profiles**: 218,071,308  
**Main Use Cases**: Contact Info Enrichment, Sales and Marketing, Skiptracing, Background Checks // People Search  
[Detailed Stats](/docs/street-address-stats)

Updated 6 days ago

---

Did this page help you?

Yes

No

---
# https://docs.peopledatalabs.com/docs/receiving-and-updating-data

# Receiving the Data

You can receive your license delivery updates in a variety of ways. Follow the instructions for one of the data delivery methods below to begin receiving data:

* [Data Delivery Using S3](/docs/data-delivery-using-s3) *(\*preferred)*
* [Data Delivery Using Snowflake](/docs/data-delivery-using-snowflake) *(\*preferred)*
* [Data Delivery Using Azure](/docs/data-delivery-using-azure)
* [Data Delivery Using GCP](/docs/data-delivery-using-gcp)
* [Data Delivery Using Direct Download](/docs/data-delivery-using-direct-download)

> ðŸ’¡
>
> ### Interested in Databricks as a delivery method?
>
> Please vote for the existing [feature request](https://feedback.peopledatalabs.com/feature-requests/p/support-databricks-as-a-license-delivery-option) to get status updates and help us prioritize improvements in our roadmap.

---

# Data Ingestion Schemas

## Preset Ingestion Schemas

We provide up-to-date ingestion schemas in our [public S3 bucket]('https://s3.console.aws.amazon.com/s3/buckets/pdl-prod-schema/') with each release.)

| Name | Description | S3 Link |
| --- | --- | --- |
| Company | All [non-premium](/docs/company-stats) Company Data fields | <https://pdl-prod-schema.s3.us-west-2.amazonaws.com/33.1/schemas/company_schema.json> |
| Location | Location fields in [Location Cleaner API](/docs/cleaner-apis-reference#location-cleaner-api-locationclean-1) responses | <https://pdl-prod-schema.s3.us-west-2.amazonaws.com/33.1/schemas/location_schema.json> |
| Person (Default) | All [non-premium](/docs/stats) Person Data fields | <https://pdl-prod-schema.s3.us-west-2.amazonaws.com/33.1/schemas/person_defaults_schema.json> |
| Person (Full) | All Person Data fields | <https://pdl-prod-schema.s3.us-west-2.amazonaws.com/33.1/schemas/person_full_schema.json> |

### Snowflake Schemas

> â„ï¸
>
> Snowflake users can find our standard schemas [here](/docs/data-delivery-using-snowflake#standard-schemas)

  

## Generate Custom Ingestion Schemas

If you have a field combination not represented in a preset schema OR if you'd prefer to build your own, you will need to generate your JSON schema for your data ingestion process.

There are many tools available that can quickly do this. For example, the Python package [GenSON](https://github.com/wolverdude/genson/) can generate a schema from one or multiple files like this:

Shell

```
$ pip install genson

# source file > target file
$ genson -d 'newline' my-pdl-data-file > my_schema.json
```

Updated 6 days ago

---

Did this page help you?

Yes

No

---
# https://docs.peopledatalabs.com/docs/job-title-roles-legacy-v271

> â—ï¸
>
> ### Deprecated as of v29.1 (Feb 2025)
>
> As of v29.1 (Feb 2025), **the set of roles on this page are no longer supported in our datasets**.
>
> This page contains the legacy role canonical values prior to the release of our improved Role / Sub Role Taxonomy in February 2025, and is provided for historical documentation purposes.
>
> For the currently supported roles values, please see: [Job Title Roles](/docs/job-title-roles).
>
> For more information, please see our [February 2025 Release Notes (v29.1)](/changelog/february-2025-release-notes-v291).

| Canonical Values for Job Title Roles |
| --- |
| customer\_service |
| design |
| education |
| engineering |
| finance |
| health |
| human\_resources |
| legal |
| marketing |
| media |
| operations |
| public\_relations |
| real\_estate |
| sales |
| trades |

*Contents of this table were sourced from the following file on our public S3 bucket:[job\_title\_role.txt](https://pdl-prod-schema.s3.us-west-2.amazonaws.com/28.0/enums/job_title_role.txt)*

## Relevant fields

* [`average_tenure_by_role`](/docs/company-schema#average_tenure_by_role)
* [`employee_count_by_month_by_role`](/docs/company-schema#employee_count_by_month_by_role)
* [`employee_count_by_role`](/docs/company-schema#employee_count_by_role)
* [`employee_growth_rate_12_month_by_role`](/docs/company-schema#employee_growth_rate_12_month_by_role)
* [`experience.title.role`](/docs/fields#experiencetitle)
* [`job_title_role`](/docs/fields#job_title_role)
* [`recent_exec_departures.job_title_role`](/docs/company-schema#recent_exec_departures)
* [`recent_exec_departures.new_company_job_title_role`](/docs/company-schema#recent_exec_departures)
* [`recent_exec_hires.job_title_role`](/docs/company-schema#recent_exec_hires)
* [`recent_exec_hires.previous_company_job_title_role`](/docs/company-schema#recent_exec_hires)
* [`top_next_employers_by_role`](/docs/company-schema#top_next_employers_by_role)
* [`top_previous_employers_by_role`](/docs/company-schema#top_previous_employers_by_role)

  

## See Also

* [Job Title Subroles](/docs/job-title-subroles)
* [Mapping Title Subroles to Roles](/docs/title-subroles-to-roles)

Updated 4 months ago

---

Did this page help you?

Yes

No

---
# https://docs.peopledatalabs.com/docs/education-school-types

| Canonical Values for Education School Types |
| --- |
| post-secondary institution |
| primary school |
| secondary school |

*Contents of this table were sourced from the following file on our public S3 bucket:[education.school.type.txt](https://pdl-prod-schema.s3.us-west-2.amazonaws.com/28.0/enums/education.school.type.txt)*

## Relevant fields

* [`education.school.type`](/docs/fields#education-1)

Updated 4 months ago

---

Did this page help you?

Yes

No

---
# https://docs.peopledatalabs.com/docs/cleaner-apis

## Overview

Clean input data can make a big difference when it comes to retrieving the best results from your queries. With our Cleaner APIs, you can clean the company, location and school data that you employ in your API queries. We use these same APIs for standardizing our data as part of our [Data Build Process](/docs/data-build).

## Examples of Location Cleaning Using the Location Cleaner API:

| Raw Location Name | Cleaned Location Name |
| --- | --- |
| "San Francisco" | `san francisco, california, united states` |
| "dc" | `washington, district of columbia, united states` |
| "USA" | `united states` |
| "London" | `london, greater london, united kingdom` |

In short, the Cleaner APIs let you:

* Clean company, school and location names before using them with our Search APIs.
* Easily clean and standardize your own raw data for your own use.

## What's Next

Please check out the following pages for more information on the Cleaner APIs:

| Page | Description |
| --- | --- |
| [Quickstart](/docs/quickstart-cleaner-apis) | A quick hands-on introduction to the APIs with simple code examples. |
| [Reference](/docs/cleaner-apis-reference) | Detailed descriptions of the technical specifications and usage constraints. |
| [Input Parameters](/docs/input-parameters-cleaner-apis) | In-depth explanations of the input parameters that the APIs support. |
| [Output Responses](/docs/output-response-cleaner-apis) | In-depth explanations of the output response objects that the APIs return. |
| [Examples](/docs/examples-cleaner-apis) | A collection of functional code examples and walkthroughs that illustrate various use cases and applications of the APIs. |
| [FAQs](/docs/faqs-cleaner-apis) | Answers to commonly asked questions and other good-to-know information. |

---



*Know someone whoâ€™d thrive building data products and helping us launch whatâ€™s next? Weâ€™d love to meet!*

*Check out our[open roles](https://www.peopledatalabs.com/company?utm_source=docs&utm_medium=footer&utm_campaign=cta#jobs) â†’*

Updated 4 months ago

---

Did this page help you?

Yes

No

---
# https://docs.peopledatalabs.com/docs/example-company-record

> ðŸ“˜
>
> ### Field Availability
>
> Not all fields shown in the example record below are available by default. For a complete list of field pricing, see [this table](/docs/company-stats).

JSON

```
{
  "id": "tnHcNHbCv8MKeLh92946LAkX6PKg",
  "name": "people data labs",
  "display_name": "People Data Labs",
  "size": "51-200",
  "employee_count": 82,
  "linkedin_follower_count": 7502,
  "founded": 2015,
  "inferred_revenue": "$50M-$100M",
  "industry": "computer software",
  "industry_v2": "software development",
  "naics": null,
  "sic": null,
  "location": {
    "name": "san francisco, california, united states",
    "locality": "san francisco",
    "region": "california",
    "metro": "san francisco, california",
    "country": "united states",
    "continent": "north america",
    "street_address": "455 market street",
    "address_line_2": "suite 1670",
    "postal_code": "94105",
    "geo": "37.76,-122.40"
  },
  "locations": [
    {
      "name": "new york, new york, united states",
      "locality": "new york",
      "region": "new york",
      "metro": "new york, new york",
      "country": "united states",
      "continent": "north america",
      "street_address": "156 5th avenue",
      "address_line_2": "suite 1200",
      "postal_code": "10010",
      "geo": "40.75,-73.98",
      "is_primary": false,
      "first_seen": "2023-07-21",
      "last_seen": "2025-12-23",
      "is_active": true
    },
    {
      "name": "san francisco, california, united states",
      "locality": "san francisco",
      "region": "california",
      "metro": "san francisco, california",
      "country": "united states",
      "continent": "north america",
      "street_address": "455 market street",
      "address_line_2": "suite 1670",
      "postal_code": "94105",
      "geo": "37.76,-122.40",
      "is_primary": true,
      "first_seen": "2020-01-01",
      "last_seen": "2025-12-23",
      "is_active": true
    },
    {
      "name": "portland, oregon, united states",
      "locality": "portland",
      "region": "oregon",
      "metro": "portland, oregon",
      "country": "united states",
      "continent": "north america",
      "street_address": "1470 northwest glisan street",
      "address_line_2": null,
      "postal_code": "97209",
      "geo": "45.47,-122.63",
      "is_primary": false,
      "first_seen": "2020-01-01",
      "last_seen": "2020-11-07",
      "is_active": false
    },
    {
      "name": "portland, oregon, united states",
      "locality": "portland",
      "region": "oregon",
      "metro": "portland, oregon",
      "country": "united states",
      "continent": "north america",
      "street_address": "239 northwest 13th avenue",
      "address_line_2": null,
      "postal_code": "97209",
      "geo": "45.47,-122.63",
      "is_primary": false,
      "first_seen": "2020-01-01",
      "last_seen": "2020-11-07",
      "is_active": false
    }
  ],
  "num_total_locations": 4,
  "num_active_locations": 2,
  "linkedin_id": "18170482",
  "linkedin_url": "linkedin.com/company/peopledatalabs",
  "linkedin_slug": "peopledatalabs",
  "facebook_url": "facebook.com/peopledatalabs",
  "twitter_url": "twitter.com/peopledatalabs",
  "profiles": [
    "linkedin.com/company/18170482",
    "crunchbase.com/organization/talentiq",
    "facebook.com/peopledatalabs",
    "twitter.com/peopledatalabs",
    "linkedin.com/company/peopledatalabs"
  ],
  "website": "peopledatalabs.com",
  "ticker": null,
  "mic_exchange": null,
  "type": "private",
  "summary": "people data labs builds b2b data for developers, engineers, and data scientists.\n\nwe empower our clients to build and scale innovative data-driven products using 2.5 billion unique, always-accurate b2b records. every day, our clients use our data to build person profiles, enrich person records, power predictive modeling, drive artificial intelligence, and build new tools to make their teams more efficient, productive, and successful \n\nwe\u2019re proud to be the preferred data partner to the data science and engineering teams building the next generation of data-driven products and services. people data labs is the single source of truth in b2b data serving enterprise and startup clients across a range of data-enabled businesses.",
  "tags": [
    "artificial intelligence",
    "developer apis",
    "ip data",
    "database",
    "data and analytics",
    "software",
    "company data",
    "people data",
    "data",
    "machine learning"
  ],
  "headline": "People and Company Intelligence",
  "alternative_names": [],
  "alternative_domains": [],
  "affiliated_profiles": [],
  "affiliated_entities": [],
  "ultimate_parent": null,
  "ultimate_parent_mic_exchange": null,
  "ultimate_parent_ticker": null,
  "immediate_parent": null,
  "direct_subsidiaries": [],
  "all_subsidiaries": [],
  "total_funding_raised": 55475000.0,
  "latest_funding_stage": "series_b",
  "last_funding_date": "2021-11-16",
  "number_funding_rounds": 7,
  "funding_stages": [
    "pre_seed",
    "series_b",
    "seed",
    "series_a"
  ],
  "active_job_postings": 5,
  "active_job_postings_by_class": {
    "other_uncategorized": 0,
    "services": 0,
    "general_and_administrative": 1,
    "sales_and_marketing": 1,
    "research_and_development": 3
  },
  "active_job_postings_by_country": {
    "remote_location": 5
  },
  "active_job_postings_by_metro": {
    "remote_location": 5
  },
  "active_job_postings_by_month": {
    "2024-10": 1,
    "2024-11": 1,
    "2024-12": 4,
    "2025-01": 6,
    "2025-02": 7,
    "2025-03": 7,
    "2025-04": 4,
    "2025-05": 6,
    "2025-06": 5,
    "2025-07": 7,
    "2025-08": 7,
    "2025-09": 5,
    "2025-10": 7,
    "2025-11": 7,
    "2025-12": 7,
    "2026-01": 5
  },
  "active_job_postings_by_role": {
    "other_uncategorized": 0,
    "advisory": 0,
    "trade": 0,
    "manufacturing": 0,
    "hospitality": 0,
    "public_service": 0,
    "support": 0,
    "research": 0,
    "product": 0,
    "education": 0,
    "human_resources": 0,
    "legal": 0,
    "operations": 1,
    "fulfillment": 0,
    "professional_service": 0,
    "creative": 0,
    "marketing": 0,
    "partnerships": 0,
    "sales_engineering": 1,
    "sales": 0,
    "health": 0,
    "analyst": 0,
    "finance": 0,
    "engineering": 3
  },
  "active_job_postings_by_sub_role": {
    "other_uncategorized": 1,
    "advisor": 0,
    "board_member": 0,
    "investor": 0,
    "agriculture": 0,
    "construction": 0,
    "electric": 0,
    "mechanic": 0,
    "plumbing": 0,
    "health_and_safety": 0,
    "machinist": 0,
    "quality_assurance": 0,
    "restaurants": 0,
    "retail": 0,
    "emergency_services": 0,
    "judicial": 0,
    "military": 0,
    "political": 0,
    "protective_service": 0,
    "social_service": 0,
    "account_management": 0,
    "customer_success": 0,
    "customer_support": 0,
    "fraud": 0,
    "academic": 0,
    "financial": 0,
    "scientific": 0,
    "product_design": 0,
    "product_management": 0,
    "curation": 0,
    "primary_and_secondary": 0,
    "professor": 0,
    "student": 0,
    "tour_and_travel": 0,
    "human_resources": 0,
    "recruiting": 0,
    "talent_analytics": 0,
    "training": 0,
    "compliance": 0,
    "legal": 0,
    "administrative": 1,
    "aides": 0,
    "building_and_grounds": 0,
    "corporate_development": 0,
    "executive": 0,
    "investor_relations": 0,
    "strategy": 0,
    "logistics": 0,
    "project_management": 0,
    "transport": 0,
    "warehouse": 0,
    "accounting_services": 0,
    "architecture": 0,
    "consulting": 0,
    "investment_banking": 0,
    "legal_services": 0,
    "marketing_services": 0,
    "translation": 0,
    "artist": 0,
    "entertainment": 0,
    "fashion": 0,
    "graphic_design": 0,
    "hair_stylist": 0,
    "journalism": 0,
    "brand": 0,
    "content": 0,
    "growth": 0,
    "marketing_design": 0,
    "business_development": 0,
    "partnerships": 0,
    "implementation": 0,
    "solutions_engineer": 1,
    "account_executive": 0,
    "insurance": 0,
    "realtor": 0,
    "sales_development": 0,
    "dental": 0,
    "doctor": 0,
    "fitness": 0,
    "nursing": 0,
    "pharmacy": 0,
    "therapy": 0,
    "veterinarian": 0,
    "wellness": 0,
    "business_analyst": 0,
    "data_analyst": 0,
    "revenue_operations": 0,
    "accounting": 0,
    "bookkeeping": 0,
    "procurement": 0,
    "planning_and_analysis": 0,
    "risk": 0,
    "chemical": 0,
    "data_engineering": 1,
    "data_science": 0,
    "devops": 0,
    "electrical": 0,
    "hardware": 0,
    "industrial": 0,
    "information_technology": 0,
    "mechanical": 0,
    "network": 0,
    "qa_engineering": 0,
    "security": 0,
    "software": 0,
    "web": 1
  },
  "average_employee_tenure": 2.74,
  "average_tenure_by_role": {
    "advisory": 2.417,
    "trade": 0.0,
    "manufacturing": 0.0,
    "hospitality": 0.0,
    "public_service": 0.0,
    "support": 1.657,
    "research": 2.792,
    "product": 2.333,
    "education": 0.0,
    "human_resources": 2.183,
    "legal": 0.0,
    "operations": 3.23,
    "fulfillment": 2.133,
    "professional_service": 0.0,
    "creative": 1.833,
    "marketing": 1.877,
    "partnerships": 1.641,
    "sales_engineering": 2.299,
    "sales": 2.036,
    "health": 0.0,
    "analyst": 1.75,
    "finance": 4.813,
    "engineering": 2.883
  },
  "average_tenure_by_level": {
    "unpaid": 0.0,
    "cxo": 4.786,
    "partner": 0.0,
    "owner": 9.972,
    "director": 1.922,
    "vp": 2.451,
    "senior": 1.979,
    "manager": 1.918,
    "entry": 0.0,
    "training": 0.5
  },
  "deactivated_job_postings": 1,
  "deactivated_job_postings_by_class": {
    "other_uncategorized": 0,
    "services": 0,
    "general_and_administrative": 1,
    "sales_and_marketing": 0,
    "research_and_development": 0
  },
  "deactivated_job_postings_by_month": {
    "2024-10": 0,
    "2024-11": 0,
    "2024-12": 1,
    "2025-01": 1,
    "2025-02": 1,
    "2025-03": 5,
    "2025-04": 1,
    "2025-05": 1,
    "2025-06": 0,
    "2025-07": 1,
    "2025-08": 2,
    "2025-09": 0,
    "2025-10": 0,
    "2025-11": 7,
    "2025-12": 3,
    "2026-01": 1
  },
  "deactivated_job_postings_by_role": {
    "other_uncategorized": 0,
    "advisory": 0,
    "trade": 0,
    "manufacturing": 0,
    "hospitality": 0,
    "public_service": 0,
    "support": 0,
    "research": 0,
    "product": 0,
    "education": 0,
    "human_resources": 0,
    "legal": 0,
    "operations": 1,
    "fulfillment": 0,
    "professional_service": 0,
    "creative": 0,
    "marketing": 0,
    "partnerships": 0,
    "sales_engineering": 0,
    "sales": 0,
    "health": 0,
    "analyst": 0,
    "finance": 0,
    "engineering": 0
  },
  "deactivated_job_postings_by_sub_role": {
    "other_uncategorized": 0,
    "advisor": 0,
    "board_member": 0,
    "investor": 0,
    "agriculture": 0,
    "construction": 0,
    "electric": 0,
    "mechanic": 0,
    "plumbing": 0,
    "health_and_safety": 0,
    "machinist": 0,
    "quality_assurance": 0,
    "restaurants": 0,
    "retail": 0,
    "emergency_services": 0,
    "judicial": 0,
    "military": 0,
    "political": 0,
    "protective_service": 0,
    "social_service": 0,
    "account_management": 0,
    "customer_success": 0,
    "customer_support": 0,
    "fraud": 0,
    "academic": 0,
    "financial": 0,
    "scientific": 0,
    "product_design": 0,
    "product_management": 0,
    "curation": 0,
    "primary_and_secondary": 0,
    "professor": 0,
    "student": 0,
    "tour_and_travel": 0,
    "human_resources": 0,
    "recruiting": 0,
    "talent_analytics": 0,
    "training": 0,
    "compliance": 0,
    "legal": 0,
    "administrative": 1,
    "aides": 0,
    "building_and_grounds": 0,
    "corporate_development": 0,
    "executive": 0,
    "investor_relations": 0,
    "strategy": 0,
    "logistics": 0,
    "project_management": 0,
    "transport": 0,
    "warehouse": 0,
    "accounting_services": 0,
    "architecture": 0,
    "consulting": 0,
    "investment_banking": 0,
    "legal_services": 0,
    "marketing_services": 0,
    "translation": 0,
    "artist": 0,
    "entertainment": 0,
    "fashion": 0,
    "graphic_design": 0,
    "hair_stylist": 0,
    "journalism": 0,
    "brand": 0,
    "content": 0,
    "growth": 0,
    "marketing_design": 0,
    "business_development": 0,
    "partnerships": 0,
    "implementation": 0,
    "solutions_engineer": 0,
    "account_executive": 0,
    "insurance": 0,
    "realtor": 0,
    "sales_development": 0,
    "dental": 0,
    "doctor": 0,
    "fitness": 0,
    "nursing": 0,
    "pharmacy": 0,
    "therapy": 0,
    "veterinarian": 0,
    "wellness": 0,
    "business_analyst": 0,
    "data_analyst": 0,
    "revenue_operations": 0,
    "accounting": 0,
    "bookkeeping": 0,
    "procurement": 0,
    "planning_and_analysis": 0,
    "risk": 0,
    "chemical": 0,
    "data_engineering": 0,
    "data_science": 0,
    "devops": 0,
    "electrical": 0,
    "hardware": 0,
    "industrial": 0,
    "information_technology": 0,
    "mechanical": 0,
    "network": 0,
    "qa_engineering": 0,
    "security": 0,
    "software": 0,
    "web": 0
  },
  "employee_churn_rate": {
    "3_month": 0.0333,
    "6_month": 0.0645,
    "12_month": 0.0745,
    "24_month": 0.1714
  },
  "employee_count_by_country": {
    "canada": 1,
    "other_uncategorized": 2,
    "united states": 79
  },
  "employee_count_by_month": {
    "2015-03": 3,
    "2015-04": 3,
    "2015-05": 3,
    "2015-06": 3,
    "2015-07": 4,
    "2015-08": 6,
    "2015-09": 7,
    "2015-10": 7,
    "2015-11": 7,
    "2015-12": 7,
    "2016-01": 7,
    "2016-02": 9,
    "2016-03": 9,
    "2016-04": 10,
    "2016-05": 11,
    "2016-06": 11,
    "2016-07": 11,
    "2016-08": 11,
    "2016-09": 11,
    "2016-10": 12,
    "2016-11": 12,
    "2016-12": 12,
    "2017-01": 13,
    "2017-02": 13,
    "2017-03": 13,
    "2017-04": 14,
    "2017-05": 16,
    "2017-06": 16,
    "2017-07": 16,
    "2017-08": 17,
    "2017-09": 17,
    "2017-10": 17,
    "2017-11": 17,
    "2017-12": 16,
    "2018-01": 19,
    "2018-02": 20,
    "2018-03": 20,
    "2018-04": 20,
    "2018-05": 22,
    "2018-06": 24,
    "2018-07": 25,
    "2018-08": 25,
    "2018-09": 25,
    "2018-10": 27,
    "2018-11": 30,
    "2018-12": 28,
    "2019-01": 38,
    "2019-02": 39,
    "2019-03": 42,
    "2019-04": 44,
    "2019-05": 44,
    "2019-06": 43,
    "2019-07": 41,
    "2019-08": 41,
    "2019-09": 41,
    "2019-10": 41,
    "2019-11": 42,
    "2019-12": 44,
    "2020-01": 49,
    "2020-02": 49,
    "2020-03": 50,
    "2020-04": 49,
    "2020-05": 47,
    "2020-06": 49,
    "2020-07": 51,
    "2020-08": 49,
    "2020-09": 54,
    "2020-10": 55,
    "2020-11": 57,
    "2020-12": 59,
    "2021-01": 66,
    "2021-02": 70,
    "2021-03": 77,
    "2021-04": 79,
    "2021-05": 83,
    "2021-06": 86,
    "2021-07": 88,
    "2021-08": 89,
    "2021-09": 89,
    "2021-10": 94,
    "2021-11": 96,
    "2021-12": 98,
    "2022-01": 107,
    "2022-02": 109,
    "2022-03": 119,
    "2022-04": 122,
    "2022-05": 125,
    "2022-06": 127,
    "2022-07": 131,
    "2022-08": 135,
    "2022-09": 135,
    "2022-10": 137,
    "2022-11": 140,
    "2022-12": 140,
    "2023-01": 122,
    "2023-02": 120,
    "2023-03": 120,
    "2023-04": 120,
    "2023-05": 118,
    "2023-06": 114,
    "2023-07": 112,
    "2023-08": 115,
    "2023-09": 114,
    "2023-10": 111,
    "2023-11": 109,
    "2023-12": 109,
    "2024-01": 105,
    "2024-02": 101,
    "2024-03": 100,
    "2024-04": 100,
    "2024-05": 94,
    "2024-06": 93,
    "2024-07": 93,
    "2024-08": 92,
    "2024-09": 94,
    "2024-10": 93,
    "2024-11": 92,
    "2024-12": 92,
    "2025-01": 94,
    "2025-02": 95,
    "2025-03": 91,
    "2025-04": 94,
    "2025-05": 92,
    "2025-06": 94,
    "2025-07": 93,
    "2025-08": 93,
    "2025-09": 93,
    "2025-10": 90,
    "2025-11": 89,
    "2025-12": 87,
    "2026-01": 87
  },
  "employee_count_by_role": {
    "other_uncategorized": 3,
    "advisory": 1,
    "trade": 0,
    "manufacturing": 0,
    "hospitality": 0,
    "public_service": 0,
    "support": 6,
    "research": 1,
    "product": 7,
    "education": 0,
    "human_resources": 5,
    "legal": 1,
    "operations": 6,
    "fulfillment": 0,
    "professional_service": 0,
    "creative": 0,
    "marketing": 5,
    "partnerships": 3,
    "sales_engineering": 4,
    "sales": 14,
    "health": 0,
    "analyst": 4,
    "finance": 3,
    "engineering": 24
  },
  "employee_count_by_sub_role": {
    "other_uncategorized": 17,
    "advisor": 1,
    "board_member": 0,
    "investor": 0,
    "agriculture": 0,
    "construction": 0,
    "electric": 0,
    "mechanic": 0,
    "plumbing": 0,
    "health_and_safety": 0,
    "machinist": 0,
    "quality_assurance": 0,
    "restaurants": 0,
    "retail": 0,
    "emergency_services": 0,
    "judicial": 0,
    "military": 0,
    "political": 0,
    "protective_service": 0,
    "social_service": 0,
    "account_management": 0,
    "customer_success": 6,
    "customer_support": 0,
    "fraud": 0,
    "academic": 0,
    "financial": 0,
    "scientific": 0,
    "product_design": 1,
    "product_management": 6,
    "curation": 0,
    "primary_and_secondary": 0,
    "professor": 0,
    "student": 0,
    "tour_and_travel": 0,
    "human_resources": 2,
    "recruiting": 1,
    "talent_analytics": 0,
    "training": 2,
    "compliance": 1,
    "legal": 0,
    "administrative": 1,
    "aides": 1,
    "building_and_grounds": 0,
    "corporate_development": 0,
    "executive": 3,
    "investor_relations": 0,
    "strategy": 0,
    "logistics": 0,
    "project_management": 0,
    "transport": 0,
    "warehouse": 0,
    "accounting_services": 0,
    "architecture": 0,
    "consulting": 0,
    "investment_banking": 0,
    "legal_services": 0,
    "marketing_services": 0,
    "translation": 0,
    "artist": 0,
    "entertainment": 0,
    "fashion": 0,
    "graphic_design": 0,
    "hair_stylist": 0,
    "journalism": 0,
    "brand": 1,
    "content": 1,
    "growth": 2,
    "marketing_design": 0,
    "business_development": 3,
    "partnerships": 0,
    "implementation": 0,
    "solutions_engineer": 4,
    "account_executive": 12,
    "insurance": 0,
    "realtor": 0,
    "sales_development": 0,
    "dental": 0,
    "doctor": 0,
    "fitness": 0,
    "nursing": 0,
    "pharmacy": 0,
    "therapy": 0,
    "veterinarian": 0,
    "wellness": 0,
    "business_analyst": 0,
    "data_analyst": 1,
    "revenue_operations": 3,
    "accounting": 1,
    "bookkeeping": 0,
    "procurement": 0,
    "planning_and_analysis": 0,
    "risk": 0,
    "chemical": 0,
    "data_engineering": 6,
    "data_science": 1,
    "devops": 0,
    "electrical": 0,
    "hardware": 0,
    "industrial": 0,
    "information_technology": 0,
    "mechanical": 0,
    "network": 0,
    "qa_engineering": 0,
    "security": 1,
    "software": 9,
    "web": 0
  },
  "employee_count_by_class": {
    "other_uncategorized": 3,
    "services": 6,
    "general_and_administrative": 20,
    "sales_and_marketing": 26,
    "research_and_development": 32
  },
  "employee_count_by_month_by_level": {
    "2015-03": {
      "unpaid": 0,
      "cxo": 2,
      "partner": 0,
      "owner": 3,
      "director": 0,
      "vp": 0,
      "senior": 0,
      "manager": 0,
      "entry": 0,
      "training": 0
    },
    "2015-04": {
      "unpaid": 0,
      "cxo": 2,
      "partner": 0,
      "owner": 3,
      "director": 0,
      "vp": 0,
      "senior": 0,
      "manager": 0,
      "entry": 0,
      "training": 0
    },
    "2015-05": {
      "unpaid": 0,
      "cxo": 2,
      "partner": 0,
      "owner": 3,
      "director": 0,
      "vp": 0,
      "senior": 0,
      "manager": 0,
      "entry": 0,
      "training": 0
    },
    "2015-06": {
      "unpaid": 0,
      "cxo": 2,
      "partner": 0,
      "owner": 3,
      "director": 0,
      "vp": 0,
      "senior": 0,
      "manager": 0,
      "entry": 0,
      "training": 0
    },
    "2015-07": {
      "unpaid": 0,
      "cxo": 2,
      "partner": 0,
      "owner": 3,
      "director": 0,
      "vp": 0,
      "senior": 0,
      "manager": 0,
      "entry": 0,
      "training": 0
    },
    "2015-08": {
      "unpaid": 0,
      "cxo": 2,
      "partner": 0,
      "owner": 3,
      "director": 0,
      "vp": 1,
      "senior": 0,
      "manager": 0,
      "entry": 0,
      "training": 0
    },
    "2015-09": {
      "unpaid": 0,
      "cxo": 2,
      "partner": 0,
      "owner": 3,
      "director": 0,
      "vp": 1,
      "senior": 0,
      "manager": 0,
      "entry": 0,
      "training": 0
    },
    "2015-10": {
      "unpaid": 0,
      "cxo": 2,
      "partner": 0,
      "owner": 3,
      "director": 0,
      "vp": 1,
      "senior": 0,
      "manager": 0,
      "entry": 0,
      "training": 0
    },
    "2015-11": {
      "unpaid": 0,
      "cxo": 2,
      "partner": 0,
      "owner": 3,
      "director": 0,
      "vp": 1,
      "senior": 0,
      "manager": 0,
      "entry": 0,
      "training": 0
    },
    "2015-12": {
      "unpaid": 0,
      "cxo": 2,
      "partner": 0,
      "owner": 3,
      "director": 0,
      "vp": 1,
      "senior": 0,
      "manager": 0,
      "entry": 0,
      "training": 0
    },
    "2016-01": {
      "unpaid": 0,
      "cxo": 2,
      "partner": 0,
      "owner": 3,
      "director": 0,
      "vp": 1,
      "senior": 0,
      "manager": 0,
      "entry": 0,
      "training": 0
    },
    "2016-02": {
      "unpaid": 0,
      "cxo": 2,
      "partner": 0,
      "owner": 3,
      "director": 0,
      "vp": 3,
      "senior": 0,
      "manager": 0,
      "entry": 0,
      "training": 0
    },
    "2016-03": {
      "unpaid": 0,
      "cxo": 2,
      "partner": 0,
      "owner": 3,
      "director": 0,
      "vp": 3,
      "senior": 0,
      "manager": 0,
      "entry": 0,
      "training": 0
    },
    "2016-04": {
      "unpaid": 0,
      "cxo": 2,
      "partner": 0,
      "owner": 3,
      "director": 0,
      "vp": 3,
      "senior": 1,
      "manager": 0,
      "entry": 0,
      "training": 0
    },
    "2016-05": {
      "unpaid": 0,
      "cxo": 2,
      "partner": 0,
      "owner": 3,
      "director": 0,
      "vp": 3,
      "senior": 1,
      "manager": 0,
      "entry": 0,
      "training": 0
    },
    "2016-06": {
      "unpaid": 0,
      "cxo": 2,
      "partner": 0,
      "owner": 3,
      "director": 0,
      "vp": 3,
      "senior": 1,
      "manager": 0,
      "entry": 0,
      "training": 0
    },
    "2016-07": {
      "unpaid": 0,
      "cxo": 2,
      "partner": 0,
      "owner": 3,
      "director": 0,
      "vp": 3,
      "senior": 1,
      "manager": 0,
      "entry": 0,
      "training": 0
    },
    "2016-08": {
      "unpaid": 0,
      "cxo": 2,
      "partner": 0,
      "owner": 3,
      "director": 0,
      "vp": 3,
      "senior": 1,
      "manager": 0,
      "entry": 0,
      "training": 0
    },
    "2016-09": {
      "unpaid": 0,
      "cxo": 2,
      "partner": 0,
      "owner": 3,
      "director": 0,
      "vp": 3,
      "senior": 1,
      "manager": 0,
      "entry": 0,
      "training": 0
    },
    "2016-10": {
      "unpaid": 0,
      "cxo": 2,
      "partner": 0,
      "owner": 3,
      "director": 0,
      "vp": 3,
      "senior": 1,
      "manager": 0,
      "entry": 0,
      "training": 0
    },
    "2016-11": {
      "unpaid": 0,
      "cxo": 2,
      "partner": 0,
      "owner": 3,
      "director": 0,
      "vp": 3,
      "senior": 1,
      "manager": 0,
      "entry": 0,
      "training": 0
    },
    "2016-12": {
      "unpaid": 0,
      "cxo": 2,
      "partner": 0,
      "owner": 3,
      "director": 0,
      "vp": 3,
      "senior": 1,
      "manager": 0,
      "entry": 0,
      "training": 0
    },
    "2017-01": {
      "unpaid": 0,
      "cxo": 2,
      "partner": 0,
      "owner": 3,
      "director": 0,
      "vp": 3,
      "senior": 2,
      "manager": 0,
      "entry": 0,
      "training": 0
    },
    "2017-02": {
      "unpaid": 0,
      "cxo": 2,
      "partner": 0,
      "owner": 3,
      "director": 1,
      "vp": 3,
      "senior": 2,
      "manager": 0,
      "entry": 0,
      "training": 0
    },
    "2017-03": {
      "unpaid": 0,
      "cxo": 2,
      "partner": 0,
      "owner": 3,
      "director": 1,
      "vp": 3,
      "senior": 2,
      "manager": 0,
      "entry": 0,
      "training": 0
    },
    "2017-04": {
      "unpaid": 0,
      "cxo": 2,
      "partner": 0,
      "owner": 3,
      "director": 1,
      "vp": 3,
      "senior": 2,
      "manager": 0,
      "entry": 0,
      "training": 0
    },
    "2017-05": {
      "unpaid": 0,
      "cxo": 2,
      "partner": 0,
      "owner": 3,
      "director": 1,
      "vp": 3,
      "senior": 2,
      "manager": 0,
      "entry": 0,
      "training": 0
    },
    "2017-06": {
      "unpaid": 0,
      "cxo": 2,
      "partner": 0,
      "owner": 3,
      "director": 1,
      "vp": 3,
      "senior": 2,
      "manager": 1,
      "entry": 0,
      "training": 0
    },
    "2017-07": {
      "unpaid": 0,
      "cxo": 2,
      "partner": 0,
      "owner": 3,
      "director": 1,
      "vp": 3,
      "senior": 2,
      "manager": 1,
      "entry": 0,
      "training": 0
    },
    "2017-08": {
      "unpaid": 0,
      "cxo": 2,
      "partner": 0,
      "owner": 3,
      "director": 1,
      "vp": 3,
      "senior": 3,
      "manager": 1,
      "entry": 0,
      "training": 0
    },
    "2017-09": {
      "unpaid": 0,
      "cxo": 2,
      "partner": 0,
      "owner": 3,
      "director": 0,
      "vp": 3,
      "senior": 4,
      "manager": 1,
      "entry": 0,
      "training": 0
    },
    "2017-10": {
      "unpaid": 0,
      "cxo": 2,
      "partner": 0,
      "owner": 3,
      "director": 0,
      "vp": 3,
      "senior": 4,
      "manager": 1,
      "entry": 0,
      "training": 0
    },
    "2017-11": {
      "unpaid": 0,
      "cxo": 2,
      "partner": 0,
      "owner": 3,
      "director": 0,
      "vp": 3,
      "senior": 4,
      "manager": 1,
      "entry": 0,
      "training": 0
    },
    "2017-12": {
      "unpaid": 0,
      "cxo": 2,
      "partner": 0,
      "owner": 3,
      "director": 0,
      "vp": 1,
      "senior": 4,
      "manager": 1,
      "entry": 0,
      "training": 0
    },
    "2018-01": {
      "unpaid": 0,
      "cxo": 2,
      "partner": 0,
      "owner": 3,
      "director": 0,
      "vp": 1,
      "senior": 5,
      "manager": 1,
      "entry": 0,
      "training": 0
    },
    "2018-02": {
      "unpaid": 0,
      "cxo": 2,
      "partner": 0,
      "owner": 3,
      "director": 1,
      "vp": 1,
      "senior": 5,
      "manager": 1,
      "entry": 0,
      "training": 0
    },
    "2018-03": {
      "unpaid": 0,
      "cxo": 2,
      "partner": 0,
      "owner": 3,
      "director": 1,
      "vp": 1,
      "senior": 5,
      "manager": 1,
      "entry": 0,
      "training": 0
    },
    "2018-04": {
      "unpaid": 0,
      "cxo": 2,
      "partner": 0,
      "owner": 3,
      "director": 1,
      "vp": 1,
      "senior": 5,
      "manager": 1,
      "entry": 0,
      "training": 0
    },
    "2018-05": {
      "unpaid": 0,
      "cxo": 2,
      "partner": 0,
      "owner": 3,
      "director": 1,
      "vp": 1,
      "senior": 5,
      "manager": 1,
      "entry": 0,
      "training": 2
    },
    "2018-06": {
      "unpaid": 0,
      "cxo": 2,
      "partner": 0,
      "owner": 3,
      "director": 1,
      "vp": 1,
      "senior": 5,
      "manager": 1,
      "entry": 0,
      "training": 3
    },
    "2018-07": {
      "unpaid": 0,
      "cxo": 2,
      "partner": 0,
      "owner": 3,
      "director": 1,
      "vp": 1,
      "senior": 5,
      "manager": 1,
      "entry": 0,
      "training": 3
    },
    "2018-08": {
      "unpaid": 0,
      "cxo": 2,
      "partner": 0,
      "owner": 3,
      "director": 1,
      "vp": 1,
      "senior": 5,
      "manager": 1,
      "entry": 0,
      "training": 3
    },
    "2018-09": {
      "unpaid": 0,
      "cxo": 2,
      "partner": 0,
      "owner": 3,
      "director": 1,
      "vp": 1,
      "senior": 5,
      "manager": 2,
      "entry": 0,
      "training": 3
    },
    "2018-10": {
      "unpaid": 0,
      "cxo": 3,
      "partner": 0,
      "owner": 3,
      "director": 1,
      "vp": 1,
      "senior": 4,
      "manager": 2,
      "entry": 0,
      "training": 2
    },
    "2018-11": {
      "unpaid": 0,
      "cxo": 3,
      "partner": 0,
      "owner": 3,
      "director": 1,
      "vp": 1,
      "senior": 4,
      "manager": 2,
      "entry": 0,
      "training": 2
    },
    "2018-12": {
      "unpaid": 0,
      "cxo": 3,
      "partner": 0,
      "owner": 3,
      "director": 1,
      "vp": 1,
      "senior": 4,
      "manager": 2,
      "entry": 0,
      "training": 0
    },
    "2019-01": {
      "unpaid": 0,
      "cxo": 3,
      "partner": 0,
      "owner": 3,
      "director": 1,
      "vp": 1,
      "senior": 4,
      "manager": 2,
      "entry": 0,
      "training": 1
    },
    "2019-02": {
      "unpaid": 0,
      "cxo": 3,
      "partner": 0,
      "owner": 3,
      "director": 1,
      "vp": 1,
      "senior": 4,
      "manager": 2,
      "entry": 0,
      "training": 1
    },
    "2019-03": {
      "unpaid": 0,
      "cxo": 3,
      "partner": 0,
      "owner": 3,
      "director": 1,
      "vp": 1,
      "senior": 4,
      "manager": 2,
      "entry": 0,
      "training": 1
    },
    "2019-04": {
      "unpaid": 0,
      "cxo": 3,
      "partner": 0,
      "owner": 3,
      "director": 2,
      "vp": 1,
      "senior": 4,
      "manager": 1,
      "entry": 0,
      "training": 1
    },
    "2019-05": {
      "unpaid": 0,
      "cxo": 3,
      "partner": 0,
      "owner": 3,
      "director": 2,
      "vp": 1,
      "senior": 4,
      "manager": 2,
      "entry": 0,
      "training": 1
    },
    "2019-06": {
      "unpaid": 0,
      "cxo": 3,
      "partner": 0,
      "owner": 3,
      "director": 3,
      "vp": 1,
      "senior": 4,
      "manager": 1,
      "entry": 0,
      "training": 1
    },
    "2019-07": {
      "unpaid": 0,
      "cxo": 3,
      "partner": 0,
      "owner": 3,
      "director": 3,
      "vp": 1,
      "senior": 4,
      "manager": 1,
      "entry": 0,
      "training": 0
    },
    "2019-08": {
      "unpaid": 0,
      "cxo": 3,
      "partner": 0,
      "owner": 3,
      "director": 3,
      "vp": 1,
      "senior": 4,
      "manager": 1,
      "entry": 0,
      "training": 0
    },
    "2019-09": {
      "unpaid": 0,
      "cxo": 3,
      "partner": 0,
      "owner": 3,
      "director": 3,
      "vp": 1,
      "senior": 4,
      "manager": 1,
      "entry": 0,
      "training": 0
    },
    "2019-10": {
      "unpaid": 0,
      "cxo": 3,
      "partner": 0,
      "owner": 3,
      "director": 3,
      "vp": 1,
      "senior": 4,
      "manager": 1,
      "entry": 0,
      "training": 0
    },
    "2019-11": {
      "unpaid": 0,
      "cxo": 3,
      "partner": 0,
      "owner": 3,
      "director": 3,
      "vp": 1,
      "senior": 4,
      "manager": 1,
      "entry": 0,
      "training": 0
    },
    "2019-12": {
      "unpaid": 0,
      "cxo": 3,
      "partner": 0,
      "owner": 3,
      "director": 8,
      "vp": 1,
      "senior": 5,
      "manager": 1,
      "entry": 0,
      "training": 0
    },
    "2020-01": {
      "unpaid": 0,
      "cxo": 4,
      "partner": 0,
      "owner": 3,
      "director": 8,
      "vp": 1,
      "senior": 5,
      "manager": 3,
      "entry": 0,
      "training": 0
    },
    "2020-02": {
      "unpaid": 0,
      "cxo": 4,
      "partner": 0,
      "owner": 3,
      "director": 8,
      "vp": 1,
      "senior": 5,
      "manager": 3,
      "entry": 0,
      "training": 0
    },
    "2020-03": {
      "unpaid": 0,
      "cxo": 4,
      "partner": 0,
      "owner": 3,
      "director": 7,
      "vp": 1,
      "senior": 6,
      "manager": 2,
      "entry": 0,
      "training": 0
    },
    "2020-04": {
      "unpaid": 0,
      "cxo": 4,
      "partner": 0,
      "owner": 3,
      "director": 7,
      "vp": 1,
      "senior": 6,
      "manager": 2,
      "entry": 0,
      "training": 0
    },
    "2020-05": {
      "unpaid": 0,
      "cxo": 4,
      "partner": 0,
      "owner": 3,
      "director": 8,
      "vp": 1,
      "senior": 6,
      "manager": 2,
      "entry": 0,
      "training": 0
    },
    "2020-06": {
      "unpaid": 0,
      "cxo": 4,
      "partner": 0,
      "owner": 3,
      "director": 7,
      "vp": 1,
      "senior": 6,
      "manager": 3,
      "entry": 0,
      "training": 0
    },
    "2020-07": {
      "unpaid": 0,
      "cxo": 3,
      "partner": 0,
      "owner": 3,
      "director": 8,
      "vp": 1,
      "senior": 6,
      "manager": 5,
      "entry": 0,
      "training": 0
    },
    "2020-08": {
      "unpaid": 0,
      "cxo": 3,
      "partner": 0,
      "owner": 3,
      "director": 8,
      "vp": 1,
      "senior": 6,
      "manager": 6,
      "entry": 0,
      "training": 0
    },
    "2020-09": {
      "unpaid": 0,
      "cxo": 3,
      "partner": 0,
      "owner": 3,
      "director": 12,
      "vp": 1,
      "senior": 10,
      "manager": 5,
      "entry": 0,
      "training": 0
    },
    "2020-10": {
      "unpaid": 0,
      "cxo": 3,
      "partner": 0,
      "owner": 3,
      "director": 12,
      "vp": 1,
      "senior": 10,
      "manager": 6,
      "entry": 0,
      "training": 0
    },
    "2020-11": {
      "unpaid": 0,
      "cxo": 3,
      "partner": 0,
      "owner": 3,
      "director": 12,
      "vp": 1,
      "senior": 11,
      "manager": 6,
      "entry": 0,
      "training": 0
    },
    "2020-12": {
      "unpaid": 0,
      "cxo": 3,
      "partner": 0,
      "owner": 3,
      "director": 12,
      "vp": 2,
      "senior": 11,
      "manager": 8,
      "entry": 0,
      "training": 0
    },
    "2021-01": {
      "unpaid": 0,
      "cxo": 3,
      "partner": 0,
      "owner": 3,
      "director": 14,
      "vp": 3,
      "senior": 14,
      "manager": 11,
      "entry": 0,
      "training": 0
    },
    "2021-02": {
      "unpaid": 0,
      "cxo": 3,
      "partner": 0,
      "owner": 3,
      "director": 13,
      "vp": 3,
      "senior": 14,
      "manager": 16,
      "entry": 0,
      "training": 0
    },
    "2021-03": {
      "unpaid": 0,
      "cxo": 3,
      "partner": 0,
      "owner": 3,
      "director": 13,
      "vp": 3,
      "senior": 16,
      "manager": 21,
      "entry": 0,
      "training": 0
    },
    "2021-04": {
      "unpaid": 0,
      "cxo": 3,
      "partner": 0,
      "owner": 3,
      "director": 13,
      "vp": 3,
      "senior": 16,
      "manager": 22,
      "entry": 0,
      "training": 0
    },
    "2021-05": {
      "unpaid": 0,
      "cxo": 3,
      "partner": 0,
      "owner": 3,
      "director": 14,
      "vp": 3,
      "senior": 18,
      "manager": 23,
      "entry": 0,
      "training": 0
    },
    "2021-06": {
      "unpaid": 0,
      "cxo": 3,
      "partner": 0,
      "owner": 3,
      "director": 16,
      "vp": 3,
      "senior": 20,
      "manager": 21,
      "entry": 0,
      "training": 0
    },
    "2021-07": {
      "unpaid": 0,
      "cxo": 3,
      "partner": 0,
      "owner": 3,
      "director": 14,
      "vp": 5,
      "senior": 18,
      "manager": 21,
      "entry": 0,
      "training": 0
    },
    "2021-08": {
      "unpaid": 0,
      "cxo": 3,
      "partner": 0,
      "owner": 3,
      "director": 15,
      "vp": 5,
      "senior": 16,
      "manager": 23,
      "entry": 0,
      "training": 0
    },
    "2021-09": {
      "unpaid": 0,
      "cxo": 3,
      "partner": 0,
      "owner": 3,
      "director": 15,
      "vp": 5,
      "senior": 16,
      "manager": 23,
      "entry": 0,
      "training": 0
    },
    "2021-10": {
      "unpaid": 0,
      "cxo": 3,
      "partner": 0,
      "owner": 3,
      "director": 14,
      "vp": 6,
      "senior": 20,
      "manager": 22,
      "entry": 0,
      "training": 0
    },
    "2021-11": {
      "unpaid": 0,
      "cxo": 5,
      "partner": 0,
      "owner": 3,
      "director": 13,
      "vp": 4,
      "senior": 21,
      "manager": 22,
      "entry": 0,
      "training": 0
    },
    "2021-12": {
      "unpaid": 0,
      "cxo": 5,
      "partner": 0,
      "owner": 3,
      "director": 14,
      "vp": 5,
      "senior": 19,
      "manager": 22,
      "entry": 0,
      "training": 0
    },
    "2022-01": {
      "unpaid": 0,
      "cxo": 5,
      "partner": 0,
      "owner": 3,
      "director": 16,
      "vp": 5,
      "senior": 22,
      "manager": 26,
      "entry": 0,
      "training": 0
    },
    "2022-02": {
      "unpaid": 0,
      "cxo": 5,
      "partner": 0,
      "owner": 3,
      "director": 16,
      "vp": 5,
      "senior": 22,
      "manager": 28,
      "entry": 0,
      "training": 0
    },
    "2022-03": {
      "unpaid": 0,
      "cxo": 5,
      "partner": 0,
      "owner": 3,
      "director": 17,
      "vp": 6,
      "senior": 23,
      "manager": 27,
      "entry": 0,
      "training": 0
    },
    "2022-04": {
      "unpaid": 0,
      "cxo": 5,
      "partner": 0,
      "owner": 3,
      "director": 17,
      "vp": 6,
      "senior": 25,
      "manager": 27,
      "entry": 0,
      "training": 0
    },
    "2022-05": {
      "unpaid": 0,
      "cxo": 5,
      "partner": 0,
      "owner": 3,
      "director": 18,
      "vp": 6,
      "senior": 27,
      "manager": 29,
      "entry": 0,
      "training": 0
    },
    "2022-06": {
      "unpaid": 0,
      "cxo": 5,
      "partner": 0,
      "owner": 3,
      "director": 18,
      "vp": 6,
      "senior": 26,
      "manager": 28,
      "entry": 0,
      "training": 0
    },
    "2022-07": {
      "unpaid": 0,
      "cxo": 5,
      "partner": 0,
      "owner": 3,
      "director": 19,
      "vp": 6,
      "senior": 25,
      "manager": 32,
      "entry": 0,
      "training": 0
    },
    "2022-08": {
      "unpaid": 0,
      "cxo": 5,
      "partner": 0,
      "owner": 3,
      "director": 19,
      "vp": 6,
      "senior": 29,
      "manager": 31,
      "entry": 0,
      "training": 0
    },
    "2022-09": {
      "unpaid": 0,
      "cxo": 5,
      "partner": 0,
      "owner": 3,
      "director": 19,
      "vp": 6,
      "senior": 30,
      "manager": 30,
      "entry": 0,
      "training": 0
    },
    "2022-10": {
      "unpaid": 0,
      "cxo": 5,
      "partner": 0,
      "owner": 3,
      "director": 19,
      "vp": 5,
      "senior": 30,
      "manager": 31,
      "entry": 0,
      "training": 0
    },
    "2022-11": {
      "unpaid": 0,
      "cxo": 5,
      "partner": 0,
      "owner": 3,
      "director": 19,
      "vp": 5,
      "senior": 32,
      "manager": 31,
      "entry": 0,
      "training": 0
    },
    "2022-12": {
      "unpaid": 0,
      "cxo": 5,
      "partner": 0,
      "owner": 3,
      "director": 20,
      "vp": 4,
      "senior": 32,
      "manager": 32,
      "entry": 0,
      "training": 0
    },
    "2023-01": {
      "unpaid": 0,
      "cxo": 4,
      "partner": 0,
      "owner": 3,
      "director": 18,
      "vp": 5,
      "senior": 29,
      "manager": 25,
      "entry": 0,
      "training": 0
    },
    "2023-02": {
      "unpaid": 0,
      "cxo": 4,
      "partner": 0,
      "owner": 3,
      "director": 19,
      "vp": 5,
      "senior": 26,
      "manager": 26,
      "entry": 0,
      "training": 0
    },
    "2023-03": {
      "unpaid": 0,
      "cxo": 4,
      "partner": 0,
      "owner": 3,
      "director": 18,
      "vp": 5,
      "senior": 27,
      "manager": 26,
      "entry": 0,
      "training": 0
    },
    "2023-04": {
      "unpaid": 0,
      "cxo": 4,
      "partner": 0,
      "owner": 3,
      "director": 15,
      "vp": 3,
      "senior": 28,
      "manager": 29,
      "entry": 0,
      "training": 0
    },
    "2023-05": {
      "unpaid": 0,
      "cxo": 4,
      "partner": 0,
      "owner": 3,
      "director": 15,
      "vp": 3,
      "senior": 28,
      "manager": 29,
      "entry": 0,
      "training": 0
    },
    "2023-06": {
      "unpaid": 0,
      "cxo": 4,
      "partner": 0,
      "owner": 3,
      "director": 13,
      "vp": 3,
      "senior": 29,
      "manager": 30,
      "entry": 0,
      "training": 0
    },
    "2023-07": {
      "unpaid": 0,
      "cxo": 4,
      "partner": 0,
      "owner": 3,
      "director": 13,
      "vp": 3,
      "senior": 29,
      "manager": 29,
      "entry": 0,
      "training": 0
    },
    "2023-08": {
      "unpaid": 0,
      "cxo": 4,
      "partner": 0,
      "owner": 3,
      "director": 13,
      "vp": 3,
      "senior": 31,
      "manager": 29,
      "entry": 0,
      "training": 0
    },
    "2023-09": {
      "unpaid": 0,
      "cxo": 4,
      "partner": 0,
      "owner": 3,
      "director": 13,
      "vp": 3,
      "senior": 30,
      "manager": 28,
      "entry": 0,
      "training": 0
    },
    "2023-10": {
      "unpaid": 0,
      "cxo": 4,
      "partner": 0,
      "owner": 3,
      "director": 12,
      "vp": 3,
      "senior": 30,
      "manager": 28,
      "entry": 0,
      "training": 0
    },
    "2023-11": {
      "unpaid": 0,
      "cxo": 4,
      "partner": 0,
      "owner": 3,
      "director": 12,
      "vp": 3,
      "senior": 30,
      "manager": 27,
      "entry": 0,
      "training": 0
    },
    "2023-12": {
      "unpaid": 0,
      "cxo": 4,
      "partner": 0,
      "owner": 3,
      "director": 12,
      "vp": 4,
      "senior": 31,
      "manager": 26,
      "entry": 0,
      "training": 0
    },
    "2024-01": {
      "unpaid": 0,
      "cxo": 4,
      "partner": 0,
      "owner": 3,
      "director": 11,
      "vp": 4,
      "senior": 31,
      "manager": 26,
      "entry": 0,
      "training": 0
    },
    "2024-02": {
      "unpaid": 0,
      "cxo": 4,
      "partner": 0,
      "owner": 3,
      "director": 12,
      "vp": 4,
      "senior": 27,
      "manager": 26,
      "entry": 0,
      "training": 0
    },
    "2024-03": {
      "unpaid": 0,
      "cxo": 4,
      "partner": 0,
      "owner": 3,
      "director": 11,
      "vp": 4,
      "senior": 27,
      "manager": 26,
      "entry": 0,
      "training": 0
    },
    "2024-04": {
      "unpaid": 0,
      "cxo": 4,
      "partner": 0,
      "owner": 3,
      "director": 11,
      "vp": 4,
      "senior": 28,
      "manager": 25,
      "entry": 0,
      "training": 0
    },
    "2024-05": {
      "unpaid": 0,
      "cxo": 4,
      "partner": 0,
      "owner": 3,
      "director": 8,
      "vp": 4,
      "senior": 23,
      "manager": 24,
      "entry": 0,
      "training": 0
    },
    "2024-06": {
      "unpaid": 0,
      "cxo": 4,
      "partner": 0,
      "owner": 3,
      "director": 8,
      "vp": 4,
      "senior": 23,
      "manager": 24,
      "entry": 0,
      "training": 0
    },
    "2024-07": {
      "unpaid": 0,
      "cxo": 4,
      "partner": 0,
      "owner": 3,
      "director": 7,
      "vp": 4,
      "senior": 22,
      "manager": 24,
      "entry": 0,
      "training": 0
    },
    "2024-08": {
      "unpaid": 0,
      "cxo": 4,
      "partner": 0,
      "owner": 3,
      "director": 7,
      "vp": 4,
      "senior": 22,
      "manager": 24,
      "entry": 0,
      "training": 0
    },
    "2024-09": {
      "unpaid": 0,
      "cxo": 5,
      "partner": 0,
      "owner": 1,
      "director": 8,
      "vp": 3,
      "senior": 24,
      "manager": 23,
      "entry": 0,
      "training": 0
    },
    "2024-10": {
      "unpaid": 0,
      "cxo": 5,
      "partner": 0,
      "owner": 1,
      "director": 8,
      "vp": 3,
      "senior": 23,
      "manager": 23,
      "entry": 0,
      "training": 0
    },
    "2024-11": {
      "unpaid": 0,
      "cxo": 5,
      "partner": 0,
      "owner": 1,
      "director": 8,
      "vp": 3,
      "senior": 24,
      "manager": 21,
      "entry": 0,
      "training": 0
    },
    "2024-12": {
      "unpaid": 0,
      "cxo": 5,
      "partner": 0,
      "owner": 1,
      "director": 8,
      "vp": 3,
      "senior": 24,
      "manager": 21,
      "entry": 0,
      "training": 0
    },
    "2025-01": {
      "unpaid": 0,
      "cxo": 5,
      "partner": 0,
      "owner": 1,
      "director": 9,
      "vp": 3,
      "senior": 26,
      "manager": 23,
      "entry": 0,
      "training": 0
    },
    "2025-02": {
      "unpaid": 0,
      "cxo": 5,
      "partner": 0,
      "owner": 1,
      "director": 9,
      "vp": 3,
      "senior": 28,
      "manager": 23,
      "entry": 0,
      "training": 0
    },
    "2025-03": {
      "unpaid": 0,
      "cxo": 5,
      "partner": 0,
      "owner": 1,
      "director": 8,
      "vp": 3,
      "senior": 26,
      "manager": 22,
      "entry": 0,
      "training": 0
    },
    "2025-04": {
      "unpaid": 0,
      "cxo": 5,
      "partner": 0,
      "owner": 1,
      "director": 9,
      "vp": 3,
      "senior": 27,
      "manager": 21,
      "entry": 0,
      "training": 0
    },
    "2025-05": {
      "unpaid": 0,
      "cxo": 5,
      "partner": 0,
      "owner": 1,
      "director": 10,
      "vp": 3,
      "senior": 24,
      "manager": 21,
      "entry": 0,
      "training": 0
    },
    "2025-06": {
      "unpaid": 0,
      "cxo": 5,
      "partner": 0,
      "owner": 1,
      "director": 10,
      "vp": 3,
      "senior": 23,
      "manager": 23,
      "entry": 0,
      "training": 0
    },
    "2025-07": {
      "unpaid": 0,
      "cxo": 5,
      "partner": 0,
      "owner": 1,
      "director": 10,
      "vp": 3,
      "senior": 21,
      "manager": 23,
      "entry": 0,
      "training": 0
    },
    "2025-08": {
      "unpaid": 0,
      "cxo": 5,
      "partner": 0,
      "owner": 1,
      "director": 10,
      "vp": 3,
      "senior": 21,
      "manager": 22,
      "entry": 0,
      "training": 0
    },
    "2025-09": {
      "unpaid": 0,
      "cxo": 5,
      "partner": 0,
      "owner": 1,
      "director": 10,
      "vp": 3,
      "senior": 21,
      "manager": 22,
      "entry": 0,
      "training": 0
    },
    "2025-10": {
      "unpaid": 0,
      "cxo": 5,
      "partner": 0,
      "owner": 1,
      "director": 10,
      "vp": 3,
      "senior": 20,
      "manager": 21,
      "entry": 0,
      "training": 0
    },
    "2025-11": {
      "unpaid": 0,
      "cxo": 5,
      "partner": 0,
      "owner": 1,
      "director": 10,
      "vp": 3,
      "senior": 20,
      "manager": 21,
      "entry": 0,
      "training": 0
    },
    "2025-12": {
      "unpaid": 0,
      "cxo": 5,
      "partner": 0,
      "owner": 1,
      "director": 10,
      "vp": 3,
      "senior": 20,
      "manager": 21,
      "entry": 0,
      "training": 0
    },
    "2026-01": {
      "unpaid": 0,
      "cxo": 5,
      "partner": 0,
      "owner": 1,
      "director": 10,
      "vp": 3,
      "senior": 21,
      "manager": 21,
      "entry": 0,
      "training": 0
    }
  },
  "employee_count_by_month_by_role": {
    "2015-03": {
      "other_uncategorized": 0,
      "advisory": 0,
      "trade": 0,
      "manufacturing": 0,
      "hospitality": 0,
      "public_service": 0,
      "support": 0,
      "research": 0,
      "product": 0,
      "education": 0,
      "human_resources": 0,
      "legal": 0,
      "operations": 3,
      "fulfillment": 0,
      "professional_service": 0,
      "creative": 0,
      "marketing": 0,
      "partnerships": 0,
      "sales_engineering": 0,
      "sales": 0,
      "health": 0,
      "analyst": 0,
      "finance": 0,
      "engineering": 0
    },
    "2015-04": {
      "other_uncategorized": 0,
      "advisory": 0,
      "trade": 0,
      "manufacturing": 0,
      "hospitality": 0,
      "public_service": 0,
      "support": 0,
      "research": 0,
      "product": 0,
      "education": 0,
      "human_resources": 0,
      "legal": 0,
      "operations": 3,
      "fulfillment": 0,
      "professional_service": 0,
      "creative": 0,
      "marketing": 0,
      "partnerships": 0,
      "sales_engineering": 0,
      "sales": 0,
      "health": 0,
      "analyst": 0,
      "finance": 0,
      "engineering": 0
    },
    "2015-05": {
      "other_uncategorized": 0,
      "advisory": 0,
      "trade": 0,
      "manufacturing": 0,
      "hospitality": 0,
      "public_service": 0,
      "support": 0,
      "research": 0,
      "product": 0,
      "education": 0,
      "human_resources": 0,
      "legal": 0,
      "operations": 3,
      "fulfillment": 0,
      "professional_service": 0,
      "creative": 0,
      "marketing": 0,
      "partnerships": 0,
      "sales_engineering": 0,
      "sales": 0,
      "health": 0,
      "analyst": 0,
      "finance": 0,
      "engineering": 0
    },
    "2015-06": {
      "other_uncategorized": 0,
      "advisory": 0,
      "trade": 0,
      "manufacturing": 0,
      "hospitality": 0,
      "public_service": 0,
      "support": 0,
      "research": 0,
      "product": 0,
      "education": 0,
      "human_resources": 0,
      "legal": 0,
      "operations": 3,
      "fulfillment": 0,
      "professional_service": 0,
      "creative": 0,
      "marketing": 0,
      "partnerships": 0,
      "sales_engineering": 0,
      "sales": 0,
      "health": 0,
      "analyst": 0,
      "finance": 0,
      "engineering": 0
    },
    "2015-07": {
      "other_uncategorized": 0,
      "advisory": 0,
      "trade": 0,
      "manufacturing": 0,
      "hospitality": 0,
      "public_service": 0,
      "support": 0,
      "research": 0,
      "product": 0,
      "education": 0,
      "human_resources": 0,
      "legal": 0,
      "operations": 3,
      "fulfillment": 0,
      "professional_service": 0,
      "creative": 0,
      "marketing": 0,
      "partnerships": 1,
      "sales_engineering": 0,
      "sales": 0,
      "health": 0,
      "analyst": 0,
      "finance": 0,
      "engineering": 0
    },
    "2015-08": {
      "other_uncategorized": 1,
      "advisory": 0,
      "trade": 0,
      "manufacturing": 0,
      "hospitality": 0,
      "public_service": 0,
      "support": 0,
      "research": 0,
      "product": 0,
      "education": 0,
      "human_resources": 0,
      "legal": 0,
      "operations": 3,
      "fulfillment": 0,
      "professional_service": 0,
      "creative": 0,
      "marketing": 0,
      "partnerships": 1,
      "sales_engineering": 0,
      "sales": 0,
      "health": 0,
      "analyst": 0,
      "finance": 0,
      "engineering": 1
    },
    "2015-09": {
      "other_uncategorized": 1,
      "advisory": 0,
      "trade": 0,
      "manufacturing": 0,
      "hospitality": 0,
      "public_service": 0,
      "support": 0,
      "research": 0,
      "product": 0,
      "education": 0,
      "human_resources": 0,
      "legal": 0,
      "operations": 3,
      "fulfillment": 0,
      "professional_service": 0,
      "creative": 0,
      "marketing": 0,
      "partnerships": 1,
      "sales_engineering": 0,
      "sales": 0,
      "health": 0,
      "analyst": 0,
      "finance": 0,
      "engineering": 2
    },
    "2015-10": {
      "other_uncategorized": 1,
      "advisory": 0,
      "trade": 0,
      "manufacturing": 0,
      "hospitality": 0,
      "public_service": 0,
      "support": 0,
      "research": 0,
      "product": 0,
      "education": 0,
      "human_resources": 0,
      "legal": 0,
      "operations": 3,
      "fulfillment": 0,
      "professional_service": 0,
      "creative": 0,
      "marketing": 0,
      "partnerships": 1,
      "sales_engineering": 0,
      "sales": 0,
      "health": 0,
      "analyst": 0,
      "finance": 0,
      "engineering": 2
    },
    "2015-11": {
      "other_uncategorized": 1,
      "advisory": 0,
      "trade": 0,
      "manufacturing": 0,
      "hospitality": 0,
      "public_service": 0,
      "support": 0,
      "research": 0,
      "product": 0,
      "education": 0,
      "human_resources": 0,
      "legal": 0,
      "operations": 3,
      "fulfillment": 0,
      "professional_service": 0,
      "creative": 0,
      "marketing": 0,
      "partnerships": 1,
      "sales_engineering": 0,
      "sales": 0,
      "health": 0,
      "analyst": 0,
      "finance": 0,
      "engineering": 2
    },
    "2015-12": {
      "other_uncategorized": 1,
      "advisory": 0,
      "trade": 0,
      "manufacturing": 0,
      "hospitality": 0,
      "public_service": 0,
      "support": 0,
      "research": 0,
      "product": 0,
      "education": 0,
      "human_resources": 0,
      "legal": 0,
      "operations": 3,
      "fulfillment": 0,
      "professional_service": 0,
      "creative": 0,
      "marketing": 0,
      "partnerships": 1,
      "sales_engineering": 0,
      "sales": 0,
      "health": 0,
      "analyst": 0,
      "finance": 0,
      "engineering": 2
    },
    "2016-01": {
      "other_uncategorized": 1,
      "advisory": 0,
      "trade": 0,
      "manufacturing": 0,
      "hospitality": 0,
      "public_service": 0,
      "support": 0,
      "research": 0,
      "product": 0,
      "education": 0,
      "human_resources": 0,
      "legal": 0,
      "operations": 3,
      "fulfillment": 0,
      "professional_service": 0,
      "creative": 0,
      "marketing": 0,
      "partnerships": 1,
      "sales_engineering": 0,
      "sales": 0,
      "health": 0,
      "analyst": 0,
      "finance": 0,
      "engineering": 2
    },
    "2016-02": {
      "other_uncategorized": 1,
      "advisory": 0,
      "trade": 0,
      "manufacturing": 0,
      "hospitality": 0,
      "public_service": 0,
      "support": 0,
      "research": 0,
      "product": 0,
      "education": 0,
      "human_resources": 0,
      "legal": 0,
      "operations": 3,
      "fulfillment": 0,
      "professional_service": 0,
      "creative": 0,
      "marketing": 2,
      "partnerships": 1,
      "sales_engineering": 0,
      "sales": 0,
      "health": 0,
      "analyst": 0,
      "finance": 0,
      "engineering": 2
    },
    "2016-03": {
      "other_uncategorized": 1,
      "advisory": 0,
      "trade": 0,
      "manufacturing": 0,
      "hospitality": 0,
      "public_service": 0,
      "support": 0,
      "research": 0,
      "product": 0,
      "education": 0,
      "human_resources": 0,
      "legal": 0,
      "operations": 3,
      "fulfillment": 0,
      "professional_service": 0,
      "creative": 0,
      "marketing": 2,
      "partnerships": 1,
      "sales_engineering": 0,
      "sales": 0,
      "health": 0,
      "analyst": 0,
      "finance": 0,
      "engineering": 2
    },
    "2016-04": {
      "other_uncategorized": 1,
      "advisory": 0,
      "trade": 0,
      "manufacturing": 0,
      "hospitality": 0,
      "public_service": 0,
      "support": 0,
      "research": 0,
      "product": 0,
      "education": 0,
      "human_resources": 0,
      "legal": 0,
      "operations": 3,
      "fulfillment": 0,
      "professional_service": 0,
      "creative": 0,
      "marketing": 2,
      "partnerships": 1,
      "sales_engineering": 0,
      "sales": 1,
      "health": 0,
      "analyst": 0,
      "finance": 0,
      "engineering": 2
    },
    "2016-05": {
      "other_uncategorized": 1,
      "advisory": 0,
      "trade": 0,
      "manufacturing": 0,
      "hospitality": 0,
      "public_service": 0,
      "support": 0,
      "research": 0,
      "product": 0,
      "education": 0,
      "human_resources": 0,
      "legal": 0,
      "operations": 3,
      "fulfillment": 0,
      "professional_service": 0,
      "creative": 0,
      "marketing": 2,
      "partnerships": 1,
      "sales_engineering": 0,
      "sales": 1,
      "health": 0,
      "analyst": 0,
      "finance": 1,
      "engineering": 2
    },
    "2016-06": {
      "other_uncategorized": 1,
      "advisory": 0,
      "trade": 0,
      "manufacturing": 0,
      "hospitality": 0,
      "public_service": 0,
      "support": 0,
      "research": 0,
      "product": 0,
      "education": 0,
      "human_resources": 0,
      "legal": 0,
      "operations": 3,
      "fulfillment": 0,
      "professional_service": 0,
      "creative": 0,
      "marketing": 2,
      "partnerships": 1,
      "sales_engineering": 0,
      "sales": 1,
      "health": 0,
      "analyst": 0,
      "finance": 1,
      "engineering": 2
    },
    "2016-07": {
      "other_uncategorized": 1,
      "advisory": 0,
      "trade": 0,
      "manufacturing": 0,
      "hospitality": 0,
      "public_service": 0,
      "support": 0,
      "research": 0,
      "product": 0,
      "education": 0,
      "human_resources": 0,
      "legal": 0,
      "operations": 3,
      "fulfillment": 0,
      "professional_service": 0,
      "creative": 0,
      "marketing": 2,
      "partnerships": 1,
      "sales_engineering": 0,
      "sales": 1,
      "health": 0,
      "analyst": 0,
      "finance": 1,
      "engineering": 2
    },
    "2016-08": {
      "other_uncategorized": 1,
      "advisory": 0,
      "trade": 0,
      "manufacturing": 0,
      "hospitality": 0,
      "public_service": 0,
      "support": 0,
      "research": 0,
      "product": 0,
      "education": 0,
      "human_resources": 0,
      "legal": 0,
      "operations": 3,
      "fulfillment": 0,
      "professional_service": 0,
      "creative": 0,
      "marketing": 2,
      "partnerships": 1,
      "sales_engineering": 0,
      "sales": 1,
      "health": 0,
      "analyst": 0,
      "finance": 1,
      "engineering": 2
    },
    "2016-09": {
      "other_uncategorized": 1,
      "advisory": 0,
      "trade": 0,
      "manufacturing": 0,
      "hospitality": 0,
      "public_service": 0,
      "support": 0,
      "research": 0,
      "product": 0,
      "education": 0,
      "human_resources": 0,
      "legal": 0,
      "operations": 3,
      "fulfillment": 0,
      "professional_service": 0,
      "creative": 0,
      "marketing": 2,
      "partnerships": 1,
      "sales_engineering": 0,
      "sales": 1,
      "health": 0,
      "analyst": 0,
      "finance": 1,
      "engineering": 2
    },
    "2016-10": {
      "other_uncategorized": 1,
      "advisory": 0,
      "trade": 0,
      "manufacturing": 0,
      "hospitality": 0,
      "public_service": 0,
      "support": 0,
      "research": 0,
      "product": 0,
      "education": 0,
      "human_resources": 0,
      "legal": 0,
      "operations": 3,
      "fulfillment": 0,
      "professional_service": 0,
      "creative": 0,
      "marketing": 2,
      "partnerships": 1,
      "sales_engineering": 1,
      "sales": 1,
      "health": 0,
      "analyst": 0,
      "finance": 1,
      "engineering": 2
    },
    "2016-11": {
      "other_uncategorized": 1,
      "advisory": 0,
      "trade": 0,
      "manufacturing": 0,
      "hospitality": 0,
      "public_service": 0,
      "support": 0,
      "research": 0,
      "product": 0,
      "education": 0,
      "human_resources": 0,
      "legal": 0,
      "operations": 3,
      "fulfillment": 0,
      "professional_service": 0,
      "creative": 0,
      "marketing": 2,
      "partnerships": 1,
      "sales_engineering": 1,
      "sales": 1,
      "health": 0,
      "analyst": 0,
      "finance": 1,
      "engineering": 2
    },
    "2016-12": {
      "other_uncategorized": 1,
      "advisory": 0,
      "trade": 0,
      "manufacturing": 0,
      "hospitality": 0,
      "public_service": 0,
      "support": 0,
      "research": 0,
      "product": 0,
      "education": 0,
      "human_resources": 0,
      "legal": 0,
      "operations": 3,
      "fulfillment": 0,
      "professional_service": 0,
      "creative": 0,
      "marketing": 2,
      "partnerships": 1,
      "sales_engineering": 1,
      "sales": 1,
      "health": 0,
      "analyst": 0,
      "finance": 1,
      "engineering": 2
    },
    "2017-01": {
      "other_uncategorized": 1,
      "advisory": 0,
      "trade": 0,
      "manufacturing": 0,
      "hospitality": 0,
      "public_service": 0,
      "support": 0,
      "research": 0,
      "product": 0,
      "education": 0,
      "human_resources": 0,
      "legal": 0,
      "operations": 3,
      "fulfillment": 0,
      "professional_service": 0,
      "creative": 0,
      "marketing": 2,
      "partnerships": 1,
      "sales_engineering": 1,
      "sales": 1,
      "health": 0,
      "analyst": 0,
      "finance": 1,
      "engineering": 3
    },
    "2017-02": {
      "other_uncategorized": 1,
      "advisory": 0,
      "trade": 0,
      "manufacturing": 0,
      "hospitality": 0,
      "public_service": 0,
      "support": 0,
      "research": 0,
      "product": 0,
      "education": 0,
      "human_resources": 0,
      "legal": 0,
      "operations": 3,
      "fulfillment": 0,
      "professional_service": 0,
      "creative": 0,
      "marketing": 2,
      "partnerships": 1,
      "sales_engineering": 0,
      "sales": 1,
      "health": 0,
      "analyst": 0,
      "finance": 1,
      "engineering": 4
    },
    "2017-03": {
      "other_uncategorized": 1,
      "advisory": 0,
      "trade": 0,
      "manufacturing": 0,
      "hospitality": 0,
      "public_service": 0,
      "support": 0,
      "research": 0,
      "product": 0,
      "education": 0,
      "human_resources": 0,
      "legal": 0,
      "operations": 3,
      "fulfillment": 0,
      "professional_service": 0,
      "creative": 0,
      "marketing": 2,
      "partnerships": 1,
      "sales_engineering": 0,
      "sales": 1,
      "health": 0,
      "analyst": 0,
      "finance": 1,
      "engineering": 4
    },
    "2017-04": {
      "other_uncategorized": 1,
      "advisory": 0,
      "trade": 0,
      "manufacturing": 0,
      "hospitality": 0,
      "public_service": 0,
      "support": 0,
      "research": 0,
      "product": 0,
      "education": 0,
      "human_resources": 0,
      "legal": 0,
      "operations": 3,
      "fulfillment": 0,
      "professional_service": 0,
      "creative": 0,
      "marketing": 2,
      "partnerships": 2,
      "sales_engineering": 0,
      "sales": 1,
      "health": 0,
      "analyst": 0,
      "finance": 1,
      "engineering": 4
    },
    "2017-05": {
      "other_uncategorized": 1,
      "advisory": 0,
      "trade": 0,
      "manufacturing": 0,
      "hospitality": 0,
      "public_service": 0,
      "support": 0,
      "research": 0,
      "product": 0,
      "education": 0,
      "human_resources": 0,
      "legal": 0,
      "operations": 3,
      "fulfillment": 0,
      "professional_service": 0,
      "creative": 0,
      "marketing": 2,
      "partnerships": 2,
      "sales_engineering": 0,
      "sales": 1,
      "health": 0,
      "analyst": 1,
      "finance": 1,
      "engineering": 5
    },
    "2017-06": {
      "other_uncategorized": 1,
      "advisory": 0,
      "trade": 0,
      "manufacturing": 0,
      "hospitality": 0,
      "public_service": 0,
      "support": 0,
      "research": 0,
      "product": 0,
      "education": 0,
      "human_resources": 0,
      "legal": 0,
      "operations": 3,
      "fulfillment": 0,
      "professional_service": 0,
      "creative": 0,
      "marketing": 2,
      "partnerships": 2,
      "sales_engineering": 0,
      "sales": 1,
      "health": 0,
      "analyst": 1,
      "finance": 1,
      "engineering": 5
    },
    "2017-07": {
      "other_uncategorized": 1,
      "advisory": 0,
      "trade": 0,
      "manufacturing": 0,
      "hospitality": 0,
      "public_service": 0,
      "support": 0,
      "research": 0,
      "product": 0,
      "education": 0,
      "human_resources": 0,
      "legal": 0,
      "operations": 3,
      "fulfillment": 0,
      "professional_service": 0,
      "creative": 0,
      "marketing": 2,
      "partnerships": 2,
      "sales_engineering": 0,
      "sales": 1,
      "health": 0,
      "analyst": 1,
      "finance": 1,
      "engineering": 5
    },
    "2017-08": {
      "other_uncategorized": 1,
      "advisory": 0,
      "trade": 0,
      "manufacturing": 0,
      "hospitality": 0,
      "public_service": 0,
      "support": 0,
      "research": 0,
      "product": 0,
      "education": 0,
      "human_resources": 0,
      "legal": 0,
      "operations": 3,
      "fulfillment": 0,
      "professional_service": 0,
      "creative": 0,
      "marketing": 2,
      "partnerships": 2,
      "sales_engineering": 0,
      "sales": 1,
      "health": 0,
      "analyst": 0,
      "finance": 1,
      "engineering": 7
    },
    "2017-09": {
      "other_uncategorized": 1,
      "advisory": 0,
      "trade": 0,
      "manufacturing": 0,
      "hospitality": 0,
      "public_service": 0,
      "support": 0,
      "research": 0,
      "product": 0,
      "education": 0,
      "human_resources": 0,
      "legal": 0,
      "operations": 3,
      "fulfillment": 0,
      "professional_service": 0,
      "creative": 0,
      "marketing": 2,
      "partnerships": 2,
      "sales_engineering": 0,
      "sales": 2,
      "health": 0,
      "analyst": 0,
      "finance": 1,
      "engineering": 6
    },
    "2017-10": {
      "other_uncategorized": 1,
      "advisory": 0,
      "trade": 0,
      "manufacturing": 0,
      "hospitality": 0,
      "public_service": 0,
      "support": 0,
      "research": 0,
      "product": 0,
      "education": 0,
      "human_resources": 0,
      "legal": 0,
      "operations": 3,
      "fulfillment": 0,
      "professional_service": 0,
      "creative": 0,
      "marketing": 2,
      "partnerships": 2,
      "sales_engineering": 0,
      "sales": 2,
      "health": 0,
      "analyst": 0,
      "finance": 1,
      "engineering": 6
    },
    "2017-11": {
      "other_uncategorized": 1,
      "advisory": 0,
      "trade": 0,
      "manufacturing": 0,
      "hospitality": 0,
      "public_service": 0,
      "support": 0,
      "research": 0,
      "product": 0,
      "education": 0,
      "human_resources": 0,
      "legal": 0,
      "operations": 3,
      "fulfillment": 0,
      "professional_service": 0,
      "creative": 0,
      "marketing": 2,
      "partnerships": 2,
      "sales_engineering": 0,
      "sales": 2,
      "health": 0,
      "analyst": 0,
      "finance": 1,
      "engineering": 6
    },
    "2017-12": {
      "other_uncategorized": 1,
      "advisory": 0,
      "trade": 0,
      "manufacturing": 0,
      "hospitality": 0,
      "public_service": 0,
      "support": 0,
      "research": 0,
      "product": 0,
      "education": 0,
      "human_resources": 0,
      "legal": 0,
      "operations": 3,
      "fulfillment": 0,
      "professional_service": 0,
      "creative": 0,
      "marketing": 0,
      "partnerships": 2,
      "sales_engineering": 0,
      "sales": 2,
      "health": 0,
      "analyst": 0,
      "finance": 1,
      "engineering": 7
    },
    "2018-01": {
      "other_uncategorized": 1,
      "advisory": 0,
      "trade": 0,
      "manufacturing": 0,
      "hospitality": 0,
      "public_service": 0,
      "support": 0,
      "research": 0,
      "product": 0,
      "education": 0,
      "human_resources": 0,
      "legal": 0,
      "operations": 3,
      "fulfillment": 0,
      "professional_service": 0,
      "creative": 0,
      "marketing": 0,
      "partnerships": 1,
      "sales_engineering": 0,
      "sales": 4,
      "health": 0,
      "analyst": 1,
      "finance": 1,
      "engineering": 8
    },
    "2018-02": {
      "other_uncategorized": 1,
      "advisory": 0,
      "trade": 0,
      "manufacturing": 0,
      "hospitality": 0,
      "public_service": 0,
      "support": 0,
      "research": 0,
      "product": 0,
      "education": 0,
      "human_resources": 0,
      "legal": 0,
      "operations": 3,
      "fulfillment": 0,
      "professional_service": 0,
      "creative": 0,
      "marketing": 0,
      "partnerships": 1,
      "sales_engineering": 0,
      "sales": 4,
      "health": 0,
      "analyst": 1,
      "finance": 1,
      "engineering": 9
    },
    "2018-03": {
      "other_uncategorized": 1,
      "advisory": 0,
      "trade": 0,
      "manufacturing": 0,
      "hospitality": 0,
      "public_service": 0,
      "support": 0,
      "research": 0,
      "product": 0,
      "education": 0,
      "human_resources": 0,
      "legal": 0,
      "operations": 4,
      "fulfillment": 0,
      "professional_service": 0,
      "creative": 0,
      "marketing": 0,
      "partnerships": 0,
      "sales_engineering": 0,
      "sales": 4,
      "health": 0,
      "analyst": 1,
      "finance": 1,
      "engineering": 9
    },
    "2018-04": {
      "other_uncategorized": 1,
      "advisory": 0,
      "trade": 0,
      "manufacturing": 0,
      "hospitality": 0,
      "public_service": 0,
      "support": 0,
      "research": 0,
      "product": 0,
      "education": 0,
      "human_resources": 0,
      "legal": 0,
      "operations": 4,
      "fulfillment": 0,
      "professional_service": 0,
      "creative": 0,
      "marketing": 0,
      "partnerships": 0,
      "sales_engineering": 0,
      "sales": 4,
      "health": 0,
      "analyst": 1,
      "finance": 1,
      "engineering": 9
    },
    "2018-05": {
      "other_uncategorized": 1,
      "advisory": 0,
      "trade": 0,
      "manufacturing": 0,
      "hospitality": 0,
      "public_service": 0,
      "support": 0,
      "research": 0,
      "product": 0,
      "education": 0,
      "human_resources": 0,
      "legal": 0,
      "operations": 4,
      "fulfillment": 0,
      "professional_service": 0,
      "creative": 0,
      "marketing": 0,
      "partnerships": 0,
      "sales_engineering": 0,
      "sales": 4,
      "health": 0,
      "analyst": 1,
      "finance": 1,
      "engineering": 11
    },
    "2018-06": {
      "other_uncategorized": 1,
      "advisory": 0,
      "trade": 0,
      "manufacturing": 0,
      "hospitality": 0,
      "public_service": 0,
      "support": 0,
      "research": 0,
      "product": 0,
      "education": 0,
      "human_resources": 0,
      "legal": 0,
      "operations": 4,
      "fulfillment": 0,
      "professional_service": 0,
      "creative": 0,
      "marketing": 0,
      "partnerships": 0,
      "sales_engineering": 0,
      "sales": 4,
      "health": 0,
      "analyst": 2,
      "finance": 1,
      "engineering": 12
    },
    "2018-07": {
      "other_uncategorized": 1,
      "advisory": 0,
      "trade": 0,
      "manufacturing": 0,
      "hospitality": 0,
      "public_service": 0,
      "support": 0,
      "research": 0,
      "product": 0,
      "education": 0,
      "human_resources": 0,
      "legal": 0,
      "operations": 4,
      "fulfillment": 0,
      "professional_service": 0,
      "creative": 0,
      "marketing": 0,
      "partnerships": 1,
      "sales_engineering": 0,
      "sales": 4,
      "health": 0,
      "analyst": 2,
      "finance": 1,
      "engineering": 12
    },
    "2018-08": {
      "other_uncategorized": 1,
      "advisory": 0,
      "trade": 0,
      "manufacturing": 0,
      "hospitality": 0,
      "public_service": 0,
      "support": 0,
      "research": 0,
      "product": 0,
      "education": 0,
      "human_resources": 0,
      "legal": 0,
      "operations": 4,
      "fulfillment": 0,
      "professional_service": 0,
      "creative": 0,
      "marketing": 0,
      "partnerships": 1,
      "sales_engineering": 0,
      "sales": 4,
      "health": 0,
      "analyst": 2,
      "finance": 1,
      "engineering": 12
    },
    "2018-09": {
      "other_uncategorized": 1,
      "advisory": 0,
      "trade": 0,
      "manufacturing": 0,
      "hospitality": 0,
      "public_service": 0,
      "support": 0,
      "research": 0,
      "product": 0,
      "education": 0,
      "human_resources": 0,
      "legal": 0,
      "operations": 4,
      "fulfillment": 0,
      "professional_service": 0,
      "creative": 0,
      "marketing": 1,
      "partnerships": 1,
      "sales_engineering": 0,
      "sales": 4,
      "health": 0,
      "analyst": 1,
      "finance": 1,
      "engineering": 12
    },
    "2018-10": {
      "other_uncategorized": 1,
      "advisory": 0,
      "trade": 0,
      "manufacturing": 0,
      "hospitality": 0,
      "public_service": 0,
      "support": 0,
      "research": 0,
      "product": 0,
      "education": 0,
      "human_resources": 0,
      "legal": 0,
      "operations": 4,
      "fulfillment": 0,
      "professional_service": 0,
      "creative": 0,
      "marketing": 2,
      "partnerships": 1,
      "sales_engineering": 0,
      "sales": 4,
      "health": 0,
      "analyst": 0,
      "finance": 1,
      "engineering": 14
    },
    "2018-11": {
      "other_uncategorized": 1,
      "advisory": 0,
      "trade": 0,
      "manufacturing": 0,
      "hospitality": 0,
      "public_service": 0,
      "support": 0,
      "research": 0,
      "product": 0,
      "education": 0,
      "human_resources": 0,
      "legal": 0,
      "operations": 4,
      "fulfillment": 0,
      "professional_service": 0,
      "creative": 0,
      "marketing": 2,
      "partnerships": 1,
      "sales_engineering": 0,
      "sales": 5,
      "health": 0,
      "analyst": 0,
      "finance": 1,
      "engineering": 16
    },
    "2018-12": {
      "other_uncategorized": 1,
      "advisory": 0,
      "trade": 0,
      "manufacturing": 0,
      "hospitality": 0,
      "public_service": 0,
      "support": 0,
      "research": 0,
      "product": 0,
      "education": 0,
      "human_resources": 0,
      "legal": 0,
      "operations": 4,
      "fulfillment": 0,
      "professional_service": 0,
      "creative": 0,
      "marketing": 2,
      "partnerships": 0,
      "sales_engineering": 0,
      "sales": 6,
      "health": 0,
      "analyst": 0,
      "finance": 1,
      "engineering": 14
    },
    "2019-01": {
      "other_uncategorized": 1,
      "advisory": 0,
      "trade": 0,
      "manufacturing": 0,
      "hospitality": 0,
      "public_service": 0,
      "support": 0,
      "research": 0,
      "product": 0,
      "education": 0,
      "human_resources": 0,
      "legal": 0,
      "operations": 5,
      "fulfillment": 0,
      "professional_service": 0,
      "creative": 0,
      "marketing": 3,
      "partnerships": 0,
      "sales_engineering": 0,
      "sales": 7,
      "health": 0,
      "analyst": 1,
      "finance": 1,
      "engineering": 20
    },
    "2019-02": {
      "other_uncategorized": 1,
      "advisory": 0,
      "trade": 0,
      "manufacturing": 0,
      "hospitality": 0,
      "public_service": 0,
      "support": 0,
      "research": 0,
      "product": 0,
      "education": 0,
      "human_resources": 0,
      "legal": 0,
      "operations": 5,
      "fulfillment": 0,
      "professional_service": 0,
      "creative": 0,
      "marketing": 3,
      "partnerships": 0,
      "sales_engineering": 0,
      "sales": 7,
      "health": 0,
      "analyst": 1,
      "finance": 1,
      "engineering": 21
    },
    "2019-03": {
      "other_uncategorized": 1,
      "advisory": 0,
      "trade": 0,
      "manufacturing": 0,
      "hospitality": 0,
      "public_service": 0,
      "support": 0,
      "research": 0,
      "product": 0,
      "education": 0,
      "human_resources": 0,
      "legal": 0,
      "operations": 5,
      "fulfillment": 0,
      "professional_service": 0,
      "creative": 0,
      "marketing": 3,
      "partnerships": 0,
      "sales_engineering": 0,
      "sales": 10,
      "health": 0,
      "analyst": 1,
      "finance": 1,
      "engineering": 21
    },
    "2019-04": {
      "other_uncategorized": 1,
      "advisory": 0,
      "trade": 0,
      "manufacturing": 0,
      "hospitality": 0,
      "public_service": 0,
      "support": 0,
      "research": 0,
      "product": 0,
      "education": 0,
      "human_resources": 0,
      "legal": 0,
      "operations": 5,
      "fulfillment": 0,
      "professional_service": 0,
      "creative": 0,
      "marketing": 3,
      "partnerships": 0,
      "sales_engineering": 0,
      "sales": 10,
      "health": 0,
      "analyst": 1,
      "finance": 1,
      "engineering": 23
    },
    "2019-05": {
      "other_uncategorized": 1,
      "advisory": 0,
      "trade": 0,
      "manufacturing": 0,
      "hospitality": 0,
      "public_service": 0,
      "support": 0,
      "research": 0,
      "product": 0,
      "education": 0,
      "human_resources": 0,
      "legal": 0,
      "operations": 5,
      "fulfillment": 0,
      "professional_service": 0,
      "creative": 0,
      "marketing": 3,
      "partnerships": 0,
      "sales_engineering": 0,
      "sales": 10,
      "health": 0,
      "analyst": 1,
      "finance": 1,
      "engineering": 23
    },
    "2019-06": {
      "other_uncategorized": 1,
      "advisory": 0,
      "trade": 0,
      "manufacturing": 0,
      "hospitality": 0,
      "public_service": 0,
      "support": 0,
      "research": 0,
      "product": 0,
      "education": 0,
      "human_resources": 0,
      "legal": 0,
      "operations": 5,
      "fulfillment": 0,
      "professional_service": 0,
      "creative": 0,
      "marketing": 1,
      "partnerships": 0,
      "sales_engineering": 0,
      "sales": 11,
      "health": 0,
      "analyst": 1,
      "finance": 1,
      "engineering": 23
    },
    "2019-07": {
      "other_uncategorized": 1,
      "advisory": 0,
      "trade": 0,
      "manufacturing": 0,
      "hospitality": 0,
      "public_service": 0,
      "support": 0,
      "research": 0,
      "product": 0,
      "education": 0,
      "human_resources": 0,
      "legal": 0,
      "operations": 5,
      "fulfillment": 0,
      "professional_service": 0,
      "creative": 0,
      "marketing": 0,
      "partnerships": 0,
      "sales_engineering": 0,
      "sales": 11,
      "health": 0,
      "analyst": 1,
      "finance": 1,
      "engineering": 22
    },
    "2019-08": {
      "other_uncategorized": 1,
      "advisory": 0,
      "trade": 0,
      "manufacturing": 0,
      "hospitality": 0,
      "public_service": 0,
      "support": 0,
      "research": 0,
      "product": 0,
      "education": 0,
      "human_resources": 0,
      "legal": 0,
      "operations": 5,
      "fulfillment": 0,
      "professional_service": 0,
      "creative": 0,
      "marketing": 0,
      "partnerships": 0,
      "sales_engineering": 0,
      "sales": 11,
      "health": 0,
      "analyst": 1,
      "finance": 1,
      "engineering": 22
    },
    "2019-09": {
      "other_uncategorized": 1,
      "advisory": 0,
      "trade": 0,
      "manufacturing": 0,
      "hospitality": 0,
      "public_service": 0,
      "support": 0,
      "research": 0,
      "product": 0,
      "education": 0,
      "human_resources": 0,
      "legal": 0,
      "operations": 5,
      "fulfillment": 0,
      "professional_service": 0,
      "creative": 0,
      "marketing": 0,
      "partnerships": 0,
      "sales_engineering": 0,
      "sales": 11,
      "health": 0,
      "analyst": 1,
      "finance": 1,
      "engineering": 22
    },
    "2019-10": {
      "other_uncategorized": 1,
      "advisory": 0,
      "trade": 0,
      "manufacturing": 0,
      "hospitality": 0,
      "public_service": 0,
      "support": 0,
      "research": 0,
      "product": 0,
      "education": 0,
      "human_resources": 0,
      "legal": 0,
      "operations": 5,
      "fulfillment": 0,
      "professional_service": 0,
      "creative": 0,
      "marketing": 0,
      "partnerships": 0,
      "sales_engineering": 0,
      "sales": 11,
      "health": 0,
      "analyst": 1,
      "finance": 1,
      "engineering": 22
    },
    "2019-11": {
      "other_uncategorized": 1,
      "advisory": 0,
      "trade": 0,
      "manufacturing": 0,
      "hospitality": 0,
      "public_service": 0,
      "support": 0,
      "research": 0,
      "product": 0,
      "education": 0,
      "human_resources": 0,
      "legal": 0,
      "operations": 5,
      "fulfillment": 0,
      "professional_service": 0,
      "creative": 0,
      "marketing": 0,
      "partnerships": 0,
      "sales_engineering": 0,
      "sales": 12,
      "health": 0,
      "analyst": 1,
      "finance": 1,
      "engineering": 22
    },
    "2019-12": {
      "other_uncategorized": 1,
      "advisory": 0,
      "trade": 0,
      "manufacturing": 0,
      "hospitality": 0,
      "public_service": 0,
      "support": 0,
      "research": 0,
      "product": 0,
      "education": 0,
      "human_resources": 0,
      "legal": 0,
      "operations": 5,
      "fulfillment": 0,
      "professional_service": 0,
      "creative": 0,
      "marketing": 0,
      "partnerships": 0,
      "sales_engineering": 0,
      "sales": 13,
      "health": 0,
      "analyst": 1,
      "finance": 1,
      "engineering": 23
    },
    "2020-01": {
      "other_uncategorized": 1,
      "advisory": 0,
      "trade": 0,
      "manufacturing": 0,
      "hospitality": 0,
      "public_service": 0,
      "support": 1,
      "research": 0,
      "product": 1,
      "education": 0,
      "human_resources": 0,
      "legal": 0,
      "operations": 5,
      "fulfillment": 0,
      "professional_service": 0,
      "creative": 0,
      "marketing": 0,
      "partnerships": 0,
      "sales_engineering": 0,
      "sales": 16,
      "health": 0,
      "analyst": 1,
      "finance": 1,
      "engineering": 23
    },
    "2020-02": {
      "other_uncategorized": 1,
      "advisory": 0,
      "trade": 0,
      "manufacturing": 0,
      "hospitality": 0,
      "public_service": 0,
      "support": 1,
      "research": 0,
      "product": 1,
      "education": 0,
      "human_resources": 0,
      "legal": 0,
      "operations": 4,
      "fulfillment": 1,
      "professional_service": 0,
      "creative": 0,
      "marketing": 0,
      "partnerships": 0,
      "sales_engineering": 0,
      "sales": 16,
      "health": 0,
      "analyst": 1,
      "finance": 1,
      "engineering": 23
    },
    "2020-03": {
      "other_uncategorized": 1,
      "advisory": 0,
      "trade": 0,
      "manufacturing": 0,
      "hospitality": 0,
      "public_service": 0,
      "support": 1,
      "research": 0,
      "product": 1,
      "education": 0,
      "human_resources": 0,
      "legal": 0,
      "operations": 4,
      "fulfillment": 1,
      "professional_service": 0,
      "creative": 0,
      "marketing": 0,
      "partnerships": 0,
      "sales_engineering": 0,
      "sales": 17,
      "health": 0,
      "analyst": 1,
      "finance": 1,
      "engineering": 23
    },
    "2020-04": {
      "other_uncategorized": 1,
      "advisory": 0,
      "trade": 0,
      "manufacturing": 0,
      "hospitality": 0,
      "public_service": 0,
      "support": 1,
      "research": 0,
      "product": 2,
      "education": 0,
      "human_resources": 0,
      "legal": 0,
      "operations": 4,
      "fulfillment": 1,
      "professional_service": 0,
      "creative": 0,
      "marketing": 0,
      "partnerships": 0,
      "sales_engineering": 0,
      "sales": 16,
      "health": 0,
      "analyst": 1,
      "finance": 1,
      "engineering": 22
    },
    "2020-05": {
      "other_uncategorized": 1,
      "advisory": 0,
      "trade": 0,
      "manufacturing": 0,
      "hospitality": 0,
      "public_service": 0,
      "support": 1,
      "research": 0,
      "product": 2,
      "education": 0,
      "human_resources": 0,
      "legal": 0,
      "operations": 4,
      "fulfillment": 1,
      "professional_service": 0,
      "creative": 0,
      "marketing": 0,
      "partnerships": 0,
      "sales_engineering": 0,
      "sales": 14,
      "health": 0,
      "analyst": 1,
      "finance": 1,
      "engineering": 22
    },
    "2020-06": {
      "other_uncategorized": 1,
      "advisory": 0,
      "trade": 0,
      "manufacturing": 0,
      "hospitality": 0,
      "public_service": 0,
      "support": 1,
      "research": 0,
      "product": 2,
      "education": 0,
      "human_resources": 0,
      "legal": 0,
      "operations": 5,
      "fulfillment": 1,
      "professional_service": 0,
      "creative": 0,
      "marketing": 0,
      "partnerships": 0,
      "sales_engineering": 0,
      "sales": 13,
      "health": 0,
      "analyst": 1,
      "finance": 2,
      "engineering": 23
    },
    "2020-07": {
      "other_uncategorized": 1,
      "advisory": 0,
      "trade": 0,
      "manufacturing": 0,
      "hospitality": 0,
      "public_service": 0,
      "support": 1,
      "research": 0,
      "product": 2,
      "education": 0,
      "human_resources": 0,
      "legal": 0,
      "operations": 5,
      "fulfillment": 1,
      "professional_service": 0,
      "creative": 0,
      "marketing": 1,
      "partnerships": 0,
      "sales_engineering": 0,
      "sales": 15,
      "health": 0,
      "analyst": 1,
      "finance": 2,
      "engineering": 22
    },
    "2020-08": {
      "other_uncategorized": 1,
      "advisory": 0,
      "trade": 0,
      "manufacturing": 0,
      "hospitality": 0,
      "public_service": 0,
      "support": 1,
      "research": 0,
      "product": 2,
      "education": 0,
      "human_resources": 0,
      "legal": 0,
      "operations": 5,
      "fulfillment": 1,
      "professional_service": 0,
      "creative": 0,
      "marketing": 1,
      "partnerships": 0,
      "sales_engineering": 0,
      "sales": 13,
      "health": 0,
      "analyst": 1,
      "finance": 2,
      "engineering": 22
    },
    "2020-09": {
      "other_uncategorized": 1,
      "advisory": 0,
      "trade": 0,
      "manufacturing": 0,
      "hospitality": 0,
      "public_service": 0,
      "support": 2,
      "research": 1,
      "product": 4,
      "education": 0,
      "human_resources": 0,
      "legal": 0,
      "operations": 5,
      "fulfillment": 1,
      "professional_service": 0,
      "creative": 0,
      "marketing": 1,
      "partnerships": 0,
      "sales_engineering": 0,
      "sales": 14,
      "health": 0,
      "analyst": 1,
      "finance": 2,
      "engineering": 22
    },
    "2020-10": {
      "other_uncategorized": 1,
      "advisory": 0,
      "trade": 0,
      "manufacturing": 0,
      "hospitality": 0,
      "public_service": 0,
      "support": 2,
      "research": 1,
      "product": 4,
      "education": 0,
      "human_resources": 1,
      "legal": 0,
      "operations": 5,
      "fulfillment": 1,
      "professional_service": 0,
      "creative": 0,
      "marketing": 1,
      "partnerships": 0,
      "sales_engineering": 0,
      "sales": 14,
      "health": 0,
      "analyst": 1,
      "finance": 2,
      "engineering": 22
    },
    "2020-11": {
      "other_uncategorized": 1,
      "advisory": 0,
      "trade": 0,
      "manufacturing": 0,
      "hospitality": 0,
      "public_service": 0,
      "support": 2,
      "research": 1,
      "product": 4,
      "education": 0,
      "human_resources": 1,
      "legal": 0,
      "operations": 5,
      "fulfillment": 1,
      "professional_service": 0,
      "creative": 1,
      "marketing": 1,
      "partnerships": 0,
      "sales_engineering": 0,
      "sales": 14,
      "health": 0,
      "analyst": 1,
      "finance": 2,
      "engineering": 23
    },
    "2020-12": {
      "other_uncategorized": 1,
      "advisory": 0,
      "trade": 0,
      "manufacturing": 0,
      "hospitality": 0,
      "public_service": 0,
      "support": 2,
      "research": 1,
      "product": 5,
      "education": 0,
      "human_resources": 1,
      "legal": 0,
      "operations": 5,
      "fulfillment": 1,
      "professional_service": 0,
      "creative": 1,
      "marketing": 0,
      "partnerships": 0,
      "sales_engineering": 0,
      "sales": 16,
      "health": 0,
      "analyst": 1,
      "finance": 2,
      "engineering": 23
    },
    "2021-01": {
      "other_uncategorized": 3,
      "advisory": 0,
      "trade": 0,
      "manufacturing": 0,
      "hospitality": 0,
      "public_service": 0,
      "support": 3,
      "research": 1,
      "product": 4,
      "education": 0,
      "human_resources": 3,
      "legal": 0,
      "operations": 5,
      "fulfillment": 1,
      "professional_service": 0,
      "creative": 1,
      "marketing": 1,
      "partnerships": 0,
      "sales_engineering": 0,
      "sales": 19,
      "health": 0,
      "analyst": 0,
      "finance": 2,
      "engineering": 23
    },
    "2021-02": {
      "other_uncategorized": 3,
      "advisory": 0,
      "trade": 0,
      "manufacturing": 0,
      "hospitality": 0,
      "public_service": 0,
      "support": 3,
      "research": 1,
      "product": 4,
      "education": 0,
      "human_resources": 3,
      "legal": 0,
      "operations": 6,
      "fulfillment": 1,
      "professional_service": 0,
      "creative": 1,
      "marketing": 2,
      "partnerships": 0,
      "sales_engineering": 2,
      "sales": 19,
      "health": 0,
      "analyst": 1,
      "finance": 2,
      "engineering": 22
    },
    "2021-03": {
      "other_uncategorized": 3,
      "advisory": 0,
      "trade": 0,
      "manufacturing": 0,
      "hospitality": 0,
      "public_service": 0,
      "support": 4,
      "research": 1,
      "product": 4,
      "education": 0,
      "human_resources": 3,
      "legal": 0,
      "operations": 6,
      "fulfillment": 1,
      "professional_service": 0,
      "creative": 1,
      "marketing": 2,
      "partnerships": 0,
      "sales_engineering": 3,
      "sales": 21,
      "health": 0,
      "analyst": 1,
      "finance": 2,
      "engineering": 25
    },
    "2021-04": {
      "other_uncategorized": 3,
      "advisory": 0,
      "trade": 0,
      "manufacturing": 0,
      "hospitality": 0,
      "public_service": 0,
      "support": 4,
      "research": 1,
      "product": 4,
      "education": 0,
      "human_resources": 3,
      "legal": 0,
      "operations": 6,
      "fulfillment": 1,
      "professional_service": 0,
      "creative": 1,
      "marketing": 3,
      "partnerships": 0,
      "sales_engineering": 3,
      "sales": 21,
      "health": 0,
      "analyst": 1,
      "finance": 2,
      "engineering": 26
    },
    "2021-05": {
      "other_uncategorized": 3,
      "advisory": 0,
      "trade": 0,
      "manufacturing": 0,
      "hospitality": 0,
      "public_service": 0,
      "support": 4,
      "research": 1,
      "product": 4,
      "education": 0,
      "human_resources": 4,
      "legal": 0,
      "operations": 6,
      "fulfillment": 1,
      "professional_service": 0,
      "creative": 1,
      "marketing": 4,
      "partnerships": 0,
      "sales_engineering": 3,
      "sales": 22,
      "health": 0,
      "analyst": 1,
      "finance": 2,
      "engineering": 27
    },
    "2021-06": {
      "other_uncategorized": 3,
      "advisory": 0,
      "trade": 0,
      "manufacturing": 0,
      "hospitality": 0,
      "public_service": 0,
      "support": 5,
      "research": 1,
      "product": 4,
      "education": 0,
      "human_resources": 4,
      "legal": 0,
      "operations": 6,
      "fulfillment": 1,
      "professional_service": 0,
      "creative": 1,
      "marketing": 4,
      "partnerships": 0,
      "sales_engineering": 3,
      "sales": 22,
      "health": 0,
      "analyst": 1,
      "finance": 2,
      "engineering": 29
    },
    "2021-07": {
      "other_uncategorized": 3,
      "advisory": 0,
      "trade": 0,
      "manufacturing": 0,
      "hospitality": 0,
      "public_service": 0,
      "support": 5,
      "research": 1,
      "product": 4,
      "education": 0,
      "human_resources": 4,
      "legal": 0,
      "operations": 6,
      "fulfillment": 1,
      "professional_service": 0,
      "creative": 1,
      "marketing": 5,
      "partnerships": 1,
      "sales_engineering": 3,
      "sales": 22,
      "health": 0,
      "analyst": 1,
      "finance": 2,
      "engineering": 29
    },
    "2021-08": {
      "other_uncategorized": 3,
      "advisory": 0,
      "trade": 0,
      "manufacturing": 0,
      "hospitality": 0,
      "public_service": 0,
      "support": 5,
      "research": 1,
      "product": 4,
      "education": 0,
      "human_resources": 4,
      "legal": 0,
      "operations": 7,
      "fulfillment": 1,
      "professional_service": 0,
      "creative": 1,
      "marketing": 5,
      "partnerships": 1,
      "sales_engineering": 2,
      "sales": 23,
      "health": 0,
      "analyst": 1,
      "finance": 2,
      "engineering": 29
    },
    "2021-09": {
      "other_uncategorized": 3,
      "advisory": 0,
      "trade": 0,
      "manufacturing": 0,
      "hospitality": 0,
      "public_service": 0,
      "support": 5,
      "research": 1,
      "product": 4,
      "education": 0,
      "human_resources": 4,
      "legal": 0,
      "operations": 7,
      "fulfillment": 1,
      "professional_service": 0,
      "creative": 1,
      "marketing": 5,
      "partnerships": 1,
      "sales_engineering": 2,
      "sales": 23,
      "health": 0,
      "analyst": 1,
      "finance": 2,
      "engineering": 29
    },
    "2021-10": {
      "other_uncategorized": 3,
      "advisory": 0,
      "trade": 0,
      "manufacturing": 0,
      "hospitality": 0,
      "public_service": 0,
      "support": 5,
      "research": 1,
      "product": 5,
      "education": 0,
      "human_resources": 5,
      "legal": 0,
      "operations": 7,
      "fulfillment": 1,
      "professional_service": 0,
      "creative": 1,
      "marketing": 5,
      "partnerships": 2,
      "sales_engineering": 3,
      "sales": 22,
      "health": 0,
      "analyst": 1,
      "finance": 2,
      "engineering": 31
    },
    "2021-11": {
      "other_uncategorized": 3,
      "advisory": 0,
      "trade": 0,
      "manufacturing": 0,
      "hospitality": 0,
      "public_service": 0,
      "support": 5,
      "research": 1,
      "product": 5,
      "education": 0,
      "human_resources": 5,
      "legal": 0,
      "operations": 7,
      "fulfillment": 1,
      "professional_service": 0,
      "creative": 1,
      "marketing": 5,
      "partnerships": 2,
      "sales_engineering": 4,
      "sales": 21,
      "health": 0,
      "analyst": 2,
      "finance": 2,
      "engineering": 32
    },
    "2021-12": {
      "other_uncategorized": 3,
      "advisory": 0,
      "trade": 0,
      "manufacturing": 0,
      "hospitality": 0,
      "public_service": 0,
      "support": 5,
      "research": 1,
      "product": 5,
      "education": 0,
      "human_resources": 7,
      "legal": 0,
      "operations": 7,
      "fulfillment": 1,
      "professional_service": 0,
      "creative": 1,
      "marketing": 5,
      "partnerships": 2,
      "sales_engineering": 4,
      "sales": 21,
      "health": 0,
      "analyst": 2,
      "finance": 2,
      "engineering": 32
    },
    "2022-01": {
      "other_uncategorized": 4,
      "advisory": 0,
      "trade": 0,
      "manufacturing": 0,
      "hospitality": 0,
      "public_service": 0,
      "support": 6,
      "research": 1,
      "product": 5,
      "education": 0,
      "human_resources": 7,
      "legal": 1,
      "operations": 8,
      "fulfillment": 1,
      "professional_service": 0,
      "creative": 1,
      "marketing": 5,
      "partnerships": 2,
      "sales_engineering": 4,
      "sales": 24,
      "health": 0,
      "analyst": 2,
      "finance": 2,
      "engineering": 34
    },
    "2022-02": {
      "other_uncategorized": 4,
      "advisory": 0,
      "trade": 0,
      "manufacturing": 0,
      "hospitality": 0,
      "public_service": 0,
      "support": 6,
      "research": 1,
      "product": 5,
      "education": 0,
      "human_resources": 7,
      "legal": 1,
      "operations": 8,
      "fulfillment": 1,
      "professional_service": 0,
      "creative": 1,
      "marketing": 5,
      "partnerships": 2,
      "sales_engineering": 4,
      "sales": 26,
      "health": 0,
      "analyst": 2,
      "finance": 2,
      "engineering": 34
    },
    "2022-03": {
      "other_uncategorized": 4,
      "advisory": 0,
      "trade": 0,
      "manufacturing": 0,
      "hospitality": 0,
      "public_service": 0,
      "support": 9,
      "research": 1,
      "product": 7,
      "education": 0,
      "human_resources": 8,
      "legal": 1,
      "operations": 8,
      "fulfillment": 1,
      "professional_service": 0,
      "creative": 1,
      "marketing": 6,
      "partnerships": 3,
      "sales_engineering": 4,
      "sales": 25,
      "health": 0,
      "analyst": 2,
      "finance": 2,
      "engineering": 37
    },
    "2022-04": {
      "other_uncategorized": 4,
      "advisory": 0,
      "trade": 0,
      "manufacturing": 0,
      "hospitality": 0,
      "public_service": 0,
      "support": 9,
      "research": 1,
      "product": 8,
      "education": 0,
      "human_resources": 8,
      "legal": 1,
      "operations": 6,
      "fulfillment": 1,
      "professional_service": 0,
      "creative": 1,
      "marketing": 7,
      "partnerships": 4,
      "sales_engineering": 4,
      "sales": 24,
      "health": 0,
      "analyst": 2,
      "finance": 2,
      "engineering": 40
    },
    "2022-05": {
      "other_uncategorized": 4,
      "advisory": 0,
      "trade": 0,
      "manufacturing": 0,
      "hospitality": 0,
      "public_service": 0,
      "support": 9,
      "research": 1,
      "product": 8,
      "education": 0,
      "human_resources": 8,
      "legal": 1,
      "operations": 7,
      "fulfillment": 1,
      "professional_service": 0,
      "creative": 1,
      "marketing": 7,
      "partnerships": 4,
      "sales_engineering": 4,
      "sales": 25,
      "health": 0,
      "analyst": 3,
      "finance": 2,
      "engineering": 40
    },
    "2022-06": {
      "other_uncategorized": 5,
      "advisory": 0,
      "trade": 0,
      "manufacturing": 0,
      "hospitality": 0,
      "public_service": 0,
      "support": 10,
      "research": 1,
      "product": 7,
      "education": 0,
      "human_resources": 8,
      "legal": 1,
      "operations": 7,
      "fulfillment": 1,
      "professional_service": 0,
      "creative": 1,
      "marketing": 7,
      "partnerships": 4,
      "sales_engineering": 4,
      "sales": 27,
      "health": 0,
      "analyst": 3,
      "finance": 3,
      "engineering": 38
    },
    "2022-07": {
      "other_uncategorized": 5,
      "advisory": 0,
      "trade": 0,
      "manufacturing": 0,
      "hospitality": 0,
      "public_service": 0,
      "support": 9,
      "research": 1,
      "product": 7,
      "education": 0,
      "human_resources": 9,
      "legal": 1,
      "operations": 8,
      "fulfillment": 1,
      "professional_service": 0,
      "creative": 1,
      "marketing": 8,
      "partnerships": 4,
      "sales_engineering": 4,
      "sales": 27,
      "health": 0,
      "analyst": 2,
      "finance": 4,
      "engineering": 40
    },
    "2022-08": {
      "other_uncategorized": 5,
      "advisory": 0,
      "trade": 0,
      "manufacturing": 0,
      "hospitality": 0,
      "public_service": 0,
      "support": 9,
      "research": 1,
      "product": 7,
      "education": 0,
      "human_resources": 9,
      "legal": 1,
      "operations": 8,
      "fulfillment": 3,
      "professional_service": 0,
      "creative": 1,
      "marketing": 8,
      "partnerships": 5,
      "sales_engineering": 4,
      "sales": 27,
      "health": 0,
      "analyst": 2,
      "finance": 4,
      "engineering": 41
    },
    "2022-09": {
      "other_uncategorized": 6,
      "advisory": 0,
      "trade": 0,
      "manufacturing": 0,
      "hospitality": 0,
      "public_service": 0,
      "support": 9,
      "research": 1,
      "product": 7,
      "education": 0,
      "human_resources": 8,
      "legal": 1,
      "operations": 7,
      "fulfillment": 3,
      "professional_service": 0,
      "creative": 0,
      "marketing": 7,
      "partnerships": 5,
      "sales_engineering": 4,
      "sales": 31,
      "health": 0,
      "analyst": 3,
      "finance": 3,
      "engineering": 40
    },
    "2022-10": {
      "other_uncategorized": 6,
      "advisory": 0,
      "trade": 0,
      "manufacturing": 0,
      "hospitality": 0,
      "public_service": 0,
      "support": 8,
      "research": 1,
      "product": 8,
      "education": 0,
      "human_resources": 8,
      "legal": 1,
      "operations": 7,
      "fulfillment": 2,
      "professional_service": 0,
      "creative": 0,
      "marketing": 6,
      "partnerships": 5,
      "sales_engineering": 5,
      "sales": 31,
      "health": 0,
      "analyst": 4,
      "finance": 3,
      "engineering": 42
    },
    "2022-11": {
      "other_uncategorized": 6,
      "advisory": 0,
      "trade": 0,
      "manufacturing": 0,
      "hospitality": 0,
      "public_service": 0,
      "support": 7,
      "research": 1,
      "product": 8,
      "education": 0,
      "human_resources": 9,
      "legal": 1,
      "operations": 7,
      "fulfillment": 2,
      "professional_service": 0,
      "creative": 0,
      "marketing": 6,
      "partnerships": 5,
      "sales_engineering": 5,
      "sales": 32,
      "health": 0,
      "analyst": 4,
      "finance": 3,
      "engineering": 44
    },
    "2022-12": {
      "other_uncategorized": 6,
      "advisory": 0,
      "trade": 0,
      "manufacturing": 0,
      "hospitality": 0,
      "public_service": 0,
      "support": 7,
      "research": 1,
      "product": 8,
      "education": 0,
      "human_resources": 9,
      "legal": 1,
      "operations": 6,
      "fulfillment": 2,
      "professional_service": 0,
      "creative": 0,
      "marketing": 7,
      "partnerships": 5,
      "sales_engineering": 5,
      "sales": 32,
      "health": 0,
      "analyst": 4,
      "finance": 3,
      "engineering": 44
    },
    "2023-01": {
      "other_uncategorized": 5,
      "advisory": 0,
      "trade": 0,
      "manufacturing": 0,
      "hospitality": 0,
      "public_service": 0,
      "support": 3,
      "research": 1,
      "product": 7,
      "education": 0,
      "human_resources": 9,
      "legal": 1,
      "operations": 6,
      "fulfillment": 2,
      "professional_service": 0,
      "creative": 0,
      "marketing": 6,
      "partnerships": 5,
      "sales_engineering": 5,
      "sales": 29,
      "health": 0,
      "analyst": 4,
      "finance": 3,
      "engineering": 36
    },
    "2023-02": {
      "other_uncategorized": 5,
      "advisory": 0,
      "trade": 0,
      "manufacturing": 0,
      "hospitality": 0,
      "public_service": 0,
      "support": 4,
      "research": 1,
      "product": 7,
      "education": 0,
      "human_resources": 8,
      "legal": 1,
      "operations": 6,
      "fulfillment": 2,
      "professional_service": 0,
      "creative": 0,
      "marketing": 6,
      "partnerships": 5,
      "sales_engineering": 5,
      "sales": 28,
      "health": 0,
      "analyst": 4,
      "finance": 3,
      "engineering": 35
    },
    "2023-03": {
      "other_uncategorized": 5,
      "advisory": 0,
      "trade": 0,
      "manufacturing": 0,
      "hospitality": 0,
      "public_service": 0,
      "support": 4,
      "research": 1,
      "product": 7,
      "education": 0,
      "human_resources": 8,
      "legal": 1,
      "operations": 6,
      "fulfillment": 2,
      "professional_service": 0,
      "creative": 0,
      "marketing": 6,
      "partnerships": 5,
      "sales_engineering": 6,
      "sales": 27,
      "health": 0,
      "analyst": 4,
      "finance": 3,
      "engineering": 35
    },
    "2023-04": {
      "other_uncategorized": 5,
      "advisory": 0,
      "trade": 0,
      "manufacturing": 0,
      "hospitality": 0,
      "public_service": 0,
      "support": 5,
      "research": 1,
      "product": 5,
      "education": 0,
      "human_resources": 8,
      "legal": 1,
      "operations": 7,
      "fulfillment": 2,
      "professional_service": 0,
      "creative": 0,
      "marketing": 6,
      "partnerships": 5,
      "sales_engineering": 6,
      "sales": 27,
      "health": 0,
      "analyst": 4,
      "finance": 3,
      "engineering": 35
    },
    "2023-05": {
      "other_uncategorized": 5,
      "advisory": 0,
      "trade": 0,
      "manufacturing": 0,
      "hospitality": 0,
      "public_service": 0,
      "support": 5,
      "research": 1,
      "product": 5,
      "education": 0,
      "human_resources": 8,
      "legal": 1,
      "operations": 7,
      "fulfillment": 2,
      "professional_service": 0,
      "creative": 0,
      "marketing": 6,
      "partnerships": 4,
      "sales_engineering": 6,
      "sales": 29,
      "health": 0,
      "analyst": 4,
      "finance": 3,
      "engineering": 32
    },
    "2023-06": {
      "other_uncategorized": 5,
      "advisory": 0,
      "trade": 0,
      "manufacturing": 0,
      "hospitality": 0,
      "public_service": 0,
      "support": 4,
      "research": 1,
      "product": 5,
      "education": 0,
      "human_resources": 8,
      "legal": 1,
      "operations": 7,
      "fulfillment": 2,
      "professional_service": 0,
      "creative": 0,
      "marketing": 6,
      "partnerships": 4,
      "sales_engineering": 6,
      "sales": 27,
      "health": 0,
      "analyst": 4,
      "finance": 3,
      "engineering": 31
    },
    "2023-07": {
      "other_uncategorized": 5,
      "advisory": 0,
      "trade": 0,
      "manufacturing": 0,
      "hospitality": 0,
      "public_service": 0,
      "support": 4,
      "research": 2,
      "product": 5,
      "education": 0,
      "human_resources": 8,
      "legal": 1,
      "operations": 7,
      "fulfillment": 2,
      "professional_service": 0,
      "creative": 0,
      "marketing": 5,
      "partnerships": 4,
      "sales_engineering": 6,
      "sales": 25,
      "health": 0,
      "analyst": 4,
      "finance": 3,
      "engineering": 31
    },
    "2023-08": {
      "other_uncategorized": 4,
      "advisory": 0,
      "trade": 0,
      "manufacturing": 0,
      "hospitality": 0,
      "public_service": 0,
      "support": 4,
      "research": 2,
      "product": 5,
      "education": 0,
      "human_resources": 9,
      "legal": 1,
      "operations": 8,
      "fulfillment": 3,
      "professional_service": 0,
      "creative": 0,
      "marketing": 5,
      "partnerships": 4,
      "sales_engineering": 6,
      "sales": 26,
      "health": 0,
      "analyst": 4,
      "finance": 3,
      "engineering": 31
    },
    "2023-09": {
      "other_uncategorized": 4,
      "advisory": 1,
      "trade": 0,
      "manufacturing": 0,
      "hospitality": 0,
      "public_service": 0,
      "support": 4,
      "research": 1,
      "product": 5,
      "education": 0,
      "human_resources": 9,
      "legal": 1,
      "operations": 8,
      "fulfillment": 3,
      "professional_service": 0,
      "creative": 0,
      "marketing": 4,
      "partnerships": 4,
      "sales_engineering": 6,
      "sales": 26,
      "health": 0,
      "analyst": 4,
      "finance": 3,
      "engineering": 31
    },
    "2023-10": {
      "other_uncategorized": 3,
      "advisory": 1,
      "trade": 0,
      "manufacturing": 0,
      "hospitality": 0,
      "public_service": 0,
      "support": 4,
      "research": 1,
      "product": 5,
      "education": 0,
      "human_resources": 9,
      "legal": 1,
      "operations": 8,
      "fulfillment": 3,
      "professional_service": 0,
      "creative": 0,
      "marketing": 4,
      "partnerships": 3,
      "sales_engineering": 6,
      "sales": 25,
      "health": 0,
      "analyst": 4,
      "finance": 3,
      "engineering": 31
    },
    "2023-11": {
      "other_uncategorized": 3,
      "advisory": 1,
      "trade": 0,
      "manufacturing": 0,
      "hospitality": 0,
      "public_service": 0,
      "support": 4,
      "research": 1,
      "product": 5,
      "education": 0,
      "human_resources": 9,
      "legal": 1,
      "operations": 8,
      "fulfillment": 3,
      "professional_service": 0,
      "creative": 0,
      "marketing": 4,
      "partnerships": 3,
      "sales_engineering": 6,
      "sales": 24,
      "health": 0,
      "analyst": 3,
      "finance": 3,
      "engineering": 31
    },
    "2023-12": {
      "other_uncategorized": 3,
      "advisory": 1,
      "trade": 0,
      "manufacturing": 0,
      "hospitality": 0,
      "public_service": 0,
      "support": 4,
      "research": 1,
      "product": 5,
      "education": 0,
      "human_resources": 9,
      "legal": 1,
      "operations": 7,
      "fulfillment": 3,
      "professional_service": 0,
      "creative": 0,
      "marketing": 5,
      "partnerships": 3,
      "sales_engineering": 6,
      "sales": 23,
      "health": 0,
      "analyst": 4,
      "finance": 3,
      "engineering": 31
    },
    "2024-01": {
      "other_uncategorized": 3,
      "advisory": 1,
      "trade": 0,
      "manufacturing": 0,
      "hospitality": 0,
      "public_service": 0,
      "support": 4,
      "research": 1,
      "product": 5,
      "education": 0,
      "human_resources": 8,
      "legal": 1,
      "operations": 7,
      "fulfillment": 3,
      "professional_service": 0,
      "creative": 0,
      "marketing": 5,
      "partnerships": 3,
      "sales_engineering": 6,
      "sales": 20,
      "health": 0,
      "analyst": 4,
      "finance": 3,
      "engineering": 31
    },
    "2024-02": {
      "other_uncategorized": 3,
      "advisory": 1,
      "trade": 0,
      "manufacturing": 0,
      "hospitality": 0,
      "public_service": 0,
      "support": 5,
      "research": 1,
      "product": 4,
      "education": 0,
      "human_resources": 8,
      "legal": 1,
      "operations": 7,
      "fulfillment": 3,
      "professional_service": 0,
      "creative": 0,
      "marketing": 4,
      "partnerships": 3,
      "sales_engineering": 6,
      "sales": 17,
      "health": 0,
      "analyst": 4,
      "finance": 3,
      "engineering": 31
    },
    "2024-03": {
      "other_uncategorized": 3,
      "advisory": 1,
      "trade": 0,
      "manufacturing": 0,
      "hospitality": 0,
      "public_service": 0,
      "support": 5,
      "research": 1,
      "product": 4,
      "education": 0,
      "human_resources": 8,
      "legal": 1,
      "operations": 7,
      "fulfillment": 3,
      "professional_service": 0,
      "creative": 0,
      "marketing": 4,
      "partnerships": 3,
      "sales_engineering": 7,
      "sales": 16,
      "health": 0,
      "analyst": 4,
      "finance": 3,
      "engineering": 30
    },
    "2024-04": {
      "other_uncategorized": 3,
      "advisory": 1,
      "trade": 0,
      "manufacturing": 0,
      "hospitality": 0,
      "public_service": 0,
      "support": 5,
      "research": 1,
      "product": 4,
      "education": 0,
      "human_resources": 8,
      "legal": 1,
      "operations": 7,
      "fulfillment": 3,
      "professional_service": 0,
      "creative": 0,
      "marketing": 4,
      "partnerships": 3,
      "sales_engineering": 8,
      "sales": 17,
      "health": 0,
      "analyst": 4,
      "finance": 3,
      "engineering": 28
    },
    "2024-05": {
      "other_uncategorized": 3,
      "advisory": 1,
      "trade": 0,
      "manufacturing": 0,
      "hospitality": 0,
      "public_service": 0,
      "support": 5,
      "research": 1,
      "product": 5,
      "education": 0,
      "human_resources": 6,
      "legal": 1,
      "operations": 7,
      "fulfillment": 3,
      "professional_service": 0,
      "creative": 0,
      "marketing": 4,
      "partnerships": 3,
      "sales_engineering": 6,
      "sales": 15,
      "health": 0,
      "analyst": 4,
      "finance": 3,
      "engineering": 27
    },
    "2024-06": {
      "other_uncategorized": 3,
      "advisory": 1,
      "trade": 0,
      "manufacturing": 0,
      "hospitality": 0,
      "public_service": 0,
      "support": 5,
      "research": 1,
      "product": 5,
      "education": 0,
      "human_resources": 6,
      "legal": 1,
      "operations": 7,
      "fulfillment": 3,
      "professional_service": 0,
      "creative": 0,
      "marketing": 4,
      "partnerships": 3,
      "sales_engineering": 6,
      "sales": 14,
      "health": 0,
      "analyst": 4,
      "finance": 3,
      "engineering": 27
    },
    "2024-07": {
      "other_uncategorized": 3,
      "advisory": 1,
      "trade": 0,
      "manufacturing": 0,
      "hospitality": 0,
      "public_service": 0,
      "support": 6,
      "research": 1,
      "product": 5,
      "education": 0,
      "human_resources": 6,
      "legal": 1,
      "operations": 7,
      "fulfillment": 3,
      "professional_service": 0,
      "creative": 0,
      "marketing": 4,
      "partnerships": 3,
      "sales_engineering": 6,
      "sales": 13,
      "health": 0,
      "analyst": 3,
      "finance": 3,
      "engineering": 28
    },
    "2024-08": {
      "other_uncategorized": 3,
      "advisory": 1,
      "trade": 0,
      "manufacturing": 0,
      "hospitality": 0,
      "public_service": 0,
      "support": 5,
      "research": 1,
      "product": 5,
      "education": 0,
      "human_resources": 6,
      "legal": 1,
      "operations": 7,
      "fulfillment": 3,
      "professional_service": 0,
      "creative": 0,
      "marketing": 4,
      "partnerships": 3,
      "sales_engineering": 6,
      "sales": 13,
      "health": 0,
      "analyst": 3,
      "finance": 3,
      "engineering": 28
    },
    "2024-09": {
      "other_uncategorized": 3,
      "advisory": 1,
      "trade": 0,
      "manufacturing": 0,
      "hospitality": 0,
      "public_service": 0,
      "support": 5,
      "research": 1,
      "product": 5,
      "education": 0,
      "human_resources": 4,
      "legal": 1,
      "operations": 6,
      "fulfillment": 3,
      "professional_service": 0,
      "creative": 0,
      "marketing": 4,
      "partnerships": 4,
      "sales_engineering": 6,
      "sales": 14,
      "health": 0,
      "analyst": 4,
      "finance": 3,
      "engineering": 30
    },
    "2024-10": {
      "other_uncategorized": 3,
      "advisory": 1,
      "trade": 0,
      "manufacturing": 0,
      "hospitality": 0,
      "public_service": 0,
      "support": 5,
      "research": 1,
      "product": 5,
      "education": 0,
      "human_resources": 4,
      "legal": 1,
      "operations": 6,
      "fulfillment": 3,
      "professional_service": 0,
      "creative": 0,
      "marketing": 4,
      "partnerships": 4,
      "sales_engineering": 6,
      "sales": 14,
      "health": 0,
      "analyst": 4,
      "finance": 3,
      "engineering": 29
    },
    "2024-11": {
      "other_uncategorized": 3,
      "advisory": 1,
      "trade": 0,
      "manufacturing": 0,
      "hospitality": 0,
      "public_service": 0,
      "support": 5,
      "research": 1,
      "product": 5,
      "education": 0,
      "human_resources": 4,
      "legal": 1,
      "operations": 6,
      "fulfillment": 3,
      "professional_service": 0,
      "creative": 0,
      "marketing": 5,
      "partnerships": 4,
      "sales_engineering": 4,
      "sales": 14,
      "health": 0,
      "analyst": 4,
      "finance": 3,
      "engineering": 29
    },
    "2024-12": {
      "other_uncategorized": 3,
      "advisory": 1,
      "trade": 0,
      "manufacturing": 0,
      "hospitality": 0,
      "public_service": 0,
      "support": 5,
      "research": 1,
      "product": 5,
      "education": 0,
      "human_resources": 4,
      "legal": 1,
      "operations": 6,
      "fulfillment": 3,
      "professional_service": 0,
      "creative": 0,
      "marketing": 5,
      "partnerships": 4,
      "sales_engineering": 4,
      "sales": 14,
      "health": 0,
      "analyst": 4,
      "finance": 3,
      "engineering": 29
    },
    "2025-01": {
      "other_uncategorized": 3,
      "advisory": 1,
      "trade": 0,
      "manufacturing": 0,
      "hospitality": 0,
      "public_service": 0,
      "support": 6,
      "research": 1,
      "product": 6,
      "education": 0,
      "human_resources": 5,
      "legal": 1,
      "operations": 7,
      "fulfillment": 2,
      "professional_service": 0,
      "creative": 0,
      "marketing": 5,
      "partnerships": 4,
      "sales_engineering": 4,
      "sales": 14,
      "health": 0,
      "analyst": 4,
      "finance": 3,
      "engineering": 28
    },
    "2025-02": {
      "other_uncategorized": 3,
      "advisory": 1,
      "trade": 0,
      "manufacturing": 0,
      "hospitality": 0,
      "public_service": 0,
      "support": 6,
      "research": 1,
      "product": 7,
      "education": 0,
      "human_resources": 5,
      "legal": 1,
      "operations": 7,
      "fulfillment": 2,
      "professional_service": 0,
      "creative": 0,
      "marketing": 4,
      "partnerships": 4,
      "sales_engineering": 4,
      "sales": 15,
      "health": 0,
      "analyst": 4,
      "finance": 3,
      "engineering": 28
    },
    "2025-03": {
      "other_uncategorized": 3,
      "advisory": 1,
      "trade": 0,
      "manufacturing": 0,
      "hospitality": 0,
      "public_service": 0,
      "support": 6,
      "research": 1,
      "product": 7,
      "education": 0,
      "human_resources": 5,
      "legal": 1,
      "operations": 6,
      "fulfillment": 2,
      "professional_service": 0,
      "creative": 0,
      "marketing": 5,
      "partnerships": 3,
      "sales_engineering": 3,
      "sales": 13,
      "health": 0,
      "analyst": 4,
      "finance": 3,
      "engineering": 28
    },
    "2025-04": {
      "other_uncategorized": 3,
      "advisory": 1,
      "trade": 0,
      "manufacturing": 0,
      "hospitality": 0,
      "public_service": 0,
      "support": 6,
      "research": 1,
      "product": 8,
      "education": 0,
      "human_resources": 5,
      "legal": 1,
      "operations": 6,
      "fulfillment": 3,
      "professional_service": 0,
      "creative": 0,
      "marketing": 5,
      "partnerships": 4,
      "sales_engineering": 3,
      "sales": 14,
      "health": 0,
      "analyst": 4,
      "finance": 3,
      "engineering": 27
    },
    "2025-05": {
      "other_uncategorized": 3,
      "advisory": 1,
      "trade": 0,
      "manufacturing": 0,
      "hospitality": 0,
      "public_service": 0,
      "support": 5,
      "research": 1,
      "product": 8,
      "education": 0,
      "human_resources": 5,
      "legal": 1,
      "operations": 7,
      "fulfillment": 2,
      "professional_service": 0,
      "creative": 0,
      "marketing": 5,
      "partnerships": 4,
      "sales_engineering": 3,
      "sales": 14,
      "health": 0,
      "analyst": 4,
      "finance": 3,
      "engineering": 26
    },
    "2025-06": {
      "other_uncategorized": 3,
      "advisory": 1,
      "trade": 0,
      "manufacturing": 0,
      "hospitality": 0,
      "public_service": 0,
      "support": 6,
      "research": 1,
      "product": 8,
      "education": 0,
      "human_resources": 6,
      "legal": 1,
      "operations": 7,
      "fulfillment": 2,
      "professional_service": 0,
      "creative": 0,
      "marketing": 5,
      "partnerships": 4,
      "sales_engineering": 3,
      "sales": 14,
      "health": 0,
      "analyst": 4,
      "finance": 3,
      "engineering": 26
    },
    "2025-07": {
      "other_uncategorized": 3,
      "advisory": 1,
      "trade": 0,
      "manufacturing": 0,
      "hospitality": 0,
      "public_service": 0,
      "support": 6,
      "research": 1,
      "product": 8,
      "education": 0,
      "human_resources": 5,
      "legal": 1,
      "operations": 7,
      "fulfillment": 2,
      "professional_service": 0,
      "creative": 0,
      "marketing": 5,
      "partnerships": 4,
      "sales_engineering": 4,
      "sales": 14,
      "health": 0,
      "analyst": 4,
      "finance": 3,
      "engineering": 25
    },
    "2025-08": {
      "other_uncategorized": 3,
      "advisory": 1,
      "trade": 0,
      "manufacturing": 0,
      "hospitality": 0,
      "public_service": 0,
      "support": 6,
      "research": 1,
      "product": 8,
      "education": 0,
      "human_resources": 5,
      "legal": 1,
      "operations": 7,
      "fulfillment": 2,
      "professional_service": 0,
      "creative": 0,
      "marketing": 5,
      "partnerships": 4,
      "sales_engineering": 4,
      "sales": 14,
      "health": 0,
      "analyst": 4,
      "finance": 3,
      "engineering": 25
    },
    "2025-09": {
      "other_uncategorized": 3,
      "advisory": 1,
      "trade": 0,
      "manufacturing": 0,
      "hospitality": 0,
      "public_service": 0,
      "support": 6,
      "research": 1,
      "product": 8,
      "education": 0,
      "human_resources": 5,
      "legal": 1,
      "operations": 7,
      "fulfillment": 2,
      "professional_service": 0,
      "creative": 0,
      "marketing": 5,
      "partnerships": 4,
      "sales_engineering": 4,
      "sales": 14,
      "health": 0,
      "analyst": 4,
      "finance": 3,
      "engineering": 25
    },
    "2025-10": {
      "other_uncategorized": 3,
      "advisory": 1,
      "trade": 0,
      "manufacturing": 0,
      "hospitality": 0,
      "public_service": 0,
      "support": 6,
      "research": 1,
      "product": 8,
      "education": 0,
      "human_resources": 5,
      "legal": 1,
      "operations": 6,
      "fulfillment": 1,
      "professional_service": 0,
      "creative": 0,
      "marketing": 5,
      "partnerships": 4,
      "sales_engineering": 4,
      "sales": 14,
      "health": 0,
      "analyst": 4,
      "finance": 3,
      "engineering": 24
    },
    "2025-11": {
      "other_uncategorized": 3,
      "advisory": 1,
      "trade": 0,
      "manufacturing": 0,
      "hospitality": 0,
      "public_service": 0,
      "support": 6,
      "research": 1,
      "product": 8,
      "education": 0,
      "human_resources": 5,
      "legal": 1,
      "operations": 6,
      "fulfillment": 0,
      "professional_service": 0,
      "creative": 0,
      "marketing": 5,
      "partnerships": 4,
      "sales_engineering": 4,
      "sales": 14,
      "health": 0,
      "analyst": 4,
      "finance": 3,
      "engineering": 24
    },
    "2025-12": {
      "other_uncategorized": 3,
      "advisory": 1,
      "trade": 0,
      "manufacturing": 0,
      "hospitality": 0,
      "public_service": 0,
      "support": 6,
      "research": 1,
      "product": 8,
      "education": 0,
      "human_resources": 5,
      "legal": 1,
      "operations": 6,
      "fulfillment": 0,
      "professional_service": 0,
      "creative": 0,
      "marketing": 5,
      "partnerships": 3,
      "sales_engineering": 4,
      "sales": 14,
      "health": 0,
      "analyst": 4,
      "finance": 3,
      "engineering": 23
    },
    "2026-01": {
      "other_uncategorized": 3,
      "advisory": 1,
      "trade": 0,
      "manufacturing": 0,
      "hospitality": 0,
      "public_service": 0,
      "support": 6,
      "research": 1,
      "product": 7,
      "education": 0,
      "human_resources": 5,
      "legal": 1,
      "operations": 6,
      "fulfillment": 0,
      "professional_service": 0,
      "creative": 0,
      "marketing": 5,
      "partnerships": 3,
      "sales_engineering": 4,
      "sales": 14,
      "health": 0,
      "analyst": 4,
      "finance": 3,
      "engineering": 24
    }
  },
  "employee_growth_rate": {
    "3_month": -0.0333,
    "6_month": -0.0645,
    "12_month": -0.0745,
    "24_month": -0.1714
  },
  "employee_growth_rate_12_month_by_role": {
    "other_uncategorized": 0.0,
    "advisory": 0.0,
    "trade": null,
    "manufacturing": null,
    "hospitality": null,
    "public_service": null,
    "support": 0.0,
    "research": 0.0,
    "product": 0.1667,
    "education": null,
    "human_resources": 0.0,
    "legal": 0.0,
    "operations": -0.1429,
    "fulfillment": -1.0,
    "professional_service": null,
    "creative": null,
    "marketing": 0.0,
    "partnerships": -0.25,
    "sales_engineering": 0.0,
    "sales": 0.0,
    "health": null,
    "analyst": 0.0,
    "finance": 0.0,
    "engineering": -0.1724
  },
  "employee_growth_rate_12_month_by_sub_role": {
    "other_uncategorized": 0.1333,
    "advisor": 0.0,
    "board_member": null,
    "investor": null,
    "agriculture": null,
    "construction": null,
    "electric": null,
    "mechanic": null,
    "plumbing": null,
    "health_and_safety": null,
    "machinist": null,
    "quality_assurance": null,
    "restaurants": null,
    "retail": null,
    "emergency_services": null,
    "judicial": null,
    "military": null,
    "political": null,
    "protective_service": null,
    "social_service": null,
    "account_management": null,
    "customer_success": 0.0,
    "customer_support": null,
    "fraud": null,
    "academic": null,
    "financial": null,
    "scientific": null,
    "product_design": 0.0,
    "product_management": 0.2,
    "curation": null,
    "primary_and_secondary": null,
    "professor": null,
    "student": null,
    "tour_and_travel": null,
    "human_resources": 0.0,
    "recruiting": 0.0,
    "talent_analytics": null,
    "training": 0.0,
    "compliance": 0.0,
    "legal": null,
    "administrative": -0.6667,
    "aides": null,
    "building_and_grounds": null,
    "corporate_development": null,
    "executive": 0.0,
    "investor_relations": null,
    "strategy": null,
    "logistics": null,
    "project_management": -1.0,
    "transport": null,
    "warehouse": null,
    "accounting_services": null,
    "architecture": null,
    "consulting": null,
    "investment_banking": null,
    "legal_services": null,
    "marketing_services": null,
    "translation": null,
    "artist": null,
    "entertainment": null,
    "fashion": null,
    "graphic_design": null,
    "hair_stylist": null,
    "journalism": null,
    "brand": 0.0,
    "content": 0.0,
    "growth": 0.0,
    "marketing_design": null,
    "business_development": 0.0,
    "partnerships": -1.0,
    "implementation": null,
    "solutions_engineer": 0.0,
    "account_executive": 0.0909,
    "insurance": null,
    "realtor": null,
    "sales_development": null,
    "dental": null,
    "doctor": null,
    "fitness": null,
    "nursing": null,
    "pharmacy": null,
    "therapy": null,
    "veterinarian": null,
    "wellness": null,
    "business_analyst": null,
    "data_analyst": 0.0,
    "revenue_operations": 0.0,
    "accounting": 0.0,
    "bookkeeping": null,
    "procurement": null,
    "planning_and_analysis": null,
    "risk": null,
    "chemical": null,
    "data_engineering": -0.3333,
    "data_science": 0.0,
    "devops": null,
    "electrical": null,
    "hardware": null,
    "industrial": null,
    "information_technology": null,
    "mechanical": null,
    "network": null,
    "qa_engineering": null,
    "security": 0.0,
    "software": 0.125,
    "web": null
  },
  "employee_growth_rate_12_month_by_class": {
    "other_uncategorized": 0.0,
    "services": -0.1429,
    "general_and_administrative": -0.0476,
    "sales_and_marketing": 0.0,
    "research_and_development": 0.0323
  },
  "gross_additions_by_month": {
    "2015-03": 3,
    "2015-04": 0,
    "2015-05": 0,
    "2015-06": 0,
    "2015-07": 1,
    "2015-08": 2,
    "2015-09": 1,
    "2015-10": 0,
    "2015-11": 0,
    "2015-12": 0,
    "2016-01": 0,
    "2016-02": 2,
    "2016-03": 0,
    "2016-04": 1,
    "2016-05": 1,
    "2016-06": 0,
    "2016-07": 0,
    "2016-08": 0,
    "2016-09": 0,
    "2016-10": 1,
    "2016-11": 0,
    "2016-12": 0,
    "2017-01": 0,
    "2017-02": 0,
    "2017-03": 0,
    "2017-04": 1,
    "2017-05": 2,
    "2017-06": 0,
    "2017-07": 0,
    "2017-08": 1,
    "2017-09": 1,
    "2017-10": 0,
    "2017-11": 0,
    "2017-12": 1,
    "2018-01": 1,
    "2018-02": 1,
    "2018-03": 0,
    "2018-04": 0,
    "2018-05": 2,
    "2018-06": 2,
    "2018-07": 1,
    "2018-08": 0,
    "2018-09": 1,
    "2018-10": 3,
    "2018-11": 3,
    "2018-12": 0,
    "2019-01": 10,
    "2019-02": 1,
    "2019-03": 3,
    "2019-04": 2,
    "2019-05": 0,
    "2019-06": 0,
    "2019-07": 1,
    "2019-08": 0,
    "2019-09": 0,
    "2019-10": 0,
    "2019-11": 1,
    "2019-12": 2,
    "2020-01": 5,
    "2020-02": 0,
    "2020-03": 1,
    "2020-04": 0,
    "2020-05": 0,
    "2020-06": 2,
    "2020-07": 3,
    "2020-08": 0,
    "2020-09": 6,
    "2020-10": 1,
    "2020-11": 2,
    "2020-12": 2,
    "2021-01": 9,
    "2021-02": 7,
    "2021-03": 7,
    "2021-04": 2,
    "2021-05": 5,
    "2021-06": 3,
    "2021-07": 4,
    "2021-08": 1,
    "2021-09": 0,
    "2021-10": 7,
    "2021-11": 4,
    "2021-12": 2,
    "2022-01": 6,
    "2022-02": 2,
    "2022-03": 13,
    "2022-04": 4,
    "2022-05": 3,
    "2022-06": 5,
    "2022-07": 5,
    "2022-08": 5,
    "2022-09": 6,
    "2022-10": 6,
    "2022-11": 4,
    "2022-12": 1,
    "2023-01": 0,
    "2023-02": 0,
    "2023-03": 1,
    "2023-04": 4,
    "2023-05": 4,
    "2023-06": 1,
    "2023-07": 1,
    "2023-08": 3,
    "2023-09": 1,
    "2023-10": 0,
    "2023-11": 0,
    "2023-12": 0,
    "2024-01": 0,
    "2024-02": 3,
    "2024-03": 2,
    "2024-04": 3,
    "2024-05": 0,
    "2024-06": 0,
    "2024-07": 2,
    "2024-08": 0,
    "2024-09": 5,
    "2024-10": 0,
    "2024-11": 2,
    "2024-12": 0,
    "2025-01": 2,
    "2025-02": 2,
    "2025-03": 0,
    "2025-04": 4,
    "2025-05": 0,
    "2025-06": 2,
    "2025-07": 2,
    "2025-08": 0,
    "2025-09": 0,
    "2025-10": 0,
    "2025-11": 0,
    "2025-12": 0,
    "2026-01": 1
  },
  "gross_departures_by_month": {
    "2017-08": 1,
    "2017-09": 0,
    "2017-10": 0,
    "2017-11": 2,
    "2017-12": 0,
    "2018-01": 0,
    "2018-02": 0,
    "2018-03": 0,
    "2018-04": 0,
    "2018-05": 0,
    "2018-06": 0,
    "2018-07": 0,
    "2018-08": 1,
    "2018-09": 1,
    "2018-10": 0,
    "2018-11": 2,
    "2018-12": 1,
    "2019-01": 0,
    "2019-02": 0,
    "2019-03": 0,
    "2019-04": 0,
    "2019-05": 1,
    "2019-06": 3,
    "2019-07": 0,
    "2019-08": 0,
    "2019-09": 0,
    "2019-10": 0,
    "2019-11": 0,
    "2019-12": 0,
    "2020-01": 0,
    "2020-02": 0,
    "2020-03": 1,
    "2020-04": 2,
    "2020-05": 0,
    "2020-06": 1,
    "2020-07": 2,
    "2020-08": 1,
    "2020-09": 0,
    "2020-10": 0,
    "2020-11": 0,
    "2020-12": 3,
    "2021-01": 2,
    "2021-02": 0,
    "2021-03": 0,
    "2021-04": 1,
    "2021-05": 0,
    "2021-06": 2,
    "2021-07": 0,
    "2021-08": 0,
    "2021-09": 1,
    "2021-10": 2,
    "2021-11": 0,
    "2021-12": 1,
    "2022-01": 0,
    "2022-02": 3,
    "2022-03": 1,
    "2022-04": 0,
    "2022-05": 3,
    "2022-06": 1,
    "2022-07": 1,
    "2022-08": 6,
    "2022-09": 3,
    "2022-10": 1,
    "2022-11": 1,
    "2022-12": 16,
    "2023-01": 2,
    "2023-02": 2,
    "2023-03": 4,
    "2023-04": 6,
    "2023-05": 5,
    "2023-06": 3,
    "2023-07": 0,
    "2023-08": 2,
    "2023-09": 3,
    "2023-10": 2,
    "2023-11": 0,
    "2023-12": 2,
    "2024-01": 7,
    "2024-02": 3,
    "2024-03": 3,
    "2024-04": 6,
    "2024-05": 1,
    "2024-06": 2,
    "2024-07": 1,
    "2024-08": 3,
    "2024-09": 1,
    "2024-10": 3,
    "2024-11": 0,
    "2024-12": 0,
    "2025-01": 1,
    "2025-02": 4,
    "2025-03": 2,
    "2025-04": 2,
    "2025-05": 0,
    "2025-06": 3,
    "2025-07": 0,
    "2025-08": 0,
    "2025-09": 3,
    "2025-10": 1,
    "2025-11": 2,
    "2025-12": 1,
    "2026-01": 2
  },
  "recent_exec_departures": [
    {
      "departed_date": "2026-01",
      "pdl_id": "GjUWfHtIiJTwyN1YUgi8SA_0000",
      "job_title": "chief product officer",
      "job_title_role": "product",
      "job_title_sub_role": "product_management",
      "job_title_class": "research_and_development",
      "job_title_levels": [
        "cxo"
      ],
      "new_company_id": null,
      "new_company_job_title": null,
      "new_company_job_title_role": null,
      "new_company_job_title_sub_role": null,
      "new_company_job_title_class": null,
      "new_company_job_title_levels": []
    }
  ],
  "recent_exec_hires": [],
  "top_next_employers": {
    "creative": [
      {
        "id": "BB4I4BUACEIgZO8zqOCCMAZtr4Gc",
        "count": 1,
        "display_name": "Lotame"
      }
    ],
    "sales": [
      {
        "id": "gbzAHmeUyu5rJyy4eUrPPgtM5jdC",
        "count": 5,
        "display_name": "Five By Five"
      },
      {
        "id": "RStPGykPmmJCVaL7ssFHOAHiQWBM",
        "count": 2,
        "display_name": "AudioEye"
      },
      {
        "id": "XBYYqoE4Wb6GZh15knT8JwT1axnO",
        "count": 2,
        "display_name": "The Center for American Women and Politics"
      },
      {
        "id": "nP2E1ncNuX3yU5TzohlzYg4DX3RD",
        "count": 2,
        "display_name": "Claro Analytics"
      },
      {
        "id": "HmwWuP1GHissFVJ7NuWviA7mMffj",
        "count": 2,
        "display_name": "University of Massachusetts Amherst"
      },
      {
        "id": "C48T7IE5S3Wng5ofMWBnmwnzh6Cx",
        "count": 2,
        "display_name": "Private Health Management"
      },
      {
        "id": "CeWYMQ3LrxqDVRxtt5L6aQZCrWIf",
        "count": 2,
        "display_name": "BriefCam (Now Milestone)"
      },
      {
        "id": "4Sdi9wP3HBKlwJ1hkPB0mAKX5JI8",
        "count": 2,
        "display_name": "BreachRx"
      },
      {
        "id": "jTI3lUxNgd7qK9i7eeoIwgW7sXYD",
        "count": 2,
        "display_name": "TalentDreams, a 501(c)(3)"
      },
      {
        "id": "OvfwSqNueSLyH0UHFGDTPAVQoue9",
        "count": 1,
        "display_name": "Decagon"
      }
    ],
    "finance": [
      {
        "id": "dFsrbsUTKoTNVLLfwI8nTwtGLNuH",
        "count": 1,
        "display_name": "99Cents Only - Discount Club Store"
      }
    ],
    "analyst": [
      {
        "id": "X1ADnyhdrQPRhrLutCwmWAHrK8yv",
        "count": 1,
        "display_name": "Axis Gymnastics & Sports Academy"
      },
      {
        "id": "n7frP3oODI1hqBUiMlkKIQ79XVEb",
        "count": 1,
        "display_name": "Eagle Crest Conference Center Resort & Golf Club"
      },
      {
        "id": "2MYFvBQk8hYCogWYQB4T2wSTg0tS",
        "count": 1,
        "display_name": "Santa Clara University"
      },
      {
        "id": "it5ClAuYl4csLWCj2PAQlwHCJ1e3",
        "count": 1,
        "display_name": "State Farm"
      },
      {
        "id": "2iF52ioZBzeIEYG6fvpY7A9HzjWx",
        "count": 1,
        "display_name": "Vail Resorts"
      },
      {
        "id": "jTI3lUxNgd7qK9i7eeoIwgW7sXYD",
        "count": 1,
        "display_name": "TalentDreams, a 501(c)(3)"
      },
      {
        "id": "obOBDrYK94u7Nnp7P64hvA8QvGQx",
        "count": 1,
        "display_name": "San Diego State University"
      },
      {
        "id": "5utxoYBIYbBOw2LWzzSxOAJzSI6w",
        "count": 1,
        "display_name": "Hidden Valley Ski. Tube. Ride."
      },
      {
        "id": "As1QQEqDyFp5G9MpMtZRhgj1CP5J",
        "count": 1,
        "display_name": "MG+M The Law Firm"
      },
      {
        "id": "iZhVxk2MHYhgFa1BPuG4dgtGd6wU",
        "count": 1,
        "display_name": "Bank of America"
      }
    ],
    "research": [
      {
        "id": "69IOeBijO7bNzClSGs6bxg4Dt7Ge",
        "count": 1,
        "display_name": "DoorDash"
      }
    ],
    "support": [
      {
        "id": "aqrOOJB0T5v4YhyEhgfSeQJT1HSr",
        "count": 2,
        "display_name": "FOSSA"
      },
      {
        "id": "Xqu106JJKFNdntoQVYuLrQi5MW1L",
        "count": 1,
        "display_name": "Fenris"
      },
      {
        "id": "6CCAFNIH9JifOSs8krLClAFr7Jk8",
        "count": 1,
        "display_name": "HeySunday"
      },
      {
        "id": "Hb6ZM2rVAMUoIJyBIuduUwj6Bo0G",
        "count": 1,
        "display_name": "Healiant Training and Education"
      },
      {
        "id": "YzbVNGiZQcQyHjlr4zXBfwjj4VvH",
        "count": 1,
        "display_name": "Aisera"
      },
      {
        "id": "GeBlYAG05dkklKxA3hCOngSLLImO",
        "count": 1,
        "display_name": "Endgame"
      },
      {
        "id": "mzviUQjfL23U0tEbTQxEXQs4kLFI",
        "count": 1,
        "display_name": "Serena Neel"
      },
      {
        "id": "WZxON2sNNh34HcmHApMMzQ0ELPZe",
        "count": 1,
        "display_name": "Bayence"
      },
      {
        "id": "rrxqqJhXCDMWbEjUxFRn8gJJBLUp",
        "count": 1,
        "display_name": "LeadIQ"
      },
      {
        "id": "Dn0GAueIRsYzwepbYEGIAQVi7Qyl",
        "count": 1,
        "display_name": "Anaconda, Inc."
      }
    ],
    "engineering": [
      {
        "id": "Al1S5rCHHy06U7OJ9Clk9gin8fbT",
        "count": 2,
        "display_name": "Prime Video & Amazon MGM Studios"
      },
      {
        "id": "T9iiLVNB7ZfYxUI1dNE8gwVXdaOh",
        "count": 2,
        "display_name": "Omnivector"
      },
      {
        "id": "PR51FRfxp6Aq3UgkwnZsBwWyqqee",
        "count": 2,
        "display_name": "Syntracts"
      },
      {
        "id": "GqDq6nxvcABfaYtyQ3V6IQehsOkN",
        "count": 2,
        "display_name": "ExtraHop"
      },
      {
        "id": "C0nbLdVMIPKRRkIf0ho8pwk7qa7s",
        "count": 2,
        "display_name": "Shipt"
      },
      {
        "id": "Dn0GAueIRsYzwepbYEGIAQVi7Qyl",
        "count": 2,
        "display_name": "Anaconda, Inc."
      },
      {
        "id": "zyDcJqSoKNDhvjtLkHBm6woIDKXq",
        "count": 2,
        "display_name": "Deliverr Inc."
      },
      {
        "id": "Ox3loJTFBPsjB0sOPNyRdw8TmoH4",
        "count": 1,
        "display_name": "Sisense for Cloud Data Teams"
      },
      {
        "id": "L5u6DMEzMjnJgsUo5lGhSgIvcG9e",
        "count": 1,
        "display_name": "Point72"
      },
      {
        "id": "zoJYBSFkt5oyd3H0wjcljgZunhwO",
        "count": 1,
        "display_name": "Heimstaden Bostad"
      }
    ],
    "all": [
      {
        "id": "gbzAHmeUyu5rJyy4eUrPPgtM5jdC",
        "count": 7,
        "display_name": "Five By Five"
      },
      {
        "id": "Dn0GAueIRsYzwepbYEGIAQVi7Qyl",
        "count": 4,
        "display_name": "Anaconda, Inc."
      },
      {
        "id": "4Sdi9wP3HBKlwJ1hkPB0mAKX5JI8",
        "count": 3,
        "display_name": "BreachRx"
      },
      {
        "id": "jTI3lUxNgd7qK9i7eeoIwgW7sXYD",
        "count": 3,
        "display_name": "TalentDreams, a 501(c)(3)"
      },
      {
        "id": "CeWYMQ3LrxqDVRxtt5L6aQZCrWIf",
        "count": 2,
        "display_name": "BriefCam (Now Milestone)"
      },
      {
        "id": "dd5qSOtI0mhoCyWLLxUPsAUem2jN",
        "count": 2,
        "display_name": "Astronomer"
      },
      {
        "id": "Al1S5rCHHy06U7OJ9Clk9gin8fbT",
        "count": 2,
        "display_name": "Prime Video & Amazon MGM Studios"
      },
      {
        "id": "GqDq6nxvcABfaYtyQ3V6IQehsOkN",
        "count": 2,
        "display_name": "ExtraHop"
      },
      {
        "id": "HmwWuP1GHissFVJ7NuWviA7mMffj",
        "count": 2,
        "display_name": "University of Massachusetts Amherst"
      },
      {
        "id": "PR51FRfxp6Aq3UgkwnZsBwWyqqee",
        "count": 2,
        "display_name": "Syntracts"
      }
    ],
    "product": [
      {
        "id": "wwsCB1KRzSOijf1bRivCAwwrRrZD",
        "count": 2,
        "display_name": "ROQ.tech"
      },
      {
        "id": "ltCOPMbY1V61SPwfgFPsEwrHfP1M",
        "count": 2,
        "display_name": "Savvy Programmers"
      },
      {
        "id": "yd6BhDGp2rtCV3WMhZgZqAlVCmwg",
        "count": 1,
        "display_name": "Citrok"
      },
      {
        "id": "krxdHEpZE0qyYwi6yD5qPgAtoadD",
        "count": 1,
        "display_name": "1datapipe\u00ae"
      },
      {
        "id": "Bqh2aB9znOTxjHFiMlVyuwfeC4lA",
        "count": 1,
        "display_name": "Bishop Fox"
      },
      {
        "id": "CB2ZzdxfCgCUvd1eCjCqtQQtrJsI",
        "count": 1,
        "display_name": "Solix Technologies, Inc."
      },
      {
        "id": "GeBlYAG05dkklKxA3hCOngSLLImO",
        "count": 1,
        "display_name": "Endgame"
      }
    ],
    "fulfillment": [
      {
        "id": "iI5OkUr7b67riPA6mWNVrwMbRX7Y",
        "count": 1,
        "display_name": "Merrill Lynch"
      },
      {
        "id": "NeNcCSqofszpMPvSqkURXwy6NqHp",
        "count": 1,
        "display_name": "Anduril Industries"
      }
    ],
    "legal": [
      {
        "id": "0Csy3EeOMWFEA8NCWHIqCg3tMJ4i",
        "count": 1,
        "display_name": "Daxko"
      }
    ],
    "sales_engineering": [
      {
        "id": "gbzAHmeUyu5rJyy4eUrPPgtM5jdC",
        "count": 2,
        "display_name": "Five By Five"
      },
      {
        "id": "dd5qSOtI0mhoCyWLLxUPsAUem2jN",
        "count": 2,
        "display_name": "Astronomer"
      },
      {
        "id": "xIVEyLobPvOqDn2JJkk2YQsl8oEn",
        "count": 1,
        "display_name": "Supabase"
      },
      {
        "id": "Ox3loJTFBPsjB0sOPNyRdw8TmoH4",
        "count": 1,
        "display_name": "Sisense for Cloud Data Teams"
      },
      {
        "id": "Dn0GAueIRsYzwepbYEGIAQVi7Qyl",
        "count": 1,
        "display_name": "Anaconda, Inc."
      },
      {
        "id": "lWtLBvQ0cGrwYZYqeBOXBgcnlwV2",
        "count": 1,
        "display_name": "Cisco"
      },
      {
        "id": "UEEQs3MCWHvTwXJU7FrmhgdJqhJl",
        "count": 1,
        "display_name": "Entrusted"
      },
      {
        "id": "tgJ5baJmPY596BScXkMUCAL2wNzm",
        "count": 1,
        "display_name": "dbt Labs"
      },
      {
        "id": "lazN6lVLFQgflMXihecQTA0PwvfP",
        "count": 1,
        "display_name": "Sisense"
      },
      {
        "id": "GeBlYAG05dkklKxA3hCOngSLLImO",
        "count": 1,
        "display_name": "Endgame"
      }
    ],
    "human_resources": [
      {
        "id": "ez6CL8FhgjKEDzpBqAq3NQr7I6Xt",
        "count": 2,
        "display_name": "Fivetran"
      },
      {
        "id": "qVhGo3EgtgCVgHwf4aS4OQJxlR8O",
        "count": 1,
        "display_name": "Attain Partners"
      },
      {
        "id": "iYUg7XDTnpg63fDbIAom0wnNN8q1",
        "count": 1,
        "display_name": "SpaceLab"
      },
      {
        "id": "xp7QUo1BVCqqcQCCRgjXYgy4nhX5",
        "count": 1,
        "display_name": "Techqueria"
      },
      {
        "id": "2dp2BsJ3X2EUXBqMCcnfEgf4p81O",
        "count": 1,
        "display_name": "Okta"
      },
      {
        "id": "C9OHTs0Ws4Lfn1nCZv7DNwVg8pJs",
        "count": 1,
        "display_name": "Cayuse"
      },
      {
        "id": "ixxTLZxbq813YqytU0j9VAcG5d2e",
        "count": 1,
        "display_name": "Antithesis"
      },
      {
        "id": "JePiYweioDkzmFp0ZwBEHQcvAoA5",
        "count": 1,
        "display_name": "Cook Systems"
      },
      {
        "id": "EuVUcZuYY76hv87sEkmAAQbIVjfY",
        "count": 1,
        "display_name": "Grand Circle Corporation"
      },
      {
        "id": "hc0cNpOr0UNz9xN4fuVQIgYfuco0",
        "count": 1,
        "display_name": "Redo"
      }
    ],
    "operations": [
      {
        "id": "GqDq6nxvcABfaYtyQ3V6IQehsOkN",
        "count": 2,
        "display_name": "ExtraHop"
      },
      {
        "id": "NeNcCSqofszpMPvSqkURXwy6NqHp",
        "count": 1,
        "display_name": "Anduril Industries"
      },
      {
        "id": "YTwf8dzhL0GFKMkjH50TZA9HJMvO",
        "count": 1,
        "display_name": "Versapay"
      },
      {
        "id": "XUSj6b7mzSoZR30QdpJSjAQj0vID",
        "count": 1,
        "display_name": "Central Oregon Gymnastics Acdy"
      },
      {
        "id": "it5ClAuYl4csLWCj2PAQlwHCJ1e3",
        "count": 1,
        "display_name": "State Farm"
      },
      {
        "id": "iI5OkUr7b67riPA6mWNVrwMbRX7Y",
        "count": 1,
        "display_name": "Merrill Lynch"
      },
      {
        "id": "V6kvOeBij5MTbwYCGf4QEQRTXQVv",
        "count": 1,
        "display_name": "The Hershey Company"
      },
      {
        "id": "A9ArdHjUZltZLGhoAQqzBwamdE36",
        "count": 1,
        "display_name": "Center for Applied Values and Ethics in Advancing Technologies, UC Santa Cruz, Crown College"
      },
      {
        "id": "5utxoYBIYbBOw2LWzzSxOAJzSI6w",
        "count": 1,
        "display_name": "Hidden Valley Ski. Tube. Ride."
      },
      {
        "id": "n7frP3oODI1hqBUiMlkKIQ79XVEb",
        "count": 1,
        "display_name": "Eagle Crest Conference Center Resort & Golf Club"
      }
    ],
    "partnerships": [
      {
        "id": "iI5OkUr7b67riPA6mWNVrwMbRX7Y",
        "count": 1,
        "display_name": "Merrill Lynch"
      },
      {
        "id": "2iF52ioZBzeIEYG6fvpY7A9HzjWx",
        "count": 1,
        "display_name": "Vail Resorts"
      },
      {
        "id": "CD0sfygRAIcSwh1RavwiFg8UM59e",
        "count": 1,
        "display_name": "Rhetorik is now part of Lightcast"
      },
      {
        "id": "cZGdP8UBDfWPxloAeypI7wswX4ar",
        "count": 1,
        "display_name": "Stealth AI Startup"
      },
      {
        "id": "Bo7NWEmcGLz1VbZpYuCIpAlp5el5",
        "count": 1,
        "display_name": "Quadient"
      },
      {
        "id": "n7frP3oODI1hqBUiMlkKIQ79XVEb",
        "count": 1,
        "display_name": "Eagle Crest Conference Center Resort & Golf Club"
      },
      {
        "id": "Fw4Z76betEsbCARZhNGlNQVmoc4k",
        "count": 1,
        "display_name": "Data Legion"
      },
      {
        "id": "QOGuo898rVPZMjC1sZdIFgl5XP21",
        "count": 1,
        "display_name": "Limble"
      },
      {
        "id": "XUSj6b7mzSoZR30QdpJSjAQj0vID",
        "count": 1,
        "display_name": "Central Oregon Gymnastics Acdy"
      },
      {
        "id": "uzzC3B0CD8BzwJMTsFfbsQpHf1r1",
        "count": 1,
        "display_name": "Influx"
      }
    ],
    "marketing": [
      {
        "id": "nZR30pWK1MCVBFJrbuzr1AvuzWyY",
        "count": 2,
        "display_name": "The Provenance Chain\u2122 Network"
      },
      {
        "id": "BVgbbrV8aDV7VaY9dNslEwVepBxL",
        "count": 2,
        "display_name": "Nasdaq"
      },
      {
        "id": "8GDvoxhxaZBRUJhfNbu1sgiP46wl",
        "count": 1,
        "display_name": "Fluor Corporation"
      },
      {
        "id": "XUSj6b7mzSoZR30QdpJSjAQj0vID",
        "count": 1,
        "display_name": "Central Oregon Gymnastics Acdy"
      },
      {
        "id": "g2d3rduhmjTIFaDKRM0jLAQBR2Zo",
        "count": 1,
        "display_name": "Amazon Web Services (AWS)"
      },
      {
        "id": "xZIpBFdyjnUZUxtrq6rDRgH5rjmc",
        "count": 1,
        "display_name": "Thoughtful AI"
      },
      {
        "id": "ZnFQdCRLqAJt74B98wKfjwvUEoDQ",
        "count": 1,
        "display_name": "Craft.co"
      },
      {
        "id": "PJQ4qjUPrmHdHBMmfYPYDwd1JXEK",
        "count": 1,
        "display_name": "Los Angeles County District Attorney's Office"
      },
      {
        "id": "5P9gR4HdPKnsrZL4kJCklAMnzoPt",
        "count": 1,
        "display_name": "National Park Service"
      },
      {
        "id": "4qwbhGI4ceFfI9AZ3biCKQofL87U",
        "count": 1,
        "display_name": "Talently"
      }
    ]
  },
  "top_previous_employers": {
    "fulfillment": [
      {
        "id": "aKCIYBNF9ey6o5CjHCCO4goHYKlf",
        "count": 2,
        "display_name": "Google"
      },
      {
        "id": "ShoBXhaXCxFpzprJU5KjOwcFvNGU",
        "count": 1,
        "display_name": "Stanford Center on Democracy, Development and the Rule of Law"
      },
      {
        "id": "F4bT8SIK7i1j9RjQiO3I8grnH8FY",
        "count": 1,
        "display_name": "Kappa Kappa Gamma"
      },
      {
        "id": "jzvRRNDir8RxArp1eh5GeAXk6w4B",
        "count": 1,
        "display_name": "Harvard University"
      },
      {
        "id": "RZOFiRjw26VpLObnwmYXGgRyn3aW",
        "count": 1,
        "display_name": "Microsoft"
      },
      {
        "id": "ChqnC4ATztHKii1bxzrvIwWIPOrC",
        "count": 1,
        "display_name": "Institute for Systems Biology (ISB)"
      },
      {
        "id": "CKHJ5P60N4XW4oZXB8BdmgKL8vvO",
        "count": 1,
        "display_name": "US Army"
      },
      {
        "id": "h4vFUBZn9VD76n5iy8mTfgKyt21q",
        "count": 1,
        "display_name": "Modern VideoFilm"
      },
      {
        "id": "VCgMqMIB0CBa7IqMBPduugdNkc8X",
        "count": 1,
        "display_name": "Arivale"
      },
      {
        "id": "HDm8bmFAcLQZRj4l0xi5lQBPC737",
        "count": 1,
        "display_name": "TERI - The Energy and Resources Institute"
      }
    ],
    "all": [
      {
        "id": "aubMfPvUgxL09C7OTtPqqQFVuAR9",
        "count": 11,
        "display_name": "Pipl"
      },
      {
        "id": "CKHJ5P60N4XW4oZXB8BdmgKL8vvO",
        "count": 7,
        "display_name": "US Army"
      },
      {
        "id": "DCD55P9HCbJ6EkJhEdPp0AFqPzf3",
        "count": 6,
        "display_name": "Oracle"
      },
      {
        "id": "Cw9vt7WFFRbhLDnoCeRbswn15Qhi",
        "count": 5,
        "display_name": "Intel Corporation"
      },
      {
        "id": "VCgMqMIB0CBa7IqMBPduugdNkc8X",
        "count": 5,
        "display_name": "Arivale"
      },
      {
        "id": "jiCjGHxMfi3P8vCCQwOAwgwjwINo",
        "count": 5,
        "display_name": "GoodTime"
      },
      {
        "id": "EPGkVHCVWiVik23Klt0bbQc8VJxM",
        "count": 5,
        "display_name": "Outreach"
      },
      {
        "id": "RZOFiRjw26VpLObnwmYXGgRyn3aW",
        "count": 5,
        "display_name": "Microsoft"
      },
      {
        "id": "kVeXPMBPHGnX9rB64wGe9At4dW3P",
        "count": 4,
        "display_name": "98point6 Technologies Inc."
      },
      {
        "id": "aKCIYBNF9ey6o5CjHCCO4goHYKlf",
        "count": 4,
        "display_name": "Google"
      }
    ],
    "marketing": [
      {
        "id": "zuWM0phgKgQjwowv6uLHgAtvQKF4",
        "count": 2,
        "display_name": "9Mile Labs"
      },
      {
        "id": "IKHQhcyKwoVRqRDiYAifIw0MxHWh",
        "count": 2,
        "display_name": "Clackamas Community College"
      },
      {
        "id": "F4yCscbGvEDuCNBnBIPXCwbyRcWi",
        "count": 2,
        "display_name": "HubSpot"
      },
      {
        "id": "FPPytrPldB9rhRCkWF60UQMr3f6O",
        "count": 1,
        "display_name": "Adrian College"
      },
      {
        "id": "fZeq269h6xMuBK9PkL3XwA4jjadC",
        "count": 1,
        "display_name": "REI"
      },
      {
        "id": "PRg7NYedWNtt7E1VCBsEuQu6HCiq",
        "count": 1,
        "display_name": "Yext"
      },
      {
        "id": "UrxDq4FW3yR8T4V5sElq9QqYWuUN",
        "count": 1,
        "display_name": "MemberClicks by Personify"
      },
      {
        "id": "ANm7TS8Bqngd4JpMC4p5wgUH1CIR",
        "count": 1,
        "display_name": "Productside"
      },
      {
        "id": "RLKj1bxH8dfLFo9CrOBTkA3BJZIb",
        "count": 1,
        "display_name": "Cengage Group"
      },
      {
        "id": "cJvSoW9PBv0WFG1W4pJfRA6rS6eU",
        "count": 1,
        "display_name": "Hummingbird Productions"
      }
    ],
    "advisory": [
      {
        "id": "aFC3ojEL5RcCedCot9bNswCrN6F8",
        "count": 1,
        "display_name": "Yale University"
      },
      {
        "id": "p9O0GG4O6WqsvtzpNyocVAI5Olub",
        "count": 1,
        "display_name": "AdeptID"
      },
      {
        "id": "W6maKRtpnOXdhZcndPP60Q53SGKI",
        "count": 1,
        "display_name": "OperaSolutions"
      },
      {
        "id": "2G1aL2PPURKyC5rJ9flDxAAprfec",
        "count": 1,
        "display_name": "Indigo"
      }
    ],
    "partnerships": [
      {
        "id": "CnNdDBWxLEHwgTm5cyY1CALfhBhq",
        "count": 2,
        "display_name": "Loyola Marymount University"
      },
      {
        "id": "y2EL4WMwV5rxo9CVmXTjPANBQafm",
        "count": 1,
        "display_name": "Zaragoza CFF"
      },
      {
        "id": "aIIgGovCCSRkaZ3IXPXwBQ7nylyX",
        "count": 1,
        "display_name": "Onramp"
      },
      {
        "id": "9IQv8mBDdA9T83cIjek0tA91S6G4",
        "count": 1,
        "display_name": "Reonomy"
      },
      {
        "id": "JBwkDDRzPRB7tQW8AzQujgSVpJ8J",
        "count": 1,
        "display_name": "Solganick"
      },
      {
        "id": "0s113ibkQ8GZ9Zs2XHDXlQhSBmXt",
        "count": 1,
        "display_name": "Elite Performance Center"
      },
      {
        "id": "fSYVNhtWvOBdEkmiErscyAuXKrmu",
        "count": 1,
        "display_name": "Growth IQ, Inc."
      },
      {
        "id": "yIiBBIvo8EzvhD7n8qyPOAsybSZ3",
        "count": 1,
        "display_name": "Late Show With David Letterman"
      },
      {
        "id": "uslwoH3BkL9ssUKeJw9SUw82PBxG",
        "count": 1,
        "display_name": "GreatHorn"
      },
      {
        "id": "z9E3J6wTxsCAM2g7gWF3tQVaTO8y",
        "count": 1,
        "display_name": "Ursa"
      }
    ],
    "sales_engineering": [
      {
        "id": "dGcRVWG9SSxCgBGxb6BZkgbcNS24",
        "count": 2,
        "display_name": "Best Buy"
      },
      {
        "id": "dBLbCRkpoGgKasPeYKyNZwtT0M2U",
        "count": 1,
        "display_name": "Hackbright Academy"
      },
      {
        "id": "Az8mYR0sZFCrWvdkco07nwi7tGTt",
        "count": 1,
        "display_name": "Affinity.co"
      },
      {
        "id": "PHLoJtHW3DBdBvjKRBkHKgCxwFUt",
        "count": 1,
        "display_name": "Deloitte"
      },
      {
        "id": "tY66NUkiChh53yzcrCflvgYxnz3y",
        "count": 1,
        "display_name": "MongoDB"
      },
      {
        "id": "lWtLBvQ0cGrwYZYqeBOXBgcnlwV2",
        "count": 1,
        "display_name": "Cisco"
      },
      {
        "id": "QSUyn37PVUc4XUkHe0gqLQbfbsVA",
        "count": 1,
        "display_name": "Conversant"
      },
      {
        "id": "KAC0Xd7EHrog0npVE64jqwLuOlQ4",
        "count": 1,
        "display_name": "Optimal GEO"
      },
      {
        "id": "O88BZ5L3ULlTh92Lc8Y7BQ193Kja",
        "count": 1,
        "display_name": "Replenium"
      },
      {
        "id": "OxIRHf44CmBRanMTIehnAguSvB9p",
        "count": 1,
        "display_name": "UPS"
      }
    ],
    "product": [
      {
        "id": "CWBitC1JRH7fkhvIYth04wK4gTpA",
        "count": 2,
        "display_name": "Deserve"
      },
      {
        "id": "YCZ9fH0r60vFhZzGBBtv1gAacAha",
        "count": 2,
        "display_name": "Playboy"
      },
      {
        "id": "yd6BhDGp2rtCV3WMhZgZqAlVCmwg",
        "count": 2,
        "display_name": "Citrok"
      },
      {
        "id": "N2IAXkhlfPq00ohIHGH5CgTCoXa4",
        "count": 2,
        "display_name": "ThinkDone Solutions"
      },
      {
        "id": "AJqxP6cjufxiBTx6Kfi9Ug8hpUcY",
        "count": 2,
        "display_name": "ICM Partners"
      },
      {
        "id": "g3fAyfjcIp1kBBHjtQBLOQKJQQAz",
        "count": 2,
        "display_name": "Usearch"
      },
      {
        "id": "Qlko3yr9bKmeDrAKcGdCGQUxPoAF",
        "count": 2,
        "display_name": "Upwork"
      },
      {
        "id": "FSriKYqyC5nUMej7Gf6tdwBK21jB",
        "count": 2,
        "display_name": "Swift Racks"
      },
      {
        "id": "iQGCkMhnFSumcC3CbMRYlwb4q4Wo",
        "count": 1,
        "display_name": "Trimble Inc."
      },
      {
        "id": "lUK6ONFpyoSrblOtVvQBBQ5iEFXu",
        "count": 1,
        "display_name": "FactSet"
      }
    ],
    "operations": [
      {
        "id": "VCgMqMIB0CBa7IqMBPduugdNkc8X",
        "count": 3,
        "display_name": "Arivale"
      },
      {
        "id": "EPGkVHCVWiVik23Klt0bbQc8VJxM",
        "count": 2,
        "display_name": "Outreach"
      },
      {
        "id": "Cw9vt7WFFRbhLDnoCeRbswn15Qhi",
        "count": 2,
        "display_name": "Intel Corporation"
      },
      {
        "id": "QztrJWszuy530mCVCum2BQY10rUc",
        "count": 2,
        "display_name": "COMPETE BePlayFuel"
      },
      {
        "id": "8QPs7V62lOefbTnR9UpgmwCn3lDe",
        "count": 2,
        "display_name": "LinkedIn"
      },
      {
        "id": "Vw6KFHe6ZqlXCB610PNIwQgbeAJC",
        "count": 2,
        "display_name": "Qualys"
      },
      {
        "id": "jIQCvYMb43oB1ZE41MtPJQ8zyQSl",
        "count": 1,
        "display_name": "Gumbiner Savett"
      },
      {
        "id": "mCCvRs2b8ZtalaXtjMsiQg6MWfcI",
        "count": 1,
        "display_name": "University of San Francisco"
      },
      {
        "id": "28AAaIbfkRjB5FPFZy7EwwihQuzp",
        "count": 1,
        "display_name": "Color"
      },
      {
        "id": "Kbvk4ci0CC7XexDSxkCjTQlCXLsM",
        "count": 1,
        "display_name": "The Walt Disney Company"
      }
    ],
    "engineering": [
      {
        "id": "Cw9vt7WFFRbhLDnoCeRbswn15Qhi",
        "count": 4,
        "display_name": "Intel Corporation"
      },
      {
        "id": "TtBkiK800Se15xklWgClBgqeo4kI",
        "count": 4,
        "display_name": "AELIUS Exploitation Technologies, LLC"
      },
      {
        "id": "CKHJ5P60N4XW4oZXB8BdmgKL8vvO",
        "count": 4,
        "display_name": "US Army"
      },
      {
        "id": "rhd7B55mGEqBK2j9TnQXOQ89ufI7",
        "count": 4,
        "display_name": "NV5 Geospatial"
      },
      {
        "id": "DCD55P9HCbJ6EkJhEdPp0AFqPzf3",
        "count": 3,
        "display_name": "Oracle"
      },
      {
        "id": "Vw6KFHe6ZqlXCB610PNIwQgbeAJC",
        "count": 2,
        "display_name": "Qualys"
      },
      {
        "id": "V3NClUWFOSPP4QXi5VgWXAXSxqbb",
        "count": 2,
        "display_name": "B3Partners BV"
      },
      {
        "id": "q9dK2WXoX3CC6B9nfAtljgGTIX32",
        "count": 2,
        "display_name": "Apple"
      },
      {
        "id": "5TNHgjRqePuXNmjOBolPfAlGjUsc",
        "count": 2,
        "display_name": "Mariner Finance"
      },
      {
        "id": "TG1BIjEJd149p4ffrVU6swXdUzSU",
        "count": 2,
        "display_name": "Millman Multimedia"
      }
    ],
    "research": [
      {
        "id": "DCD55P9HCbJ6EkJhEdPp0AFqPzf3",
        "count": 1,
        "display_name": "Oracle"
      },
      {
        "id": "ROyBU3NZrjUZoIaT8I1vQQTsxzRj",
        "count": 1,
        "display_name": "thryver"
      },
      {
        "id": "CB8k0Owwyi2AIFKrwEDCIQ3Qx9Mz",
        "count": 1,
        "display_name": "G2 Crowd"
      },
      {
        "id": "finq1C7GlLFSRyirchjGMQCKsDq5",
        "count": 1,
        "display_name": "Phi Gamma Nu - University of Michigan"
      },
      {
        "id": "6tCvxmJYT1IPWW4wLoHTWw4N51iJ",
        "count": 1,
        "display_name": "University of Michigan"
      },
      {
        "id": "cCiBz82LBfHBE90FRkUJBgadXpcZ",
        "count": 1,
        "display_name": "Glocal Partners - innovation without borders"
      },
      {
        "id": "VCdIxBCmgPdmaGAATNeZcwUovOHA",
        "count": 1,
        "display_name": "Red Bull"
      },
      {
        "id": "CKHJ5P60N4XW4oZXB8BdmgKL8vvO",
        "count": 1,
        "display_name": "US Army"
      },
      {
        "id": "HKCBzjcdUhVPHCmb246CSAYwkTC1",
        "count": 1,
        "display_name": "Center for Effective Government"
      },
      {
        "id": "gSB4RCaVeXXRrhh8EpSSPQeANDeu",
        "count": 1,
        "display_name": "VH Strategies"
      }
    ],
    "sales": [
      {
        "id": "aubMfPvUgxL09C7OTtPqqQFVuAR9",
        "count": 8,
        "display_name": "Pipl"
      },
      {
        "id": "B7V3Ti2sbqP5v2KBwNoK6whNkTNx",
        "count": 4,
        "display_name": "Twilio"
      },
      {
        "id": "jiCjGHxMfi3P8vCCQwOAwgwjwINo",
        "count": 4,
        "display_name": "GoodTime"
      },
      {
        "id": "FkUNtIzoUvvHTzkPVRPa4ArqxxXY",
        "count": 3,
        "display_name": "Twilio Segment"
      },
      {
        "id": "q5gqs3Ekr9Kpo61n9rw7Sw3DojNi",
        "count": 2,
        "display_name": "Fullstory"
      },
      {
        "id": "dzHbRfCbAyz8JJQBnG7eqgiT5XHA",
        "count": 2,
        "display_name": "TEKsystems"
      },
      {
        "id": "GHHSjwwlfcdihAW4hcjOSwHVkq8d",
        "count": 2,
        "display_name": "Gem"
      },
      {
        "id": "QpEvE5C0r4xUdCuv58GC1QckMLn4",
        "count": 2,
        "display_name": "University of Oregon Alumni Association"
      },
      {
        "id": "RTLRi50EYtA9gMcQvCfmaQoA4xpo",
        "count": 2,
        "display_name": "BlueJeans by Verizon"
      },
      {
        "id": "BCl6Te8MyW4Cv4iZN6HWVw9nTsvb",
        "count": 2,
        "display_name": "First Interstate"
      }
    ],
    "finance": [
      {
        "id": "aV3NkqzO1Qe639fay2UzigiXpkF3",
        "count": 1,
        "display_name": "Conversica"
      },
      {
        "id": "Pt8QqdHiI5swPLyB4kwkWAnYh66C",
        "count": 1,
        "display_name": "University of Massachusetts Dartmouth"
      },
      {
        "id": "O9Dcf0OOwvtjB2uAjIRT5gPuGfyJ",
        "count": 1,
        "display_name": "Popsugar"
      },
      {
        "id": "BpwXsi21tBkG7Hi2jA12WQ9tAHae",
        "count": 1,
        "display_name": "Virgin America"
      },
      {
        "id": "wFQCmQqBHo5X55LpuwFW7wcJPUoZ",
        "count": 1,
        "display_name": "UMass Dartmouth"
      },
      {
        "id": "7L0SglhytLJVj2JOx3PqVgDa2lnM",
        "count": 1,
        "display_name": "MineralTree, Inc."
      }
    ],
    "support": [
      {
        "id": "FmDHGWBNkfa4T6cxWIHaLwi6gKon",
        "count": 2,
        "display_name": "Kentik"
      },
      {
        "id": "IC4HW1aunaKBBa0Cmr6TWA860WHj",
        "count": 2,
        "display_name": "Talkdesk"
      },
      {
        "id": "Yv1y1zaxv6V7f2fHcCu6LgQRMsij",
        "count": 1,
        "display_name": "WorkStep"
      },
      {
        "id": "DiUqzSzx5YWPCq3TOvSWPgBURY7B",
        "count": 1,
        "display_name": "Peace Corps"
      },
      {
        "id": "SawNhCuLWVRtMu8YYP4cEgpefwbH",
        "count": 1,
        "display_name": "RELENTLESS Venture Studio"
      },
      {
        "id": "tWAPoBXzEhgQqCK0pIJuOAGRDzMI",
        "count": 1,
        "display_name": "InMoment"
      },
      {
        "id": "97TIPTzWxg9syDCyGOHVXAFoPEcc",
        "count": 1,
        "display_name": "Thrive Commerce"
      },
      {
        "id": "GxSBhsfToP7taU3gLd5J4AaoA27d",
        "count": 1,
        "display_name": "PAX"
      },
      {
        "id": "EBDMvr90fOA7oCD8AdBJZgxZpRP8",
        "count": 1,
        "display_name": "U.S. Geological Survey (USGS)"
      },
      {
        "id": "7SfRVOIYR06O2sIKwDBqcges4Oxn",
        "count": 1,
        "display_name": "Weatherford"
      }
    ],
    "creative": [
      {
        "id": "pCAYOjYgaVGt2A62PRdkmwVWlRpk",
        "count": 1,
        "display_name": "K\u00f6nig Creative Co."
      },
      {
        "id": "Wk4G8RC7plx1pi0blBaNgwJ6lWN7",
        "count": 1,
        "display_name": "Busybee Design"
      },
      {
        "id": "nIzedfJEumuq2Bd5zhCCuAxN6neR",
        "count": 1,
        "display_name": "Philadelphia Society for the Preservation of Landmarks"
      },
      {
        "id": "6Z3frRVTKFANC39QhFOVcgCGX4M8",
        "count": 1,
        "display_name": "San Diego Convention Center Corporation"
      },
      {
        "id": "2lVxAUWJuXaBCd8o909IoA40sE9D",
        "count": 1,
        "display_name": "Temple University"
      },
      {
        "id": "BaJBfcUOqB4uLBcb9FJgwQoYAElb",
        "count": 1,
        "display_name": "Pennsylvania Horticultural Society (PHS)"
      },
      {
        "id": "gWJBBj8gzRwcXgY6hzaGiwXMVtGY",
        "count": 1,
        "display_name": "Philadelphia Eyeglass Labs"
      }
    ],
    "legal": [
      {
        "id": "RZOFiRjw26VpLObnwmYXGgRyn3aW",
        "count": 1,
        "display_name": "Microsoft"
      },
      {
        "id": "6bDMBJQhrBuSdqYQCmcgeQkkkC1J",
        "count": 1,
        "display_name": "LexisNexis Risk Solutions"
      },
      {
        "id": "UnPEIlo9ixc2CgceSlBDEwuSHJm9",
        "count": 1,
        "display_name": "University of Washington College of Engineering"
      }
    ],
    "human_resources": [
      {
        "id": "EPGkVHCVWiVik23Klt0bbQc8VJxM",
        "count": 4,
        "display_name": "Outreach"
      },
      {
        "id": "kVeXPMBPHGnX9rB64wGe9At4dW3P",
        "count": 4,
        "display_name": "98point6 Technologies Inc."
      },
      {
        "id": "VCgMqMIB0CBa7IqMBPduugdNkc8X",
        "count": 4,
        "display_name": "Arivale"
      },
      {
        "id": "4zjKczMlgtrvmvnupujH0QwvSfId",
        "count": 2,
        "display_name": "Actian"
      },
      {
        "id": "QTBLUHqq2JSk8OepdLQrxwP5TNub",
        "count": 2,
        "display_name": "BeenVerified.com"
      },
      {
        "id": "KSagHk2e5x71Kbm1ZwxAvguJg2WX",
        "count": 2,
        "display_name": "GE Digital"
      },
      {
        "id": "RZOFiRjw26VpLObnwmYXGgRyn3aW",
        "count": 1,
        "display_name": "Microsoft"
      },
      {
        "id": "Os4EgZyx41p7CRYWKSWoKA0Ry858",
        "count": 1,
        "display_name": "Reflektive"
      },
      {
        "id": "zL893tAsmFsf468kCsaDSQf28oU4",
        "count": 1,
        "display_name": "Seattle University"
      },
      {
        "id": "96j6UIHI6NIPosCt6y8VGwOz7rbE",
        "count": 1,
        "display_name": "SCA Technologies"
      }
    ],
    "analyst": [
      {
        "id": "EPGkVHCVWiVik23Klt0bbQc8VJxM",
        "count": 2,
        "display_name": "Outreach"
      },
      {
        "id": "uyy07kGZp3kx4JGn5ScLpwFZnJem",
        "count": 1,
        "display_name": "CSAA Insurance Group, a AAA Insurer"
      },
      {
        "id": "OgM9JiwShkjRU9drhuqDBApkfk7R",
        "count": 1,
        "display_name": "University of San Diego"
      },
      {
        "id": "LXTS0NJ4Xou4rSnHlfW8RgDye28S",
        "count": 1,
        "display_name": "Controlco"
      },
      {
        "id": "yA4QxUVgBphbp6hECpOcoQrZf7Lc",
        "count": 1,
        "display_name": "ScienceLogic"
      },
      {
        "id": "obOBDrYK94u7Nnp7P64hvA8QvGQx",
        "count": 1,
        "display_name": "San Diego State University"
      },
      {
        "id": "4oLitm1O6wHAwDIBoacBBQUXWKzF",
        "count": 1,
        "display_name": "T-Mobile"
      },
      {
        "id": "SSL0fn4PmnVG7srxTLW5Yw7a7Q5f",
        "count": 1,
        "display_name": "Comscore, Inc."
      },
      {
        "id": "F8v2fePkcvLUNVPwQcSOWwfx9X3J",
        "count": 1,
        "display_name": "FICO"
      },
      {
        "id": "2iF52ioZBzeIEYG6fvpY7A9HzjWx",
        "count": 1,
        "display_name": "Vail Resorts"
      }
    ]
  },
  "top_next_employers_12_month": {
    "sales": [
      {
        "id": "C48T7IE5S3Wng5ofMWBnmwnzh6Cx",
        "count": 2,
        "display_name": "Private Health Management"
      },
      {
        "id": "XYHsHzNJYjj2C9hV6XH2zAelO7dK",
        "count": 1,
        "display_name": "Sybill"
      },
      {
        "id": "CdUJbUqZm8X1vjguUwKdOwRQBxkw",
        "count": 1,
        "display_name": "Tria"
      },
      {
        "id": "sbfBF4GZ3zKJOprVxfDyugp7MI44",
        "count": 1,
        "display_name": "Stuut"
      },
      {
        "id": "QevcMSgBVzzCDkQMe1CAJwKCjooa",
        "count": 1,
        "display_name": "Mesh"
      },
      {
        "id": "45DRWSKT1CxuPSClLxxwog3617IC",
        "count": 1,
        "display_name": "Transcend"
      },
      {
        "id": "4qwbhGI4ceFfI9AZ3biCKQofL87U",
        "count": 1,
        "display_name": "Talently"
      },
      {
        "id": "80Noq4hRteCcaAEf2nwHrw4cKY0M",
        "count": 1,
        "display_name": "U.S. District Court, Eastern District of Pennsylvania"
      },
      {
        "id": "Rv8KBQCgfg2M67wPv79mngc10ROF",
        "count": 1,
        "display_name": "Spokeo"
      },
      {
        "id": "Z6HhBQttIcaKaVPTjxJbfQxY4PmJ",
        "count": 1,
        "display_name": "Paycom"
      }
    ],
    "operations": [
      {
        "id": "YTwf8dzhL0GFKMkjH50TZA9HJMvO",
        "count": 1,
        "display_name": "Versapay"
      },
      {
        "id": "NeNcCSqofszpMPvSqkURXwy6NqHp",
        "count": 1,
        "display_name": "Anduril Industries"
      },
      {
        "id": "V6kvOeBij5MTbwYCGf4QEQRTXQVv",
        "count": 1,
        "display_name": "The Hershey Company"
      },
      {
        "id": "GqDq6nxvcABfaYtyQ3V6IQehsOkN",
        "count": 1,
        "display_name": "ExtraHop"
      },
      {
        "id": "ZzJPvScCOeuHLvyu8S033QogePt8",
        "count": 1,
        "display_name": "Flex"
      }
    ],
    "human_resources": [
      {
        "id": "qVhGo3EgtgCVgHwf4aS4OQJxlR8O",
        "count": 1,
        "display_name": "Attain Partners"
      },
      {
        "id": "IESWZWlf1vhMsiL4jnh3jwtgDj95",
        "count": 1,
        "display_name": "Hallow"
      },
      {
        "id": "ixxTLZxbq813YqytU0j9VAcG5d2e",
        "count": 1,
        "display_name": "Antithesis"
      },
      {
        "id": "UqJeZFHRNewUCY3o0r9GBAFTSRUS",
        "count": 1,
        "display_name": "IntraEdge"
      },
      {
        "id": "eHGg5zP2674lR7S1vfvZKwdl0oNS",
        "count": 1,
        "display_name": "String AI"
      },
      {
        "id": "3vKDhYO9m23bvxLkctCuCwj668fq",
        "count": 1,
        "display_name": "Stealth"
      },
      {
        "id": "3eyqGcIV9l2aHajdSQtRqgAH1diu",
        "count": 1,
        "display_name": "Covet Health"
      },
      {
        "id": "gLC77GBZiN1AVCAL14RfAgCkBcl7",
        "count": 1,
        "display_name": "NetDocuments"
      }
    ],
    "product": [
      {
        "id": "ltCOPMbY1V61SPwfgFPsEwrHfP1M",
        "count": 2,
        "display_name": "Savvy Programmers"
      },
      {
        "id": "GeBlYAG05dkklKxA3hCOngSLLImO",
        "count": 1,
        "display_name": "Endgame"
      }
    ],
    "analyst": [
      {
        "id": "jTI3lUxNgd7qK9i7eeoIwgW7sXYD",
        "count": 1,
        "display_name": "TalentDreams, a 501(c)(3)"
      },
      {
        "id": "vUwqgAcfSXuv1nUkECq8awBbPKbw",
        "count": 1,
        "display_name": "County of Santa Clara"
      }
    ],
    "partnerships": [
      {
        "id": "uzzC3B0CD8BzwJMTsFfbsQpHf1r1",
        "count": 1,
        "display_name": "Influx"
      },
      {
        "id": "Bo7NWEmcGLz1VbZpYuCIpAlp5el5",
        "count": 1,
        "display_name": "Quadient"
      },
      {
        "id": "80Noq4hRteCcaAEf2nwHrw4cKY0M",
        "count": 1,
        "display_name": "U.S. District Court, Eastern District of Pennsylvania"
      },
      {
        "id": "Fw4Z76betEsbCARZhNGlNQVmoc4k",
        "count": 1,
        "display_name": "Data Legion"
      },
      {
        "id": "CD0sfygRAIcSwh1RavwiFg8UM59e",
        "count": 1,
        "display_name": "Rhetorik is now part of Lightcast"
      },
      {
        "id": "cZGdP8UBDfWPxloAeypI7wswX4ar",
        "count": 1,
        "display_name": "Stealth AI Startup"
      }
    ],
    "marketing": [
      {
        "id": "hH63udDiUZVLOTx3JjhVewjBcJC4",
        "count": 1,
        "display_name": "Moveworks"
      },
      {
        "id": "4qwbhGI4ceFfI9AZ3biCKQofL87U",
        "count": 1,
        "display_name": "Talently"
      },
      {
        "id": "8GDvoxhxaZBRUJhfNbu1sgiP46wl",
        "count": 1,
        "display_name": "Fluor Corporation"
      },
      {
        "id": "CdUJbUqZm8X1vjguUwKdOwRQBxkw",
        "count": 1,
        "display_name": "Tria"
      },
      {
        "id": "xZIpBFdyjnUZUxtrq6rDRgH5rjmc",
        "count": 1,
        "display_name": "Thoughtful AI"
      },
      {
        "id": "5P9gR4HdPKnsrZL4kJCklAMnzoPt",
        "count": 1,
        "display_name": "National Park Service"
      }
    ],
    "fulfillment": [
      {
        "id": "NeNcCSqofszpMPvSqkURXwy6NqHp",
        "count": 1,
        "display_name": "Anduril Industries"
      }
    ],
    "support": [
      {
        "id": "0N451P9CZ6O4VCOXugdetAd2hb1M",
        "count": 1,
        "display_name": "topSERV Fractional"
      },
      {
        "id": "qOCO9aqSt1JgLpcCDCaIGwUuZEPD",
        "count": 1,
        "display_name": "Envoy"
      },
      {
        "id": "DbX7kqMmt3NS44BYlECRKwscq467",
        "count": 1,
        "display_name": "Pinecone"
      },
      {
        "id": "80Noq4hRteCcaAEf2nwHrw4cKY0M",
        "count": 1,
        "display_name": "U.S. District Court, Eastern District of Pennsylvania"
      },
      {
        "id": "WLxmJozjeNK5ajCBpE1uTAnhtxir",
        "count": 1,
        "display_name": "Pindrop"
      },
      {
        "id": "mzviUQjfL23U0tEbTQxEXQs4kLFI",
        "count": 1,
        "display_name": "Serena Neel"
      },
      {
        "id": "aqrOOJB0T5v4YhyEhgfSeQJT1HSr",
        "count": 1,
        "display_name": "FOSSA"
      },
      {
        "id": "8BiIjxsDuBqS9TQvT3zRHQih7gYJ",
        "count": 1,
        "display_name": "Mixpanel"
      },
      {
        "id": "GeBlYAG05dkklKxA3hCOngSLLImO",
        "count": 1,
        "display_name": "Endgame"
      },
      {
        "id": "WZxON2sNNh34HcmHApMMzQ0ELPZe",
        "count": 1,
        "display_name": "Bayence"
      }
    ],
    "sales_engineering": [
      {
        "id": "gbzAHmeUyu5rJyy4eUrPPgtM5jdC",
        "count": 1,
        "display_name": "Five By Five"
      },
      {
        "id": "Dn0GAueIRsYzwepbYEGIAQVi7Qyl",
        "count": 1,
        "display_name": "Anaconda, Inc."
      },
      {
        "id": "tgJ5baJmPY596BScXkMUCAL2wNzm",
        "count": 1,
        "display_name": "dbt Labs"
      },
      {
        "id": "GeBlYAG05dkklKxA3hCOngSLLImO",
        "count": 1,
        "display_name": "Endgame"
      },
      {
        "id": "xIVEyLobPvOqDn2JJkk2YQsl8oEn",
        "count": 1,
        "display_name": "Supabase"
      },
      {
        "id": "lWtLBvQ0cGrwYZYqeBOXBgcnlwV2",
        "count": 1,
        "display_name": "Cisco"
      },
      {
        "id": "dd5qSOtI0mhoCyWLLxUPsAUem2jN",
        "count": 1,
        "display_name": "Astronomer"
      }
    ],
    "engineering": [
      {
        "id": "PR51FRfxp6Aq3UgkwnZsBwWyqqee",
        "count": 2,
        "display_name": "Syntracts"
      },
      {
        "id": "GqDq6nxvcABfaYtyQ3V6IQehsOkN",
        "count": 1,
        "display_name": "ExtraHop"
      },
      {
        "id": "Az8mYR0sZFCrWvdkco07nwi7tGTt",
        "count": 1,
        "display_name": "Affinity.co"
      },
      {
        "id": "20TplFCve1gCyVLLHonwQg0zHHvr",
        "count": 1,
        "display_name": "Tint"
      },
      {
        "id": "Dn0GAueIRsYzwepbYEGIAQVi7Qyl",
        "count": 1,
        "display_name": "Anaconda, Inc."
      },
      {
        "id": "i9rOBw1zghZjv7oIw7wmJQc5h9Gk",
        "count": 1,
        "display_name": "Artisan"
      },
      {
        "id": "GeBlYAG05dkklKxA3hCOngSLLImO",
        "count": 1,
        "display_name": "Endgame"
      },
      {
        "id": "7BRyINZQy27a2pCdRiOW5QbyscCE",
        "count": 1,
        "display_name": "CLEAR"
      },
      {
        "id": "tgJ5baJmPY596BScXkMUCAL2wNzm",
        "count": 1,
        "display_name": "dbt Labs"
      },
      {
        "id": "es7LgyqRNsFDLcWXC3WAvACHVh9g",
        "count": 1,
        "display_name": "Salesforce"
      }
    ],
    "legal": [
      {
        "id": "0Csy3EeOMWFEA8NCWHIqCg3tMJ4i",
        "count": 1,
        "display_name": "Daxko"
      }
    ],
    "all": [
      {
        "id": "Dn0GAueIRsYzwepbYEGIAQVi7Qyl",
        "count": 3,
        "display_name": "Anaconda, Inc."
      },
      {
        "id": "NeNcCSqofszpMPvSqkURXwy6NqHp",
        "count": 2,
        "display_name": "Anduril Industries"
      },
      {
        "id": "PR51FRfxp6Aq3UgkwnZsBwWyqqee",
        "count": 2,
        "display_name": "Syntracts"
      },
      {
        "id": "ltCOPMbY1V61SPwfgFPsEwrHfP1M",
        "count": 2,
        "display_name": "Savvy Programmers"
      },
      {
        "id": "C48T7IE5S3Wng5ofMWBnmwnzh6Cx",
        "count": 2,
        "display_name": "Private Health Management"
      },
      {
        "id": "45DRWSKT1CxuPSClLxxwog3617IC",
        "count": 1,
        "display_name": "Transcend"
      },
      {
        "id": "L5u6DMEzMjnJgsUo5lGhSgIvcG9e",
        "count": 1,
        "display_name": "Point72"
      },
      {
        "id": "UlHUHkewQOBrfpPFIXBlugJ1EDAF",
        "count": 1,
        "display_name": "Vidalytics"
      },
      {
        "id": "XYHsHzNJYjj2C9hV6XH2zAelO7dK",
        "count": 1,
        "display_name": "Sybill"
      },
      {
        "id": "QevcMSgBVzzCDkQMe1CAJwKCjooa",
        "count": 1,
        "display_name": "Mesh"
      }
    ]
  },
  "top_previous_employers_12_month": {
    "support": [
      {
        "id": "qPkbBnXGZYu88dEzy8vLyAVDsheu",
        "count": 1,
        "display_name": "Smartsheet"
      },
      {
        "id": "uTLoh0XEceWFNUAm2e6jkgikETz1",
        "count": 1,
        "display_name": "Aspire"
      }
    ],
    "engineering": [
      {
        "id": "a9Fry20w3fB1NMxE2hSy9wV9XyQ6",
        "count": 1,
        "display_name": "SmileDirectClub"
      },
      {
        "id": "DRRZ4kyGgASQQCE4xObH3A5vdP3i",
        "count": 1,
        "display_name": "Tandems"
      },
      {
        "id": "Uqb0j2VGjFif49L6Wix1ggxHNrpl",
        "count": 1,
        "display_name": "Legion Technologies"
      },
      {
        "id": "ZhswoJ41nK0ci3VDzgt5cgQE3b6C",
        "count": 1,
        "display_name": "Begin"
      }
    ],
    "partnerships": [
      {
        "id": "lCs46RFnAkR8YA8hNrGdbAx9Y15h",
        "count": 1,
        "display_name": "Keeper Security, Inc."
      }
    ],
    "product": [
      {
        "id": "n3wJsBfhE6sYUFAN2WIrBQuG1pVs",
        "count": 1,
        "display_name": "HG Insights"
      },
      {
        "id": "aYmBzd3kwLg3bleuc1WefAs3VHU9",
        "count": 1,
        "display_name": "Aumni"
      }
    ],
    "all": [
      {
        "id": "n3wJsBfhE6sYUFAN2WIrBQuG1pVs",
        "count": 1,
        "display_name": "HG Insights"
      },
      {
        "id": "FS5QJLzh40brLyO2uSG5nwST4LdN",
        "count": 1,
        "display_name": "Concord"
      },
      {
        "id": "W8XKMY2C1QTI7p5dUlwaiQKNiJqC",
        "count": 1,
        "display_name": "3X4 Genetics"
      },
      {
        "id": "qPkbBnXGZYu88dEzy8vLyAVDsheu",
        "count": 1,
        "display_name": "Smartsheet"
      },
      {
        "id": "LrHluOz1NnQDki6tgaXBJgFlaAkG",
        "count": 1,
        "display_name": "1 Hotels"
      },
      {
        "id": "DRRZ4kyGgASQQCE4xObH3A5vdP3i",
        "count": 1,
        "display_name": "Tandems"
      },
      {
        "id": "a9Fry20w3fB1NMxE2hSy9wV9XyQ6",
        "count": 1,
        "display_name": "SmileDirectClub"
      },
      {
        "id": "iFO0iYvbbNUFymh2ncNyngDJyBwi",
        "count": 1,
        "display_name": "QuicksortRx"
      },
      {
        "id": "nWva2ShJiKnSB95bmTWAbwl2bM7B",
        "count": 1,
        "display_name": "PlanSource"
      },
      {
        "id": "aYmBzd3kwLg3bleuc1WefAs3VHU9",
        "count": 1,
        "display_name": "Aumni"
      }
    ],
    "sales_engineering": [
      {
        "id": "RkQf5SheAMlojDPUBdgJawJQ4G2R",
        "count": 1,
        "display_name": "Mitsubishi Electric Iconics Digital Solutions"
      }
    ],
    "sales": [
      {
        "id": "If6DRmwAMwjPfFuNzSN5BgHtS4Eu",
        "count": 1,
        "display_name": "HumanFirst"
      },
      {
        "id": "FkUNtIzoUvvHTzkPVRPa4ArqxxXY",
        "count": 1,
        "display_name": "Twilio Segment"
      }
    ],
    "fulfillment": [
      {
        "id": "W8XKMY2C1QTI7p5dUlwaiQKNiJqC",
        "count": 1,
        "display_name": "3X4 Genetics"
      },
      {
        "id": "aKCIYBNF9ey6o5CjHCCO4goHYKlf",
        "count": 1,
        "display_name": "Google"
      }
    ],
    "human_resources": [
      {
        "id": "LrHluOz1NnQDki6tgaXBJgFlaAkG",
        "count": 1,
        "display_name": "1 Hotels"
      },
      {
        "id": "iFO0iYvbbNUFymh2ncNyngDJyBwi",
        "count": 1,
        "display_name": "QuicksortRx"
      },
      {
        "id": "FS5QJLzh40brLyO2uSG5nwST4LdN",
        "count": 1,
        "display_name": "Concord"
      }
    ],
    "marketing": [
      {
        "id": "d7zkq3MFUwjqLTLCW1hUDQsR2jiy",
        "count": 1,
        "display_name": "The Junior League of Atlanta, Inc."
      }
    ]
  },
  "top_us_employee_metros": {
    "san francisco, california, united states": {
      "current_headcount": 9,
      "12_month_growth_rate": -0.1818
    },
    "san diego, california, united states": {
      "current_headcount": 8,
      "12_month_growth_rate": 0.0
    },
    "seattle, washington, united states": {
      "current_headcount": 7,
      "12_month_growth_rate": -0.2222
    },
    "new york, new york, united states": {
      "current_headcount": 7,
      "12_month_growth_rate": -0.2222
    },
    "boston, massachusetts, united states": {
      "current_headcount": 5,
      "12_month_growth_rate": 0.25
    },
    "atlanta, georgia, united states": {
      "current_headcount": 4,
      "12_month_growth_rate": 0.3333
    },
    "portland, oregon, united states": {
      "current_headcount": 4,
      "12_month_growth_rate": -0.2
    },
    "denver, colorado, united states": {
      "current_headcount": 4,
      "12_month_growth_rate": -0.3333
    },
    "los angeles, california, united states": {
      "current_headcount": 3,
      "12_month_growth_rate": 0.0
    },
    "district of columbia, united states": {
      "current_headcount": 2,
      "12_month_growth_rate": 0.0
    }
  },
  "dataset_version": "33.1"
}
```

Updated about 11 hours ago

---

Did this page help you?

Yes

No

---
# https://docs.peopledatalabs.com/docs/cleaner-apis-reference

We designed the Cleaner APIs to clean your company, school and location data so that you can better query our person data. We use these same cleaners for standardizing our data as part of our [Data Build Process](/docs/data-build).

## Endpoints

The endpoints for the Cleaner APIs are:

Company: `https://api.peopledatalabs.com/v5/company/clean`  
Location: `https://api.peopledatalabs.com/v5/location/clean`  
School: `https://api.peopledatalabs.com/v5/school/clean`

## Billing and Access

The Cleaner APIs are public and we make them available by default to all customers.

## Rate Limiting

The standard rate limit is 10 per minute, and we have a standard total limit of 10,000 per month that we provide free of charge. To increase your monthly limit above 10,000, reach out to your Data Consultant or Customer Success Manager.

## Input Parameters

Each of the three Cleaner API endpoints supports a different set of input parameters, which we've described in the tables below:

> ðŸ“˜
>
> ### For More Details, See [Input Parameters - Cleaner APIs](/docs/input-parameters-cleaner-apis)
>
> You can also click on the individual parameter names in the table below to view more information on them.

### Company Cleaner API (`/company/clean`)

| Parameter Name | Required | Description | Default | Example |
| --- | --- | --- | --- | --- |
| [`name`](/docs/input-parameters-cleaner-apis#name) | No (but see note below) | The name of the company that you want to identify. We accept unformatted strings with arbitrary capitalizations, leading and trailing whitespaces and so forth. | None | `â€œPeople data LABSâ€` |
| [`website`](/docs/input-parameters-cleaner-apis#website) | No (but see note below) | The website of the company that you want to identify. We accept unformatted URLs with arbitrary capitalizations, leading and trailing whitespaces and so forth. | None | `www.peopledatalabs.com` |
| [`profile`](/docs/input-parameters-cleaner-apis#profile) | No (but see note below) | The social profile URL of the company that you want to identify. We accept unformatted URLs with arbitrary capitalizations, leading and trailing whitespaces and so forth. | None | `â€https://linkedin.com/company/peopledatalabsâ€` |
| [`pretty`](/docs/input-parameters-cleaner-apis#pretty) | No | Whether the output should have human-readable indentation. | `False` | `True` |
| [`api_key`](/docs/input-parameters-cleaner-apis#api_key) | No\* | Your secret API key.  While we do not require this as part of the request parameters, if you don't provide it here, then you must provide it in an alternative way, such as by using the `x-api-key` field in the headers. For more information, see the [Authentication](/docs/authentication) page. | None |  |

**Note**: Although the Company Cleaner API doesn't require any specific input fields, it requires **at least one** of the following identifying fields: `name`, `website` or `profile`.

### Location Cleaner API (`/location/clean`)

| Parameter Name | Required | Description | Default | Example |
| --- | --- | --- | --- | --- |
| [`location`](/docs/input-parameters-cleaner-apis#location) | Yes | The name of the location that you want to identify. We accept unformatted locations with arbitrary capitalizations, leading and trailing whitespaces and so forth. | None | `"san francisco"` |
| [`pretty`](/docs/input-parameters-cleaner-apis#pretty-1) | No | Whether the output should have human-readable indentation. | `False` | `True` |
| [`api_key`](/docs/input-parameters-cleaner-apis#api_key-1) | No\* | Your secret API key.  While we do not require this as part of the request parameters, if you don't provide it here, then you must provide it in an alternative way, such as by using the `x-api-key` field in the headers. For more information, see the [Authentication](/docs/authentication) page. | None |  |

### School Cleaner API (`/school/clean`)

| Parameter Name | Required | Description | Default | Example |
| --- | --- | --- | --- | --- |
| [`name`](/docs/input-parameters-cleaner-apis#name-1) | No (but see note below) | The name of the company that you want to identify. We accept unformatted strings with arbitrary capitalizations, leading and trailing whitespaces and so forth. | None | `â€œPeople data LABSâ€` |
| [`website`](/docs/input-parameters-cleaner-apis#website-1) | No (but see note below) | The website of the company that you want to identify. We accept unformatted URLs with arbitrary capitalizations, leading and trailing whitespaces and so forth. | None | `www.peopledatalabs.com` |
| [`profile`](/docs/input-parameters-cleaner-apis#profile-1) | No (but see note below) | The social profile URL of the company that you want to identify. We accept unformatted URLs with arbitrary capitalizations, leading and trailing whitespaces and so forth. | None | `â€https://linkedin.com/company/peopledatalabsâ€` |
| [`pretty`](/docs/input-parameters-cleaner-apis#pretty-2) | No | Whether the output should have human-readable indentation. | `False` | `True` |
| [`api_key`](/docs/input-parameters-cleaner-apis#api_key-2) | No\* | Your secret API key.  While we do not require this as part of the request parameters, if you don't provide it here, then you must provide it in an alternative way, such as by using the `x-api-key` field in the headers. For more information, see the [Authentication](/docs/authentication) page. | None |  |

**Note**: Although the School Cleaner API doesn't require any specific input fields, it requires **at least one** of the following identifying fields: `name`, `website` or `profile`.

## Output Responses

Each of the three Cleaner API endpoints returns a different response, as shown below:

> ðŸ“˜
>
> ### For More Details, see [Output Response - Cleaner APIs](/docs/output-response-cleaner-apis)

### Company Cleaner API (`/company/clean`)

Here is an example response from the Company Cleaner API:

JSON

```
{
  "name": "people data labs",
  "size": "11-50",
  "id": "tnHcNHbCv8MKeLh92946LAkX6PKg",
  "founded": 2015,
  "industry": "computer software",
  "location": {
    "name": "san francisco, california, united states",
    "locality": "san francisco",
    "region": "california",
    "metro": "san francisco, california",
    "country": "united states",
    "continent": "north america",
    "street_address": "455 market street",
    "address_line_2": "suite 1670",
    "postal_code": "94105",
    "geo": "37.77,-122.41"
  },
  "linkedin_url": "linkedin.com/company/peopledatalabs",
  "linkedin_id": "18170482",
  "facebook_url": "facebook.com/peopledatalabs",
  "twitter_url": "twitter.com/peopledatalabs",
  "website": "peopledatalabs.com",
  "ticker": null,
  "type": "private",
  "raw": [],
  "score": 3.0,
  "fuzzy_match": false
}
```

### Location Cleaner API (`/location/clean`)

Here is an example response from the Location Cleaner API:

JSON

```
{
  "name": "portland, oregon, united states",
  "locality": "portland",
  "region": "oregon",
  "subregion": "multnomah county",
  "country": "united states",
  "continent": "north america",
  "type": "locality",
  "geo": "45.52,-122.67",
}
```

### School Cleaner API (`/school/clean`)

Here is an example response from the School Cleaner API:

JSON

```
{
  "name": "university of california, los angeles",
  "type": "post-secondary institution",
  "id": "72978d72-275a-49c8-b9b9-f227ccfb1361",
  "location": {
    "name": "los angeles, california, united states",
    "locality": "los angeles",
    "region": "california",
    "country": "united states",
    "continent": "north america"
  },
  "linkedin_url": "linkedin.com/school/ucla",
  "facebook_url": null,
  "twitter_url": null,
  "linkedin_id": "17950",
  "website": "ucla.edu",
  "domain": "ucla.edu"
}
```

Updated 4 months ago

---

Did this page help you?

Yes

No

---
# https://docs.peopledatalabs.com/docs/reference-skill-enrichment-api

> â—ï¸
>
> ### The Skill Enrichment API is now fully removed
>
> This endpoint was removed in our April 2025 (v30.0) Release and is no longer available. This page is retained for historical documentation purposes.
>
> For more information, please see our [April 2025 Release Notes (v30.0)](/changelog/april-2025-release-notes-v300).

## Endpoint

The endpoint for the Skill Enrichment API is `v5/skill/enrich`.

## Billing and Access

This API is currently in production, and you can access it by using your API key.

The HTTP response code will be `200` when the API returns a matching job title, and the response code will be `404` when the API neither finds nor returns a matching job title. We charge per match.

## Rate Limiting

Our default limit for free customers is 100 per minute. Our default limit for paying customers is 5,000 per minute.

## Input Parameters

> ðŸ“˜
>
> ### For More Details, See [Skill Enrichment API - Input Parameters](/docs/input-parameters-skill-enrichment-api)
>
> You can also click on the individual parameter names in the table below to view more information on them.

| Parameter Name | Required | Description | Default | Example |
| --- | --- | --- | --- | --- |
| [`skill`](/docs/input-parameters-skill-enrichment-api#skill) | Yes | The skill that you are enriching. |  | `pyspark` |
| [`api_key`](/docs/input-parameters-skill-enrichment-api#api_key) | No\* | Your secret API key.  While we do not require this as part of the request parameters, if you do not provide it here, then you must provide it using an alternative means, such as in the headers using the `x-api-key` field. For more information, see the [Authentication](/docs/authentication) page. |  |  |
| [`pretty`](/docs/input-parameters-skill-enrichment-api#pretty) | No | Whether the output should have human-readable indentation. | `false` | `true` |
| [`titlecase`](/docs/input-parameters-skill-enrichment-api#titlecase) | No | All text in the API responses returns as lowercase by default. Setting `titlecase` to `true` will titlecase the text in `200` responses. | `false` | `true` |

## Output Response

### Response Fields

> ðŸ“˜
>
> ### For More Details, See [Skill Enrichment API - Output Response](/docs/output-response-skill-enrichment-api).
>
> You can also click the field names in the table below to view more information on them.

| Field Name | Type | Description |
| --- | --- | --- |
| [`cleaned_skill`](/docs/output-response-skill-enrichment-api#cleaned_skill) | `String` | The skill that matches the API input `skill` after passing it through our internal skill cleaner. |
| [`similar_skills`](/docs/output-response-job-title-enrichment-api#similar_job_titles) | `Array (String)` | A list of up to five other skills. |
| [`relevant_job_titles`](/docs/output-response-skill-enrichment-api#relevant_job_titles) | `Array (String)` | A list of up to five of the most contextually-similar job titles to the `cleaned_skill`, determined using our global resume data. |

### Full Example Response

Input Query (click to toggle)

Python

```
import requests

url = "https://api.peopledatalabs.com/v5/skill/enrich"

query_string = {"skill": "ai"}

headers = {
    'accept': "application/json",
    'content-type': "application/json",
    'x-api-key': "YOUR_API_KEY"
    }

response = requests.request("GET", url, headers=headers, params=query_string)

print(response.text)
```

Output Response (full):

JSON

```
{
  "cleaned_skill": "ai",
  "similar_skills": [
    "machine learning",
    "artificial intelligence",
    "deep learning",
    "data science",
    "iot"
  ],
  "relevant_job_titles": [
    "data scientist",
    "software engineer",
    "senior data scientist",
    "chief technology officer",
    "senior software engineer"
  ]
}
```

Updated 4 months ago

---

Did this page help you?

Yes

No

---
# https://docs.peopledatalabs.com/docs/company-enrichment-api

## Overview

The Company Enrichment API lets you enrich data on a company by performing a one-to-one match of this company with the numerous company profiles that are hosted on our site. Once matched, you have access to all the fields in our [Company Schema](/docs/company-fields).

## What's Next

Please check out the following pages for more information on the Company Enrichment API:

| Page | Description |
| --- | --- |
| [Quickstart](/docs/quickstart-company-enrichment-api) | A quick hands-on introduction to the API with simple code examples. |
| [Reference](/docs/reference-company-enrichment-api) | Detailed descriptions of the technical specifications and usage constraints. |
| [Input Parameters](/docs/input-parameters-company-enrichment-api) | In-depth explanations of the input parameters that the API supports. |
| [Output Response](/docs/output-response-company-enrichment-api) | In-depth explanations of the output response object that the API returns. |
| [Examples](/docs/examples-company-enrichment-api) | A collection of functional code examples and walkthroughs that illustrate various use cases and applications of the API. |
| [FAQs](/docs/faqs-company-enrichment-api) | Answers to commonly asked questions and other good-to-know information. |
| [Bulk Company Enrichment API](/docs/bulk-company-enrichment-api) | Enrich multiple Company profiles in one request. |

---



*Know someone whoâ€™d thrive building data products and helping us launch whatâ€™s next? Weâ€™d love to meet!*

*Check out our[open roles](https://www.peopledatalabs.com/company?utm_source=docs&utm_medium=footer&utm_campaign=cta#jobs) â†’*

Updated 4 months ago

---

Did this page help you?

Yes

No

---
# https://docs.peopledatalabs.com/docs/developer-stats

## Description

The Developer Slice Dataset is a subset of our full [Person Dataset](/docs/stats) and is composed of all the records containing a GitHub URL. The table below summarizes some key statistics and fill rates for fields within this dataset. Premium fields are not accessible by default.

**Common Use Cases**  
*Recruiting, Investment Sourcing*

| Field | Count | Numeric | Fill Percentage |
| --- | --- | --- | --- |
| `Total` | 3,058,252 | 3058252 | 100.0% |
| `birth_date` | 68,619 | 68619 | 2.2% |
| `birth_year` | 141,137 | 141137 | 4.6% |
| `certifications` | 269,118 | 269118 | 8.8% |
| `certifications.end_date` | 222,763 | 222763 | 7.3% |
| `certifications.name` | 269,118 | 269118 | 8.8% |
| `certifications.organization` | 266,842 | 266842 | 8.7% |
| `certifications.start_date` | 243,884 | 243884 | 8.0% |
| `countries` | 1,804,666 | 1804666 | 59.0% |
| `education` | 649,622 | 649622 | 21.2% |
| `education.degrees` | 487,550 | 487550 | 15.9% |
| `education.end_date` | 597,929 | 597929 | 19.6% |
| `education.gpa` | 40,842 | 40842 | 1.3% |
| `education.majors` | 526,193 | 526193 | 17.2% |
| `education.minors` | 8,384 | 8384 | 0.3% |
| `education.raw` | 618,768 | 618768 | 20.2% |
| `education.school` | 649,144 | 649144 | 21.2% |
| `education.school.domain` | 614,560 | 614560 | 20.1% |
| `education.school.facebook_url` | 533,145 | 533145 | 17.4% |
| `education.school.id` | 619,270 | 619270 | 20.2% |
| `education.school.linkedin_id` | 619,270 | 619270 | 20.2% |
| `education.school.linkedin_url` | 619,270 | 619270 | 20.2% |
| `education.school.location` | 611,298 | 611298 | 20.0% |
| `education.school.location.continent` | 611,298 | 611298 | 20.0% |
| `education.school.location.country` | 611,298 | 611298 | 20.0% |
| `education.school.location.locality` | 597,364 | 597364 | 19.5% |
| `education.school.location.name` | 611,298 | 611298 | 20.0% |
| `education.school.location.region` | 606,696 | 606696 | 19.8% |
| `education.school.name` | 649,131 | 649131 | 21.2% |
| `education.school.raw` | 646,412 | 646412 | 21.1% |
| `education.school.twitter_url` | 517,888 | 517888 | 16.9% |
| `education.school.type` | 631,060 | 631060 | 20.6% |
| `education.school.website` | 614,560 | 614560 | 20.1% |
| `education.start_date` | 584,535 | 584535 | 19.1% |
| `education.summary` | 302,988 | 302988 | 9.9% |
| `emails` | 2,022,234 | 2022234 | 66.1% |
| `emails.address` | 2,022,234 | 2022234 | 66.1% |
| `emails.first_seen` | 2,022,234 | 2022234 | 66.1% |
| `emails.last_seen` | 2,022,234 | 2022234 | 66.1% |
| `emails.md5_hash` | 2,022,234 | 2022234 | 66.1% |
| `emails.num_sources` | 2,022,234 | 2022234 | 66.1% |
| `emails.sha_256_hash` | 2,022,234 | 2022234 | 66.1% |
| `emails.type` | 1,677,182 | 1677182 | 54.8% |
| `experience` | 916,696 | 916696 | 30.0% |
| `experience.company` | 912,147 | 912147 | 29.8% |
| `experience.company.facebook_url` | 683,115 | 683115 | 22.3% |
| `experience.company.founded` | 737,104 | 737104 | 24.1% |
| `experience.company.id` | 767,920 | 767920 | 25.1% |
| `experience.company.industry` | 761,593 | 761593 | 24.9% |
| `experience.company.industry_v2` | 733,845 | 733845 | 24.0% |
| `experience.company.linkedin_id` | 767,920 | 767920 | 25.1% |
| `experience.company.linkedin_url` | 767,920 | 767920 | 25.1% |
| `experience.company.location` | 759,707 | 759707 | 24.8% |
| `experience.company.location.address_line_2` | 340,410 | 340410 | 11.1% |
| `experience.company.location.continent` | 759,045 | 759045 | 24.8% |
| `experience.company.location.country` | 759,707 | 759707 | 24.8% |
| `experience.company.location.geo` | 745,136 | 745136 | 24.4% |
| `experience.company.location.locality` | 748,290 | 748290 | 24.5% |
| `experience.company.location.metro` | 518,079 | 518079 | 16.9% |
| `experience.company.location.name` | 759,707 | 759707 | 24.8% |
| `experience.company.location.postal_code` | 709,056 | 709056 | 23.2% |
| `experience.company.location.region` | 751,258 | 751258 | 24.6% |
| `experience.company.location.street_address` | 702,014 | 702014 | 23.0% |
| `experience.company.name` | 912,144 | 912144 | 29.8% |
| `experience.company.raw` | 912,145 | 912145 | 29.8% |
| `experience.company.size` | 767,920 | 767920 | 25.1% |
| `experience.company.ticker` | 348,626 | 348626 | 11.4% |
| `experience.company.twitter_url` | 668,748 | 668748 | 21.9% |
| `experience.company.type` | 767,920 | 767920 | 25.1% |
| `experience.company.website` | 753,211 | 753211 | 24.6% |
| `experience.end_date` | 612,302 | 612302 | 20.0% |
| `experience.first_seen` | 916,696 | 916696 | 30.0% |
| `experience.is_primary` | 916,696 | 916696 | 30.0% |
| `experience.last_seen` | 916,696 | 916696 | 30.0% |
| `experience.location_names` | 582,474 | 582474 | 19.0% |
| `experience.num_sources` | 916,696 | 916696 | 30.0% |
| `experience.start_date` | 641,364 | 641364 | 21.0% |
| `experience.summary` | 595,716 | 595716 | 19.5% |
| `experience.title` | 682,803 | 682803 | 22.3% |
| `experience.title.class` | 661,545 | 661545 | 21.6% |
| `experience.title.levels` | 563,575 | 563575 | 18.4% |
| `experience.title.name` | 682,803 | 682803 | 22.3% |
| `experience.title.raw` | 682,803 | 682803 | 22.3% |
| `experience.title.role` | 661,545 | 661545 | 21.6% |
| `experience.title.sub_role` | 628,230 | 628230 | 20.5% |
| `facebook_friends` | 71,618 | 71618 | 2.3% |
| `facebook_id` | 263,792 | 263792 | 8.6% |
| `facebook_url` | 415,861 | 415861 | 13.6% |
| `facebook_username` | 415,861 | 415861 | 13.6% |
| `first_name` | 3,058,252 | 3058252 | 100.0% |
| `first_seen` | 3,058,252 | 3058252 | 100.0% |
| `full_name` | 3,058,252 | 3058252 | 100.0% |
| `github_url` | 3,058,252 | 3058252 | 100.0% |
| `github_username` | 3,058,252 | 3058252 | 100.0% |
| `headline` | 537,412 | 537412 | 17.6% |
| `id` | 3,058,252 | 3058252 | 100.0% |
| `industry` | 650,999 | 650999 | 21.3% |
| `inferred_salary` | 445,116 | 445116 | 14.6% |
| `inferred_years_experience` | 640,546 | 640546 | 20.9% |
| `interests` | 316,566 | 316566 | 10.4% |
| `job_company_12mo_employee_growth_rate` | 449,538 | 449538 | 14.7% |
| `job_company_employee_count` | 453,519 | 453519 | 14.8% |
| `job_company_facebook_url` | 278,006 | 278006 | 9.1% |
| `job_company_founded` | 392,030 | 392030 | 12.8% |
| `job_company_id` | 453,540 | 453540 | 14.8% |
| `job_company_industry` | 445,097 | 445097 | 14.6% |
| `job_company_industry_v2` | 429,631 | 429631 | 14.0% |
| `job_company_inferred_revenue` | 453,519 | 453519 | 14.8% |
| `job_company_linkedin_id` | 453,540 | 453540 | 14.8% |
| `job_company_linkedin_url` | 453,540 | 453540 | 14.8% |
| `job_company_location_address_line_2` | 63,919 | 63919 | 2.1% |
| `job_company_location_continent` | 428,964 | 428964 | 14.0% |
| `job_company_location_country` | 430,514 | 430514 | 14.1% |
| `job_company_location_geo` | 408,205 | 408205 | 13.3% |
| `job_company_location_locality` | 413,009 | 413009 | 13.5% |
| `job_company_location_metro` | 228,710 | 228710 | 7.5% |
| `job_company_location_name` | 430,517 | 430517 | 14.1% |
| `job_company_location_postal_code` | 326,793 | 326793 | 10.7% |
| `job_company_location_region` | 420,881 | 420881 | 13.8% |
| `job_company_location_street_address` | 312,817 | 312817 | 10.2% |
| `job_company_name` | 512,071 | 512071 | 16.7% |
| `job_company_size` | 453,540 | 453540 | 14.8% |
| `job_company_ticker` | 95,727 | 95727 | 3.1% |
| `job_company_total_funding_raised` | 208,904 | 208904 | 6.8% |
| `job_company_twitter_url` | 256,547 | 256547 | 8.4% |
| `job_company_type` | 453,540 | 453540 | 14.8% |
| `job_company_website` | 431,459 | 431459 | 14.1% |
| `job_history` | 916,960 | 916960 | 30.0% |
| `job_history.company_id` | 773,846 | 773846 | 25.3% |
| `job_history.company_name` | 913,505 | 913505 | 29.9% |
| `job_history.first_seen` | 916,960 | 916960 | 30.0% |
| `job_history.last_seen` | 916,960 | 916960 | 30.0% |
| `job_history.num_sources` | 916,960 | 916960 | 30.0% |
| `job_history.title` | 683,192 | 683192 | 22.3% |
| `job_last_changed` | 522,753 | 522753 | 17.1% |
| `job_last_verified` | 522,753 | 522753 | 17.1% |
| `job_onet_broad_occupation` | 297,724 | 297724 | 9.7% |
| `job_onet_code` | 297,724 | 297724 | 9.7% |
| `job_onet_major_group` | 297,724 | 297724 | 9.7% |
| `job_onet_minor_group` | 297,724 | 297724 | 9.7% |
| `job_onet_specific_occupation` | 297,724 | 297724 | 9.7% |
| `job_onet_specific_occupation_detail` | 196,279 | 196279 | 6.4% |
| `job_start_date` | 503,896 | 503896 | 16.5% |
| `job_summary` | 244,174 | 244174 | 8.0% |
| `job_title` | 522,070 | 522070 | 17.1% |
| `job_title_class` | 452,587 | 452587 | 14.8% |
| `job_title_levels` | 299,102 | 299102 | 9.8% |
| `job_title_role` | 452,587 | 452587 | 14.8% |
| `job_title_sub_role` | 322,696 | 322696 | 10.6% |
| `languages` | 426,990 | 426990 | 14.0% |
| `languages.name` | 426,990 | 426990 | 14.0% |
| `languages.proficiency` | 110,791 | 110791 | 3.6% |
| `last_initial` | 3,058,252 | 3058252 | 100.0% |
| `last_name` | 3,056,726 | 3056726 | 100.0% |
| `linkedin_connections` | 658,727 | 658727 | 21.5% |
| `linkedin_id` | 648,838 | 648838 | 21.2% |
| `linkedin_url` | 716,323 | 716323 | 23.4% |
| `linkedin_username` | 716,323 | 716323 | 23.4% |
| `location_address_line_2` | 37,184 | 37184 | 1.2% |
| `location_continent` | 1,805,368 | 1805368 | 59.0% |
| `location_country` | 1,804,608 | 1804608 | 59.0% |
| `location_geo` | 1,387,838 | 1387838 | 45.4% |
| `location_last_updated` | 643,442 | 643442 | 21.0% |
| `location_locality` | 1,400,334 | 1400334 | 45.8% |
| `location_metro` | 562,418 | 562418 | 18.4% |
| `location_name` | 1,805,368 | 1805368 | 59.0% |
| `location_names` | 1,413,138 | 1413138 | 46.2% |
| `location_postal_code` | 175,718 | 175718 | 5.7% |
| `location_region` | 1,524,519 | 1524519 | 49.8% |
| `location_street_address` | 176,425 | 176425 | 5.8% |
| `middle_initial` | 416,021 | 416021 | 13.6% |
| `middle_name` | 313,174 | 313174 | 10.2% |
| `mobile_phone` | 277,932 | 277932 | 9.1% |
| `name_aliases` | 198,278 | 198278 | 6.5% |
| `num_records` | 3,058,252 | 3058252 | 100.0% |
| `num_sources` | 3,058,252 | 3058252 | 100.0% |
| `personal_emails` | 1,538,550 | 1538550 | 50.3% |
| `phone_numbers` | 373,772 | 373772 | 12.2% |
| `phones` | 373,772 | 373772 | 12.2% |
| `phones.first_seen` | 373,772 | 373772 | 12.2% |
| `phones.last_seen` | 373,772 | 373772 | 12.2% |
| `phones.num_sources` | 373,772 | 373772 | 12.2% |
| `phones.number` | 373,772 | 373772 | 12.2% |
| `possible_birth_dates` | 78,106 | 78106 | 2.6% |
| `possible_emails` | 470,360 | 470360 | 15.4% |
| `possible_emails.address` | 470,360 | 470360 | 15.4% |
| `possible_emails.first_seen` | 470,360 | 470360 | 15.4% |
| `possible_emails.last_seen` | 470,360 | 470360 | 15.4% |
| `possible_emails.md5_hash` | 470,360 | 470360 | 15.4% |
| `possible_emails.num_sources` | 470,360 | 470360 | 15.4% |
| `possible_emails.sha_256_hash` | 470,360 | 470360 | 15.4% |
| `possible_emails.type` | 352,417 | 352417 | 11.5% |
| `possible_location_names` | 664,294 | 664294 | 21.7% |
| `possible_phones` | 116,319 | 116319 | 3.8% |
| `possible_phones.first_seen` | 116,319 | 116319 | 3.8% |
| `possible_phones.last_seen` | 116,319 | 116319 | 3.8% |
| `possible_phones.num_sources` | 116,319 | 116319 | 3.8% |
| `possible_phones.number` | 116,319 | 116319 | 3.8% |
| `possible_profiles` | 575,214 | 575214 | 18.8% |
| `possible_profiles.first_seen` | 575,214 | 575214 | 18.8% |
| `possible_profiles.id` | 85,071 | 85071 | 2.8% |
| `possible_profiles.last_seen` | 575,214 | 575214 | 18.8% |
| `possible_profiles.network` | 575,214 | 575214 | 18.8% |
| `possible_profiles.num_sources` | 575,214 | 575214 | 18.8% |
| `possible_profiles.url` | 575,214 | 575214 | 18.8% |
| `possible_profiles.username` | 565,740 | 565740 | 18.5% |
| `possible_street_addresses` | 54,437 | 54437 | 1.8% |
| `possible_street_addresses.address_line_2` | 14,349 | 14349 | 0.5% |
| `possible_street_addresses.continent` | 54,437 | 54437 | 1.8% |
| `possible_street_addresses.country` | 54,437 | 54437 | 1.8% |
| `possible_street_addresses.first_seen` | 54,437 | 54437 | 1.8% |
| `possible_street_addresses.geo` | 54,433 | 54433 | 1.8% |
| `possible_street_addresses.last_seen` | 54,437 | 54437 | 1.8% |
| `possible_street_addresses.locality` | 54,434 | 54434 | 1.8% |
| `possible_street_addresses.metro` | 49,764 | 49764 | 1.6% |
| `possible_street_addresses.name` | 54,437 | 54437 | 1.8% |
| `possible_street_addresses.num_sources` | 54,437 | 54437 | 1.8% |
| `possible_street_addresses.postal_code` | 54,126 | 54126 | 1.8% |
| `possible_street_addresses.region` | 54,435 | 54435 | 1.8% |
| `possible_street_addresses.street_address` | 54,437 | 54437 | 1.8% |
| `profiles` | 3,058,252 | 3058252 | 100.0% |
| `profiles.first_seen` | 3,058,252 | 3058252 | 100.0% |
| `profiles.id` | 767,158 | 767158 | 25.1% |
| `profiles.last_seen` | 3,058,252 | 3058252 | 100.0% |
| `profiles.network` | 3,058,252 | 3058252 | 100.0% |
| `profiles.num_sources` | 3,058,252 | 3058252 | 100.0% |
| `profiles.url` | 3,058,252 | 3058252 | 100.0% |
| `profiles.username` | 3,058,252 | 3058252 | 100.0% |
| `recommended_personal_email` | 1,538,401 | 1538401 | 50.3% |
| `regions` | 1,542,845 | 1542845 | 50.4% |
| `sex` | 2,189,997 | 2189997 | 71.6% |
| `skills` | 612,799 | 612799 | 20.0% |
| `street_addresses` | 252,230 | 252230 | 8.2% |
| `street_addresses.address_line_2` | 133,768 | 133768 | 4.4% |
| `street_addresses.continent` | 252,230 | 252230 | 8.2% |
| `street_addresses.country` | 252,230 | 252230 | 8.2% |
| `street_addresses.first_seen` | 252,230 | 252230 | 8.2% |
| `street_addresses.geo` | 244,597 | 244597 | 8.0% |
| `street_addresses.last_seen` | 252,230 | 252230 | 8.2% |
| `street_addresses.locality` | 245,646 | 245646 | 8.0% |
| `street_addresses.metro` | 222,571 | 222571 | 7.3% |
| `street_addresses.name` | 252,230 | 252230 | 8.2% |
| `street_addresses.num_sources` | 252,230 | 252230 | 8.2% |
| `street_addresses.postal_code` | 233,564 | 233564 | 7.6% |
| `street_addresses.region` | 245,973 | 245973 | 8.0% |
| `street_addresses.street_address` | 252,230 | 252230 | 8.2% |
| `summary` | 510,777 | 510777 | 16.7% |
| `twitter_url` | 490,446 | 490446 | 16.0% |
| `twitter_username` | 490,446 | 490446 | 16.0% |
| `work_email` | 225,016 | 225016 | 7.4% |

*Stats shown are accurate as of data version 33.1*

Updated 6 days ago

---

Did this page help you?

Yes

No

---
# https://docs.peopledatalabs.com/docs/faqs-company-enrichment-api

> â“
>
> ### Have a Question You Want Answered? Ask Us!
>
> Head over to the [Help Center](https://support.peopledatalabs.com) and search for your question. If you still can't find what you're looking for, create a support ticket and we will get it answered for you!

## Will I be charged for retrieving the same profile multiple times?

Yes. PDL will charge for the retrieval of the same profile.

**Example**  
You enrich for a profile with the LinkedIn URL: linkedin.com/company/peopledatalabs. A day later you enrich a profile with the same LinkedIn URL. You will be charged two credits, one for each successful response.

To handle for situations demonstrated in the above example , PDL recommends duplicate call detection. You can use methods like unique key constraints. For example, you can hash the request, storing the hash, and check for a duplicate call before sending it to the API.

Updated 4 months ago

---

Did this page help you?

Yes

No

---
# https://docs.peopledatalabs.com/docs/input-parameters-person-identify-api

## Required Parameters

A valid Person Identify API request must include **at least one** of the following:

* [`profile`](#profile)
* [`email`](#email)
* [`phone`](#phone)
* [`email_hash`](#email_hash)
* [`lid`](#lid)
* [`street_address`](#street_address)
* [`locality`](#locality)
* [`region`](#region)
* [`company`](#company)
* [`school`](#school)
* [`location`](#location)
* [`postal_code`](#postal_code)
* [`name`](#name)
* [`first_name`](#first_name) AND [`last_name`](#last_name)

  

### `api_key`

| Type | Description | Default | Example |
| --- | --- | --- | --- |
| `String` | Your secret API key. |  |  |

Your API Key **must** be included in either the request header or the `api_key` parameter. For more information about request authentication, see the [Authentication](/docs/authentication) page.

---

## Optional Parameters

### `name`

| Type | Description | Example |
| --- | --- | --- |
| `String` | The person's full name, at least the first and last. | `Jennifer C. Jackson` |

  

### `first_name`

| Type | Description | Example |
| --- | --- | --- |
| `String` | The person's first name. | `Jennifer` |

  

### `last_name`

| Type | Description | Example |
| --- | --- | --- |
| `String` | The person's last name. | `Jackson` |

  

### `middle_name`

| Type | Description | Example |
| --- | --- | --- |
| `String` | The person's middle name. | `Cassandra` |

  

### `location`

| Type | Description | Example |
| --- | --- | --- |
| `String` | The location where a person lives. This can be anything from a street address to a country name. | `Medford, OR USA` |

  

### `street_address`

| Type | Description | Example |
| --- | --- | --- |
| `String` | The street address where the person lives. | `1234 Main Street` |

  

### `locality`

| Type | Description | Example |
| --- | --- | --- |
| `String` | The locality where the person lives. | `Boise` |

  

### `region`

| Type | Description | Example |
| --- | --- | --- |
| `String` | The state or region where the person lives. | `Idaho` |

  

### `country`

| Type | Description | Example |
| --- | --- | --- |
| `String` | The country where the person lives. | `United States` |

  

### `postal_code`

| Type | Description | Example |
| --- | --- | --- |
| `String` | The postal code where the person lives. If there is no value for country, the postal code is assumed to be US. | `83701` |

  

### `company`

| Type | Description | Example |
| --- | --- | --- |
| `String` | The name, website, or social URL of a company where the person has worked. | `Amazon` |

  

### `school`

| Type | Description | Example |
| --- | --- | --- |
| `String` | The name, website, or social URL of a university or college the person has attended. | `University of Iowa` |

  

### `phone`

| Type | Description | Example |
| --- | --- | --- |
| `String` | A phone number the person has used. **Input must begin with `+[country code]` for a match to be returned.** | `+1 555-234-1234` |

  

### `email`

| Type | Description | Example |
| --- | --- | --- |
| `String` | An email the person has used. | `renee.c.paulsen1959@yahoo.com` |

  

### `email_hash`

| Type | Description | Example |
| --- | --- | --- |
| `String` | The SHA-256 or MD5 email hash for an email the person has used. | `e206e6cd7fa5f9499fd6d2d943dcf7d9c1469bad351061483f5ce7181663b8d4` |

  

### `profile`

| Type | Description | Example |
| --- | --- | --- |
| `String` | A social profile that the person has used (see [list of supported social profiles](/docs/social-networks)). | `https://linkedin.com/in/seanthorne` |

  

### `lid`

| Type | Description | Example |
| --- | --- | --- |
| `String` | The person's LinkedIn ID. | `145991517` |

  

### `birth_date`

| Type | Description | Example |
| --- | --- | --- |
| `String` | The person's birth date: either the year or a full birth date in the format `YYYY-MM-DD`. | `1996-10-01` |

  

### `pretty`

| Type | Description | Default | Example |
| --- | --- | --- | --- |
| `Boolean` | Whether the output should have [human-readable](http://jsonprettyprint.net/) indentation. | `false` | `true` |

  

### `titlecase`

| Type | Description | Default | Example |
| --- | --- | --- | --- |
| `Boolean` | All text in API responses returns as lowercase by default. Setting `titlecase` to `true` will titlecase response data instead. | `false` | `true` |

### `data_include`

| Type | Description | Default | Example |
| --- | --- | --- | --- |
| `String` | A comma-separated string of fields that you want the response to include. |  | `"full_name,emails.address"` |

### `include_if_matched`

| Type | Description | Default | Example |
| --- | --- | --- | --- |
| `Boolean` | If `true`, the response will include the field [`matches.matched_on`](/docs/output-response-person-identify-api#matchesmatched_on) that contains a list of every query input that matched this profile. | `false` | `true` |

As an example, if we wanted to enrich Sean Thorne using the following query:

JSON

```
{
   "first_name": "sean",
   "last_name": "thorne",
   "company": "people data labs",
   "location": "abu dhabi",
   "include_if_matched": true
}
```

Since Sean's location is in California and not Abu Dhabi in the dataset, the response would contain:

JSON

```
{
   "matched": [
        "company",
        "name"
    ]
}
```

Updated 4 months ago

---

Did this page help you?

Yes

No

---
# https://docs.peopledatalabs.com/docs/input-parameters-person-search-api

## Required Parameters

You **must** provide either the [`query`](#query) or the [`sql`](#sql) parameter (but not both) to receive a successful response. We recommend using the Elasticsearch `query` parameter for most use cases.

When you execute an API request, the query runs directly against our [Person Dataset](/docs/stats) without any cleaning or preprocessing. This means that you have a *lot* of freedom to explore the dataset and return the perfect records for your particular use case. It also means that you will need to understand the available fields to make successful queries.

Use the field descriptions on the [Person Schema](/docs/fields) and the underlying [Elasticsearch Mapping](/docs/elasticsearch-mapping) to help write better queries.

To help you identify how to best query for specific sub-entities (schools, companies, and locations), we offer a suite of [Cleaner APIs](/docs/cleaner-apis).

You can also use our [API Playground](https://dashboard.peopledatalabs.com/tools/api-playground) (accessible with a free PDL account) to help write and test queries for our Search APIs.

### `api_key`

| Type | Description | Default | Example |
| --- | --- | --- | --- |
| `String` | Your secret API key. |  |  |

Your API Key **must** be included in either the request header or the `api_key` parameter. For more information about request authentication, see the [Authentication](/docs/authentication) page.

---

## Optional Parameters

### `query`

| Type | Description | Example |
| --- | --- | --- |
| `Object` | An [Elasticsearch (v7.7) query](https://www.elastic.co/guide/en/elasticsearch/reference/7.7/query-dsl.html) involving our [person fields](/docs/fields). \n \nSee our underlying [Elasticsearch Mapping](/docs/elasticsearch-mapping) for reference. | `"query": "term": "job_company_name": "people data labs"` |

#### **Elasticsearch Query Limitations**

The `query` value should align directly with the [Elasticsearch DSL](https://www.elastic.co/guide/en/elasticsearch/reference/7.7/query-dsl.html).

We accept the following Elasticsearch query types:

* [term](https://www.elastic.co/guide/en/elasticsearch/reference/7.7/query-dsl-term-query.html)
* [terms](https://www.elastic.co/guide/en/elasticsearch/reference/7.7/query-dsl-terms-query.html)
* [exists](https://www.elastic.co/guide/en/elasticsearch/reference/7.7/query-dsl-exists-query.html)
* [bool](https://www.elastic.co/guide/en/elasticsearch/reference/7.7/query-dsl-bool-query.html)
* [match](https://www.elastic.co/guide/en/elasticsearch/reference/7.7/query-dsl-match-query.html)
* [range](https://www.elastic.co/guide/en/elasticsearch/reference/7.7/query-dsl-range-query.html)
* [match\_phrase](https://www.elastic.co/guide/en/elasticsearch/reference/7.7/query-dsl-match-query-phrase.html)
* [wildcard](https://www.elastic.co/guide/en/elasticsearch/reference/7.7/query-dsl-wildcard-query.html)
* [prefix](https://www.elastic.co/guide/en/elasticsearch/reference/7.7/query-dsl-prefix-query.html)
* [match\_all](https://www.elastic.co/guide/en/elasticsearch/reference/7.7/query-dsl-match-all-query.html)

We've disabled most specialized options, such as boosting and custom scoring, and we do not allow aggregations.

Any array in a query (such as a `terms` array) will have a hard limit of 1000 elements. If a request goes over this limit, it will fail.

### `sql`

| Type | Description | Example |
| --- | --- | --- |
| `String` | A SQL query of the format: `SELECT * FROM person WHERE XXX`, where XXX is a standard SQL boolean query involving our [person fields](/docs/fields). | `SELECT * FROM person WHERE job_company_name='people data labs'` |

#### **SQL Query Limitations**

We execute SQL queries using [Elasticsearch SQL](https://www.elastic.co/what-is/elasticsearch-sql).

We accept any SQL query that translates to the [above Elasticsearch query types](#elasticsearch-query-limitations) through the [ES SQL translate API](https://www.elastic.co/guide/en/elasticsearch/reference/7.7/sql-translate.html).

We will ignore any use of column selections or the `LIMIT` keyword.

We limit the number of wildcard terms (using `LIKE` with `%`) to 20 per request. If a request goes over this limit, it will fail.

You must use subfields rather than top-level fields when making SQL queries. For example, `SELECT * FROM person WHERE experience IS NOT NULL` will fail but `SELECT * FROM person WHERE experience.title.name IS NOT NULL` will behave as expected.

### `size`

| Type | Description | Default | Example |
| --- | --- | --- | --- |
| `Integer` | The maximum number of matched records to return for this query if they exist. Must be between `1` and `100`. | `1` | `100` |

### `scroll_token`

| Type | Description | Default | Example |
| --- | --- | --- | --- |
| `String` | Each search API response returns a `scroll_token`. Include it in the next request to fetch the next `size` matching records. |  | `104$14.278746` |

A `scroll_token` returns in every [Person Search API response](/docs/output-response-person-search-api#scroll_token) and serves as a placeholder or bookmark for the last record received. For queries with more results than can fit in a single API response (see the [`size`](#size) field), use the `scroll_token` to get the next batch of results.

For example, if you send a query to the Person Search API that has 10,000 matches, you will need multiple API calls to retrieve all the records. The `scroll_token` represents how far along you are in that list of records.

Generally, the way to use `scroll_token` is:

1. Send a query to the Person Search API.
2. Get a response back containing one batch of records as well as a `scroll_token` response value (if you have already retrieved all the available records in this batch, then the `scroll_token` value will be `null`).
3. Use the same query from Step 1 and the `scroll_token` you just received to make another request to the Person Search API.
4. Get another response back with the next batch of records and a new `scroll_token` value.
5. Repeat steps 3 and 4 until you have received the desired number of records or until you receive a 404 status code because pagination is complete and the `scroll_token` key is missing from the response.

For a detailed working example of this process, see the following code example: [Bulk Retrieval](/docs/examples-person-search-api#bulk-retrieval).

### `dataset`

| Type | Description | Default | Example |
| --- | --- | --- | --- |
| `Enum (String)` | Specifies which [dataset(s)](/docs/datasets#list-of-slice-datasets) the API should search against. | `resume` | `all` |

You can input multiple datasets by separating each with a comma.

Valid dataset names are:

* `all`
* `resume`
* `email`
* `phone`
* `mobile_phone`
* `street_address`
* `consumer_social`
* `developer`

See [Person Stats](/docs/datasets) for details about each dataset.

You can exclude dataset(s) by using `-` as the first character. Entering `-` will exclude all of the comma-separated datasets following the character and needs to be entered only once. For example, `"all,-phone,consumer_social"` will include search results from every dataset except the phone and consumer\_social datasets.

### `titlecase`

| Type | Description | Default | Example |
| --- | --- | --- | --- |
| `Boolean` | All text in API responses returns as lowercase by default. Setting `titlecase` to `true` will titlecase any records returned instead. | `false` | `true` |

### `data_include`

| Type | Description | Default | Example |
| --- | --- | --- | --- |
| `String` | A comma-separated string of fields that you want the response to include. |  | `"full_name,emails.address"` |

### `pretty`

| Type | Description | Default | Example |
| --- | --- | --- | --- |
| `Boolean` | Whether the output should have [human-readable](http://jsonprettyprint.net/) indentation. | `false` | `true` |

Updated 14 days ago

---

Did this page help you?

Yes

No

---
# https://docs.peopledatalabs.com/docs/currency-codes

| Canonical Values for Currency Codes |
| --- |
| aed |
| afn |
| all |
| amd |
| ang |
| aoa |
| ars |
| aud |
| awg |
| azn |
| bam |
| bbd |
| bdt |
| bgn |
| bhd |
| bif |
| bmd |
| bnd |
| bob |
| brl |
| bsd |
| btn |
| bwp |
| byr |
| bzd |
| cad |
| cdf |
| cfa |
| chf |
| clp |
| cny |
| cop |
| crc |
| cup |
| cve |
| czk |
| djf |
| dkk |
| dop |
| dzd |
| ecs |
| egp |
| ern |
| etb |
| eur |
| fjd |
| fkp |
| gbp |
| gel |
| ghs |
| gip |
| gmd |
| gnf |
| gyd |
| hkd |
| hnl |
| hrk |
| htg |
| huf |
| idr |
| ils |
| inr |
| iqd |
| irr |
| isk |
| jmd |
| jod |
| jpy |
| kes |
| kgs |
| khr |
| kmf |
| kpw |
| krw |
| kwd |
| kyd |
| kzt |
| lak |
| lbp |
| lkr |
| lrd |
| lsl |
| ltl |
| lvl |
| lyd |
| mad |
| mdl |
| mgf |
| mkd |
| mmr |
| mnt |
| mop |
| mro |
| mur |
| mvr |
| mwk |
| mxn |
| myr |
| mzn |
| nad |
| ngn |
| nio |
| nok |
| npr |
| nzd |
| omr |
| pab |
| pen |
| pgk |
| php |
| pkr |
| pln |
| pyg |
| qar |
| qtq |
| ron |
| rsd |
| rub |
| rwf |
| sar |
| sbd |
| scr |
| sdg |
| sek |
| sgd |
| shp |
| sll |
| sos |
| srd |
| ssp |
| std |
| svc |
| syp |
| szl |
| thb |
| tjs |
| tmt |
| tnd |
| top |
| try |
| ttd |
| tzs |
| uah |
| ugx |
| usd |
| uyu |
| uzs |
| vef |
| vnd |
| vuv |
| wst |
| xaf |
| xcd |
| xof |
| xpf |
| yer |
| zar |
| zmw |
| zwd |

  

## Relevant fields

* [`funding_details.funding_currency`](/docs/company-schema#funding_details)
* [`salary_currency`](/docs/jp-schema#salary_currency)

Updated 4 months ago

---

Did this page help you?

Yes

No

---
# https://docs.peopledatalabs.com/docs/person-endpoints

## The Differences Between Our Person-Related APIs

We offer multiple person-related APIs, so how are they different? Here's a summary of each:

**Person Enrichment**: Finds the single best profile matching certain attributes about a particular person.

**Person Search**: Finds all the profiles for any number of persons that satisfy some search criteria.

**Person Identify**: Finds the best selection of profiles associated with a particular set of attributes for a person or related persons.

Here's a table that summarizes some of the key differences:

|  | Person Enrichment | Person Identify | Person Search |
| --- | --- | --- | --- |
| **Matching Type** | 1:1 | 1:Many | 1:Many |
| **Input Cleaning** | Yes | Yes | No |
| **Supported Query Parameters** | Only supported inputs, which must be uniquely identifying | Only supported inputs, which do not need to be uniquely identifying | Anything in the Person Schema |
| **Number of Profiles per Unique Query** | 1 | Up to 20 | No limit |
| **Sorting of Returned Profiles** | N/A - only the single best-matched profile is returned | Sorted by match score | Sorted by profile completeness |

The key takeaway is that the **Person Identify API exists between our Person Enrichment and Search APIs** in terms of functionality.

Compared to the Person Enrichment API, which returns a single record for a single person, the **Person Identify API supports broader search inputs and returns multiple strongly-related profiles**. This means that the Person Identify API is ideal for situations in which you do not have enough information to uniquely resolve a person and are interested in recovering highly-probable candidates. The Person Enrichment API is better suited to targeted enrichment when you have enough uniquely-identifying information.

Compared to the Person Search API, the **Person Identify API has standardized input parameters and provides a match score for each returned profile.** This means that you can use the Person Identify API to recover a focused selection of highly related profiles, unlike the Person Search API, which will return a potentially large demographic cross-section of our Person Dataset with more loosely-related profiles.

## [Person Enrichment API](/docs/person-enrichment-api)

You can use the Person Enrichment API to enrich data on a person:

Python3 SDKcURLJavaScriptRubyGoPython3

```
import json

# See https://github.com/peopledatalabs/peopledatalabs-python
from peopledatalabs import PDLPY

# Create a client, specifying your API key
CLIENT = PDLPY(
    api_key="YOUR API KEY",
)

# Create a parameters JSON object
PARAMS = {
    "profile": ["linkedin.com/in/seanthorne"]
}

# Pass the parameters object to the Person Enrichment API
json_response = CLIENT.person.enrichment(**PARAMS).json()

# Print the API response in JSON format
print(json_response)
```

```
curl -X GET \
  'https://api.peopledatalabs.com/v5/person/enrich?api_key=xxxx&profile=linkedin.com/in/seanthorne'
```

```
// See https://github.com/peopledatalabs/peopledatalabs-js
import PDLJS from 'peopledatalabs';

// Create a client, specifying your API key
const PDLJSClient = new PDLJS({ apiKey: "YOUR API KEY" });

// Create a parameters JSON object
const params = {
  profile: "http://linkedin.com/in/seanthorne"
}

// Pass the parameters object to the Person Enrichment API
PDLJSClient.person.enrichment(params).then((jsonResponse) => {
  // Print the API response in JSON format
  console.log(jsonResponse);
}).catch((error) => {
  console.log(error);
});
```

```
require 'json'

# See https://github.com/peopledatalabs/peopledatalabs-ruby
require 'peopledatalabs'

# Set your API key
Peopledatalabs.api_key = 'YOUR API KEY'

# Create a parameters JSON object
PARAMS = {
    profile: ['linkedin.com/in/seanthorne']
}

# Pass the parameters object to the Person Enrichment API
json_response = Peopledatalabs::Enrichment.person(params: PARAMS)

# Print the API response in JSON format
puts JSON.dump(json_response)
```

```
package main

import (
    "fmt"
    "encoding/json"
    "context"
)

// See https://github.com/peopledatalabs/peopledatalabs-go
import (
    pdl "github.com/peopledatalabs/peopledatalabs-go"
    pdlmodel "github.com/peopledatalabs/peopledatalabs-go/model"
)

func main() {
    // Set your API key
    apiKey := "YOUR API KEY"
    // Set API key as environmental variable
    // apiKey := os.Getenv("API_KEY")

    // Create a client, specifying your API key
    client := pdl.New(apiKey)
    
    // Create a parameters JSON object
    params := pdlmodel.EnrichPersonParams {
        PersonParams: pdlmodel.PersonParams {
            Profile: []string{"linkedin.com/in/seanthorne"},
        },
    }

    // Pass the parameters object to the Person Enrichment API
    response, err := client.Person.Enrich(context.Background(), params)
    
    // Convert the API response to JSON
    jsonResponse, jsonErr := json.Marshal(response.Data)

    // Print the API response
    if err == nil && jsonErr == nil {
        fmt.Println(string(jsonResponse))
    }  
}
```

```
import requests

# Set your API key
API_KEY = "YOUR API KEY"

# Set the Person Enrichment API URL
PDL_URL = "https://api.peopledatalabs.com/v5/person/enrich"

# Create a parameters JSON object
PARAMS = {
    "api_key": API_KEY,
    "profile": ["linkedin.com/in/seanthorne"]
}

# Pass the parameters object to the Person Enrichment API
json_response = requests.get(PDL_URL, params=PARAMS).json()

# Print the API response in JSON format
print(json_response)
```

## [Bulk Person Enrichment API](/docs/bulk-enrichment-api)

We also provide a Bulk Person Enrichment API, which allows you to enrich 1-100 persons in a single request (recommended for high-volume usage):

Python3 SDKcURLJavaScriptRubyGoPython3

```
import json

# See https://github.com/peopledatalabs/peopledatalabs-python
from peopledatalabs import PDLPY

# Create a client, specifying your API key
CLIENT = PDLPY(
    api_key="YOUR API KEY",
)

# Create an array of parameters JSON objects
DATA = {"requests": [{"params": {"profile": ["linkedin.com/in/seanthorne"]}}]}

# Pass the bulk parameters object to the Bulk Person Enrichment API
json_response = CLIENT.person.bulk(**DATA).json()

# Print the API response in JSON format
print(json_response)
```

```
curl -X POST "https://api.peopledatalabs.com/v5/person/bulk" -H 'X-Api-Key: xxxx' 'Content-Type: application/json' -d'
{
    "requests": [
    	{
    		"params": {
    			"profile": ["linkedin.com/in/seanthorne"]
    		}
    	}
    ]
}
```

```
// See https://github.com/peopledatalabs/peopledatalabs-js
import PDLJS from 'peopledatalabs';

// Create a client, specifying your API key
const PDLJSClient = new PDLJS({ apiKey: "YOUR API KEY" });

// Create an array of parameters JSON objects
const data = {
  requests: [
    {
      params: {
        profile: ['linkedin.com/in/seanthorne']
      }
    }
  ]
};

// Pass the parameters object to the Bulk Person Enrichment API
PDLJSClient.person.bulk(data).then((jsonResponse) => {
  // Print the API response in JSON format
  console.log(jsonResponse);
}).catch((error) => {
  console.log(error);
});
```

```
require 'json'

# See https://github.com/peopledatalabs/peopledatalabs-ruby
require 'peopledatalabs'

# Set your API key
Peopledatalabs.api_key = 'YOUR API KEY'

# Create an array of parameters JSON objects
DATA = {requests: [{params: {profile: ['linkedin.com/in/seanthorne']}}]}

# Pass the bulk parameters object to the Bulk Person Enrichment API
json_response = Peopledatalabs::Bulk.person(params: DATA)

# Print the API response in JSON format
puts JSON.dump(json_response)
```

```
package main

import (
    "fmt"
    "encoding/json"
    "context"
)

// See https://github.com/peopledatalabs/peopledatalabs-go
import (
    pdl "github.com/peopledatalabs/peopledatalabs-go"
    pdlmodel "github.com/peopledatalabs/peopledatalabs-go/model"
)

func main() {
    // Set your API key
    apiKey := "YOUR API KEY"
    // Set API key as environmental variable
    // apiKey := os.Getenv("API_KEY")

    // Create a client, specifying your API key
    client := pdl.New(apiKey)
    
    // Create an array of parameters JSON objects
    params := pdlmodel.BulkEnrichPersonParams {
        Requests: []pdlmodel.BulkEnrichSinglePersonParams {
            {
                Params: pdlmodel.PersonParams {
                    Profile:  []string{"linkedin.com/in/seanthorne"},
                },
            },
        },
    }

    // Pass the parameters object to the Bulk Person Enrichment API
    response, err := client.Person.BulkEnrich(context.Background(), params)
    
    // Convert the API response to JSON
    jsonResponse, jsonErr := json.Marshal(response)

    // Print the API response
    if err == nil && jsonErr == nil {
        fmt.Println(string(jsonResponse))
    }  
}
```

```
import requests

# Set your API key
API_KEY = "YOUR API KEY"

# Set the Bulk Person Enrichment API URL
PDL_URL = "https://api.peopledatalabs.com/v5/person/bulk"

# Pass your API key in header
HEADERS = {
    'X-Api-Key': API_KEY,
    'Content-Type': 'application/json'
}

# Create an array of parameters JSON objects
DATA = '{"requests": [{"params": {"profile": ["linkedin.com/in/seanthorne"]}}]}'

# Pass the bulk parameters object to the Bulk Person Enrichment API
json_response = requests.post(PDL_URL, headers=HEADERS, data=DATA).json()

# Print the API response in JSON format
print(json_response)
```

## [Person Search API](/docs/person-search-api)

You can use the Person Search API to write queries (in either Elasticsearch or SQL format) against our Person Dataset and return the profiles that match those queries:

Python3 SDK (Elasticsearch)Python3 SDK (SQL)cURLJavaScript (Elasticsearch)JavaScript (SQL)Ruby (Elasticsearch)Ruby (SQL)Go (Elasticsearch)Go (SQL)Python3 (Elasticsearch)Python3 (SQL)

```
import json

# See https://github.com/peopledatalabs/peopledatalabs-python
from peopledatalabs import PDLPY

# Create a client, specifying your API key
CLIENT = PDLPY(
    api_key="YOUR API KEY",
)

# Create an Elasticsearch query
ES_QUERY = {
  'query': {
    'bool': {
        'must': [
            {'term': {'location_country': "mexico"}},
            {'term': {'job_title_role': "health"}},
            {'exists': {'field': "phone_numbers"}}
      ]
    }
  }
}

# Create a parameters JSON object
PARAMS = {
  'query': ES_QUERY,
  'size': 10,
  'pretty': True
}

# Pass the parameters object to the Person Search API
response = CLIENT.person.search(**PARAMS).json()

# Check for successful response
if response["status"] == 200:
  data = response['data']
  # Write out each profile found to file
  with open("my_pdl_search.jsonl", "w") as out:
    for record in data:
      out.write(json.dumps(record) + "\n")
  print(f"Successfully grabbed {len(data)} records from PDL.")
  print(f"{response['total']} total PDL records exist matching this query.")
else:
  print("NOTE: The carrier pigeons lost motivation in flight. See error and try again.")
  print("Error:", response)
```

```
import json

# See https://github.com/peopledatalabs/peopledatalabs-python
from peopledatalabs import PDLPY

# Create a client, specifying your API key
CLIENT = PDLPY(
    api_key="YOUR API KEY",
)

# Create an SQL query
SQL_QUERY = \
"""
  SELECT * FROM person
  WHERE location_country='mexico'
  AND job_title_role='health'
  AND phone_numbers IS NOT NULL;
 """

# Create a parameters JSON object
PARAMS = {
  'sql': SQL_QUERY,
  'size': 10,
  'pretty': True
}

# Pass the parameters object to the Person Search API
response = CLIENT.person.search(**PARAMS).json()

# Check for successful response
if response["status"] == 200:
  data = response['data']
  # Write out each profile found to file
  with open("my_pdl_search.jsonl", "w") as out:
    for record in data:
      out.write(json.dumps(record) + "\n")
  print(f"Successfully grabbed {len(data)} records from PDL.")
  print(f"{response['total']} total PDL records exist matching this query.")
else:
  print("NOTE: The carrier pigeons lost motivation in flight. See error and try again.")
  print("Error:", response)
```

```
# Elasticsearch
curl -X GET 'https://api.peopledatalabs.com/v5/person/search' \
-H 'X-Api-Key: xxxx' \
--data-raw '{
  "size": 10,
  "query": {
    "bool": {
      "must": [
        {"term": {"location_country": "mexico"}},
        {"term": {"job_title_role": "health"}},
        {"exists": {"field": "phone_numbers"}}
      ]
    }
  }
}'

# SQL
curl -X GET \
  'https://api.peopledatalabs.com/v5/person/search' \
  -H 'X-Api-Key: xxxx' \
  --data-raw '{
    "size": 10,
    "sql": "SELECT * FROM person WHERE location_country='\''mexico'\'' AND job_title_role='\''health'\'' AND phone_numbers IS NOT NULL;"
}'
```

```
// See https://github.com/peopledatalabs/peopledatalabs-js
import PDLJS from 'peopledatalabs';

import fs from 'fs';

// Create a client, specifying your API key
const PDLJSClient = new PDLJS({ apiKey: "YOUR API KEY" });

// Create an Elasticsearch query
const esQuery = {
  query: {
    bool: {
      must:[
        {term: {location_country: "mexico"}}, 
        {term: {job_title_role: "health"}}, 
        {exists: {field: "phone_numbers"}}
      ]
    }
  }
}

// Create a parameters JSON object
const params = {
  searchQuery: esQuery, 
  size: 10,
  pretty: true
}

// Pass the parameters object to the Person Search API
PDLJSClient.person.search.elastic(params).then((data) => {
    // Write out all profiles found to file
    fs.writeFile("my_pdl_search.jsonl", Buffer.from(JSON.stringify(data.data)), (err) => {
        if (err) throw err;
    });
    console.log(`Successfully grabbed ${data.data.length} records from PDL.`);
    console.log(`${data["total"]} total PDL records exist matching this query.`)
}).catch((error) => {
    console.log("NOTE: The carrier pigeons lost motivation in flight. See error and try again.")
    console.log(error);
});
```

```
// See https://github.com/peopledatalabs/peopledatalabs-js
import PDLJS from 'peopledatalabs';

import fs from 'fs';

// Create a client, specifying your API key
const PDLJSClient = new PDLJS({ apiKey: "YOUR API KEY" });

// Create an SQL query
const sqlQuery = `SELECT * FROM person 
                  WHERE location_country='mexico' 
                  AND job_title_role='health'
                  AND phone_numbers IS NOT NULL;`

// Create a parameters JSON object
const params = {
  searchQuery: sqlQuery, 
  size: 10,
  pretty: true
}

// Pass the parameters object to the Person Search API
PDLJSClient.person.search.sql(params).then((data) => {
    // Write out all profiles found to file
    fs.writeFile("my_pdl_search.jsonl", Buffer.from(JSON.stringify(data.data)), (err) => {
        if (err) throw err;
    });
    console.log(`Successfully grabbed ${data.data.length} records from PDL.`);
    console.log(`${data["total"]} total PDL records exist matching this query.`)
}).catch((error) => {
    console.log("NOTE: The carrier pigeons lost motivation in flight. See error and try again.")
    console.log(error);
});
```

```
require 'json'

# See https://github.com/peopledatalabs/peopledatalabs-ruby
require 'peopledatalabs'

# Set your API key
Peopledatalabs.api_key = 'YOUR API KEY'

# Create an Elasticsearch query
ES_QUERY = {
  "query": {
    "bool": {
        "must": [
            {"term": {"location_country": "mexico"}},
            {"term": {"job_title_role": "health"}},
            {"exists": {"field": "phone_numbers"}}
      ]
    }
  }
}

# Pass parameters to the Person Search API
response = Peopledatalabs::Search.person(searchType: 'elastic', query: ES_QUERY, size: 10, pretty: true)

# Check for successful response
if response['status'] == 200
    data = response['data']
    # Write out each profile found to file
    File.open("my_pdl_search.jsonl", "w") do |out|
        data.each { |record| out.write(JSON.dump(record) + "\n") }
    end
    puts "Successfully grabbed #{data.length()} records from PDL."
    puts "#{response['total']} total PDL records exist matching this query."
else
    puts "NOTE: The carrier pigeons lost motivation in flight. See error and try again."
    puts "Error: #{response}"
end
```

```
require 'json'

# See https://github.com/peopledatalabs/peopledatalabs-ruby
require 'peopledatalabs'

# Set your API key
Peopledatalabs.api_key = 'YOUR API KEY'

# Create an SQL query
SQL_QUERY = \
"""
  SELECT * FROM person
  WHERE location_country='mexico'
  AND job_title_role='health'
  AND phone_numbers IS NOT NULL;
 """

# Pass parameters to the Person Search API
response = Peopledatalabs::Search.person(searchType: 'sql', query: SQL_QUERY, size: 10, pretty: true)

# Check for successful response
if response['status'] == 200
    data = response['data']
    # Write out each profile found to file
    File.open("my_pdl_search.jsonl", "w") do |out|
        data.each { |record| out.write(JSON.dump(record) + "\n") }
    end
    puts "Successfully grabbed #{data.length()} records from PDL."
    puts "#{response['total']} total PDL records exist matching this query."
else
    puts "NOTE: The carrier pigeons lost motivation in flight. See error and try again."
    puts "Error: #{response}"
end
```

```
package main

import (
    "fmt"
    "os"
    "encoding/json"
    "context"
)

// See https://github.com/peopledatalabs/peopledatalabs-go
import (
    pdl "github.com/peopledatalabs/peopledatalabs-go"
    pdlmodel "github.com/peopledatalabs/peopledatalabs-go/model"
)

func main() {
    // Set your API key
    apiKey := "YOUR API KEY"
    // Set API key as environmental variable
    // apiKey := os.Getenv("API_KEY")

    // Create a client, specifying your API key
    client := pdl.New(apiKey)
    
    // Create an Elasticsearch query
    elasticSearchQuery := map[string]interface{} {
        "query": map[string]interface{} {
            "bool": map[string]interface{} {
                "must": []map[string]interface{} {
                    {"term": map[string]interface{}{"location_country": "mexico"}},
                    {"term": map[string]interface{}{"job_title_role": "health"}},
                    {"exists": map[string]interface{}{"field": "phone_numbers"}},
                },
            },
        },
    }

    // Create a parameters JSON object
    params := pdlmodel.SearchParams {
        BaseParams: pdlmodel.BaseParams {
            Size: 10,
            Pretty: true,
        },
        SearchBaseParams: pdlmodel.SearchBaseParams {
            Query: elasticSearchQuery,
        },
    }
    
    // Pass the parameters object to the Person Search API
    response, err := client.Person.Search(context.Background(), params)
    // Check for successful response
    if err == nil {
        data := response.Data
        // Create file
        out, outErr := os.Create("my_pdl_search.jsonl")
        defer out.Close()
        if (outErr == nil) {
            for i := range data {
                // Convert each profile found to JSON
                record, jsonErr := json.Marshal(data[i])
                // Write out each profile to file
                if (jsonErr == nil) {
                    out.WriteString(string(record) + "\n")
                }
            }
            out.Sync()
        }
        fmt.Printf("Successfully grabbed %d records from PDL.\n", len(data))
        fmt.Printf("%d total PDL records exist matching this query.\n", response.Total)
    } else {
        fmt.Println("NOTE: The carrier pigeons lost motivation in flight. See error and try again.")
        fmt.Println("Error:", err)
    } 
}
```

```
package main

import (
    "fmt"
    "os"
    "encoding/json"
    "context"
)

// See https://github.com/peopledatalabs/peopledatalabs-go
import (
    pdl "github.com/peopledatalabs/peopledatalabs-go"
    pdlmodel "github.com/peopledatalabs/peopledatalabs-go/model"
)

func main() {
    // Set your API key
    apiKey := "YOUR API KEY"
    // Set API key as environmental variable
    // apiKey := os.Getenv("API_KEY")

    // Create a client, specifying your API key
    client := pdl.New(apiKey)
    
    // Create an SQL query
    sqlQuery := "SELECT * FROM person" +
        " WHERE location_country='mexico'" +
        " AND job_title_role='health'" +
        " AND phone_numbers IS NOT NULL;"

    // Create a parameters JSON object
    params := pdlmodel.SearchParams {
        BaseParams: pdlmodel.BaseParams {
            Size: 10,
            Pretty: true,
        },
        SearchBaseParams: pdlmodel.SearchBaseParams {
            SQL: sqlQuery,
        },
    }
    
    // Pass the parameters object to the Person Search API
    response, err := client.Person.Search(context.Background(), params)
    // Check for successful response
    if err == nil {
        data := response.Data
        // Create file
        out, outErr := os.Create("my_pdl_search.jsonl")
        defer out.Close()
        if (outErr == nil) {
            for i := range data {
                // Convert each profile found to JSON
                record, jsonErr := json.Marshal(data[i])
                // Write out each profile to file
                if (jsonErr == nil) {
                    out.WriteString(string(record) + "\n")
                }
            }
            out.Sync()
        }
        fmt.Printf("Successfully grabbed %d records from PDL.\n", len(data))
        fmt.Printf("%d total PDL records exist matching this query.\n", response.Total)
    } else {
        fmt.Println("NOTE: The carrier pigeons lost motivation in flight. See error and try again.")
        fmt.Println("Error:", err)
    } 
}
```

```
import requests, json

# Set your API key
API_KEY = "YOUR API KEY"

# Set the Person Search API URL
PDL_URL = "https://api.peopledatalabs.com/v5/person/search"

# Set headers
HEADERS = {
  'Content-Type': "application/json",
  'X-api-key': API_KEY
}

# Create an Elasticsearch query
ES_QUERY = {
  'query': {
    'bool': {
        'must': [
            {'term': {'location_country': "mexico"}},
            {'term': {'job_title_role': "health"}},
            {'exists': {'field': "phone_numbers"}}
      ]
    }
  }
}

# Create a parameters JSON object
PARAMS = {
  'query': json.dumps(ES_QUERY),
  'size': 10,
  'pretty': True
}

# Pass the parameters object to the Person Search API
response = requests.get(
  PDL_URL,
  headers=HEADERS,
  params=PARAMS
).json()

# Check for successful response
if response["status"] == 200:
  data = response['data']
  # Write out each profile found to file
  with open("my_pdl_search.jsonl", "w") as out:
    for record in data:
      out.write(json.dumps(record) + "\n")
  print(f"Successfully grabbed {len(data)} records from PDL.")
  print(f"{response['total']} total PDL records exist matching this query.")
else:
  print("NOTE: The carrier pigeons lost motivation in flight. See error and try again.")
  print("Error:", response)
```

```
import requests, json

# Set your API key
API_KEY = "YOUR API KEY"

# Set the Person Search API URL
PDL_URL = "https://api.peopledatalabs.com/v5/person/search"

# Set headers
HEADERS = {
  'Content-Type': "application/json",
  'X-api-key': API_KEY
}

# Create an SQL query
SQL_QUERY = \
"""
  SELECT * FROM person
  WHERE location_country='mexico'
  AND job_title_role='health'
  AND phone_numbers IS NOT NULL;
 """

# Create a parameters JSON object
PARAMS = {
  'sql': SQL_QUERY,
  'size': 10,
  'pretty': True
}

# Pass the parameters object to the Person Search API
response = requests.get(
  PDL_URL,
  headers=HEADERS,
  params=PARAMS
).json()

# Check for successful response
if response["status"] == 200:
  data = response['data']
  # Write out each profile found to file
  with open("my_pdl_search.jsonl", "w") as out:
    for record in data:
      out.write(json.dumps(record) + "\n")
  print(f"Successfully grabbed {len(data)} records from PDL.")
  print(f"{response['total']} total PDL records exist matching this query.")
else:
  print("NOTE: The carrier pigeons lost motivation in flight. See error and try again.")
  print("Error:", response)
```

## [Person Identify API](/docs/person-identify-api)

You can use the Person Identify API to access multiple strongly-associated profiles based on some broadly identifying criteria (such as a name or a street address):

Python3 SDKcURLJavaScriptRubyGoPython3

```
import json

# See https://github.com/peopledatalabs/peopledatalabs-python
from peopledatalabs import PDLPY

# Create a client, specifying your API key
CLIENT = PDLPY(
    api_key="YOUR API KEY",
)

# Create a parameters JSON object
PARAMS = {
 "first_name": "sean", 
 "last_name": "thorne", 
 "company": "people data labs",
 "pretty": True
}

# Pass the parameters object to the Person Identify API
response_data = CLIENT.person.identify(**PARAMS).json()

# Create a list of matches
identities = response_data['matches']

# Print the matches in JSON format
print(identities)
print(f"Found {len(identities)} identities!")
```

```
API_KEY="ENTER YOUR API KEY HERE"
curl -X GET -G \
 "https://api.peopledatalabs.com/v5/person/identify"\
 -H "X-Api-Key: ${API_KEY}" \
 --data-urlencode 'first_name=sean'\
 --data-urlencode 'last_name=thorne'\
 --data-urlencode 'company="people data labs"'\
 --data-urlencode 'pretty=True'
```

```
// See https://github.com/peopledatalabs/peopledatalabs-js
import PDLJS from 'peopledatalabs';

// Create a client, specifying your API key
const PDLJSClient = new PDLJS({ apiKey: "YOUR API KEY" });

// Create a parameters JSON object
const params = {
  first_name: "sean", 
  last_name: "thorne", 
  company: "people data labs",
  pretty: true,
}

// Pass the parameters object to the Person Identify API
PDLJSClient.person.identify(params).then((data) => {
  // Create a list of matches
  var identities = data["matches"]
  
  // Print the matches in JSON format
  console.log(identities);
  console.log(`Found ${identities.length} identities!`)
}).catch((error) => {
  console.log(error);
});
```

```
# See https://github.com/peopledatalabs/peopledatalabs-ruby
require 'peopledatalabs'

# Set your API key
Peopledatalabs.api_key = 'YOUR API KEY'

# Create a parameters JSON object
PARAMS = {
 "first_name": "sean", 
 "last_name": "thorne", 
 "company": "people data labs",
 "pretty": true
}

# Pass the parameters object to the Person Identify API
response = Peopledatalabs::Identify.person(params: PARAMS)

# Create a list of matches
identities = response['matches']

# Print the matches in JSON format
puts JSON.dump(identities)
puts "Found #{identities.length()} identities!"
```

```
package main

import (
    "fmt"
    "encoding/json"
    "context"
)

// See https://github.com/peopledatalabs/peopledatalabs-go
import (
    pdl "github.com/peopledatalabs/peopledatalabs-go"
    pdlmodel "github.com/peopledatalabs/peopledatalabs-go/model"
)

func main() {
    // Set your API key
    apiKey := "YOUR API KEY"
    // Set API key as environmental variable
    // apiKey := os.Getenv("API_KEY")

    // Create a client, specifying your API key
    client := pdl.New(apiKey)
    
    // Create a parameters JSON object
    params := pdlmodel.IdentifyPersonParams {
        BaseParams: pdlmodel.BaseParams {
            Pretty: true,
        },
        PersonParams: pdlmodel.PersonParams {
            FirstName: []string{"sean"},
            LastName: []string{"thorne"},
            Company: []string{"people data labs"},
        },
    }
    
    // Pass the parameters object to the Person Identify API
    response, err := client.Person.Identify(context.Background(), params)
    // Check for successful response
    if err == nil {
        // Create a list of matches
        identities := response.Matches
        // Convert the matches to JSON
        jsonResponse, jsonErr := json.Marshal(identities)
        // Print the matches
        if (jsonErr == nil) {
            fmt.Println(string(jsonResponse))
        }
        
        fmt.Printf("Found %d identities!\n", len(identities))
    }
}
```

```
import requests

# Set your API key
API_KEY = "YOUR API KEY"

# Set the Person Identify API URL
PDL_URL = "https://api.peopledatalabs.com/v5/person/identify"

# Create a parameters JSON object
PARAMS = {
 "first_name": "sean", 
 "last_name": "thorne", 
 "company": "people data labs",
 "pretty": True,
 "api_key": API_KEY
}

# Pass the parameters object to the Person Identify API
response = requests.request("GET", PDL_URL, params=PARAMS)

response_data = response.json()

# Create a list of matches
identities = response_data['matches']

# Print the matches in JSON format
print(identities)
print(f"Found {len(identities)} identities!")
```

Updated 4 months ago

---

Did this page help you?

Yes

No

---
# https://docs.peopledatalabs.com/docs/job-title-class

> ðŸ“˜
>
> ### Launched in v28.0 (October 2024)
>
> The new field `job_title_class` and taxonomy below is now fully available to all customers via API and flat file deliveries.
>
> * API customers may access this taxonomy by passing the parameter `updated_title_roles` and setting the value to `true`.
> * Data License customers should reach out to your dedicated customer team to opt-in to the updated taxonomy if your data deliveries for v28.0, v28.1, v28.2, and v29.0 (Oct - Jan releases).
>
> Please see our [October 2024 Release Announcement (v28.0)](/changelog/october-2024-release-announcement-v280#taxonomy-stats) for further information.

| Canonical Values for Job Title Class |
| --- |
| general\_and\_administrative |
| research\_and\_development |
| sales\_and\_marketing |
| services |
| unemployed |

*Contents of this table were sourced from the following file on our public S3 bucket:[job\_title\_role.txt](https://pdl-prod-schema.s3.us-west-2.amazonaws.com/30.0/enums/job_title_class.txt)*

## Relevant fields

* [`job_title_class`](/docs/fields#job_title_class)
* [`experience.title.class`](/docs/fields#experiencetitle)

Updated 4 months ago

---

Did this page help you?

Yes

No

---
# https://docs.peopledatalabs.com/docs/input-parameters-company-search-api

## Required Parameters

You **must** provide either the [`query`](#query) or the [`sql`](#sql) parameter (but not both) to receive a successful response. We recommend using the Elasticsearch `query` parameter for most use cases.

When you execute an API request, the query runs directly against our [Company Dataset](/docs/company-stats) without any cleaning or preprocessing. This means that you have a *lot* of freedom to explore the dataset and return the perfect records for your particular use case. It also means that you will need to understand the available fields to make successful queries.

Use the field descriptions on the [Company Schema](/docs/company-schema) and the underlying [Elasticsearch Mapping](/docs/elasticsearch-mapping-company) to help write better queries.

To help you identify how to best query for specific sub-entities (schools, companies, and locations), we offer a suite of [Cleaner APIs](/docs/cleaner-apis).

You can also use our [API Playground](https://dashboard.peopledatalabs.com/tools/api-playground) (accessible with a free PDL account) to help write and test queries for our Search APIs.

### `api_key`

| Type | Description | Default | Example |
| --- | --- | --- | --- |
| `String` | Your secret API key. |  |  |

Your API Key **must** be included in either the request header or the `api_key` parameter. For more information about request authentication, see the [Authentication](/docs/authentication) page.

---

## Optional Parameters

### `query`

| Type | Description | Example |
| --- | --- | --- |
| `Object` | An [Elasticsearch (v7.7) query](https://www.elastic.co/guide/en/elasticsearch/reference/7.7/query-dsl.html) involving our company fields.   See our underlying [Elasticsearch Mapping](/docs/elasticsearch-mapping-company) for reference. | `"query": {"term": {"name": "people data labs"}}"` |

#### **Elasticsearch Query Limitations**

We accept the following Elasticsearch query types:

* [term](https://www.elastic.co/guide/en/elasticsearch/reference/7.7/query-dsl-term-query.html)
* [terms](https://www.elastic.co/guide/en/elasticsearch/reference/7.7/query-dsl-terms-query.html)
* [exists](https://www.elastic.co/guide/en/elasticsearch/reference/7.7/query-dsl-exists-query.html)
* [bool](https://www.elastic.co/guide/en/elasticsearch/reference/7.7/query-dsl-bool-query.html)
* [match](https://www.elastic.co/guide/en/elasticsearch/reference/7.7/query-dsl-match-query.html)
* [range](https://www.elastic.co/guide/en/elasticsearch/reference/7.7/query-dsl-range-query.html)
* [match\_phrase](https://www.elastic.co/guide/en/elasticsearch/reference/7.7/query-dsl-match-query-phrase.html)
* [wildcard](https://www.elastic.co/guide/en/elasticsearch/reference/7.7/query-dsl-wildcard-query.html)
* [prefix](https://www.elastic.co/guide/en/elasticsearch/reference/7.7/query-dsl-prefix-query.html)
* [match\_all](https://www.elastic.co/guide/en/elasticsearch/reference/7.7/query-dsl-match-all-query.html)

We've disabled most specialized options, such as boosting and custom scoring, and we do not allow aggregations.

Any array in a query (such as a `terms` array) will have a hard limit of 100 elements. If a request goes over this limit, it will fail.

### `sql`

| Type | Description | Example |
| --- | --- | --- |
| `String` | An SQL query of the format: `SELECT * FROM company WHERE XXX`, where XXX is a standard SQL boolean query involving our [company fields](/docs/company-schema). | `SELECT * FROM company WHERE name='people data labs'` |

#### **SQL Query Limitations**

We execute SQL queries using [Elasticsearch SQL](https://www.elastic.co/what-is/elasticsearch-sql).

We accept any SQL query that translates to the [above Elasticsearch query types](#elasticsearch-query-limitations) through the [ES SQL translate API](https://www.elastic.co/guide/en/elasticsearch/reference/7.7/sql-translate.html).

We will ignore any use of column selections or the `LIMIT` keyword.

We limit the number of wildcard terms (using `LIKE` with `%`) to 20 per request. If a request goes over this limit, it will fail.

### `size`

| Type | Description | Default | Example |
| --- | --- | --- | --- |
| `Integer` | The maximum number of matched records to return for this query if they exist. Must be between `1` and `100`. | `1` | `100` |

### `scroll_token`

| Type | Description | Default | Example |
| --- | --- | --- | --- |
| `String` | Each search API response returns a `scroll_token`. Include it in the next request to fetch the next `size` matching records. |  | `104$14.278746` |

A `scroll_token` returns in every [Company Search API response](/docs/output-response-company-search-api#scroll_token) and serves as a placeholder or bookmark for the last record received. For queries with more results than can fit in a single API response (see the [`size`](#size) field), use the `scroll_token` to get the next batch of results.

For example, if you send a query to the Company Search API that has 10,000 matches, you will need multiple API calls to retrieve all the records. The `scroll_token` represents how far along you are in that list of records.

Generally, the way to use `scroll_token` is:

1. Send a query to the Company Search API.
2. Get a response back containing one batch of records as well as a `scroll_token` response value (if you have already retrieved all the available records in this batch, then the `scroll_token` value will be `null`).
3. Use the same query from Step 1 and the `scroll_token` you just received to make another request to the Company Search API.
4. Get another response back with the next batch of records and a new `scroll_token` value.
5. Repeat steps 3 and 4 until you have received the desired number of records or until you receive a 404 status code because pagination is complete and the `scroll_token` key is missing from the response.

For a detailed working example of this process, see the following code example: [Bulk Retrieval](/docs/examples-company-search-api#bulk-retrieval).

### `titlecase`

| Type | Description | Default | Example |
| --- | --- | --- | --- |
| `Boolean` | All text in API responses returns as lowercase by default. Setting `titlecase` to `true` will titlecase any records returned instead. | `false` | `true` |

### `pretty`

| Type | Description | Default | Example |
| --- | --- | --- | --- |
| `Boolean` | Whether the output should have [human-readable](http://jsonprettyprint.net/) indentation. | `false` | `true` |

Updated 14 days ago

---

Did this page help you?

Yes

No

---
# https://docs.peopledatalabs.com/docs/persistent-ids

Persistent IDs allow for a significantly easier ingestion of new releases for our license customers. It provides for faster updates, a better understanding of how our dataset changes between builds and for collaboration between our license customers and products.

## Goals

We created our persistent ID solution to do the following:

1. Maintain IDs across builds for the great majority of records.
2. Provide metadata on a lineage of ID movement from one release to the next.

## How do IDs persist?

We built each production record in our dataset from many raw input source records. We further generate a record ID for each raw input record as it enters our ingestion pipeline. We then merge these records at some point into clusters of raw records that make up our final person records. Finally, we generate our persistent IDs by taking the oldest and most fundamental raw record that contributes to the final record in the cluster. This means that our **highest confidence** sources, which are the bedrock of our data, are contributing the majority of our IDs.

The only case in which an ID would disappear from our data would be if we removed a bedrock source, which happens very rarely and will continue to happen increasingly rarely over time.

## For License Customers

Please consult our [ID changelog](/docs/id-changelog) to learn more about how this impacts your deliveries.

Updated 4 months ago

---

Did this page help you?

Yes

No

---
# https://docs.peopledatalabs.com/docs/autocomplete-api

## Overview

The Autocomplete API allows you to get suggestions for Search API query values along with the number of available records for each suggestion. For example, `schools starting with "harv"`.

This API provides access to our [canonicalized datasets](/docs/canonical-data) and is meant for use in conjunction with the Person and Company Search APIs as a way of previewing what records are available before retrieving them. The Autocomplete API currently supports completion for the following field values:

* `class`: Job Classes
* `company`: Company Names
* `country`: Country Names
* `industry`: Industries
* `location`: Location Names
* `major`: Educational Majors (Field of Study)
* `region`: Region Name (for example, states for the US)
* `role`: Job Roles
* `sub_role`: Job Sub Roles
* `school`: School Names
* `skill`: Skills
* `title`: Job Titles
* `website`: Company Websites

The Autocomplete API powers the above dropdown list on the backend.

## What's Next

Please check out the following pages for more information on the Autocomplete API:

| Page | Description |
| --- | --- |
| [Quickstart](/docs/autocomplete-api-quickstart) | A quick hands-on introduction to the API with simple code examples. |
| [Reference](/docs/reference-autocomplete-api) | Detailed descriptions of the technical specifications and usage constraints. |
| [Input Parameters](/docs/input-parameters-autocomplete-api) | In-depth explanations of the input parameters that the API supports. |
| [Output Response](/docs/output-response-autocomplete-api) | In-depth explanations of the output response object that the API returns. |
| [Examples](/docs/examples-autocomplete-api) | A collection of functional examples and walkthroughs that illustrate various use cases and applications of the API. |
| [FAQs](/docs/autocomplete-api-faqs) | Answers to commonly-asked questions and other good-to-know information. |

---



*Know someone whoâ€™d thrive building data products and helping us launch whatâ€™s next? Weâ€™d love to meet!*

*Check out our[open roles](https://www.peopledatalabs.com/company?utm_source=docs&utm_medium=footer&utm_campaign=cta#jobs) â†’*

Updated 4 months ago

---

See the following pages for more details on the Autocomplete API

Did this page help you?

Yes

No

---
# https://docs.peopledatalabs.com/docs/data-sources

People Data Labs has thousands of data sources that enhance our person data and our ancillary canonical location, school and company datasets. These sources fall into two categories: our proprietary sources and our public data sources.

## Proprietary Sources

Sources of our proprietary data warrant their data is fully compliant with applicable data privacy regulations. Some data sources have been provided as a one-time file, while others we refresh every time we do a new data build. Our data sources come from a variety of verticals, including HR Tech, Real Estate Tech, Identity/Anti-Fraud, Martech and others. People Data Labs actively works with suppliers on compliance-based topics since regulations are changing quickly.

## Public Data Sources

Our public data sources include open-sourced datasets, publicly available data, governmental public records and others as defined by various state and national laws. As public records, this data is compliant.

> ðŸ“˜
>
> ### Job Posting Data Sourcing
>
> Our Job Posting Dataset is sourced exclusively from company career pages (as opposed to third party or other proprietary sources). We believe this is a unique differentiator for this dataset as it:
>
> * Provides a higher fidelity representation of the company's hiring activity (and avoids stale / zombie posts that are not as well-maintained on external job boards).
> * Provides coverage on smaller and younger companies that may not have presence on third party job boards
> * Provides a close-to-real-time signal of new and closed job posts since a company's career page is often the first place a company will update it's job openings

## Source Validation and Accuracy

Before we add a source to our data builds, it goes through multiple steps of validation. We check aggregate information across each source, ensure accurate cardinality between fields and hand-check large samples of every single source before we add it to the build. We take extensive measures to prevent false linkages that could adversely affect our product.

## Compliance

We evaluate data sources from a compliance standpoint before we integrate them into the dataset. The evaluation criteria includes a review of permissions and how the data has been obtained. We offer opt-outs and data request forms at the bottom of our website that any individual in the world can use. PDL generates various data attributes using metadata, aggregated data, inferences, or predictive models. None of our attributes are or describe sensitive personal data as defined by GDPR or the privacy laws of various US states. We also have a strict Acceptable Data Use Policy governing what our data can be used for, which you can find [here](https://www.peopledatalabs.com/acceptable-data-use-policy).

Updated 4 months ago

---

Did this page help you?

Yes

No

---
# https://docs.peopledatalabs.com/docs/data-delivery-using-azure

1. Log into your Azure storage account (or [create one](https://learn.microsoft.com/en-us/azure/storage/common/storage-account-create?tabs=azure-portal)).
2. Go to **Settings > Configuration** and disable Blob anonymous access.

3. Request PDL's delivery server IP address from [security.team@peopledatalabs.com](mailto:security.team@peopledatalabs.com).
4. Go to **Security + networking > Networking > Firewall** and add PDL's IP address to the allowed IP ranges. Please reach out to your CSM to obtain PDL's IP address to add the the allowed IP ranges.

5. Create a [container](https://learn.microsoft.com/en-us/azure/storage/blobs/blob-containers-portal#create-a-container) in the storage account.
6. Create an [access policy](https://learn.microsoft.com/en-us/azure/role-based-access-control/role-assignments-portal) for the container with **Read, Write, Delete, and List** permissions.
7. Generate a [SAS token and URL](https://learn.microsoft.com/en-us/azure/ai-services/translator/document-translation/how-to-guides/create-sas-tokens?tabs=Containers) for your container.
   1. Let the SAS token and URL live for up to 1 year to facilitate quarterly or monthly deliveries.
   2. **Securely** share the SAS token and URL with PDL using 1password share, a limited shared Google drive with the blob token in it, or another method of secure sharing where only those who need to know (you and the PDL security team) can view it.

Updated 4 months ago

---

Did this page help you?

Yes

No

---
# https://docs.peopledatalabs.com/docs/output-response-company-search-api

## Response Data Structure

Here is an example response from the Company Search API:

JSON

```
{
    "status": 200,
    "data": [
        {
            "id": "tnHcNHbCv8MKeLh92946LAkX6PKg",
            "name": "people data labs",
            ...
        },
        ...
    ],
    "total": 6,
    "scroll_token": "13.312621$543927"
}
```

## Response Fields

### `data.*`

| Type | Description |
| --- | --- |
| `Array (Object)` | The company response objects that match the input query in the format described in our [Company Schema](/docs/company-schema). |

The `data` list is made up of objects that contain the entire [PDL profile](/docs/company-schema) for each company that matches the Search API request. Any profile field that we do not have data for will have a `null` value.

  

### `status`

| Type | Description |
| --- | --- |
| `Integer` | The [API response code](/docs/errors). |

  

### `total`

| Type | Description |
| --- | --- |
| `Integer` | The total number of records that matched the input query. |

  

### `scroll_token`

| Type | Description |
| --- | --- |
| `String` | The scroll token to use to fetch the next batch of results for the query. |

For more information on using `scroll_token`, see [here](/docs/input-parameters-company-search-api#scroll_token).

## Errors

Any request that does not return a `200` success response will instead use the format described in [Errors](/docs/errors).

Updated 4 months ago

---

Did this page help you?

Yes

No

---
# https://docs.peopledatalabs.com/docs/identify-api-output-response

## Response Data Structure

The response from the Person Identify API will be in this format:

JSON

```
{
  "status": 200,
  "matches": [
    {
      "data": {
        ...
      },
      "match_score": 92,
      "matched_on": [
        "company",
        "name"
      ]
    },
    {
      "data": {
        ...
      },
      "match_score": 5,
      "matched_on": [
        "name"
      ]
    },
    ...
  ]
}
```

## Response Fields

### `status`

| Type | Description |
| --- | --- |
| `Integer` | The [API response code](/docs/errors). |

  

### `matches`

| Type | Description |
| --- | --- |
| `Array (Object)` | A list of up to 20 profiles matching the input criteria from the API request. Only returns profiles with a [`match_score`](#matchesmatch_score) greater than 5. |

Each object returned in the matches array will have the following attributes:

  

### `matches.match_score`

| Type | Description |
| --- | --- |
| `Integer` | How likely that this record is the record you're looking for based on your query. Will be between `1-99`. |

`match_score` measures how strongly a profile matches the input search criteria. The score is used to rank matching profiles and filter out profiles below a given score (default 5).

The more specific the input criteria is, the more useful the match\_score becomes. For example, if you wanted to find "John Smith", there would be too many possible matches. However, if you searched for "John Smith in New York City with the email address \_\_\_", it is much more likely that the profile with the highest `match_score` is the person you're looking for.

  

### `matches.data`

| Type | Description |
| --- | --- |
| `Object` | The full [person profile](/docs/fields) of the match. |

  

### `matches.matched_on`

| Type | Description |
| --- | --- |
| `Array (String)` | Which fields in the input query match the results in the returned profile.   * \*IMPORTANT:\*\* This field will only be included in the response if the [`include_if_matched` flag](/docs/input-parameters-person-identify-api#include_if_matched) is set to `true`. |

See the [`include_if_matched` input parameter](/docs/input-parameters-person-identify-api#include_if_matched) for more details.

  

## Errors

Any request that does not return a `200` success response will instead use the format described in [Errors](/docs/errors).

Updated 4 months ago

---

Did this page help you?

Yes

No

---
# https://docs.peopledatalabs.com/docs/naics-national-industries

| Canonical Values for NAICS National Industries |
| --- |
| abrasive product manufacturing |
| accounting, tax preparation, bookkeeping, and payroll services |
| adhesive manufacturing |
| administration of air and water resource and solid waste management programs |
| administration of conservation programs |
| administration of education programs |
| administration of general economic programs |
| administration of housing programs |
| administration of human resource programs (except education, public health, and veterans' affairs programs) |
| administration of public health programs |
| administration of urban planning and community and rural development |
| administration of veterans' affairs |
| advertising agencies |
| advertising material distribution services |
| aerospace product and parts manufacturing |
| agents and managers for artists, athletes, entertainers, and other public figures |
| agricultural implement manufacturing |
| airport operations |
| all other ambulatory health care services |
| all other amusement and recreation industries |
| all other animal production |
| all other chemical product and preparation manufacturing |
| all other crop farming |
| all other electrical equipment and component manufacturing |
| all other fabricated metal product manufacturing |
| all other financial investment activities |
| all other food manufacturing |
| all other general purpose machinery manufacturing |
| all other information services |
| all other miscellaneous manufacturing |
| all other miscellaneous store retailers |
| all other nonmetallic mineral product manufacturing |
| all other personal services |
| all other pipeline transportation |
| all other professional, scientific, and technical services |
| all other schools and instruction |
| all other specialty trade contractors |
| all other support services |
| all other textile product mills |
| all other waste management services |
| all other wood product manufacturing |
| alumina and aluminum production and processing |
| ambulance services |
| american indian and alaska native tribal governments |
| amusement and theme parks |
| amusement arcades |
| animal food manufacturing |
| animal slaughtering and processing |
| apiculture |
| apparel accessories and other apparel manufacturing |
| aquaculture |
| architectural services |
| art dealers |
| artificial and synthetic fibers and filaments manufacturing |
| asphalt paving, roofing, and saturated materials manufacturing |
| audio and video equipment manufacturing |
| automobile and light duty motor vehicle manufacturing |
| automobile and other motor vehicle merchant wholesalers |
| automotive body, paint, interior, and glass repair |
| automotive mechanical and electrical repair and maintenance |
| automotive parts and accessories stores |
| battery manufacturing |
| beef cattle ranching and farming, including feedlots |
| beer and ale merchant wholesalers |
| beer, wine, and liquor stores |
| blind and shade manufacturing |
| book publishers |
| book stores and news dealers |
| book, periodical, and newspaper merchant wholesalers |
| bowling centers |
| bread and bakery product manufacturing |
| breakfast cereal manufacturing |
| breweries |
| brick, stone, and related construction material merchant wholesalers |
| broadwoven fabric mills |
| broilers and other meat type chicken production |
| building inspection services |
| business and secretarial schools |
| business associations |
| business service centers |
| business to business electronic markets |
| cable and other subscription programming |
| carpet and rug mills |
| carpet and upholstery cleaning services |
| casino hotels |
| casinos (except casino hotels) |
| caterers |
| cement manufacturing |
| cemeteries and crematories |
| charter bus industry |
| chicken egg production |
| child and youth services |
| child day care services |
| children's and infants' clothing stores |
| chocolate and confectionery manufacturing |
| citrus (except orange) groves |
| civic and social organizations |
| clay building material and refractories manufacturing |
| clothing accessories stores |
| coal and other mineral and ore merchant wholesalers |
| coal mining |
| coating, engraving, heat treating, and allied activities |
| coffee and tea manufacturing |
| coin-operated laundries and drycleaners |
| collection agencies |
| colleges, universities, and professional schools |
| commercial and industrial machinery and equipment (except automotive and electronic) repair and maintenance |
| commercial and institutional building construction |
| commercial and service industry machinery manufacturing |
| commercial banking |
| commodity contracts brokerage |
| commodity contracts dealing |
| communication and energy wire and cable manufacturing |
| community food services |
| community housing services |
| computer and computer peripheral equipment and software merchant wholesalers |
| computer and peripheral equipment manufacturing |
| computer systems design and related services |
| computer training |
| concrete pipe, brick, and block manufacturing |
| confectionery merchant wholesalers |
| construction and mining (except oil well) machinery and equipment merchant wholesalers |
| construction machinery manufacturing |
| construction, transportation, mining, and forestry machinery and equipment rental and leasing |
| consumer electronics and appliances rental |
| continuing care retirement communities and assisted living facilities for the elderly |
| convenience stores |
| convention and trade show organizers |
| cookie, cracker, and pasta manufacturing |
| copper rolling, drawing, extruding, and alloying |
| copper, nickel, lead, and zinc mining |
| corn farming |
| correctional institutions |
| cosmetics, beauty supplies, and perfume stores |
| cotton farming |
| couriers and express delivery services |
| courts |
| credit bureaus |
| credit card issuing |
| credit unions |
| crude petroleum extraction |
| curtain and linen mills |
| cut and sew apparel contractors |
| cutlery and handtool manufacturing |
| dairy cattle and milk production |
| dairy product (except dried or canned) merchant wholesalers |
| dairy product (except frozen) manufacturing |
| dance companies |
| data processing, hosting, and related services |
| deep sea, coastal, and great lakes water transportation |
| department stores |
| direct insurance (except life, health, and medical) carriers |
| direct life, health, and medical insurance carriers |
| direct mail advertising |
| directory and mailing list publishers |
| distilleries |
| document preparation services |
| doll, toy, and game manufacturing |
| drafting services |
| drinking places (alcoholic beverages) |
| drugs and druggists' sundries merchant wholesalers |
| dry pea and bean farming |
| drycleaning and laundry services (except coin-operated) |
| drywall and insulation contractors |
| dual-purpose cattle ranching and farming |
| educational support services |
| electric lamp bulb and part manufacturing |
| electric power generation |
| electric power transmission, control, and distribution |
| electrical apparatus and equipment, wiring supplies, and related equipment merchant wholesalers |
| electrical contractors and other wiring installation contractors |
| electrical equipment manufacturing |
| electronic and precision equipment repair and maintenance |
| electronic shopping and mail-order houses |
| electronics and appliance stores |
| elementary and secondary schools |
| emergency and other relief services |
| employment placement agencies and executive search services |
| engine, turbine, and power transmission equipment manufacturing |
| engineering services |
| environmental consulting services |
| executive and legislative offices, combined |
| executive offices |
| explosives manufacturing |
| exterminating and pest control services |
| fabric coating mills |
| facilities support services |
| family clothing stores |
| family planning centers |
| farm and garden machinery and equipment merchant wholesalers |
| farm product warehousing and storage |
| farm supplies merchant wholesalers |
| ferrous metal foundries |
| fertilizer manufacturing |
| fiber, yarn, and thread mills |
| financial transactions processing, reserve, and clearinghouse activities |
| fine arts schools |
| finish carpentry contractors |
| fire protection |
| fish and seafood markets |
| fish and seafood merchant wholesalers |
| fishing |
| fitness and recreational sports centers |
| flavoring syrup and concentrate manufacturing |
| floor covering stores |
| flooring contractors |
| florists |
| flour milling and malt manufacturing |
| flower, nursery stock, and florists' supplies merchant wholesalers |
| food crops grown under cover |
| food service contractors |
| footwear and leather goods repair |
| footwear manufacturing |
| footwear merchant wholesalers |
| forest nurseries and gathering of forest products |
| forging and stamping |
| framing contractors |
| freight transportation arrangement |
| fresh fruit and vegetable merchant wholesalers |
| frozen food manufacturing |
| fruit and vegetable canning, pickling, and drying |
| fruit and vegetable markets |
| fuel dealers |
| funeral homes and funeral services |
| fur-bearing animal and rabbit production |
| furniture merchant wholesalers |
| furniture stores |
| gasoline stations with convenience stores |
| general freight trucking, local |
| general freight trucking, long-distance |
| general line grocery merchant wholesalers |
| general medical and surgical hospitals |
| general merchandise stores, including warehouse clubs and supercenters |
| general rental centers |
| general warehousing and storage |
| geophysical surveying and mapping services |
| gift, novelty, and souvenir stores |
| glass and glass product manufacturing |
| glass and glazing contractors |
| goat farming |
| gold ore and silver ore mining |
| golf courses and country clubs |
| grain and field bean merchant wholesalers |
| grantmaking and giving services |
| graphic design services |
| gypsum product manufacturing |
| hair, nail, and skin care services |
| hardware manufacturing |
| hardware merchant wholesalers |
| hardware stores |
| hay farming |
| health and welfare funds |
| heavy duty truck manufacturing |
| highway, street, and bridge construction |
| historical sites |
| hobby, toy, and game stores |
| hog and pig farming |
| home and garden equipment and appliance repair and maintenance |
| home centers |
| home furnishing merchant wholesalers |
| home health care services |
| horses and other equine production |
| hosiery and sock mills |
| hotels (except casino hotels) and motels |
| household and institutional furniture manufacturing |
| household appliances, electric housewares, and consumer electronics merchant wholesalers |
| hunting and trapping |
| ice cream and frozen dessert manufacturing |
| independent artists, writers, and performers |
| industrial and personal service paper merchant wholesalers |
| industrial building construction |
| industrial design services |
| industrial gas manufacturing |
| industrial machinery and equipment merchant wholesalers |
| industrial machinery manufacturing |
| industrial supplies merchant wholesalers |
| inland water transportation |
| insurance agencies and brokerages |
| interior design services |
| international affairs |
| internet publishing and broadcasting and web search portals |
| interurban and rural bus transportation |
| investigation, guard, and armored car services |
| investment advice |
| investment banking and securities dealing |
| iron and steel mills and ferroalloy manufacturing |
| iron and steel pipe and tube manufacturing from purchased steel |
| iron ore mining |
| janitorial services |
| jewelry and silverware manufacturing |
| jewelry stores |
| jewelry, watch, precious stone, and precious metal merchant wholesalers |
| junior colleges |
| knit fabric mills |
| labor unions and similar labor organizations |
| laminated plastics plate, sheet (except packaging), and shape manufacturing |
| land subdivision |
| landscape architectural services |
| landscaping services |
| language schools |
| leather and hide tanning and finishing |
| legal counsel and prosecution |
| legislative bodies |
| lessors of miniwarehouses and self-storage units |
| lessors of nonfinancial intangible assets (except copyrighted works) |
| lessors of nonresidential buildings (except miniwarehouses) |
| lessors of other real estate property |
| lessors of residential buildings and dwellings |
| libraries and archives |
| lighting fixture manufacturing |
| lime manufacturing |
| limousine service |
| linen and uniform supply |
| livestock merchant wholesalers |
| local messengers and local delivery |
| logging |
| luggage and leather goods stores |
| lumber, plywood, millwork, and wood panel merchant wholesalers |
| machine shops |
| major household appliance manufacturing |
| management consulting services |
| management of companies and enterprises |
| manufactured (mobile) home dealers |
| manufacturing and reproducing magnetic and optical media |
| marinas |
| marine cargo handling |
| marketing research and public opinion polling |
| masonry contractors |
| material handling equipment manufacturing |
| materials recovery facilities |
| mattress manufacturing |
| meat and meat product merchant wholesalers |
| meat markets |
| media buying agencies |
| media representatives |
| medical and diagnostic laboratories |
| medical equipment and supplies manufacturing |
| medical, dental, and hospital equipment and supplies merchant wholesalers |
| men's and boys' clothing and furnishings merchant wholesalers |
| men's clothing stores |
| menâ€™s and boysâ€™ cut and sew apparel manufacturing |
| metal can, box, and other metal container (light gauge) manufacturing |
| metal service centers and other metal merchant wholesalers |
| metal tank (heavy gauge) manufacturing |
| metal valve manufacturing |
| metalworking machinery manufacturing |
| millwork |
| mining and oil and gas field machinery manufacturing |
| miscellaneous intermediation |
| mobile food services |
| monetary authorities-central bank |
| mortgage and nonmortgage loan brokers |
| motion picture and video distribution |
| motion picture and video exhibition |
| motion picture and video production |
| motor vehicle body and trailer manufacturing |
| motor vehicle brake system manufacturing |
| motor vehicle electrical and electronic equipment manufacturing |
| motor vehicle gasoline engine and engine parts manufacturing |
| motor vehicle metal stamping |
| motor vehicle parts (used) merchant wholesalers |
| motor vehicle seating and interior trim manufacturing |
| motor vehicle steering and suspension components (except spring) manufacturing |
| motor vehicle supplies and new parts merchant wholesalers |
| motor vehicle towing |
| motor vehicle transmission and power train parts manufacturing |
| motorcycle, boat, and other motor vehicle dealers |
| museums |
| music publishers |
| musical groups and artists |
| musical instrument and supplies stores |
| narrow fabric mills and schiffli machine embroidery |
| national security |
| natural gas distribution |
| natural gas extraction |
| nature parks and other similar institutions |
| navigational services to shipping |
| navigational, measuring, electromedical, and control instruments manufacturing |
| new car dealers |
| news syndicates |
| newspaper publishers |
| nonchocolate confectionery manufacturing |
| noncitrus fruit and tree nut farming |
| nonferrous metal (except aluminum) smelting and refining |
| nonferrous metal (except copper and aluminum) rolling, drawing, extruding, and alloying |
| nonferrous metal foundries |
| nonscheduled air transportation |
| nonwoven fabric mills |
| nursery and floriculture production |
| nursery, garden center, and farm supply stores |
| nursing care facilities (skilled nursing facilities) |
| office administrative services |
| office equipment merchant wholesalers |
| office furniture (including fixtures) manufacturing |
| office machinery and equipment rental and leasing |
| office supplies (except paper) manufacturing |
| office supplies and stationery stores |
| offices of all other health practitioners |
| offices of chiropractors |
| offices of dentists |
| offices of lawyers |
| offices of mental health practitioners (except physicians) |
| offices of notaries |
| offices of optometrists |
| offices of physical, occupational and speech therapists, and audiologists |
| offices of physicians |
| offices of real estate agents and brokers |
| offices of real estate appraisers |
| oil and gas pipeline and related structures construction |
| oilseed (except soybean) farming |
| open-end investment funds |
| ophthalmic goods merchant wholesalers |
| optical goods stores |
| orange groves |
| ornamental and architectural metal products manufacturing |
| other activities related to credit intermediation |
| other activities related to real estate |
| other apparel knitting mills |
| other automotive repair and maintenance |
| other basic inorganic chemical manufacturing |
| other basic organic chemical manufacturing |
| other building equipment contractors |
| other building finishing contractors |
| other building material dealers |
| other business support services |
| other chemical and allied products merchant wholesalers |
| other clothing stores |
| other commercial and industrial machinery and equipment rental and leasing |
| other commercial equipment merchant wholesalers |
| other communications equipment manufacturing |
| other concrete product manufacturing |
| other construction material merchant wholesalers |
| other consumer goods rental |
| other converted paper product manufacturing |
| other cut and sew apparel manufacturing |
| other depository credit intermediation |
| other direct selling establishments |
| other electronic parts and equipment merchant wholesalers |
| other farm product raw material merchant wholesalers |
| other financial vehicles |
| other foundation, structure, and building exterior contractors |
| other gambling industries |
| other gasoline stations |
| other general government support |
| other grain farming |
| other grocery and related products merchant wholesalers |
| other health and personal care stores |
| other heavy and civil engineering construction |
| other home furnishings stores |
| other individual and family services |
| other insurance funds |
| other insurance related activities |
| other justice, public order, and safety activities |
| other leather and allied product manufacturing |
| other legal services |
| other metal ore mining |
| other miscellaneous durable goods merchant wholesalers |
| other miscellaneous nondurable goods merchant wholesalers |
| other motor vehicle parts manufacturing |
| other nondepository credit intermediation |
| other nonmetallic mineral mining and quarrying |
| other outpatient care centers |
| other performing arts companies |
| other personal and household goods repair and maintenance |
| other personal care services |
| other petroleum and coal products manufacturing |
| other plastics product manufacturing |
| other poultry production |
| other professional equipment and supplies merchant wholesalers |
| other publishers |
| other residential care facilities |
| other rubber product manufacturing |
| other scientific and technical consulting services |
| other services related to advertising |
| other services to buildings and dwellings |
| other similar organizations (except business, professional, labor, and political organizations) |
| other sound recording industries |
| other specialized design services |
| other specialty food stores |
| other support activities for air transportation |
| other support activities for road transportation |
| other support activities for transportation |
| other support activities for water transportation |
| other telecommunications |
| other transit and ground passenger transportation |
| other transportation equipment manufacturing |
| other travel arrangement and reservation services |
| other traveler accommodation |
| other warehousing and storage |
| outdoor advertising |
| outdoor power equipment stores |
| outpatient mental health and substance abuse centers |
| packaged frozen food merchant wholesalers |
| packaging and labeling services |
| paint and coating manufacturing |
| paint and wallpaper stores |
| paint, varnish, and supplies merchant wholesalers |
| painting and wall covering contractors |
| paper bag and coated and treated paper manufacturing |
| paper mills |
| paperboard container manufacturing |
| paperboard mills |
| parking lots and garages |
| parole offices and probation offices |
| passenger car rental and leasing |
| pension funds |
| periodical publishers |
| pesticide and other agricultural chemical manufacturing |
| pet and pet supplies stores |
| pet care (except veterinary) services |
| petrochemical manufacturing |
| petroleum and petroleum products merchant wholesalers (except bulk stations and terminals) |
| petroleum bulk stations and terminals |
| petroleum refineries |
| pharmaceutical and medicine manufacturing |
| pharmacies and drug stores |
| photofinishing |
| photographic equipment and supplies merchant wholesalers |
| photographic services |
| piece goods, notions, and other dry goods merchant wholesalers |
| pipeline transportation of crude oil |
| pipeline transportation of natural gas |
| pipeline transportation of refined petroleum products |
| plastics bottle manufacturing |
| plastics materials and basic forms and shapes merchant wholesalers |
| plastics packaging materials and unlaminated film and sheet manufacturing |
| plastics pipe, pipe fitting, and unlaminated profile shape manufacturing |
| plate work and fabricated structural product manufacturing |
| plumbing and heating equipment and supplies (hydronics) merchant wholesalers |
| plumbing, heating, and air-conditioning contractors |
| police protection |
| political organizations |
| polystyrene foam product manufacturing |
| port and harbor operations |
| portfolio management |
| postal service |
| postproduction services and other motion picture and video industries |
| pottery, ceramics, and plumbing fixture manufacturing |
| poultry and poultry product merchant wholesalers |
| poultry hatcheries |
| poured concrete foundation and structure contractors |
| power and communication line and related structures construction |
| power boiler and heat exchanger manufacturing |
| printing |
| printing and writing paper merchant wholesalers |
| printing ink manufacturing |
| private households |
| professional and management development training |
| professional employer organizations |
| professional organizations |
| promoters of performing arts, sports, and similar events with facilities |
| promoters of performing arts, sports, and similar events without facilities |
| psychiatric and substance abuse hospitals |
| public finance activities |
| public relations agencies |
| pulp mills |
| pump and compressor manufacturing |
| radio and television broadcasting and wireless communications equipment manufacturing |
| radio broadcasting |
| rail transportation |
| railroad rolling stock manufacturing |
| ready-mix concrete manufacturing |
| real estate property managers |
| record production and distribution |
| recreational vehicle dealers |
| recyclable material merchant wholesalers |
| refrigerated warehousing and storage |
| refrigeration equipment and supplies merchant wholesalers |
| regulation and administration of communications, electric, gas, and other utilities |
| regulation and administration of transportation programs |
| regulation of agricultural marketing and commodities |
| regulation, licensing, and inspection of miscellaneous commercial sectors |
| reinsurance carriers |
| religious organizations |
| remediation services |
| research and development in the physical, engineering, and life sciences |
| research and development in the social sciences and humanities |
| residential building construction |
| residential intellectual and developmental disability facilities |
| residential mental health and substance abuse facilities |
| resin and synthetic rubber manufacturing |
| restaurants and other eating places |
| reupholstery and furniture repair |
| rice farming |
| rolling and drawing of purchased steel |
| roofing contractors |
| roofing, siding, and insulation material merchant wholesalers |
| rooming and boarding houses, dormitories, and workers' camps |
| rubber and plastics hoses and belting manufacturing |
| rv (recreational vehicle) parks and recreational camps |
| sales financing |
| sand, gravel, clay, and ceramic and refractory minerals mining and quarrying |
| satellite telecommunications |
| savings institutions |
| sawmills and wood preservation |
| scenic and sightseeing transportation, land |
| scenic and sightseeing transportation, other |
| scenic and sightseeing transportation, water |
| scheduled air transportation |
| school and employee bus transportation |
| seafood product preparation and packaging |
| seasoning and dressing manufacturing |
| securities and commodity exchanges |
| securities brokerage |
| security systems services |
| semiconductor and other electronic component manufacturing |
| service establishment equipment and supplies merchant wholesalers |
| services for the elderly and persons with disabilities |
| sewage treatment facilities |
| sewing, needlework, and piece goods stores |
| sheep farming |
| ship and boat building |
| shoe stores |
| siding contractors |
| sign manufacturing |
| site preparation contractors |
| skiing facilities |
| small electrical appliance manufacturing |
| snack food manufacturing |
| soap and cleaning compound manufacturing |
| social advocacy organizations |
| soft drink and ice manufacturing |
| software publishers |
| sound recording studios |
| soybean farming |
| space research and technology |
| specialized freight (except used goods) trucking, local |
| specialized freight (except used goods) trucking, long-distance |
| specialty (except psychiatric and substance abuse) hospitals |
| spectator sports |
| sporting and athletic goods manufacturing |
| sporting and recreational goods and supplies merchant wholesalers |
| sporting goods stores |
| sports and recreation instruction |
| spring and wire product manufacturing |
| starch and vegetable fats and oils manufacturing |
| stationery and office supplies merchant wholesalers |
| stationery product manufacturing |
| steam and air-conditioning supply |
| stone mining and quarrying |
| structural steel and precast concrete contractors |
| sugar manufacturing |
| sugarcane farming |
| supermarkets and other grocery (except convenience) stores |
| support activities for animal production |
| support activities for crop production |
| support activities for forestry |
| support activities for mining |
| support activities for printing |
| support activities for rail transportation |
| surveying and mapping (except geophysical) services |
| synthetic dye and pigment manufacturing |
| taxi service |
| technical and trade schools |
| telephone apparatus manufacturing |
| telephone call centers |
| television broadcasting |
| temporary help services |
| testing laboratories |
| textile and fabric finishing mills |
| textile bag and canvas mills |
| theater companies and dinner theaters |
| tile and terrazzo contractors |
| timber tract operations |
| tire and tube merchant wholesalers |
| tire dealers |
| tire manufacturing |
| tobacco and tobacco product merchant wholesalers |
| tobacco farming |
| tobacco manufacturing |
| toilet preparation manufacturing |
| tortilla manufacturing |
| tour operators |
| toy and hobby goods and supplies merchant wholesalers |
| translation and interpretation services |
| transportation equipment and supplies (except motor vehicle) merchant wholesalers |
| travel agencies |
| truck, utility trailer, and rv (recreational vehicle) rental and leasing |
| trusts, estates, and agency accounts |
| turkey production |
| turned product and screw, nut, and bolt manufacturing |
| urban transit systems |
| urethane and other foam product (except polystyrene) manufacturing |
| used car dealers |
| used household and office goods moving |
| used merchandise stores |
| vegetable and melon farming |
| vending machine operators |
| veneer, plywood, and engineered wood product manufacturing |
| ventilation, heating, air-conditioning, and commercial refrigeration equipment manufacturing |
| veterinary services |
| vocational rehabilitation services |
| warm air heating and air-conditioning equipment and supplies merchant wholesalers |
| waste collection |
| waste treatment and disposal |
| water and sewer line and related structures construction |
| water supply and irrigation systems |
| wheat farming |
| wholesale trade agents and brokers |
| wine and distilled alcoholic beverage merchant wholesalers |
| wineries |
| wired and wireless telecommunications carriers |
| wiring device manufacturing |
| women's clothing stores |
| women's, children's, and infants' clothing and accessories merchant wholesalers |
| womenâ€™s, girlsâ€™, and infantsâ€™ cut and sew apparel manufacturing |
| wood container and pallet manufacturing |
| wood kitchen cabinet and countertop manufacturing |
| zoos and botanical gardens |

*Contents of this table were sourced from the following file on our public S3 bucket:[naics\_industry.txt](https://pdl-prod-schema.s3.us-west-2.amazonaws.com/28.0/enums/naics_industry.txt)*

## Relevant fields

* [`naics.national_industry`](/docs/company-schema#naics)

Updated 4 months ago

---

Did this page help you?

Yes

No

---
# https://docs.peopledatalabs.com/docs/faqs-person-identify-api

> â“
>
> ### Have a Question You Want Answered? Ask Us!
>
> Head over to the [Help Center](https://support.peopledatalabs.com) and search for your question. If you still can't find what you're looking for, create a support ticket and we will get it answered for you!

---

## What is the difference between the various Person APIs?

Check out [this page](/docs/person-endpoints#the-differences-between-our-person-related-apis) for a comparison of the various person-related APIs that we offer.

## Why don't all the profiles returned by the Person Identify API match for Enrichment?

The information returned by the Person Identify API contains the strongest set of profiles from our Person Dataset matching some input characteristics about a particular identity. These profiles each represent independent "chunks" of identity information.

Based on our strict [Entity Merging and De-Duplication](/docs/data-build#de-duplication) practices, we only merge profiles when we are very confident that they represent the same identity. Therefore, each profile contains highly self-consistent information about an identity.

The Person Identify API and the set of identities returned by the Person Identify API holds a more loosely connected but likely associated set of profiles in comparison to our more strict Person Enrichment API.

## Will I be charged a credit even if I don't receive a match?

Yes, the Person Identify API will charge for each requests regardless of whether or not you receive a match. This is contrary to the rest of our APIs that charge per successful match.

The reason we charge for reach request instead of each successful match is because receiving a non-match about information your pass to the Person Identify API is also a valuable data point. That information could be used as a signal to identify the information associated with an individual may not be related to an actual person.

Updated 4 months ago

---

Did this page help you?

Yes

No

---
# https://docs.peopledatalabs.com/docs/job-title-schema

## Response Data Structure

Here is the structure of an example response from the Job Title Enrichment API:

JSON

```
{
  "cleaned_job_title": "supply manager",
  "similar_job_titles": [
    "senior supply manager",
    "supply chain manager",
    "supply specialist",
    "supply supervisor",
    "supply coordinator"
  ],
  "relevant_skills": [
    "supply management",
    "spend analysis",
    "supplier development",
    "demand planning",
    "strategic sourcing"
  ]
}
```

## Response Fields

### `cleaned_job_title`

| Type | Description |
| --- | --- |
| `String` | The job title that matches the API input `job_title` after passing it through our internal job title cleaner. |

  

### `similar_job_titles`

| Type | Description |
| --- | --- |
| `Array [String]` | A list of up to five of the most contextually-similar job titles to the `cleaned_job_title`, determined using our global resume data. |

  

### `relevant_skills`

| Type | Description |
| --- | --- |
| `Array [String]` | A list of up to five of the most contextually-similar skills to the `cleaned_job_title`, determined using our global resume data. |

Updated 4 months ago

---

Did this page help you?

Yes

No

---
# https://docs.peopledatalabs.com/docs/faqs-cleaner-apis

> ðŸ‘
>
> ### Have a Question You Want Answered? Ask Us!
>
> You can either use the `Suggest Edits` button in the top right-hand corner of this page to ask a question or you can post your question in our [Roadmap Board](https://feedback.peopledatalabs.com/).

---

Updated 4 months ago

---

Did this page help you?

Yes

No

---
# https://docs.peopledatalabs.com/docs/reference-person-search-api

The Person Search API is perfect for finding specific segments of people that you need to power your projects and products. It gives you direct access to our full [Person Dataset](/docs/datasets#api-dataset) and provides many degrees of freedom, which allow you to find any kind of person(s) with a single query.

# Endpoint

The endpoint for the Person Search API is `https://api.peopledatalabs.com/v5/person/search`.

# Person Search API Access and Billing

We charge **per record retrieved**. Each person record in the `data` array of the response counts as a single credit against your total package.

# Requests

See [Authentication](/docs/authentication) and [Requests](/docs/requests) to learn how to input requests. We recommend using a JSON object to capture request parameters and will do so in the examples.

# Rate Limiting

The current default rate limit is 10 requests per minute.

# Input Parameters

> ðŸ“˜
>
> ### For more details, see [Input Parameters - Person Search API](/docs/input-parameters-person-search-api)
>
> You can also click on the individual parameter names in the table below to view more information on them.

| Parameter Name | Description | Default | Example |
| --- | --- | --- | --- |
| [`query`](/docs/input-parameters-person-search-api#query) | An [Elasticsearch (v7.7) query](https://www.elastic.co/guide/en/elasticsearch/reference/7.7/query-dsl.html). See our underlying [Elasticsearch mapping](#full-field-mapping) for reference. |  | `{"query": {"term": {"job_company_name": "people data labs"}}}` |
| [`sql`](/docs/input-parameters-person-search-api#sql) | An SQL query of the format: `SELECT * FROM person WHERE XXX`, where XXX is a standard SQL boolean query involving our [person fields](/docs/fields). We will ignore any use of column selections or the LIMIT keyword. |  | `SELECT * FROM person WHERE job_company_name='people data labs'` |
| [`size`](/docs/input-parameters-person-search-api#size) | The batch size or the maximum number of matched records to return for this query if they exist, which must be between `1` and `100`. | `1` | `100` |
| [`from`](/docs/input-parameters-person-search-api#from) | * \* Person The `from` field is not recommended for use and will not be supported long term. Use the `scroll_token` field instead\*\*An offset value for paginating between batches, which can be a number between`0` and `9999`. You can execute pagination for a maximum of 10,000 records per query. \*\*NOTE: YOU CANNOT USE `FROM` WITH `SCROLL_TOKEN` IN THE SAME REQUEST\*\*. | `0` | `0`, `100`, `200` ... |
| [`scroll_token`](/docs/input-parameters-person-search-api#scroll_token) | An offset key for paginating between batches. Unlike the legacy `from` parameter, you can use this parameter for any number of records. Each Person Search API response returns a `scroll_token`, which you can use to fetch the next `size` records. | `None` | `104$14.278746` |
| [`dataset`](/docs/input-parameters-person-search-api#dataset) | Specifies which [dataset](/docs/datasets) the API should search against. You can input multiple datasets by separating them with a comma. Valid names are `resume`, `email`, `phone`, `mobile_phone`, `street_address`, `consumer_social`, `developer` and `all`. You can also exclude datasets by using `-` as the first character. | `resume` | `all` |
| [`titlecase`](/docs/input-parameters-person-search-api#titlecase) | All text in the data of API responses returns as lowercase by default. Setting `titlecase` to `true` will titlecase any records returned. | `false` | `true` |
| [`pretty`](/docs/input-parameters-person-search-api#pretty) | Whether the output should have [human-readable](http://jsonprettyprint.net/) indentation. | `false` | `true` |
| [`api_key`](/docs/input-parameters-person-search-api#api_key) | Your secret API key.     **Note**: you can also provide this in the request header instead, as shown on the [Authentication](/docs/authentication) page. |  |  |

# Output Response

The API will return an HTTP response code of `200` for any valid request, regardless of whether it found records for your query or not. For that reason, pay close attention to the `total` value in your response object to understand query success. Each person record in the `data` array of the response counts as a single credit against your total package. The responses in the output are sorted by profile completeness.

## Response Fields

> ðŸ“˜
>
> ### For more details, see [Output Response - Person Search API](/docs/output-response-person-search-api)
>
> You can also click the field names in the table below to view more information on them.

| Field | Description | Type |
| --- | --- | --- |
| [`status`](/docs/output-response-person-search-api#status) | The API response code (see a description of our [error codes](/docs/errors)). | `Integer` |
| [`data`](/docs/output-response-person-search-api#data) | The person response objects that match the input query (see the [example person record](/docs/example-record)). | `Array (Object)` |
| [`total`](/docs/output-response-person-search-api#total) | The number of records matching a given `query` or `sql` input. | `Integer` |
| [`scroll_token`](/docs/output-response-person-search-api#scroll_token) | The scroll token to use to fetch the next batch of results for the query. | `String` |

## Response Data Structure

The response from the Person Search API will be in this format:

JSON

```
{
    "status": 200,
    "data": [
        {
            "id": "qEnOZ5Oh0poWnQ1luFBfVw_0000",
            "full_name": "sean thorne",
            ...
        },
        ...
    ],
    "scroll_token": "1117$12.176522",
    "total": 99
}
```

See [Example Person Record](/docs/example-record) for a full example of the fields included in the `data` object.

## Errors

If the request encounters an error, it will instead return an Error Response in the format described in [Errors](/docs/errors).

# Elasticsearch Field Mapping

See [Elasticsearch Mapping](/docs/elasticsearch-mapping).

# All Data Field Descriptions

See the [Person Schema](/docs/fields).

Updated 4 months ago

---

Did this page help you?

Yes

No

---
# https://docs.peopledatalabs.com/docs/introduction

## Overview

This section will describe the structure, request methods, and access for working with our APIS.

We've organized our APIs around [REST](https://en.wikipedia.org/wiki/Representational_state_transfer) commands and use HTTP response codes to indicate successful API calls and those that produce errors. We return all API responses, including errors, as [JSON](http://www.json.org) objects.

Our APIs reside at `api.peopledatalabs.com`. When making direct API requests in URL, you must do so over [HTTPS](https://en.wikipedia.org/wiki/HTTPS). Calls made over standard HTTP will fail. API requests without proper Authentication (a valid API key) will also fail.

## API Structure

Structure

```
{BaseURL}/{version}/{entity}/{endpoint}?{parameters}
```

* **Base URL**: <https://api.peopledatalabs.com>
* **Version**: version number
  + All live endpoints operate on "v5"
* **Entity**: References the type of data to request
  + Person or Company or IP
* **Endpoint**: The type of product to request
  + Typically `enrich` or `search`
* **Parameters**: Each endpoint has a set of required parameters

Example

```
https://api.peopledatalabs.com/v5/person/enrich?api_key=XXXX&profile=linkedin.com/in/seanthorne
```

## Methods

PDL support `GET` requests for all endpoints and `POST` for the following endpoints:

* [Person Enrichment API](/docs/person-enrichment-api)
* [Person Search API](/docs/person-search-api)
* [Company Search API](/docs/company-search-api)
* [Autocomplete API](/docs/autocomplete-api)
* [Cleaner APIs](/docs/cleaner-apis)
* [Job Title Enrichment API](/docs/job-title-enrichment-api)

## Access

You can access our APIs via:

* Custom scripts in the language of your choice
* One of our [SDKs](/docs/overview)
* Use our [Postman Collection](https://www.postman.com/pdl-official/workspace/people-data-labs-workspace/collection/32867294-ef278c05-d32d-47a1-b147-b819bc96238a?action=share&creator=32867294)

Updated 4 months ago

---

Did this page help you?

Yes

No

---
# https://docs.peopledatalabs.com/docs/id-changelog

To read more about our persistent Person ID logic, please consult our [Persistent IDs](/docs/persistent-ids) page.

## Person Changelog

We also provide an additional changelog as a flat file in [this public AWS bucket](https://s3.console.aws.amazon.com/s3/buckets/pdl-prod-id-changelog?region=us-west-2&prefix=33.1/&showversions=false). Each part of the changelog is capped to a file size of approximately 100MB. Changelogs are separated by update cadence with the following paths:

* Monthly: `s3://pdl-prod-id-changelog/version_number/monthly/`
* Quarterly: `s3://pdl-prod-id-changelog/version_number/quarterly/`

Here is a description of each possible record status:

| Status | Description |
| --- | --- |
| `added` | Newly added records |
| `deleted` | Records that have been deleted |
| `merged` | Records merged into other records, including metadata of the merged records |
| `opted_out` | Records that have opted out through our website |
| `updated` | Records where a value in any field has changed and/or a profile has been merged into the record |

### Additional Metadata

Some of the statuses listed in the table above will also contain the following metadata:

| Metadata Field | Corresponding Version Status | Description |
| --- | --- | --- |
| `contains` | `updated` | The persistent IDs of any records that existed in a previous version and have been merged before or during the current version. |
| `fields_updated` | `updated` | The specific fields of the record that have changed. Changes for child fields will be limited to their parents. For example, if a recordâ€™s `experience.end_date` changes, that will be shown as `â€œfields_updatedâ€: [â€œexperienceâ€]`. |
| `to` | `merged` | The persistent ID that this record has been assigned in the current version. |

### Sample Changelogs

Added

```
{
  "id": "123",
  "previous_version": "24.1",
  "current_version": "24.2",
  "status": "added",
  "additional_metadata": null
}
```

Deleted

```
{
  "id": "123",
  "previous_version": "24.1",
  "current_version": "24.2",
  "status": "deleted",
  "additional_metadata": null
}
```

Merged

```
{
  "id": "123",
  "previous_version": "24.1",
  "current_version": "24.2",
  "status": "merged",
  "additional_metadata": {
    "to": ["abcabc", ...]
  }
}
```

Opted Out

```
{
  "id": "123",
  "previous_version": "24.1",
  "current_version": "24.2",
  "status": "opted_out",
  "additional_metadata": null
}
```

Updated

```
{
  "id": "123",
  "previous_version": "24.1",
  "current_version": "24.2",
  "status": "updated",
  "additional_metadata": {
    "contains": ["123123", ...],
    "fields_updated": ["work_email", "job_company_type", ...]
  }
}
```

Updated 6 days ago

---

Did this page help you?

Yes

No

---
# https://docs.peopledatalabs.com/docs/mic-codes

| Canonical Values for MIC Codes |
| --- |
| alxl |
| asex |
| bvca |
| misx |
| notc |
| pinx |
| xams |
| xase |
| xasx |
| xber |
| xbkk |
| xbom |
| xbru |
| xbsp |
| xbud |
| xbue |
| xcai |
| xcnq |
| xcol |
| xcse |
| xdub |
| xdus |
| xetr |
| xfka |
| xfra |
| xham |
| xhan |
| xhkg |
| xidx |
| xist |
| xjse |
| xkls |
| xkos |
| xkrx |
| xlon |
| xmce |
| xmex |
| xmil |
| xmun |
| xnas |
| xngm |
| xnms |
| xnse |
| xnys |
| xnys |
| xnze |
| xosl |
| xpar |
| xpra |
| xsap |
| xsau |
| xses |
| xsgo |
| xshe |
| xshg |
| xsto |
| xstu |
| xtae |
| xtai |
| xtse |
| xwbo |

*Contents of this table were sourced from the following file on our public S3 bucket:[ticker\_mic\_exchange.txt](https://pdl-prod-schema.s3.us-west-2.amazonaws.com/28.0/enums/ticker_mic_exchange.txt)*

## Relevant fields

* [`mic_exchange`](/docs/company-schema#mic_exchange)
* [`ultimate_parent_mic_exchange`](/docs/company-schema#ultimate_parent_mic_exchange)

Updated 4 months ago

---

Did this page help you?

Yes

No

---
# https://docs.peopledatalabs.com/docs/elasticsearch-mapping

The following is the full Elasticsearch field mapping for Person data. Use the mapping when writing Elasticsearch queries with the [Person Search API](/docs/person-search-api) to fine-tune your results.

For more information about Elasticsearch fields, see <https://www.elastic.co/guide/en/elasticsearch/reference/current/mapping-types.html>.

JSON

```
{
  "properties": {
    "full_name": {
      "type": "keyword",
      "index": true,
      "doc_values": true
    },
    "first_name": {
      "type": "keyword",
      "index": true,
      "doc_values": true
    },
    "middle_initial": {
      "type": "keyword",
      "index": true,
      "doc_values": true
    },
    "middle_name": {
      "type": "keyword",
      "index": true,
      "doc_values": true
    },
    "last_name": {
      "type": "keyword",
      "index": true,
      "doc_values": true
    },
    "last_initial": {
      "type": "keyword",
      "index": true,
      "doc_values": true
    },
    "sex": {
      "type": "keyword",
      "index": true,
      "doc_values": true
    },
    "birth_year": {
      "type": "date",
      "index": true,
      "doc_values": true,
      "format": "yyyy-MM-dd||yyyy-MM||yyyy",
      "ignore_malformed": true
    },
    "birth_date": {
      "type": "date",
      "index": true,
      "doc_values": true,
      "format": "yyyy-MM-dd||yyyy-MM||yyyy",
      "ignore_malformed": true
    },
    "linkedin_url": {
      "type": "keyword",
      "index": true,
      "doc_values": true
    },
    "linkedin_url_percent_encoded": {
      "type": "keyword",
      "index": true,
      "doc_values": true
    },
    "linkedin_username": {
      "type": "keyword",
      "index": true,
      "doc_values": true
    },
    "linkedin_id": {
      "type": "keyword",
      "index": true,
      "doc_values": true
    },
    "facebook_url": {
      "type": "keyword",
      "index": true,
      "doc_values": true
    },
    "facebook_username": {
      "type": "keyword",
      "index": true,
      "doc_values": true
    },
    "facebook_id": {
      "type": "keyword",
      "index": true,
      "doc_values": true
    },
    "twitter_url": {
      "type": "keyword",
      "index": true,
      "doc_values": true
    },
    "twitter_username": {
      "type": "keyword",
      "index": true,
      "doc_values": true
    },
    "github_url": {
      "type": "keyword",
      "index": true,
      "doc_values": true
    },
    "github_username": {
      "type": "keyword",
      "index": true,
      "doc_values": true
    },
    "work_email": {
      "type": "keyword",
      "index": true,
      "doc_values": true
    },
    "personal_emails": {
      "type": "keyword",
      "index": true,
      "doc_values": true
    },
    "recommended_personal_email": {
      "type": "keyword",
      "index": true,
      "doc_values": true
    },
    "mobile_phone": {
      "type": "keyword",
      "index": true,
      "doc_values": true
    },
    "industry": {
      "type": "keyword",
      "index": true,
      "doc_values": true
    },
    "job_title": {
      "type": "keyword",
      "index": true,
      "doc_values": true,
      "ignore_above": 256,
      "fields": {
        "text": {
          "type": "text",
          "doc_values": false
        }
      }
    },
    "job_title_class": {
      "type": "keyword",
      "index": true,
      "doc_values": true
    },
    "job_title_role": {
      "type": "keyword",
      "index": true,
      "doc_values": true
    },
    "job_title_sub_role": {
      "type": "keyword",
      "index": true,
      "doc_values": true
    },
    "job_title_levels": {
      "type": "keyword",
      "index": true,
      "doc_values": true
    },
    "job_company_id": {
      "type": "keyword",
      "index": true,
      "doc_values": true
    },
    "job_company_name": {
      "type": "keyword",
      "index": true,
      "doc_values": true
    },
    "job_company_website": {
      "type": "keyword",
      "index": true,
      "doc_values": true
    },
    "job_company_size": {
      "type": "keyword",
      "index": true,
      "doc_values": true
    },
    "job_company_industry": {
      "type": "keyword",
      "index": true,
      "doc_values": true
    },
    "job_company_industry_v2": {
      "type": "keyword",
      "index": true,
      "doc_values": true
    },
    "job_company_founded": {
      "type": "date",
      "index": true,
      "doc_values": true,
      "format": "yyyy-MM-dd||yyyy-MM||yyyy",
      "ignore_malformed": true
    },
    "job_company_linkedin_url": {
      "type": "keyword",
      "index": true,
      "doc_values": true
    },
    "job_company_linkedin_id": {
      "type": "keyword",
      "index": true,
      "doc_values": true
    },
    "job_company_facebook_url": {
      "type": "keyword",
      "index": true,
      "doc_values": true
    },
    "job_company_twitter_url": {
      "type": "keyword",
      "index": true,
      "doc_values": true
    },
    "job_company_type": {
      "type": "keyword",
      "index": true,
      "doc_values": true
    },
    "job_company_ticker": {
      "type": "keyword",
      "index": true,
      "doc_values": true,
      "normalizer": "lowercase"
    },
    "job_company_location_name": {
      "type": "keyword",
      "index": true,
      "doc_values": true
    },
    "job_company_location_locality": {
      "type": "keyword",
      "index": true,
      "doc_values": true
    },
    "job_company_location_region": {
      "type": "keyword",
      "index": true,
      "doc_values": true
    },
    "job_company_location_metro": {
      "type": "keyword",
      "index": true,
      "doc_values": true
    },
    "job_company_location_country": {
      "type": "keyword",
      "index": true,
      "doc_values": true
    },
    "job_company_location_continent": {
      "type": "keyword",
      "index": true,
      "doc_values": true
    },
    "job_company_location_street_address": {
      "type": "keyword",
      "index": true,
      "doc_values": true
    },
    "job_company_location_address_line_2": {
      "type": "keyword",
      "index": true,
      "doc_values": true
    },
    "job_company_location_postal_code": {
      "type": "keyword",
      "index": true,
      "doc_values": true
    },
    "job_company_location_geo": {
      "type": "geo_point",
      "index": true,
      "doc_values": false
    },
    "job_company_employee_count": {
      "type": "long",
      "index": true,
      "doc_values": false
    },
    "job_company_inferred_revenue": {
      "type": "keyword",
      "index": true,
      "doc_values": true,
      "normalizer": "lowercase"
    },
    "job_company_12mo_employee_growth_rate": {
      "type": "float",
      "index": true,
      "doc_values": false
    },
    "job_company_total_funding_raised": {
      "type": "float",
      "index": true,
      "doc_values": false
    },
    "job_last_verified": {
      "type": "date",
      "index": true,
      "doc_values": true,
      "format": "yyyy-MM-dd||yyyy-MM||yyyy",
      "ignore_malformed": true
    },
    "job_last_changed": {
      "type": "keyword",
      "index": true,
      "doc_values": true
    },
    "job_start_date": {
      "type": "date",
      "index": true,
      "doc_values": true,
      "format": "yyyy-MM-dd||yyyy-MM||yyyy",
      "ignore_malformed": true
    },
    "job_summary": {
      "type": "text",
      "index": true,
      "doc_values": false
    },
    "job_onet_code": {
      "type": "keyword",
      "index": true,
      "doc_values": true
    },
    "job_onet_major_group": {
      "type": "keyword",
      "index": true,
      "doc_values": true
    },
    "job_onet_minor_group": {
      "type": "keyword",
      "index": true,
      "doc_values": true
    },
    "job_onet_broad_occupation": {
      "type": "keyword",
      "index": true,
      "doc_values": true
    },
    "job_onet_specific_occupation": {
      "type": "keyword",
      "index": true,
      "doc_values": true
    },
    "job_onet_specific_occupation_detail": {
      "type": "keyword",
      "index": true,
      "doc_values": true
    },
    "location_name": {
      "type": "keyword",
      "index": true,
      "doc_values": true
    },
    "location_locality": {
      "type": "keyword",
      "index": true,
      "doc_values": true
    },
    "location_region": {
      "type": "keyword",
      "index": true,
      "doc_values": true
    },
    "location_metro": {
      "type": "keyword",
      "index": true,
      "doc_values": true
    },
    "location_country": {
      "type": "keyword",
      "index": true,
      "doc_values": true
    },
    "location_continent": {
      "type": "keyword",
      "index": true,
      "doc_values": true
    },
    "location_full_address": {
      "type": "keyword",
      "index": true,
      "doc_values": true
    },
    "location_street_address": {
      "type": "keyword",
      "index": true,
      "doc_values": true
    },
    "location_address_line_2": {
      "type": "keyword",
      "index": true,
      "doc_values": true
    },
    "location_postal_code": {
      "type": "keyword",
      "index": true,
      "doc_values": true
    },
    "location_geo": {
      "type": "geo_point",
      "index": true,
      "doc_values": false
    },
    "location_last_updated": {
      "type": "date",
      "index": true,
      "doc_values": true,
      "format": "yyyy-MM-dd||yyyy-MM||yyyy",
      "ignore_malformed": true
    },
    "linkedin_connections": {
      "type": "integer",
      "index": true,
      "doc_values": false
    },
    "facebook_friends": {
      "type": "integer",
      "index": true,
      "doc_values": false
    },
    "inferred_salary": {
      "type": "keyword",
      "index": true,
      "doc_values": true
    },
    "inferred_years_experience": {
      "type": "integer",
      "index": true,
      "doc_values": false
    },
    "summary": {
      "type": "text",
      "index": true,
      "doc_values": false
    },
    "headline": {
      "type": "text",
      "index": true,
      "doc_values": false
    },
    "phone_numbers": {
      "type": "keyword",
      "index": true,
      "doc_values": true
    },
    "phones": {
      "properties": {
        "number": {
          "type": "keyword",
          "index": true,
          "doc_values": true
        },
        "first_seen": {
          "type": "date",
          "index": true,
          "doc_values": true,
          "format": "yyyy-MM-dd||yyyy-MM||yyyy",
          "ignore_malformed": true
        },
        "last_seen": {
          "type": "date",
          "index": true,
          "doc_values": true,
          "format": "yyyy-MM-dd||yyyy-MM||yyyy",
          "ignore_malformed": true
        },
        "num_sources": {
          "type": "integer",
          "index": true,
          "doc_values": false
        },
        "type": {
          "type": "keyword",
          "index": true,
          "doc_values": true
        },
        "purpose": {
          "type": "keyword",
          "index": true,
          "doc_values": true
        },
        "is_primary_owner": {
          "type": "boolean",
          "index": true,
          "doc_values": false
        }
      }
    },
    "possible_phones": {
      "properties": {
        "number": {
          "type": "keyword",
          "index": true,
          "doc_values": true
        },
        "first_seen": {
          "type": "date",
          "index": true,
          "doc_values": true,
          "format": "yyyy-MM-dd||yyyy-MM||yyyy",
          "ignore_malformed": true
        },
        "last_seen": {
          "type": "date",
          "index": true,
          "doc_values": true,
          "format": "yyyy-MM-dd||yyyy-MM||yyyy",
          "ignore_malformed": true
        },
        "num_sources": {
          "type": "integer",
          "index": true,
          "doc_values": false
        },
        "type": {
          "type": "keyword",
          "index": true,
          "doc_values": true
        },
        "purpose": {
          "type": "keyword",
          "index": true,
          "doc_values": true
        },
        "is_primary_owner": {
          "type": "boolean",
          "index": true,
          "doc_values": false
        }
      }
    },
    "interests": {
      "type": "keyword",
      "index": true,
      "doc_values": true
    },
    "skills": {
      "type": "keyword",
      "index": true,
      "doc_values": true
    },
    "location_names": {
      "type": "keyword",
      "index": true,
      "doc_values": true
    },
    "regions": {
      "type": "keyword",
      "index": true,
      "doc_values": true
    },
    "countries": {
      "type": "keyword",
      "index": true,
      "doc_values": true
    },
    "emails": {
      "properties": {
        "address": {
          "type": "keyword",
          "index": true,
          "doc_values": true
        },
        "type": {
          "type": "keyword",
          "index": true,
          "doc_values": true
        },
        "first_seen": {
          "type": "date",
          "index": true,
          "doc_values": true,
          "format": "yyyy-MM-dd||yyyy-MM||yyyy",
          "ignore_malformed": true
        },
        "last_seen": {
          "type": "date",
          "index": true,
          "doc_values": true,
          "format": "yyyy-MM-dd||yyyy-MM||yyyy",
          "ignore_malformed": true
        },
        "num_sources": {
          "type": "integer",
          "index": true,
          "doc_values": false
        },
        "sha_256_hash": {
          "type": "keyword",
          "index": true,
          "doc_values": true
        },
        "md5_hash": {
          "type": "keyword",
          "index": true,
          "doc_values": true
        }
      }
    },
    "possible_emails": {
      "properties": {
        "address": {
          "type": "keyword",
          "index": true,
          "doc_values": true
        },
        "type": {
          "type": "keyword",
          "index": true,
          "doc_values": true
        },
        "first_seen": {
          "type": "date",
          "index": true,
          "doc_values": true,
          "format": "yyyy-MM-dd||yyyy-MM||yyyy",
          "ignore_malformed": true
        },
        "last_seen": {
          "type": "date",
          "index": true,
          "doc_values": true,
          "format": "yyyy-MM-dd||yyyy-MM||yyyy",
          "ignore_malformed": true
        },
        "num_sources": {
          "type": "integer",
          "index": true,
          "doc_values": false
        },
        "sha_256_hash": {
          "type": "keyword",
          "index": true,
          "doc_values": true
        },
        "md5_hash": {
          "type": "keyword",
          "index": true,
          "doc_values": true
        }
      }
    },
    "street_addresses": {
      "properties": {
        "name": {
          "type": "keyword",
          "index": true,
          "doc_values": true
        },
        "locality": {
          "type": "keyword",
          "index": true,
          "doc_values": true
        },
        "region": {
          "type": "keyword",
          "index": true,
          "doc_values": true
        },
        "metro": {
          "type": "keyword",
          "index": true,
          "doc_values": true
        },
        "country": {
          "type": "keyword",
          "index": true,
          "doc_values": true
        },
        "continent": {
          "type": "keyword",
          "index": true,
          "doc_values": true
        },
        "street_address": {
          "type": "keyword",
          "index": true,
          "doc_values": true
        },
        "address_line_2": {
          "type": "keyword",
          "index": true,
          "doc_values": true
        },
        "postal_code": {
          "type": "keyword",
          "index": true,
          "doc_values": true
        },
        "geo": {
          "type": "geo_point",
          "index": true,
          "doc_values": false
        },
        "full_address": {
          "type": "keyword",
          "index": true,
          "doc_values": true
        },
        "first_seen": {
          "type": "date",
          "index": true,
          "doc_values": true,
          "format": "yyyy-MM-dd||yyyy-MM||yyyy",
          "ignore_malformed": true
        },
        "last_seen": {
          "type": "date",
          "index": true,
          "doc_values": true,
          "format": "yyyy-MM-dd||yyyy-MM||yyyy",
          "ignore_malformed": true
        },
        "num_sources": {
          "type": "integer",
          "index": true,
          "doc_values": false
        }
      }
    },
    "possible_street_addresses": {
      "properties": {
        "name": {
          "type": "keyword",
          "index": true,
          "doc_values": true
        },
        "locality": {
          "type": "keyword",
          "index": false,
          "doc_values": true
        },
        "metro": {
          "type": "keyword",
          "index": false,
          "doc_values": true
        },
        "region": {
          "type": "keyword",
          "index": false,
          "doc_values": true
        },
        "country": {
          "type": "keyword",
          "index": false,
          "doc_values": true
        },
        "continent": {
          "type": "keyword",
          "index": false,
          "doc_values": true
        },
        "street_address": {
          "type": "keyword",
          "index": false,
          "doc_values": true
        },
        "address_line_2": {
          "type": "keyword",
          "index": false,
          "doc_values": true
        },
        "postal_code": {
          "type": "keyword",
          "index": false,
          "doc_values": true
        },
        "geo": {
          "type": "keyword",
          "index": false,
          "doc_values": true
        },
        "first_seen": {
          "type": "date",
          "index": true,
          "doc_values": true,
          "format": "yyyy-MM-dd||yyyy-MM||yyyy",
          "ignore_malformed": true
        },
        "last_seen": {
          "type": "date",
          "index": true,
          "doc_values": true,
          "format": "yyyy-MM-dd||yyyy-MM||yyyy",
          "ignore_malformed": true
        },
        "num_sources": {
          "type": "integer",
          "index": true,
          "doc_values": false
        }
      }
    },
    "experience": {
      "properties": {
        "company": {
          "properties": {
            "name": {
              "type": "keyword",
              "index": true,
              "doc_values": true
            },
            "size": {
              "type": "keyword",
              "index": true,
              "doc_values": true
            },
            "id": {
              "type": "keyword",
              "index": true,
              "doc_values": true
            },
            "founded": {
              "type": "date",
              "index": true,
              "doc_values": true,
              "format": "yyyy-MM-dd||yyyy-MM||yyyy",
              "ignore_malformed": true
            },
            "industry": {
              "type": "keyword",
              "index": true,
              "doc_values": true
            },
            "industry_v2": {
              "type": "keyword",
              "index": true,
              "doc_values": true
            },
            "location": {
              "properties": {
                "name": {
                  "type": "keyword",
                  "index": true,
                  "doc_values": true
                },
                "locality": {
                  "type": "keyword",
                  "index": true,
                  "doc_values": true
                },
                "region": {
                  "type": "keyword",
                  "index": true,
                  "doc_values": true
                },
                "metro": {
                  "type": "keyword",
                  "index": true,
                  "doc_values": true
                },
                "country": {
                  "type": "keyword",
                  "index": true,
                  "doc_values": true
                },
                "continent": {
                  "type": "keyword",
                  "index": true,
                  "doc_values": true
                },
                "street_address": {
                  "type": "keyword",
                  "index": true,
                  "doc_values": true
                },
                "address_line_2": {
                  "type": "keyword",
                  "index": true,
                  "doc_values": true
                },
                "postal_code": {
                  "type": "keyword",
                  "index": true,
                  "doc_values": true
                },
                "geo": {
                  "type": "geo_point",
                  "index": true,
                  "doc_values": false
                }
              }
            },
            "linkedin_url": {
              "type": "keyword",
              "index": true,
              "doc_values": true
            },
            "linkedin_id": {
              "type": "keyword",
              "index": true,
              "doc_values": true
            },
            "facebook_url": {
              "type": "keyword",
              "index": true,
              "doc_values": true
            },
            "twitter_url": {
              "type": "keyword",
              "index": true,
              "doc_values": true
            },
            "website": {
              "type": "keyword",
              "index": true,
              "doc_values": true
            },
            "ticker": {
              "type": "keyword",
              "index": true,
              "doc_values": true,
              "normalizer": "lowercase"
            },
            "type": {
              "type": "keyword",
              "index": true,
              "doc_values": true
            },
            "raw": {
              "type": "keyword",
              "index": true,
              "doc_values": true
            }
          }
        },
        "location_names": {
          "type": "keyword",
          "index": true,
          "doc_values": true
        },
        "end_date": {
          "type": "date",
          "index": true,
          "doc_values": true,
          "format": "yyyy-MM-dd||yyyy-MM||yyyy",
          "ignore_malformed": true
        },
        "start_date": {
          "type": "date",
          "index": true,
          "doc_values": true,
          "format": "yyyy-MM-dd||yyyy-MM||yyyy",
          "ignore_malformed": true
        },
        "title": {
          "properties": {
            "name": {
              "type": "keyword",
              "index": true,
              "doc_values": true,
              "ignore_above": 256,
              "fields": {
                "text": {
                  "type": "text",
                  "doc_values": false
                }
              }
            },
            "raw": {
              "type": "keyword",
              "index": true,
              "doc_values": true
            },
            "levels": {
              "type": "keyword",
              "index": true,
              "doc_values": true
            },
            "class": {
              "type": "keyword",
              "index": true,
              "doc_values": true
            },
            "role": {
              "type": "keyword",
              "index": true,
              "doc_values": true
            },
            "sub_role": {
              "type": "keyword",
              "index": true,
              "doc_values": true
            }
          }
        },
        "is_primary": {
          "type": "boolean",
          "index": true,
          "doc_values": false
        },
        "summary": {
          "type": "text",
          "index": true,
          "doc_values": false
        },
        "num_sources": {
          "type": "integer",
          "index": true,
          "doc_values": false
        },
        "first_seen": {
          "type": "date",
          "index": true,
          "doc_values": true,
          "format": "yyyy-MM-dd||yyyy-MM||yyyy",
          "ignore_malformed": true
        },
        "last_seen": {
          "type": "date",
          "index": true,
          "doc_values": true,
          "format": "yyyy-MM-dd||yyyy-MM||yyyy",
          "ignore_malformed": true
        }
      }
    },
    "job_history": {
      "properties": {
        "company_id": {
          "type": "keyword",
          "index": true,
          "doc_values": true
        },
        "company_name": {
          "type": "keyword",
          "index": true,
          "doc_values": true
        },
        "title": {
          "type": "keyword",
          "index": true,
          "doc_values": true,
          "ignore_above": 256,
          "fields": {
            "text": {
              "type": "text",
              "doc_values": false
            }
          }
        },
        "first_seen": {
          "type": "date",
          "index": true,
          "doc_values": true,
          "format": "yyyy-MM-dd||yyyy-MM||yyyy",
          "ignore_malformed": true
        },
        "last_seen": {
          "type": "date",
          "index": true,
          "doc_values": true,
          "format": "yyyy-MM-dd||yyyy-MM||yyyy",
          "ignore_malformed": true
        },
        "num_sources": {
          "type": "integer",
          "index": true,
          "doc_values": false
        }
      }
    },
    "education": {
      "properties": {
        "school": {
          "properties": {
            "name": {
              "type": "keyword",
              "index": true,
              "doc_values": true
            },
            "type": {
              "type": "keyword",
              "index": true,
              "doc_values": true
            },
            "id": {
              "type": "keyword",
              "index": true,
              "doc_values": true
            },
            "location": {
              "properties": {
                "name": {
                  "type": "keyword",
                  "index": true,
                  "doc_values": true
                },
                "country": {
                  "type": "keyword",
                  "index": true,
                  "doc_values": true
                },
                "locality": {
                  "type": "keyword",
                  "index": true,
                  "doc_values": true
                },
                "continent": {
                  "type": "keyword",
                  "index": true,
                  "doc_values": true
                },
                "region": {
                  "type": "keyword",
                  "index": true,
                  "doc_values": true
                }
              }
            },
            "linkedin_url": {
              "type": "keyword",
              "index": true,
              "doc_values": true
            },
            "facebook_url": {
              "type": "keyword",
              "index": true,
              "doc_values": true
            },
            "twitter_url": {
              "type": "keyword",
              "index": true,
              "doc_values": true
            },
            "linkedin_id": {
              "type": "keyword",
              "index": true,
              "doc_values": true
            },
            "website": {
              "type": "keyword",
              "index": true,
              "doc_values": true
            },
            "domain": {
              "type": "keyword",
              "index": true,
              "doc_values": true
            },
            "raw": {
              "type": "keyword",
              "index": true,
              "doc_values": true
            },
            "matched_on": {
              "type": "keyword",
              "index": true,
              "doc_values": true
            }
          }
        },
        "degrees": {
          "type": "keyword",
          "index": true,
          "doc_values": true
        },
        "start_date": {
          "type": "date",
          "index": true,
          "doc_values": true,
          "format": "yyyy-MM-dd||yyyy-MM||yyyy",
          "ignore_malformed": true
        },
        "end_date": {
          "type": "date",
          "index": true,
          "doc_values": true,
          "format": "yyyy-MM-dd||yyyy-MM||yyyy",
          "ignore_malformed": true
        },
        "majors": {
          "type": "keyword",
          "index": true,
          "doc_values": true
        },
        "minors": {
          "type": "keyword",
          "index": true,
          "doc_values": true
        },
        "gpa": {
          "type": "float",
          "index": true,
          "doc_values": false
        },
        "raw": {
          "type": "keyword",
          "index": false,
          "doc_values": true
        },
        "summary": {
          "type": "text",
          "index": true,
          "doc_values": false
        }
      }
    },
    "profiles": {
      "properties": {
        "network": {
          "type": "keyword",
          "index": true,
          "doc_values": true
        },
        "id": {
          "type": "keyword",
          "index": true,
          "doc_values": true
        },
        "url": {
          "type": "keyword",
          "index": true,
          "doc_values": true
        },
        "url_percent_encoded": {
          "type": "keyword",
          "index": true,
          "doc_values": true
        },
        "username": {
          "type": "keyword",
          "index": true,
          "doc_values": true
        },
        "num_sources": {
          "type": "integer",
          "index": true,
          "doc_values": false
        },
        "first_seen": {
          "type": "date",
          "index": true,
          "doc_values": true,
          "format": "yyyy-MM-dd||yyyy-MM||yyyy",
          "ignore_malformed": true
        },
        "last_seen": {
          "type": "date",
          "index": true,
          "doc_values": true,
          "format": "yyyy-MM-dd||yyyy-MM||yyyy",
          "ignore_malformed": true
        }
      }
    },
    "possible_profiles": {
      "properties": {
        "network": {
          "type": "keyword",
          "index": true,
          "doc_values": true
        },
        "id": {
          "type": "keyword",
          "index": true,
          "doc_values": true
        },
        "url": {
          "type": "keyword",
          "index": true,
          "doc_values": true
        },
        "url_percent_encoded": {
          "type": "keyword",
          "index": true,
          "doc_values": true
        },
        "username": {
          "type": "keyword",
          "index": true,
          "doc_values": true
        },
        "num_sources": {
          "type": "integer",
          "index": true,
          "doc_values": false
        },
        "first_seen": {
          "type": "date",
          "index": true,
          "doc_values": true,
          "format": "yyyy-MM-dd||yyyy-MM||yyyy",
          "ignore_malformed": true
        },
        "last_seen": {
          "type": "date",
          "index": true,
          "doc_values": true,
          "format": "yyyy-MM-dd||yyyy-MM||yyyy",
          "ignore_malformed": true
        }
      }
    },
    "certifications": {
      "properties": {
        "organization": {
          "type": "keyword",
          "index": true,
          "doc_values": true
        },
        "start_date": {
          "type": "date",
          "index": true,
          "doc_values": true,
          "format": "yyyy-MM-dd||yyyy-MM||yyyy",
          "ignore_malformed": true
        },
        "end_date": {
          "type": "date",
          "index": true,
          "doc_values": true,
          "format": "yyyy-MM-dd||yyyy-MM||yyyy",
          "ignore_malformed": true
        },
        "name": {
          "type": "keyword",
          "index": true,
          "doc_values": true
        }
      }
    },
    "languages": {
      "properties": {
        "name": {
          "type": "keyword",
          "index": true,
          "doc_values": true
        },
        "proficiency": {
          "type": "integer",
          "index": true,
          "doc_values": false
        }
      }
    },
    "name_aliases": {
      "type": "keyword",
      "index": true,
      "doc_values": true
    },
    "possible_location_names": {
      "type": "keyword",
      "index": true,
      "doc_values": true
    },
    "num_sources": {
      "type": "integer",
      "index": true,
      "doc_values": false
    },
    "num_records": {
      "type": "integer",
      "index": true,
      "doc_values": false
    },
    "first_seen": {
      "type": "date",
      "index": true,
      "doc_values": true,
      "format": "yyyy-MM-dd||yyyy-MM||yyyy",
      "ignore_malformed": true
    },
    "id": {
      "type": "keyword",
      "index": true,
      "doc_values": true
    },
    "dataset_version": {
      "type": "keyword",
      "index": true,
      "doc_values": true
    }
  }
}
```

Updated 6 days ago

---

Did this page help you?

Yes

No

---
# https://docs.peopledatalabs.com/docs/quickstart-wrapup

We have covered a lot with this Quickstart. Hereâ€™s a recap:

* You created a PDL account and got a free API key, which you can use to access a variety of API endpoints
* You used a simple URL to look up person profiles in our PDL dataset right in your browser by LinkedIn URL (in the data world, weâ€™d say that you â€œenrichedâ€ a profile using a LinkedIn URL)
* You learned how to use the Person Enrichment API to look up person profile records
* You also learned how to use the Company Enrichment API to look up company profile records
* You saw multiple examples of person and company profiles that you retrieved from our datasets.

Not bad for a few minutes of copying and pasting ðŸ˜

To continue your learning in the API Dashboard, check out the [API Dashboard Quickstart](https://blog.peopledatalabs.com/post/self-signup-api-quickstart) for a high level overview of the available features and functionality.

Updated 4 months ago

---

Now that you've sent your first API requests, check out the Introduction section to level up to writing scripts

* [Introduction](/docs/introduction)
* [API Dashboard Quickstart](https://blog.peopledatalabs.com/post/self-signup-api-quickstart)

Did this page help you?

Yes

No

---
# https://docs.peopledatalabs.com/docs/reference-company-search-api

The Company Search API is perfect for finding specific segments of companies that you need to power your projects and products. It gives you direct access to our full [Company Dataset](/docs/company-fields). There are many degrees of freedom, which allow you to find any kind of company with a single query.

# Endpoint

The endpoint for the Company Search API is `https://api.peopledatalabs.com/v5/company/search`.

# Company Search API Access and Billing

We charge **per record retrieved**. Each company record in the `data` array in the response counts as one credit against your total package.

# Requests

See [Authentication](/docs/authentication) and [Requests](/docs/requests) to learn how to input requests. We recommend using a JSON object to capture request parameters and will do so in the examples.

# Rate Limiting

The current default rate limit is 10 requests per minute.

# Input Parameters

> ðŸ“˜
>
> ### For More Details, See [Input Parameters - Company Search API](/docs/input-parameters-company-search-api)
>
> You can also click on the individual parameter names in the table below to view more information on them.

| Parameter Name | Description | Default | Example |
| --- | --- | --- | --- |
| [`query`](/docs/input-parameters-company-search-api#query) | An [Elasticsearch (v7.7) query](https://www.elastic.co/guide/en/elasticsearch/reference/7.7/query-dsl.html). See our underlying [Elasticsearch mapping](#full-field-mapping) for reference. |  | `{"query": {"term": {"name": "people data labs"}}}` |
| [`sql`](/docs/input-parameters-company-search-api#sql) | An SQL query of the format: `SELECT * FROM company WHERE XXX`, where XXX is a standard SQL boolean query involving our [company fields](/docs/company-fields). We will ignore any use of column selections or the LIMIT keyword. |  | `SELECT * FROM company WHERE name='people data labs'` |
| [`size`](/docs/input-parameters-company-search-api#size) | The batch size or the maximum number of matched records to return for this query if they exist. Must be between `1` and `100`. | `1` | `100` |
| [`from`](/docs/input-parameters-company-search-api#from) | **[LEGACY] The `from` field is not recommended for use and will not be supported long term. Use the `scroll_token` field instead** An offset value for paginating between batches, which can be a number between `0` and `9999`. We will execute pagination for a maximum of 10,000 records per query. **NOTE: YOU CANNOT USE `FROM` WITH `SCROLL_TOKEN` IN THE SAME REQUEST**. | `0` | `0`, `100`, `200` ... |
| [`scroll_token`](/docs/input-parameters-company-search-api#scroll_token) | An offset key for paginating between batches. Unlike the legacy `from`, you can use this parameter for any number of records. Each Company Search API response returns a `scroll_token`, which you can use to fetch the next `size` records. | `None` | `104$14.278746` |
| [`titlecase`](/docs/input-parameters-company-search-api#titlecase) | All text in API responses returns as lowercase by default. Setting `titlecase` to `true` will titlecase the person data in `200` responses. | `false` | `true` |
| [`pretty`](/docs/input-parameters-company-search-api#pretty) | Whether the output should have [human-readable](http://jsonprettyprint.net/) indentation. | `false` | `true` |
| [`api_key`](/docs/input-parameters-company-search-api#api_key) | Your secret API key (**Note**: you can also provide this in the request header instead, as shown on the [Authentication](/docs/authentication) page). |  |  |

# Output Response

We will return an HTTP response code of `200` for any valid request, regardless of whether records were found for your query or not. For that reason, pay close attention to the `total` value in your response object to understand query success. Each company record in the `data` array of the response counts as a single credit against your total package. The responses in the output are sorted by profile completeness.

## Response Fields

> ðŸ“˜
>
> ### For More Details, See [Output Response - Company Search API](/docs/output-response-company-search-api)
>
> You can also click the field names in the table below to view more information as well.

| Field | Description | Type |
| --- | --- | --- |
| [`status`](/docs/output-response-company-search-api#status) | The response code. See a description of our [error codes](errors). | `Integer` |
| [`data`](/docs/output-response-company-search-api#data) | The company response objects that match the input query (see the [example company record](/docs/example-company-record). | `Array (Object)` |
| [`total`](/docs/output-response-company-search-api#total) | The number of records matching a given `query` or `sql` input. | `Integer` |
| [`scroll_token`](/docs/output-response-company-search-api#scroll_token) | The scroll value, which you can use for further pagination. | `String` |

## Response Data Structure

The response from the Company Search API will be in this format:

JSON

```
{
    "status": 200,
    "data": [
        {
          "id": "tnHcNHbCv8MKeLh92946LAkX6PKg",
          "name": "people data labs",
          ...
        },
        ...
    ],
    "total": 6,
    "scroll_token": "13.312621$543927"
}
```

See [Example Company Record](/docs/example-company-record) for a full example of the fields included in the `data` object.

## Errors

If the request encounters an error, it will instead return an Error Response in the format described in [Errors](/docs/errors).

# Full Field Mapping

See [Elasticsearch Mapping](/docs/elasticsearch-mapping-company).

# All Data Field Descriptions

See [Company Schema](/docs/company-schema).

Updated 4 months ago

---

Did this page help you?

Yes

No

---
# https://docs.peopledatalabs.com/docs/reference-company-enrichment-api

The Company Enrichment API provides a **one-to-one** company match. The company data provided by this endpoint includes all the fields in our [Company Schema](/docs/company-fields).

# Endpoint

The endpoint for the Company Enrichment API is `https://api.peopledatalabs.com/v5/company/enrich`.

# Company Enrichment API Access and Billing

When the API finds a matching company, it returns this company along with an HTTP response code of `200`. When it doesn't find a matching company, it returns an HTTP response code of `404`. We charge **per match**.

# Requests

See [Authentication](/docs/authentication) and [Requests](/docs/requests) for how to input requests. We recommend using a JSON object to capture request parameters and will do so in the examples.

# Rate Limiting

The standard rate limit is 10 per minute for free customers and 1,000 per minute for paying customers.

# Input Parameters

When querying the API in URL, you can add data points to a queried company as key/value pairs at the end of a `v5` request string.

You can use the following parameters to specify information about the requested company. Adding more data points to a request increases the probability of a `200` response and increases the [likelihood score](/docs/output-response-company-enrichment-api#likelihood-score). Adding unique parameters such as `website`, `ticker` or `profile` are more likely to yield a match than a `name`.

> ðŸ“˜
>
> ### For More Details, See [Input Parameters - Company Enrichment API](/docs/input-parameters-company-enrichment-api)
>
> You can also click on the individual parameter names in the table below to view more information on them.

| ParameterÂ Name | Description | Example |
| --- | --- | --- |
| [`pdl_id`](https://docs.peopledatalabs.com/docs/input-parameters-company-enrichment-api#pdl_id) | The PDL ID for a record in our Company Dataset.  **Note**: If you enrich on ID and anything else, only ID is used and the other inputs for matching are ignored. | `aKCIYBNF9ey6o5CjHCCO4goHYKlf` |
| [`name`](https://docs.peopledatalabs.com/docs/input-parameters-company-enrichment-api#name) | The company's name. | `Google, Inc.` |
| [`profile`](https://docs.peopledatalabs.com/docs/input-parameters-company-enrichment-api#profile) | The company's social profile. | `linkedin.com/company/google` |
| [`ticker`](https://docs.peopledatalabs.com/docs/input-parameters-company-enrichment-api#ticker) | The company's stock ticker, if publicly traded. | `GOOGL` |
| [`website`](https://docs.peopledatalabs.com/docs/input-parameters-company-enrichment-api#website) | The company's website. | `google.com` |
| [`location`](https://docs.peopledatalabs.com/docs/input-parameters-company-enrichment-api#location) | The complete or partial company location. You can input multiple location values. | `1600 Amphitheatre Pkwy, Mountain View, CA 94043` |
| [`locality`](https://docs.peopledatalabs.com/docs/input-parameters-company-enrichment-api#locality) | The company's locality. You can only input one locality. | `mountainview` |
| [`region`](https://docs.peopledatalabs.com/docs/input-parameters-company-enrichment-api#region) | The company's region. You can only input one region. | `california` |
| [`country`](https://docs.peopledatalabs.com/docs/input-parameters-company-enrichment-api#country) | The company's country. You can only input one country. | `united states` |
| [`street_address`](https://docs.peopledatalabs.com/docs/input-parameters-company-enrichment-api#street_address) | The company's street address. You can only input one street address. | `1600 Amphitheatre Pkwy` |
| [`postal_code`](https://docs.peopledatalabs.com/docs/input-parameters-company-enrichment-api#postal_code) | The company's postal code. You can only input one postal code. | `94043` |
| [`api_key`](https://docs.peopledatalabs.com/docs/input-parameters-company-enrichment-api#api_key) | Your secret API key. **Note**: You can also provide this in the request header instead, as shown on the [Authentication](https://docs.peopledatalabs.com/docs/authentication) page. |  |

For our Company Enrichment API, we require a *non-ambiguous* match. This means that you must input a `name` OR `ticker` OR `website` OR `profile`.

## Additional Input Parameters

You are not required to use the following additional input parameters. They generally transform or control various aspects of the enrichment process (returning matches or formatting results.)

| ParameterÂ Name | Description | Default | Example |
| --- | --- | --- | --- |
| [`titlecase`](https://docs.peopledatalabs.com/docs/input-parameters-company-enrichment-api#titlecase) | All text in API responses returns as lowercase by default. Setting titlecase to `true` will titlecase the person data in `200` responses. | `false` | `true` |
| [`pretty`](https://docs.peopledatalabs.com/docs/input-parameters-company-enrichment-api#pretty) | Whether the output should have [human-readable](http://jsonprettyprint.net/) indentation. | `false` | `true` |
| [`include_if_matched`](https://docs.peopledatalabs.com/docs/input-parameters-company-enrichment-api#include_if_matched) | If `true`, the response includes the top-level field `matched` (along with `data`, `status` and so forth), which includes a value for each queried field parameter that was matched during our internal query. | `false` | `true` |
| [`min_likelihood`](https://docs.peopledatalabs.com/docs/input-parameters-company-enrichment-api#min_likelihood) | The minimum `likelihood` score that a response must have to return a `200`. | `2` | `6` |
| [`required`](https://docs.peopledatalabs.com/docs/input-parameters-company-enrichment-api#min_likelihood) | The fields a response must have to return a `200`. |  | `ticker` |
| [`data_include`](https://docs.peopledatalabs.com/docs/input-parameters-company-enrichment-api#data_include) | A comma-separated string of fields that you want the response to include.  Begin the string with a `-` if you want to *exclude* the specified fields. If you want to exclude all data from being returned, use `data_include=""`. |  | `"full_name,emails.address"` |

# Output Response

When you execute an API request, we preprocess the queried data points and build them into a query, which we then execute against our [Company Dataset](/docs/company-stats). Most profiles and websites map to a unique company. We fuzzy-match company names based on name appearance relative to different unique company profiles. The company name that appears most frequently in our data is the one that is most likely to be the company returned in a `200` HTTP response code. If we do not find a match or cannot resolve the query to a unique company based on a `name`, we will return a `404` HTTP response code.

## Response Fields

> ðŸ“˜
>
> ### For More Details, See [Output Response - Company Enrichment API](/docs/output-response-company-enrichment-api)
>
> You can also click the field names in the table below to view more information on them.

| Field | Description | Type |
| --- | --- | --- |
| [`status`](/docs/output-response-company-enrichment-api#status) | The response code (see a description of our [error codes](errors)). | `Integer` |
| [`likelihood`](/docs/output-response-company-enrichment-api#likelihood) | The degree of confidence. The field is an integer between `1` and `10` that represents how confident we are that the company that we returned is the same as the company that you requested. You can control the minimum likelihood score a response must have in order to return a `200` by using the `min_likelihood` parameter in the API request. | `Integer` |
| [`*`](/docs/output-response-company-enrichment-api#section-) | The matched profile record containing fields from our [Company Schema](/docs/company-fields). Any fields in the profile record that do not contain any data will have a `null` value. |  |

## Response Data Structure

Here is an example response from the Company Enrichment API:

JSON

```
{
  "status": 200,
  "name": "people data labs",
  "id": "tnHcNHbCv8MKeLh92946LAkX6PKg",
  ...,
  "likelihood": 6
}
```

See [Example Company Record](/docs/example-company-record) for a full example of the fields included in the response object.

## Errors

If the request encounters an error, it will instead return an Error Response in the format described in [Errors](/docs/errors).

Updated 4 months ago

---

Did this page help you?

Yes

No

---
# https://docs.peopledatalabs.com/docs/inferred-revenue-ranges

| Canonical Values for Inferred Revenue Ranges |
| --- |
| $0-$1M |
| $1M-$10M |
| $10M-$25M |
| $25M-$50M |
| $50M-$100M |
| $100M-$250M |
| $250M-$500M |
| $500M-$1B |
| $1B-$10B |
| $10B+ |

*Contents of this table were sourced from the following file on our public S3 bucket:[job\_company\_inferred\_revenue.txt](https://pdl-prod-schema.s3.us-west-2.amazonaws.com/28.0/enums/job_company_inferred_revenue.txt)*

## Relevant fields

* [`inferred_revenue`](/docs/company-schema#inferred_revenue)
* [`job_company_inferred_revenue`](/docs/fields#job_company_inferred_revenue)

Updated 4 months ago

---

Did this page help you?

Yes

No

---
# https://docs.peopledatalabs.com/docs/data-delivery-using-direct-download

## What are Direct Downloads

Historically, People Data Labs only offered a **Push** delivery model for our Data License customers - where we send your dataset directly to a storage location that you own and have configured (e.g. S3, Azure, GCP, Snowflake, etc).

**Push**: Delivery initiated by PDL

As of November 2025, we now also offer a **Pull** option: **Direct Downloads**.

**Pull**: You download data via SFTP / SSH

  

With Direct Downloads, instead of you creating the destination bucket, we create and host it for you. Once your data is delivered, you can securely download it on your schedule via SFTP or SSH. Youâ€™ll also get an email notification as soon as each delivery is ready.

  

## Why Switch to Direct Downloads

If you are currently a Data License customer receiving data to a bucket that you control (e.g. the Push Model), switching to Direct Downloads offers several key benefits, including:

**No setup required on your end.**
We handle the bucket creation and maintenance, so you donâ€™t need to configure credentials.

**Pull on your own schedule.**
Download deliveries whenever it's most convenient for your teamâ€”no waiting on a push, no dependency on storage syncing.

**Simple, secure access.**
Use standard tools like SFTP, SSH, or AWS to access your data securely with credentials you manage through the PDL dashboard.

**No Additional Cost**  
There is no additional charge for using the Direct Downloads delivery method (or for switching from a Pull delivery method).

## How to Get Started

To get started with Direct Downloads, just follow these quick steps:

1. **Contact your CSM**  
   Let your Customer Success Manager know you'd like to switch to Direct Downloads. Our team will handle the backend setup and spin up your secure bucket. *Note: a minor contract amendment for the adjusted delivery location may be required.*
2. **Set your Credentials**  
   Once, we've enabled your new delivery method, go to the **Settings** area of your PDL Dashboard to retrieve your username and setup your password or SSH key.

Accessing and configuring credentials in the PDL Dashboard

3. **Connect & Download**  
   You'll get a notification each time a new dataset is delivered. Using, your preferred SFTP client, connect with any collection of the following:
   1. **Host**: `pdl.sftp.peopledatalabs.com`
   2. **SFTP URL**: `[username]@pdl.sftp.peopledatalabs.com:`
   3. **Port**: 22
   4. **Username + Password** *or* **SSH Key**  
      From there, you can download your files at your convenience.

## Frequently Asked Questions

### **ðŸ” Is this method secure?**

Yes. All connections use encrypted SFTP (or SSH with secure credentials). You control access on your end just like with traditional pull-based systems.

### **ðŸ§° Can I connect using command line tools (like `sftp`)?**

Yes! You can connect directly to the PDL-hosted bucket using standard SFTP commands in your terminal. Once your credentials are set, here are a few bash examples:

Shell

```
# Start an SFTP session
sftp [username]@pdl.sftp.peopledatalabs.com

# After logging in:
ls                    # List available files
get dataset.csv       # Download a specific file
mget *.csv            # Download all CSV files
mget *                # Download all files
scp -r                # Download everything in selected directory
bye                   # Exit the session
```

### **ðŸ“… When are deliveries made?**

Delivery timing doesnâ€™t change: your data will still be delivered according to your current monthly or quarterly schedule. Youâ€™ll get an email notification when it's ready to download.

### **ðŸ“ Will older deliveries be available in the bucket?**

By default, any data placed in the bucket will expire after 110 days in order to conserve resources. This allows for some wiggle room if you need any past deliveries.

### **ðŸ’¸ Does this cost extra?**

Nope! Itâ€™s just a different delivery method - no additional cost required.

Updated 30 days ago

---

Did this page help you?

Yes

No

---
# https://docs.peopledatalabs.com/docs/naics-industries

| Canonical Values for NAICS Industries |
| --- |
| abrasive product manufacturing |
| accounting, tax preparation, bookkeeping, and payroll services |
| adhesive manufacturing |
| administration of air and water resource and solid waste management programs |
| administration of conservation programs |
| administration of education programs |
| administration of general economic programs |
| administration of housing programs |
| administration of human resource programs (except education, public health, and veterans' affairs programs) |
| administration of public health programs |
| administration of urban planning and community and rural development |
| administration of veterans' affairs |
| advertising agencies |
| advertising material distribution services |
| aerospace product and parts manufacturing |
| agents and managers for artists, athletes, entertainers, and other public figures |
| agricultural implement manufacturing |
| airport operations |
| all other ambulatory health care services |
| all other amusement and recreation industries |
| all other animal production |
| all other chemical product and preparation manufacturing |
| all other crop farming |
| all other electrical equipment and component manufacturing |
| all other fabricated metal product manufacturing |
| all other financial investment activities |
| all other food manufacturing |
| all other general purpose machinery manufacturing |
| all other information services |
| all other miscellaneous manufacturing |
| all other miscellaneous store retailers |
| all other nonmetallic mineral product manufacturing |
| all other personal services |
| all other pipeline transportation |
| all other professional, scientific, and technical services |
| all other schools and instruction |
| all other specialty trade contractors |
| all other support services |
| all other textile product mills |
| all other waste management services |
| all other wood product manufacturing |
| alumina and aluminum production and processing |
| ambulance services |
| american indian and alaska native tribal governments |
| amusement and theme parks |
| amusement arcades |
| animal food manufacturing |
| animal slaughtering and processing |
| apiculture |
| apparel accessories and other apparel manufacturing |
| aquaculture |
| architectural services |
| art dealers |
| artificial and synthetic fibers and filaments manufacturing |
| asphalt paving, roofing, and saturated materials manufacturing |
| audio and video equipment manufacturing |
| automobile and light duty motor vehicle manufacturing |
| automobile and other motor vehicle merchant wholesalers |
| automotive body, paint, interior, and glass repair |
| automotive mechanical and electrical repair and maintenance |
| automotive parts and accessories stores |
| battery manufacturing |
| beef cattle ranching and farming, including feedlots |
| beer and ale merchant wholesalers |
| beer, wine, and liquor stores |
| blind and shade manufacturing |
| book publishers |
| book stores and news dealers |
| book, periodical, and newspaper merchant wholesalers |
| bowling centers |
| bread and bakery product manufacturing |
| breakfast cereal manufacturing |
| breweries |
| brick, stone, and related construction material merchant wholesalers |
| broadwoven fabric mills |
| broilers and other meat type chicken production |
| building inspection services |
| business and secretarial schools |
| business associations |
| business service centers |
| business to business electronic markets |
| cable and other subscription programming |
| carpet and rug mills |
| carpet and upholstery cleaning services |
| casino hotels |
| casinos (except casino hotels) |
| caterers |
| cement manufacturing |
| cemeteries and crematories |
| charter bus industry |
| chicken egg production |
| child and youth services |
| child day care services |
| children's and infants' clothing stores |
| chocolate and confectionery manufacturing |
| citrus (except orange) groves |
| civic and social organizations |
| clay building material and refractories manufacturing |
| clothing accessories stores |
| coal and other mineral and ore merchant wholesalers |
| coal mining |
| coating, engraving, heat treating, and allied activities |
| coffee and tea manufacturing |
| coin-operated laundries and drycleaners |
| collection agencies |
| colleges, universities, and professional schools |
| commercial and industrial machinery and equipment (except automotive and electronic) repair and maintenance |
| commercial and institutional building construction |
| commercial and service industry machinery manufacturing |
| commercial banking |
| commodity contracts brokerage |
| commodity contracts dealing |
| communication and energy wire and cable manufacturing |
| community food services |
| community housing services |
| computer and computer peripheral equipment and software merchant wholesalers |
| computer and peripheral equipment manufacturing |
| computer systems design and related services |
| computer training |
| concrete pipe, brick, and block manufacturing |
| confectionery merchant wholesalers |
| construction and mining (except oil well) machinery and equipment merchant wholesalers |
| construction machinery manufacturing |
| construction, transportation, mining, and forestry machinery and equipment rental and leasing |
| consumer electronics and appliances rental |
| continuing care retirement communities and assisted living facilities for the elderly |
| convenience stores |
| convention and trade show organizers |
| cookie, cracker, and pasta manufacturing |
| copper rolling, drawing, extruding, and alloying |
| copper, nickel, lead, and zinc mining |
| corn farming |
| correctional institutions |
| cosmetics, beauty supplies, and perfume stores |
| cotton farming |
| couriers and express delivery services |
| courts |
| credit bureaus |
| credit card issuing |
| credit unions |
| crude petroleum extraction |
| curtain and linen mills |
| cut and sew apparel contractors |
| cutlery and handtool manufacturing |
| dairy cattle and milk production |
| dairy product (except dried or canned) merchant wholesalers |
| dairy product (except frozen) manufacturing |
| dance companies |
| data processing, hosting, and related services |
| deep sea, coastal, and great lakes water transportation |
| department stores |
| direct insurance (except life, health, and medical) carriers |
| direct life, health, and medical insurance carriers |
| direct mail advertising |
| directory and mailing list publishers |
| distilleries |
| document preparation services |
| doll, toy, and game manufacturing |
| drafting services |
| drinking places (alcoholic beverages) |
| drugs and druggists' sundries merchant wholesalers |
| dry pea and bean farming |
| drycleaning and laundry services (except coin-operated) |
| drywall and insulation contractors |
| dual-purpose cattle ranching and farming |
| educational support services |
| electric lamp bulb and part manufacturing |
| electric power generation |
| electric power transmission, control, and distribution |
| electrical apparatus and equipment, wiring supplies, and related equipment merchant wholesalers |
| electrical contractors and other wiring installation contractors |
| electrical equipment manufacturing |
| electronic and precision equipment repair and maintenance |
| electronic shopping and mail-order houses |
| electronics and appliance stores |
| elementary and secondary schools |
| emergency and other relief services |
| employment placement agencies and executive search services |
| engine, turbine, and power transmission equipment manufacturing |
| engineering services |
| environmental consulting services |
| executive and legislative offices, combined |
| executive offices |
| explosives manufacturing |
| exterminating and pest control services |
| fabric coating mills |
| facilities support services |
| family clothing stores |
| family planning centers |
| farm and garden machinery and equipment merchant wholesalers |
| farm product warehousing and storage |
| farm supplies merchant wholesalers |
| ferrous metal foundries |
| fertilizer manufacturing |
| fiber, yarn, and thread mills |
| financial transactions processing, reserve, and clearinghouse activities |
| fine arts schools |
| finish carpentry contractors |
| fire protection |
| fish and seafood markets |
| fish and seafood merchant wholesalers |
| fishing |
| fitness and recreational sports centers |
| flavoring syrup and concentrate manufacturing |
| floor covering stores |
| flooring contractors |
| florists |
| flour milling and malt manufacturing |
| flower, nursery stock, and florists' supplies merchant wholesalers |
| food crops grown under cover |
| food service contractors |
| footwear and leather goods repair |
| footwear manufacturing |
| footwear merchant wholesalers |
| forest nurseries and gathering of forest products |
| forging and stamping |
| framing contractors |
| freight transportation arrangement |
| fresh fruit and vegetable merchant wholesalers |
| frozen food manufacturing |
| fruit and vegetable canning, pickling, and drying |
| fruit and vegetable markets |
| fuel dealers |
| funeral homes and funeral services |
| fur-bearing animal and rabbit production |
| furniture merchant wholesalers |
| furniture stores |
| gasoline stations with convenience stores |
| general freight trucking, local |
| general freight trucking, long-distance |
| general line grocery merchant wholesalers |
| general medical and surgical hospitals |
| general merchandise stores, including warehouse clubs and supercenters |
| general rental centers |
| general warehousing and storage |
| geophysical surveying and mapping services |
| gift, novelty, and souvenir stores |
| glass and glass product manufacturing |
| glass and glazing contractors |
| goat farming |
| gold ore and silver ore mining |
| golf courses and country clubs |
| grain and field bean merchant wholesalers |
| grantmaking and giving services |
| graphic design services |
| gypsum product manufacturing |
| hair, nail, and skin care services |
| hardware manufacturing |
| hardware merchant wholesalers |
| hardware stores |
| hay farming |
| health and welfare funds |
| heavy duty truck manufacturing |
| highway, street, and bridge construction |
| historical sites |
| hobby, toy, and game stores |
| hog and pig farming |
| home and garden equipment and appliance repair and maintenance |
| home centers |
| home furnishing merchant wholesalers |
| home health care services |
| horses and other equine production |
| hosiery and sock mills |
| hotels (except casino hotels) and motels |
| household and institutional furniture manufacturing |
| household appliances, electric housewares, and consumer electronics merchant wholesalers |
| hunting and trapping |
| ice cream and frozen dessert manufacturing |
| independent artists, writers, and performers |
| industrial and personal service paper merchant wholesalers |
| industrial building construction |
| industrial design services |
| industrial gas manufacturing |
| industrial machinery and equipment merchant wholesalers |
| industrial machinery manufacturing |
| industrial supplies merchant wholesalers |
| inland water transportation |
| insurance agencies and brokerages |
| interior design services |
| international affairs |
| internet publishing and broadcasting and web search portals |
| interurban and rural bus transportation |
| investigation, guard, and armored car services |
| investment advice |
| investment banking and securities dealing |
| iron and steel mills and ferroalloy manufacturing |
| iron and steel pipe and tube manufacturing from purchased steel |
| iron ore mining |
| janitorial services |
| jewelry and silverware manufacturing |
| jewelry stores |
| jewelry, watch, precious stone, and precious metal merchant wholesalers |
| junior colleges |
| knit fabric mills |
| labor unions and similar labor organizations |
| laminated plastics plate, sheet (except packaging), and shape manufacturing |
| land subdivision |
| landscape architectural services |
| landscaping services |
| language schools |
| leather and hide tanning and finishing |
| legal counsel and prosecution |
| legislative bodies |
| lessors of miniwarehouses and self-storage units |
| lessors of nonfinancial intangible assets (except copyrighted works) |
| lessors of nonresidential buildings (except miniwarehouses) |
| lessors of other real estate property |
| lessors of residential buildings and dwellings |
| libraries and archives |
| lighting fixture manufacturing |
| lime manufacturing |
| limousine service |
| linen and uniform supply |
| livestock merchant wholesalers |
| local messengers and local delivery |
| logging |
| luggage and leather goods stores |
| lumber, plywood, millwork, and wood panel merchant wholesalers |
| machine shops |
| major household appliance manufacturing |
| management consulting services |
| management of companies and enterprises |
| manufactured (mobile) home dealers |
| manufacturing and reproducing magnetic and optical media |
| marinas |
| marine cargo handling |
| marketing research and public opinion polling |
| masonry contractors |
| material handling equipment manufacturing |
| materials recovery facilities |
| mattress manufacturing |
| meat and meat product merchant wholesalers |
| meat markets |
| media buying agencies |
| media representatives |
| medical and diagnostic laboratories |
| medical equipment and supplies manufacturing |
| medical, dental, and hospital equipment and supplies merchant wholesalers |
| men's and boys' clothing and furnishings merchant wholesalers |
| men's clothing stores |
| menâ€™s and boysâ€™ cut and sew apparel manufacturing |
| metal can, box, and other metal container (light gauge) manufacturing |
| metal service centers and other metal merchant wholesalers |
| metal tank (heavy gauge) manufacturing |
| metal valve manufacturing |
| metalworking machinery manufacturing |
| millwork |
| mining and oil and gas field machinery manufacturing |
| miscellaneous intermediation |
| mobile food services |
| monetary authorities-central bank |
| mortgage and nonmortgage loan brokers |
| motion picture and video distribution |
| motion picture and video exhibition |
| motion picture and video production |
| motor vehicle body and trailer manufacturing |
| motor vehicle brake system manufacturing |
| motor vehicle electrical and electronic equipment manufacturing |
| motor vehicle gasoline engine and engine parts manufacturing |
| motor vehicle metal stamping |
| motor vehicle parts (used) merchant wholesalers |
| motor vehicle seating and interior trim manufacturing |
| motor vehicle steering and suspension components (except spring) manufacturing |
| motor vehicle supplies and new parts merchant wholesalers |
| motor vehicle towing |
| motor vehicle transmission and power train parts manufacturing |
| motorcycle, boat, and other motor vehicle dealers |
| museums |
| music publishers |
| musical groups and artists |
| musical instrument and supplies stores |
| narrow fabric mills and schiffli machine embroidery |
| national security |
| natural gas distribution |
| natural gas extraction |
| nature parks and other similar institutions |
| navigational services to shipping |
| navigational, measuring, electromedical, and control instruments manufacturing |
| new car dealers |
| news syndicates |
| newspaper publishers |
| nonchocolate confectionery manufacturing |
| noncitrus fruit and tree nut farming |
| nonferrous metal (except aluminum) smelting and refining |
| nonferrous metal (except copper and aluminum) rolling, drawing, extruding, and alloying |
| nonferrous metal foundries |
| nonscheduled air transportation |
| nonwoven fabric mills |
| nursery and floriculture production |
| nursery, garden center, and farm supply stores |
| nursing care facilities (skilled nursing facilities) |
| office administrative services |
| office equipment merchant wholesalers |
| office furniture (including fixtures) manufacturing |
| office machinery and equipment rental and leasing |
| office supplies (except paper) manufacturing |
| office supplies and stationery stores |
| offices of all other health practitioners |
| offices of chiropractors |
| offices of dentists |
| offices of lawyers |
| offices of mental health practitioners (except physicians) |
| offices of notaries |
| offices of optometrists |
| offices of physical, occupational and speech therapists, and audiologists |
| offices of physicians |
| offices of real estate agents and brokers |
| offices of real estate appraisers |
| oil and gas pipeline and related structures construction |
| oilseed (except soybean) farming |
| open-end investment funds |
| ophthalmic goods merchant wholesalers |
| optical goods stores |
| orange groves |
| ornamental and architectural metal products manufacturing |
| other activities related to credit intermediation |
| other activities related to real estate |
| other apparel knitting mills |
| other automotive repair and maintenance |
| other basic inorganic chemical manufacturing |
| other basic organic chemical manufacturing |
| other building equipment contractors |
| other building finishing contractors |
| other building material dealers |
| other business support services |
| other chemical and allied products merchant wholesalers |
| other clothing stores |
| other commercial and industrial machinery and equipment rental and leasing |
| other commercial equipment merchant wholesalers |
| other communications equipment manufacturing |
| other concrete product manufacturing |
| other construction material merchant wholesalers |
| other consumer goods rental |
| other converted paper product manufacturing |
| other cut and sew apparel manufacturing |
| other depository credit intermediation |
| other direct selling establishments |
| other electronic parts and equipment merchant wholesalers |
| other farm product raw material merchant wholesalers |
| other financial vehicles |
| other foundation, structure, and building exterior contractors |
| other gambling industries |
| other gasoline stations |
| other general government support |
| other grain farming |
| other grocery and related products merchant wholesalers |
| other health and personal care stores |
| other heavy and civil engineering construction |
| other home furnishings stores |
| other individual and family services |
| other insurance funds |
| other insurance related activities |
| other justice, public order, and safety activities |
| other leather and allied product manufacturing |
| other legal services |
| other metal ore mining |
| other miscellaneous durable goods merchant wholesalers |
| other miscellaneous nondurable goods merchant wholesalers |
| other motor vehicle parts manufacturing |
| other nondepository credit intermediation |
| other nonmetallic mineral mining and quarrying |
| other outpatient care centers |
| other performing arts companies |
| other personal and household goods repair and maintenance |
| other personal care services |
| other petroleum and coal products manufacturing |
| other plastics product manufacturing |
| other poultry production |
| other professional equipment and supplies merchant wholesalers |
| other publishers |
| other residential care facilities |
| other rubber product manufacturing |
| other scientific and technical consulting services |
| other services related to advertising |
| other services to buildings and dwellings |
| other similar organizations (except business, professional, labor, and political organizations) |
| other sound recording industries |
| other specialized design services |
| other specialty food stores |
| other support activities for air transportation |
| other support activities for road transportation |
| other support activities for transportation |
| other support activities for water transportation |
| other telecommunications |
| other transit and ground passenger transportation |
| other transportation equipment manufacturing |
| other travel arrangement and reservation services |
| other traveler accommodation |
| other warehousing and storage |
| outdoor advertising |
| outdoor power equipment stores |
| outpatient mental health and substance abuse centers |
| packaged frozen food merchant wholesalers |
| packaging and labeling services |
| paint and coating manufacturing |
| paint and wallpaper stores |
| paint, varnish, and supplies merchant wholesalers |
| painting and wall covering contractors |
| paper bag and coated and treated paper manufacturing |
| paper mills |
| paperboard container manufacturing |
| paperboard mills |
| parking lots and garages |
| parole offices and probation offices |
| passenger car rental and leasing |
| pension funds |
| periodical publishers |
| pesticide and other agricultural chemical manufacturing |
| pet and pet supplies stores |
| pet care (except veterinary) services |
| petrochemical manufacturing |
| petroleum and petroleum products merchant wholesalers (except bulk stations and terminals) |
| petroleum bulk stations and terminals |
| petroleum refineries |
| pharmaceutical and medicine manufacturing |
| pharmacies and drug stores |
| photofinishing |
| photographic equipment and supplies merchant wholesalers |
| photographic services |
| piece goods, notions, and other dry goods merchant wholesalers |
| pipeline transportation of crude oil |
| pipeline transportation of natural gas |
| pipeline transportation of refined petroleum products |
| plastics bottle manufacturing |
| plastics materials and basic forms and shapes merchant wholesalers |
| plastics packaging materials and unlaminated film and sheet manufacturing |
| plastics pipe, pipe fitting, and unlaminated profile shape manufacturing |
| plate work and fabricated structural product manufacturing |
| plumbing and heating equipment and supplies (hydronics) merchant wholesalers |
| plumbing, heating, and air-conditioning contractors |
| police protection |
| political organizations |
| polystyrene foam product manufacturing |
| port and harbor operations |
| portfolio management |
| postal service |
| postproduction services and other motion picture and video industries |
| pottery, ceramics, and plumbing fixture manufacturing |
| poultry and poultry product merchant wholesalers |
| poultry hatcheries |
| poured concrete foundation and structure contractors |
| power and communication line and related structures construction |
| power boiler and heat exchanger manufacturing |
| printing |
| printing and writing paper merchant wholesalers |
| printing ink manufacturing |
| private households |
| professional and management development training |
| professional employer organizations |
| professional organizations |
| promoters of performing arts, sports, and similar events with facilities |
| promoters of performing arts, sports, and similar events without facilities |
| psychiatric and substance abuse hospitals |
| public finance activities |
| public relations agencies |
| pulp mills |
| pump and compressor manufacturing |
| radio and television broadcasting and wireless communications equipment manufacturing |
| radio broadcasting |
| rail transportation |
| railroad rolling stock manufacturing |
| ready-mix concrete manufacturing |
| real estate property managers |
| record production and distribution |
| recreational vehicle dealers |
| recyclable material merchant wholesalers |
| refrigerated warehousing and storage |
| refrigeration equipment and supplies merchant wholesalers |
| regulation and administration of communications, electric, gas, and other utilities |
| regulation and administration of transportation programs |
| regulation of agricultural marketing and commodities |
| regulation, licensing, and inspection of miscellaneous commercial sectors |
| reinsurance carriers |
| religious organizations |
| remediation services |
| research and development in the physical, engineering, and life sciences |
| research and development in the social sciences and humanities |
| residential building construction |
| residential intellectual and developmental disability facilities |
| residential mental health and substance abuse facilities |
| resin and synthetic rubber manufacturing |
| restaurants and other eating places |
| reupholstery and furniture repair |
| rice farming |
| rolling and drawing of purchased steel |
| roofing contractors |
| roofing, siding, and insulation material merchant wholesalers |
| rooming and boarding houses, dormitories, and workers' camps |
| rubber and plastics hoses and belting manufacturing |
| rv (recreational vehicle) parks and recreational camps |
| sales financing |
| sand, gravel, clay, and ceramic and refractory minerals mining and quarrying |
| satellite telecommunications |
| savings institutions |
| sawmills and wood preservation |
| scenic and sightseeing transportation, land |
| scenic and sightseeing transportation, other |
| scenic and sightseeing transportation, water |
| scheduled air transportation |
| school and employee bus transportation |
| seafood product preparation and packaging |
| seasoning and dressing manufacturing |
| securities and commodity exchanges |
| securities brokerage |
| security systems services |
| semiconductor and other electronic component manufacturing |
| service establishment equipment and supplies merchant wholesalers |
| services for the elderly and persons with disabilities |
| sewage treatment facilities |
| sewing, needlework, and piece goods stores |
| sheep farming |
| ship and boat building |
| shoe stores |
| siding contractors |
| sign manufacturing |
| site preparation contractors |
| skiing facilities |
| small electrical appliance manufacturing |
| snack food manufacturing |
| soap and cleaning compound manufacturing |
| social advocacy organizations |
| soft drink and ice manufacturing |
| software publishers |
| sound recording studios |
| soybean farming |
| space research and technology |
| specialized freight (except used goods) trucking, local |
| specialized freight (except used goods) trucking, long-distance |
| specialty (except psychiatric and substance abuse) hospitals |
| spectator sports |
| sporting and athletic goods manufacturing |
| sporting and recreational goods and supplies merchant wholesalers |
| sporting goods stores |
| sports and recreation instruction |
| spring and wire product manufacturing |
| starch and vegetable fats and oils manufacturing |
| stationery and office supplies merchant wholesalers |
| stationery product manufacturing |
| steam and air-conditioning supply |
| stone mining and quarrying |
| structural steel and precast concrete contractors |
| sugar manufacturing |
| sugarcane farming |
| supermarkets and other grocery (except convenience) stores |
| support activities for animal production |
| support activities for crop production |
| support activities for forestry |
| support activities for mining |
| support activities for printing |
| support activities for rail transportation |
| surveying and mapping (except geophysical) services |
| synthetic dye and pigment manufacturing |
| taxi service |
| technical and trade schools |
| telephone apparatus manufacturing |
| telephone call centers |
| television broadcasting |
| temporary help services |
| testing laboratories |
| textile and fabric finishing mills |
| textile bag and canvas mills |
| theater companies and dinner theaters |
| tile and terrazzo contractors |
| timber tract operations |
| tire and tube merchant wholesalers |
| tire dealers |
| tire manufacturing |
| tobacco and tobacco product merchant wholesalers |
| tobacco farming |
| tobacco manufacturing |
| toilet preparation manufacturing |
| tortilla manufacturing |
| tour operators |
| toy and hobby goods and supplies merchant wholesalers |
| translation and interpretation services |
| transportation equipment and supplies (except motor vehicle) merchant wholesalers |
| travel agencies |
| truck, utility trailer, and rv (recreational vehicle) rental and leasing |
| trusts, estates, and agency accounts |
| turkey production |
| turned product and screw, nut, and bolt manufacturing |
| urban transit systems |
| urethane and other foam product (except polystyrene) manufacturing |
| used car dealers |
| used household and office goods moving |
| used merchandise stores |
| vegetable and melon farming |
| vending machine operators |
| veneer, plywood, and engineered wood product manufacturing |
| ventilation, heating, air-conditioning, and commercial refrigeration equipment manufacturing |
| veterinary services |
| vocational rehabilitation services |
| warm air heating and air-conditioning equipment and supplies merchant wholesalers |
| waste collection |
| waste treatment and disposal |
| water and sewer line and related structures construction |
| water supply and irrigation systems |
| wheat farming |
| wholesale trade agents and brokers |
| wine and distilled alcoholic beverage merchant wholesalers |
| wineries |
| wired and wireless telecommunications carriers |
| wiring device manufacturing |
| women's clothing stores |
| women's, children's, and infants' clothing and accessories merchant wholesalers |
| womenâ€™s, girlsâ€™, and infantsâ€™ cut and sew apparel manufacturing |
| wood container and pallet manufacturing |
| wood kitchen cabinet and countertop manufacturing |
| zoos and botanical gardens |

*Contents of this table were sourced from the following file on our public S3 bucket:[naics\_industry.txt](https://pdl-prod-schema.s3.us-west-2.amazonaws.com/28.0/enums/naics_industry.txt)*

## Relevant fields

* [`naics.naics_industry`](/docs/company-schema#naics)

Updated 4 months ago

---

Did this page help you?

Yes

No

---
# https://docs.peopledatalabs.com/docs/examples-person-search-api

# Examples

We've provided code samples in Python, cURL, Ruby, Go and JavaScript. If you aren't comfortable working in any of these languages, feel free to use this [handy tool](https://curl.trillworks.com/) to convert code from cURL to the language of your choice.

> â—ï¸
>
> ### Heads Up! Credit Usage
>
> Person Search API calls cost the number of **total search results** returned.
>
> If you are making a search that could have a large number of results, make sure to use the [`size` parameter](/docs/input-parameters-person-search-api#size) to set the maximum number of results and cap your credit usage.

> ðŸ’¡
>
> ### We want your feedback!
>
> Do you see a bug? Is there an example you'd like to see that's not listed here?
>
> Head over to the public roadmap and submit a [bug ticket](https://peopledatalabs.canny.io/bugs) or a [feature request](https://peopledatalabs.canny.io/feature-requests) and receive automatic notifications as your bug is resolved or your request is implemented.

## Basic Usage

*"I want to make a query and save the results to a file."*

Python3 SDK (Elasticsearch)Python3 SDK (SQL)cURLJavaScript (Elasticsearch)JavaScript (SQL)Ruby (Elasticsearch)Ruby (SQL)Go (Elasticsearch)Go (SQL)Python3 (Elasticsearch)Python3 (SQL)

```
import json

# See https://github.com/peopledatalabs/peopledatalabs-python
from peopledatalabs import PDLPY

# Create a client, specifying your API key
CLIENT = PDLPY(
    api_key="YOUR API KEY",
)

# Create an Elasticsearch query
ES_QUERY = {
  "query": {
    "bool": {
        "must": [
            {"term": {"location_country": "mexico"}},
            {"term": {"job_title_role": "health"}},
            {"exists": {"field": "phone_numbers"}}
      ]
    }
  }
}

# Create a parameters JSON object
PARAMS = {
  'query': ES_QUERY,
  'size': 10,
  'pretty': True
}

# Pass the parameters object to the Person Search API
response = CLIENT.person.search(**PARAMS).json()

# Check for successful response
if response["status"] == 200:
  data = response['data']
  # Write out each profile found to file
  with open("my_pdl_search.jsonl", "w") as out:
    for record in data:
      out.write(json.dumps(record) + "\n")
  print(f"Successfully grabbed {len(data)} records from PDL.")
  print(f"{response['total']} total PDL records exist matching this query.")
else:
  print("NOTE: The carrier pigeons lost motivation in flight. See error and try again.")
  print("Error:", response)
```

```
import json

# See https://github.com/peopledatalabs/peopledatalabs-python
from peopledatalabs import PDLPY

# Create a client, specifying your API key
CLIENT = PDLPY(
    api_key="YOUR API KEY",
)

# Create an SQL query
SQL_QUERY = \
"""
  SELECT * FROM person
  WHERE location_country='mexico'
  AND job_title_role='health'
  AND phone_numbers IS NOT NULL;
 """

# Create a parameters JSON object
PARAMS = {
  'sql': SQL_QUERY,
  'size': 10,
  'pretty': True
}

# Pass the parameters object to the Person Search API
response = CLIENT.person.search(**PARAMS).json()

# Check for successful response
if response["status"] == 200:
  data = response['data']
  # Write out each profile found to file
  with open("my_pdl_search.jsonl", "w") as out:
    for record in data:
      out.write(json.dumps(record) + "\n")
  print(f"Successfully grabbed {len(data)} records from PDL.")
  print(f"{response['total']} total PDL records exist matching this query.")
else:
  print("NOTE: The carrier pigeons lost motivation in flight. See error and try again.")
  print("Error:", response)
```

```
# Elasticsearch
curl -X GET 'https://api.peopledatalabs.com/v5/person/search' \
-H 'X-Api-Key: xxxx' \
--data-raw '{
  "size": 10,
  "query": {
    "bool": {
      "must": [
        {"term": {"location_country": "mexico"}},
        {"term": {"job_title_role": "health"}},
        {"exists": {"field": "phone_numbers"}}
      ]
    }
  }
}'

# SQL
curl -X GET \
  'https://api.peopledatalabs.com/v5/person/search' \
  -H 'X-Api-Key: xxxx' \
  --data-raw '{
    "size": 10,
    "sql": "SELECT * FROM person WHERE location_country='\''mexico'\'' AND job_title_role='\''health'\'' AND phone_numbers IS NOT NULL;"
}'
```

```
// See https://github.com/peopledatalabs/peopledatalabs-js
import PDLJS from 'peopledatalabs';

import fs from 'fs';

// Create a client, specifying your API key
const PDLJSClient = new PDLJS({ apiKey: "YOUR API KEY" });

// Create an Elasticsearch query
const esQuery = {
  query: {
    bool: {
      must:[
        {term: {location_country: "mexico"}}, 
        {term: {job_title_role: "health"}}, 
        {exists: {field: "phone_numbers"}}
      ]
    }
  }
}

// Create a parameters JSON object
const params = {
  searchQuery: esQuery, 
  size: 10,
  pretty: true
}

// Pass the parameters object to the Person Search API
PDLJSClient.person.search.elastic(params).then((data) => {
    // Write out all profiles found to file
    fs.writeFile("my_pdl_search.jsonl", Buffer.from(JSON.stringify(data.data)), (err) => {
        if (err) throw err;
    });
    console.log(`Successfully grabbed ${data.data.length} records from PDL.`);
    console.log(`${data["total"]} total PDL records exist matching this query.`)
}).catch((error) => {
    console.log("NOTE: The carrier pigeons lost motivation in flight. See error and try again.")
    console.log(error);
});
```

```
// See https://github.com/peopledatalabs/peopledatalabs-js
import PDLJS from 'peopledatalabs';

import fs from 'fs';

// Create a client, specifying your API key
const PDLJSClient = new PDLJS({ apiKey: "YOUR API KEY" });

// Create an SQL query
const sqlQuery = `SELECT * FROM person 
                  WHERE location_country='mexico' 
                  AND job_title_role='health'
                  AND phone_numbers IS NOT NULL;`

// Create a parameters JSON object
const params = {
  searchQuery: sqlQuery, 
  size: 10,
  pretty: true
}

// Pass the parameters object to the Person Search API
PDLJSClient.person.search.sql(params).then((data) => {
    // Write out all profiles found to file
    fs.writeFile("my_pdl_search.jsonl", Buffer.from(JSON.stringify(data.data)), (err) => {
        if (err) throw err;
    });
    console.log(`Successfully grabbed ${data.data.length} records from PDL.`);
    console.log(`${data["total"]} total PDL records exist matching this query.`)
}).catch((error) => {
    console.log("NOTE: The carrier pigeons lost motivation in flight. See error and try again.")
    console.log(error);
});
```

```
require 'json'

# See https://github.com/peopledatalabs/peopledatalabs-ruby
require 'peopledatalabs'

# Set your API key
Peopledatalabs.api_key = 'YOUR API KEY'

# Create an Elasticsearch query
ES_QUERY = {
  "query": {
    "bool": {
        "must": [
            {"term": {"location_country": "mexico"}},
            {"term": {"job_title_role": "health"}},
            {"exists": {"field": "phone_numbers"}}
      ]
    }
  }
}

# Pass parameters to the Person Search API
response = Peopledatalabs::Search.person(searchType: 'elastic', query: ES_QUERY, size: 10, pretty: true)

# Check for successful response
if response['status'] == 200
    data = response['data']
    # Write out each profile found to file
    File.open("my_pdl_search.jsonl", "w") do |out|
        data.each { |record| out.write(JSON.dump(record) + "\n") }
    end
    puts "Successfully grabbed #{data.length()} records from PDL."
    puts "#{response['total']} total PDL records exist matching this query."
else
    puts "NOTE: The carrier pigeons lost motivation in flight. See error and try again."
    puts "Error: #{response}"
end
```

```
require 'json'

# See https://github.com/peopledatalabs/peopledatalabs-ruby
require 'peopledatalabs'

# Set your API key
Peopledatalabs.api_key = 'YOUR API KEY'

# Create an SQL query
SQL_QUERY = \
"""
  SELECT * FROM person
  WHERE location_country='mexico'
  AND job_title_role='health'
  AND phone_numbers IS NOT NULL;
 """

# Pass parameters to the Person Search API
response = Peopledatalabs::Search.person(searchType: 'sql', query: SQL_QUERY, size: 10, pretty: true)

# Check for successful response
if response['status'] == 200
    data = response['data']
    # Write out each profile found to file
    File.open("my_pdl_search.jsonl", "w") do |out|
        data.each { |record| out.write(JSON.dump(record) + "\n") }
    end
    puts "Successfully grabbed #{data.length()} records from PDL."
    puts "#{response['total']} total PDL records exist matching this query."
else
    puts "NOTE: The carrier pigeons lost motivation in flight. See error and try again."
    puts "Error: #{response}"
end
```

```
package main

import (
    "fmt"
    "os"
    "encoding/json"
    "context"
)

// See https://github.com/peopledatalabs/peopledatalabs-go
import (
    pdl "github.com/peopledatalabs/peopledatalabs-go"
    pdlmodel "github.com/peopledatalabs/peopledatalabs-go/model"
)

func main() {
    // Set your API key
    apiKey := "YOUR API KEY"
    // Set API key as environmental variable
    // apiKey := os.Getenv("API_KEY")

    // Create a client, specifying your API key
    client := pdl.New(apiKey)

    // Create an Elasticsearch query
    elasticSearchQuery := map[string]interface{} {
        "query": map[string]interface{} {
            "bool": map[string]interface{} {
                "must": []map[string]interface{} {
                    {"term": map[string]interface{}{"location_country": "mexico"}},
                    {"term": map[string]interface{}{"job_title_role": "health"}},
                    {"exists": map[string]interface{}{"field": "phone_numbers"}},
                },
            },
        },
    }

    // Create a parameters JSON object
    params := pdlmodel.SearchParams {
        BaseParams: pdlmodel.BaseParams {
            Size: 10,
            Pretty: true,
        },
        SearchBaseParams: pdlmodel.SearchBaseParams {
            Query: elasticSearchQuery,
        },
    }
    
    // Pass the parameters object to the Person Search API
    response, err := client.Person.Search(context.Background(), params)
    // Check for successful response
    if err == nil {
        data := response.Data
        // Create file
        out, outErr := os.Create("my_pdl_search.jsonl")
        defer out.Close()
        if (outErr == nil) {
            for i := range data {
                // Convert each profile found to JSON
                record, jsonErr := json.Marshal(data[i])
                // Write out each profile to file
                if (jsonErr == nil) {
                    out.WriteString(string(record) + "\n")
                }
            }
            out.Sync()
        }
        fmt.Printf("Successfully grabbed %d records from PDL.\n", len(data))
        fmt.Printf("%d total PDL records exist matching this query.\n", response.Total)
    } else {
        fmt.Println("NOTE: The carrier pigeons lost motivation in flight. See error and try again.")
        fmt.Println("Error:", err)
    } 
}
```

```
package main

import (
    "fmt"
    "os"
    "encoding/json"
    "context"
)

// See https://github.com/peopledatalabs/peopledatalabs-go
import (
    pdl "github.com/peopledatalabs/peopledatalabs-go"
    pdlmodel "github.com/peopledatalabs/peopledatalabs-go/model"
)

func main() {
    // Set your API key
    apiKey := "YOUR API KEY"
    // Set API key as environmental variable
    // apiKey := os.Getenv("API_KEY")

    // Create a client, specifying your API key
    client := pdl.New(apiKey)

    // Create an SQL query
    sqlQuery := "SELECT * FROM person" +
        " WHERE location_country='mexico'" +
        " AND job_title_role='health'" +
        " AND phone_numbers IS NOT NULL;"

    // Create a parameters JSON object
    params := pdlmodel.SearchParams {
        BaseParams: pdlmodel.BaseParams {
            Size: 10,
            Pretty: true,
        },
        SearchBaseParams: pdlmodel.SearchBaseParams {
            SQL: sqlQuery,
        },
    }

    // Pass the parameters object to the Person Search API
    response, err := client.Person.Search(context.Background(), params)
    // Check for successful response
    if err == nil {
        data := response.Data
        // Create file
        out, outErr := os.Create("my_pdl_search.jsonl")
        defer out.Close()
        if (outErr == nil) {
            for i := range data {
                // Convert each profile found to JSON
                record, jsonErr := json.Marshal(data[i])
                // Write out each profile to file
                if (jsonErr == nil) {
                    out.WriteString(string(record) + "\n")
                }
            }
            out.Sync()
        }
        fmt.Printf("Successfully grabbed %d records from PDL.\n", len(data))
        fmt.Printf("%d total PDL records exist matching this query.\n", response.Total)
    } else {
        fmt.Println("NOTE: The carrier pigeons lost motivation in flight. See error and try again.")
        fmt.Println("Error:", err)
    } 
}
```

```
import requests, json

# Set your API key
API_KEY = "YOUR API KEY"

# Set the Person Search API URL
PDL_URL = "https://api.peopledatalabs.com/v5/person/search"

# Set headers
HEADERS = {
  'Content-Type': "application/json",
  'X-api-key': API_KEY
}

# Create an Elasticsearch query
ES_QUERY = {
  "query": {
    "bool": {
        "must": [
            {"term": {"location_country": "mexico"}},
            {"term": {"job_title_role": "health"}},
            {"exists": {"field": "phone_numbers"}}
      ]
    }
  }
}

# Create a parameters JSON object
PARAMS = {
  'query': json.dumps(ES_QUERY),
  'size': 10,
  'pretty': True
}

# Pass the parameters object to the Person Search API
response = requests.get(
  PDL_URL,
  headers=HEADERS,
  params=PARAMS
).json()

# Check for successful response
if response["status"] == 200:
  data = response['data']
  # Write out each profile found to file
  with open("my_pdl_search.jsonl", "w") as out:
    for record in data:
      out.write(json.dumps(record) + "\n")
  print(f"Successfully grabbed {len(data)} records from PDL.")
  print(f"{response['total']} total PDL records exist matching this query.")
else:
  print("NOTE: The carrier pigeons lost motivation in flight. See error and try again.")
  print("Error:", response)
```

```
import requests, json

# Set your API key
API_KEY = "YOUR API KEY"

# Set the Person Search API URL
PDL_URL = "https://api.peopledatalabs.com/v5/person/search"

# Set headers
HEADERS = {
  'Content-Type': "application/json",
  'X-api-key': API_KEY
}

# Create an SQL query
SQL_QUERY = \
"""
  SELECT * FROM person
  WHERE location_country='mexico'
  AND job_title_role='health'
  AND phone_numbers IS NOT NULL;
 """

# Create a parameters JSON object
PARAMS = {
  'sql': SQL_QUERY,
  'size': 10,
  'pretty': True
}

# Pass the parameters object to the Person Search API
response = requests.get(
  PDL_URL,
  headers=HEADERS,
  params=PARAMS
).json()

# Check for successful response
if response["status"] == 200:
  data = response['data']
  # Write out each profile found to file
  with open("my_pdl_search.jsonl", "w") as out:
    for record in data:
      out.write(json.dumps(record) + "\n")
  print(f"Successfully grabbed {len(data)} records from PDL.")
  print(f"{response['total']} total PDL records exist matching this query.")
else:
  print("NOTE: The carrier pigeons lost motivation in flight. See error and try again.")
  print("error:", response)
```

## Using POST Requests

*"I want to use POST requests instead of GET requests so that I can make queries with a lot of parameters."*

> ðŸ“˜
>
> ### Difference Between GET and POST Requests
>
> See this article for a comparison of the [differences between GET and POST requests](https://www.w3schools.com/tags/ref_httpmethods.asp). The biggest difference is that POST requests don't have any limits on the amount of data that you can pass in the request.

Python3 (Elasticsearch)Python3 (SQL)cURL

```
import requests, json

# Set your API key
API_KEY = "YOUR API KEY"

# Set the Person Search API URL
PDL_URL = "https://api.peopledatalabs.com/v5/person/search"

# Set headers
HEADERS = {
  'Content-Type': "application/json",
  'X-api-key': API_KEY
}

# Create an Elasticsearch query
ES_QUERY = {
  "query": {
    "bool": {
        "must": [
            {"term": {"location_country": "mexico"}},
            {"term": {"job_title_role": "health"}},
            {"exists": {"field": "phone_numbers"}}
      ]
    }
  }
}

# Create a parameters JSON object
PARAMS = {
  'query': ES_QUERY, # This is a different syntax than when using GET requests
  'size': 10,
  'pretty': True
}

# Pass the parameters object to the Person Search API using POST method
response = requests.post(
  PDL_URL,
  headers=HEADERS,
  json=PARAMS # Passing the data directly as a JSON object
  # data=json.dumps(PARAMS) # This is an alternative way of passing data using a string
).json()

# Check for successful response
if response["status"] == 200:
  data = response['data']
  # Write out each profile found to file
  with open("my_pdl_search.jsonl", "w") as out:
    for record in data:
      out.write(json.dumps(record) + "\n")
  print(f"Successfully grabbed {len(data)} records from PDL.")
  print(f"{response['total']} total PDL records exist matching this query.")
else:
  print("NOTE: The carrier pigeons lost motivation in flight. See error and try again.")
  print("Error:", response)
```

```
import requests, json

# Set your API key
API_KEY = "YOUR API KEY"

# Set the Person Search API URL
PDL_URL = "https://api.peopledatalabs.com/v5/person/search"

# Set headers
HEADERS = {
  'Content-Type': "application/json",
  'X-api-key': API_KEY
}

# Create an SQL query
SQL_QUERY = \
"""
  SELECT * FROM person
  WHERE location_country='mexico'
  AND job_title_role='health'
  AND phone_numbers IS NOT NULL;
 """

# Create a parameters JSON object
PARAMS = {
  'sql': SQL_QUERY,
  'size': 10,
  'pretty': True
}

# Pass the parameters object to the Person Search API using POST method
response = requests.post(
  PDL_URL,
  headers=HEADERS,
  json=PARAMS # Pass the data directly as a JSON object
  # data=json.dumps(PARAMS) # This is an alternative way of passing data using a string
).json()

# Check for successful response
if response["status"] == 200:
  data = response['data']
  # Write out each profile found to file
  with open("my_pdl_search.jsonl", "w") as out:
    for record in data:
      out.write(json.dumps(record) + "\n")
  print(f"Successfully grabbed {len(data)} records from PDL.")
  print(f"{response['total']} total PDL records exist matching this query.")
else:
  print("NOTE: The carrier pigeons lost motivation in flight. See error and try again.")
  print("Error:", response)
```

```
# Elasticsearch
curl -X POST \
  'https://api.peopledatalabs.com/v5/person/search' \
  -H 'X-Api-Key: your-api-key' \
  -H 'Content-Type: application/json' \
  -d '{
  "size": 10,
  "query": {
    "bool": {
      "must": [
        {"term": {"location_country": "mexico"}},
        {"term": {"job_title_role": "health"}},
        {"exists": {"field": "phone_numbers"}}
      ]
    }
  }
}'

# SQL
curl -X POST \
  'https://api.peopledatalabs.com/v5/person/search' \
  -H 'X-Api-Key: your-api-key' \
  -H 'Content-Type: application/json' \
  -d '{
    "size": 10,
    "sql": "SELECT * FROM person WHERE location_country='\''mexico'\'' AND job_title_role='\''health'\'' AND phone_numbers IS NOT NULL;"
}'
```

## Searching Specific Datasets

*"I want to run a simple query against PDL's[Phone Dataset](/docs/datasets#phone-slice)."*

> ðŸ“˜
>
> ### Maintaining Backwards Compatibility
>
> We introduced the `dataset` parameter with the [July 2021 release](/changelog/july-2021-release-notes#changing-the-default-de-duplication-in-the-search-api), in which we also changed the default dataset from `all` to `resume`. For users that want to maintain the same performance in their queries as prior to this change, set the `dataset` parameter to `all` in the example below.

Python3 SDK (Elasticsearch)Python3 SDK (SQL)cURLJavaScript (Elasticsearch)JavaScript (SQL)Ruby (Elasticsearch)Ruby (SQL)Go (Elasticsearch)Go (SQL)Python3 (Elasticsearch)Python3 (SQL)

```
import json

# See https://github.com/peopledatalabs/peopledatalabs-python
from peopledatalabs import PDLPY

# Create a client, specifying your API key
CLIENT = PDLPY(
    api_key="YOUR API KEY",
)

# Create an Elasticsearch query
ES_QUERY = {
  "query": {
    "bool": {
        "must": [
            {"term": {"location_country": "mexico"}},
            {"term": {"job_title_role": "health"}}
      ]
    }
  }
}

# Create a parameters JSON object
PARAMS = {
  'query': ES_QUERY,
  'size': 10,
  'pretty': True,
  'dataset': "phone" # Search for records with a phone number
}

# Pass the parameters object to the Person Search API
response = CLIENT.person.search(**PARAMS).json()

# Check for successful response
if response["status"] == 200:
  data = response['data']
  # Write out each profile found to file
  with open("my_pdl_search.jsonl", "w") as out:
    for record in data:
      out.write(json.dumps(record) + "\n")
  print(f"Successfully grabbed {len(data)} records from PDL.")
  print(f"{response['total']} total PDL records exist matching this query.")
else:
  print("NOTE: The carrier pigeons lost motivation in flight. See error and try again.")
  print("Error:", response)
```

```
import json

# See https://github.com/peopledatalabs/peopledatalabs-python
from peopledatalabs import PDLPY

# Create a client, specifying your API key
CLIENT = PDLPY(
    api_key="YOUR API KEY",
)

# Create an SQL query
SQL_QUERY = \
"""
  SELECT * FROM person
  WHERE location_country='mexico'
  AND job_title_role='health'
  AND phone_numbers IS NOT NULL;
 """

# Create a parameters JSON object
PARAMS = {
  'sql': SQL_QUERY,
  'size': 10,
  'pretty': True,
  'dataset': "phone" # Search for records with a phone number
}

# Pass the parameters object to the Person Search API
response = CLIENT.person.search(**PARAMS).json()

# Check for successful response
if response["status"] == 200:
  data = response['data']
  # Write out each profile found to file
  with open("my_pdl_search.jsonl", "w") as out:
    for record in data:
      out.write(json.dumps(record) + "\n")
  print(f"Successfully grabbed {len(data)} records from PDL.")
  print(f"{response['total']} total PDL records exist matching this query.")
else:
  print("NOTE: The carrier pigeons lost motivation in flight. See error and try again.")
  print("Error:", response)
```

```
# Elasticsearch
curl -X GET 'https://api.peopledatalabs.com/v5/person/search' \
-H 'X-Api-Key: xxxx' \
--data-raw '{
  "size": 10,
  "dataset": "all",
  "query": {
    "bool": {
      "must": [
        {"term": {"location_country": "mexico"}},
        {"term": {"job_title_role": "health"}},
      ]
    }
  }
}'

# SQL
curl -X GET \
  'https://api.peopledatalabs.com/v5/person/search' \
  -H 'X-Api-Key: xxxx' \
  --data-raw '{
    "size": 10,
    "dataset: "phone",
    "sql": "SELECT * FROM person WHERE location_country='\''mexico'\'' AND job_title_role='\''health'\'' AND phone_numbers IS NOT NULL;"
}'
```

```
// See https://github.com/peopledatalabs/peopledatalabs-js
import PDLJS from 'peopledatalabs';

import fs from 'fs';

// Create a client, specifying your API key
const PDLJSClient = new PDLJS({ apiKey: "YOUR API KEY" });

// Create an Elasticsearch query
const esQuery = {
  query: {
    bool: {
      must:[
        {term: {location_country: "mexico"}}, 
        {term: {job_title_role: "health"}}, 
      ]
    }
  }
}

// Create a parameters JSON object
const params = {
  searchQuery: esQuery, 
  size: 10,
  pretty: true,
  dataset: "phone" // Search for records with a phone number
}

// Pass the parameters object to the Person Search API
PDLJSClient.person.search.elastic(params).then((data) => {
    // Write out all profiles found to file
    fs.writeFile("my_pdl_search.jsonl", Buffer.from(JSON.stringify(data.data)), (err) => {
        if (err) throw err;
    });
    console.log(`Successfully grabbed ${data.data.length} records from PDL.`);
    console.log(`${data["total"]} total PDL records exist matching this query.`)
}).catch((error) => {
    console.log("NOTE: The carrier pigeons lost motivation in flight. See error and try again.")
    console.log(error);
});
```

```
// See https://github.com/peopledatalabs/peopledatalabs-js
import PDLJS from 'peopledatalabs';

import fs from 'fs';

// Create a client, specifying your API key
const PDLJSClient = new PDLJS({ apiKey: "YOUR API KEY" });

// Create an SQL query
const sqlQuery = `SELECT * FROM person 
                  WHERE location_country='mexico' 
                  AND job_title_role='health';`

// Create an Elasticsearch query
const params = {
  searchQuery: sqlQuery, 
  size: 10,
  pretty: true,
  dataset: "phone" // Search for records with a phone number
}

// Pass the parameters object to the Person Search API
PDLJSClient.person.search.sql(params).then((data) => {
    // Write out all profiles found to file
    fs.writeFile("my_pdl_search.jsonl", Buffer.from(JSON.stringify(data.data)), (err) => {
        if (err) throw err;
    });
    console.log(`Successfully grabbed ${data.data.length} records from PDL.`);
    console.log(`${data["total"]} total PDL records exist matching this query.`)
}).catch((error) => {
    console.log("NOTE: The carrier pigeons lost motivation in flight. See error and try again.")
    console.log(error);
});
```

```
require 'json'

# See https://github.com/peopledatalabs/peopledatalabs-ruby
require 'peopledatalabs'

# Set your API key
Peopledatalabs.api_key = 'YOUR API KEY'

# Create an Elasticsearch query
ES_QUERY = {
  "query": {
    "bool": {
        "must": [
            {"term": {"location_country": "mexico"}},
            {"term": {"job_title_role": "health"}}
      ]
    }
  }
}

# Pass parameters to the Person Search API
response = Peopledatalabs::Search.people(searchType: 'elastic', query: ES_QUERY, size: 10, pretty: true, 'dataset': 'phone')

# Check for successful response
if response['status'] == 200
    data = response['data']
    # Write out each profile found to file
    File.open("my_pdl_search.jsonl", "w") do |out|
        data.each { |record| out.write(JSON.dump(record) + "\n") }
    end
    puts "Successfully grabbed #{data.length()} records from PDL."
    puts "#{response['total']} total PDL records exist matching this query."
else
    puts "NOTE: The carrier pigeons lost motivation in flight. See error and try again."
    puts "Error: #{response}"
end
```

```
require 'json'

# See https://github.com/peopledatalabs/peopledatalabs-ruby
require 'peopledatalabs'

# Set your API key
Peopledatalabs.api_key = 'YOUR API KEY'

# Create an SQL query
SQL_QUERY = \
"""
  SELECT * FROM person
  WHERE location_country='mexico'
  AND job_title_role='health'
  AND phone_numbers IS NOT NULL;
 """

# Pass parameters to the Person Search API
response = Peopledatalabs::Search.people(searchType: 'sql', query: SQL_QUERY, size: 10, pretty: true, 'dataset': 'phone')

# Check for successful response
if response['status'] == 200
    data = response['data']
    # Write out each profile found to file
    File.open("my_pdl_search.jsonl", "w") do |out|
        data.each { |record| out.write(JSON.dump(record) + "\n") }
    end
    puts "Successfully grabbed #{data.length()} records from PDL."
    puts "#{response['total']} total PDL records exist matching this query."
else
    puts "NOTE: The carrier pigeons lost motivation in flight. See error and try again."
    puts "Error: #{response}"
end
```

```
package main

import (
    "fmt"
    "os"
    "encoding/json"
    "context"
)

// See https://github.com/peopledatalabs/peopledatalabs-go
import (
    pdl "github.com/peopledatalabs/peopledatalabs-go"
    pdlmodel "github.com/peopledatalabs/peopledatalabs-go/model"
)

func main() {
    // Set your API key
    apiKey := "YOUR API KEY"
    // Set API key as environmental variable
    // apiKey := os.Getenv("API_KEY")

    // Create a client, specifying your API key
    client := pdl.New(apiKey)

    // Create an Elasticsearch query
    elasticSearchQuery := map[string]interface{} {
        "query": map[string]interface{} {
            "bool": map[string]interface{} {
                "must": []map[string]interface{} {
                    {"term": map[string]interface{}{"location_country": "mexico"}},
                    {"term": map[string]interface{}{"job_title_role": "health"}},
                 },
            },
        },
    }

    // Create a parameters JSON object
    params := pdlmodel.SearchParams {
        BaseParams: pdlmodel.BaseParams {
            Size: 10,
            Pretty: true,
        },
        SearchBaseParams: pdlmodel.SearchBaseParams {
            Query: elasticSearchQuery,
            Dataset: "phone", // Search for records with a phone number
        },
    }

    // Pass the parameters object to the Person Search API
    response, err := client.Person.Search(context.Background(), params)
    // Check for successful response
    if err == nil {
        data := response.Data
        // Create file
        out, outErr := os.Create("my_pdl_search.jsonl")
        defer out.Close()
        if (outErr == nil) {
            for i := range data {
                // Convert each profile found to JSON
                record, jsonErr := json.Marshal(data[i])
                // Write out each profile to file
                if (jsonErr == nil) {
                    out.WriteString(string(record) + "\n")
                }
            }
            out.Sync()
        }
        fmt.Printf("Successfully grabbed %d records from PDL.\n", len(data))
        fmt.Printf("%d total PDL records exist matching this query.\n", response.Total)
    } else {
        fmt.Println("NOTE: The carrier pigeons lost motivation in flight. See error and try again.")
        fmt.Println("Error:", err)
    } 
}
```

```
package main

import (
    "fmt"
    "os"
    "encoding/json"
    "context"
)

// See https://github.com/peopledatalabs/peopledatalabs-go
import (
    pdl "github.com/peopledatalabs/peopledatalabs-go"
    pdlmodel "github.com/peopledatalabs/peopledatalabs-go/model"
)

func main() {
    // Set your API key
    apiKey := "YOUR API KEY"
    // Set API key as environmental variable
    // apiKey := os.Getenv("API_KEY")

    // Create a client, specifying your API key
    client := pdl.New(apiKey)

    // Create an SQL query
    sqlQuery := "SELECT * FROM person" +
        " WHERE location_country='mexico'" +
        " AND job_title_role='health';"
 
    // Create a parameters JSON object
    params := pdlmodel.SearchParams {
        BaseParams: pdlmodel.BaseParams {
            Size: 10,
            Pretty: true,
        },
        SearchBaseParams: pdlmodel.SearchBaseParams {
            SQL: sqlQuery,
            Dataset: "phone", // Search for records with a phone number
        },
    }

    // Pass the parameters object to the Person Search API
    response, err := client.Person.Search(context.Background(), params)
    // Check for successful response
    if err == nil {
        data := response.Data
        // Create file
        out, outErr := os.Create("my_pdl_search.jsonl")
        defer out.Close()
        if (outErr == nil) {
            for i := range data {
                // Convert each profile found to JSON
                record, jsonErr := json.Marshal(data[i])
                // Write out each profile to file
                if (jsonErr == nil) {
                    out.WriteString(string(record) + "\n")
                }
            }
            out.Sync()
        }
        fmt.Printf("Successfully grabbed %d records from PDL.\n", len(data))
        fmt.Printf("%d total PDL records exist matching this query.\n", response.Total)
    } else {
        fmt.Println("NOTE: The carrier pigeons lost motivation in flight. See error and try again.")
        fmt.Println("Error:", err)
    } 
}
```

```
import requests, json

# Set your API key
API_KEY = "YOUR API KEY"

# Set the Person Search API URL
PDL_URL = "https://api.peopledatalabs.com/v5/person/search"

# Set headers
HEADERS = {
  'Content-Type': "application/json",
  'X-api-key': API_KEY
}

# Create an Elasticsearch query
ES_QUERY = {
  "query": {
    "bool": {
        "must": [
            {"term": {"location_country": "mexico"}},
            {"term": {"job_title_role": "health"}}
      ]
    }
  }
}

# Create a parameters JSON object
PARAMS = {
  'query': json.dumps(ES_QUERY),
  'size': 10,
  'pretty': True,
  'dataset': "phone" # Search for records with a phone number
}

# Pass the parameters object to the Person Search API
response = requests.get(
  PDL_URL,
  headers=HEADERS,
  params=PARAMS
).json()

# Check for successful response
if response["status"] == 200:
  data = response['data']
  # Write out each profile found to file
  with open("my_pdl_search.jsonl", "w") as out:
    for record in data:
      out.write(json.dumps(record) + "\n")
  print(f"Successfully grabbed {len(data)} records from PDL.")
  print(f"{response['total']} total PDL records exist matching this query.")
else:
  print("NOTE: The carrier pigeons lost motivation in flight. See error and try again.")
  print("Error:", response)
```

```
import requests, json

# Set your API key
API_KEY = "YOUR API KEY"

# Set the Person Search API URL
PDL_URL = "https://api.peopledatalabs.com/v5/person/search"

# Set headers
HEADERS = {
  'Content-Type': "application/json",
  'X-api-key': API_KEY
}

# Create an SQL query
SQL_QUERY = \
"""
  SELECT * FROM person
  WHERE location_country='mexico'
  AND job_title_role='health'
  AND phone_numbers IS NOT NULL;
 """

# Create a parameters JSON object
PARAMS = {
  'sql': SQL_QUERY,
  'size': 10,
  'pretty': True,
  'dataset': "phone" # Search for records with a phone number
}

# Pass the parameters object to the Person Search API
response = requests.get(
  PDL_URL,
  headers=HEADERS,
  params=PARAMS
).json()

# Check for successful response
if response["status"] == 200:
  data = response['data']
  # Write out each profile found to file
  with open("my_pdl_search.jsonl", "w") as out:
    for record in data:
      out.write(json.dumps(record) + "\n")
  print(f"Successfully grabbed {len(data)} records from PDL.")
  print(f"{response['total']} total PDL records exist matching this query.")
else:
  print("NOTE: The carrier pigeons lost motivation in flight. See error and try again.")
  print("error:", response)
```

## Excluding Datasets

*"I want to run a simple query against all PDL datasets except the[email](/docs/email-stats) and [phone](/docs/datasets#phone-slice) datasets."*

Python3 SDK (Elasticsearch)JavaScript (Elasticsearch)Ruby (Elasticsearch)Go (Elasticsearch)Python3 (Elasticsearch)

```
import json

# See https://github.com/peopledatalabs/peopledatalabs-python
from peopledatalabs import PDLPY

# Create a client, specifying your API key
CLIENT = PDLPY(
    api_key="YOUR API KEY",
)

# Create an Elasticsearch query
ES_QUERY = {
  "query": {
    "bool": {
        "must": [
            {"term": {"location_country": "mexico"}},
            {"term": {"job_title_role": "health"}}
      ]
    }
  }
}

# Create a parameters JSON object
PARAMS = {
  'query': ES_QUERY,
  'size': 10,
  'pretty': True,
  'dataset': "-email,phone" # Search all datasets EXCEPT the email and phone slices
}

# Pass the parameters object to the Person Search API
response = CLIENT.person.search(**PARAMS).json()

# Check for successful response
if response["status"] == 200:
  data = response['data']
  # Write out each profile found to file
  with open("my_pdl_search.jsonl", "w") as out:
    for record in data:
      out.write(json.dumps(record) + "\n")
  print(f"Successfully grabbed {len(data)} records from PDL.")
  print(f"{response['total']} total PDL records exist matching this query.")
else:
  print("NOTE: The carrier pigeons lost motivation in flight. See error and try again.")
  print("Error:", response)
```

```
// See https://github.com/peopledatalabs/peopledatalabs-js
import PDLJS from 'peopledatalabs';

import fs from 'fs';

// Create a client, specifying your API key
const PDLJSClient = new PDLJS({ apiKey: "YOUR API KEY" });

// Create an Elasticsearch query
const esQuery = {
  query: {
    bool: {
      must:[
        {term: {location_country: "mexico"}}, 
        {term: {job_title_role: "health"}}, 
      ]
    }
  }
}

// Create a parameters JSON object
const params = {
  searchQuery: esQuery, 
  size: 10,
  pretty: true,
  dataset: "-email,phone" // Search all datasets EXCEPT the email and phone slices
}

// Pass the parameters object to the Person Search API
PDLJSClient.person.search.elastic(params).then((data) => {
    // Write out all profiles found to file
    fs.writeFile("my_pdl_search.jsonl", Buffer.from(JSON.stringify(data.data)), (err) => {
        if (err) throw err;
    });
    console.log(`Successfully grabbed ${data.data.length} records from PDL.`);
    console.log(`${data["total"]} total PDL records exist matching this query.`)
}).catch((error) => {
    console.log("NOTE: The carrier pigeons lost motivation in flight. See error and try again.")
    console.log(error);
});
```

```
require 'json'

# See https://github.com/peopledatalabs/peopledatalabs-ruby
require 'peopledatalabs'

# Set your API key
Peopledatalabs.api_key = 'YOUR API KEY'

# Create an Elasticsearch query
ES_QUERY = {
  "query": {
    "bool": {
        "must": [
            {"term": {"location_country": "mexico"}},
            {"term": {"job_title_role": "health"}}
      ]
    }
  }
}

# Pass parameters to the Person Search API
response = Peopledatalabs::Search.people(searchType: 'elastic', query: ES_QUERY, size: 10, pretty: true, 'dataset': '-email,phone')

# Check for successful response
if response['status'] == 200
    data = response['data']
    # Write out each profile found to file
    File.open("my_pdl_search.jsonl", "w") do |out|
        data.each { |record| out.write(JSON.dump(record) + "\n") }
    end
    puts "Successfully grabbed #{data.length()} records from PDL."
    puts "#{response['total']} total PDL records exist matching this query."
else
    puts "NOTE: The carrier pigeons lost motivation in flight. See error and try again."
    puts "Error: #{response}"
end
```

```
package main

import (
    "fmt"
    "os"
    "encoding/json"
    "context"
)

// See https://github.com/peopledatalabs/peopledatalabs-go
import (
    pdl "github.com/peopledatalabs/peopledatalabs-go"
    pdlmodel "github.com/peopledatalabs/peopledatalabs-go/model"
)

func main() {
    // Set your API key
    apiKey := "YOUR API KEY"
    // Set API key as environmental variable
    // apiKey := os.Getenv("API_KEY")

    // Create a client, specifying your API key
    client := pdl.New(apiKey)

    // Create an Elasticsearch query
    elasticSearchQuery := map[string]interface{} {
        "query": map[string]interface{} {
            "bool": map[string]interface{} {
                "must": []map[string]interface{} {
                    {"term": map[string]interface{}{"location_country": "mexico"}},
                    {"term": map[string]interface{}{"job_title_role": "health"}},
                 },
            },
        },
    }

    // Create a parameters JSON object
    params := pdlmodel.SearchParams {
        BaseParams: pdlmodel.BaseParams {
            Size: 10,
            Pretty: true,
        },
        SearchBaseParams: pdlmodel.SearchBaseParams {
            Query: elasticSearchQuery,
            Dataset: "-email,phone", // Search all datasets EXCEPT the email and phone slices
        },
    }

    // Pass the parameters object to the Person Search API
    response, err := client.Person.Search(context.Background(), params)
    // Check for successful response
    if err == nil {
        data := response.Data
        // Create file
        out, outErr := os.Create("my_pdl_search.jsonl")
        defer out.Close()
        if (outErr == nil) {
            for i := range data {
                // Convert each profile found to JSON
                record, jsonErr := json.Marshal(data[i])
                // Write out each profile to file
                if (jsonErr == nil) {
                    out.WriteString(string(record) + "\n")
                }
            }
            out.Sync()
        }
        fmt.Printf("Successfully grabbed %d records from PDL.\n", len(data))
        fmt.Printf("%d total PDL records exist matching this query.\n", response.Total)
    } else {
        fmt.Println("NOTE: The carrier pigeons lost motivation in flight. See error and try again.")
        fmt.Println("Error:", err)
    } 
}
```

```
import requests, json

# Set your API key
API_KEY = "YOUR API KEY"

# Set the Person Search API URL
PDL_URL = "https://api.peopledatalabs.com/v5/person/search"

# Set headers
HEADERS = {
  'Content-Type': "application/json",
  'X-api-key': API_KEY
}

# Create an Elasticsearch query
ES_QUERY = {
  "query": {
    "bool": {
        "must": [
            {"term": {"location_country": "mexico"}},
            {"term": {"job_title_role": "health"}}
      ]
    }
  }
}

# Create a parameters JSON object
PARAMS = {
  'query': json.dumps(ES_QUERY),
  'size': 10,
  'pretty': True,
  'dataset': "-email,phone" # Search all datasets EXCEPT the email and phone slices
}

# Pass the parameters object to the Person Search API
response = requests.get(
  PDL_URL,
  headers=HEADERS,
  params=PARAMS
).json()

# Check for successful response
if response["status"] == 200:
  data = response['data']
  # Write out each profile found to file
  with open("my_pdl_search.jsonl", "w") as out:
    for record in data:
      out.write(json.dumps(record) + "\n")
  print(f"Successfully grabbed {len(data)} records from PDL.")
  print(f"{response['total']} total PDL records exist matching this query.")
else:
  print("NOTE: The carrier pigeons lost motivation in flight. See error and try again.")
  print("Error:", response)
```

## Bulk Retrieval

*"I want to pull all current employees at Amazon and save their profiles to a CSV file."*

> ðŸš§
>
> ### High Credit Usage Code Below
>
> The code example below illustrates retrieving all the employee profiles in a large company and is meant primarily for demonstrating the use of the `scroll_token` parameter when requesting large amounts of records. As a result, this code is mostly illustrative in purpose. It can further expend a lot of credits and doesn't have any error handling. The `MAX_NUM_RECORDS_LIMIT` parameter in the example sets the maximum number of profiles that we will retrieve (and the maximum number of credits that you will expend), so please set it accordingly when testing this example.

Python3 SDK (Elasticsearch)Python3 SDK (SQL)JavaScript (Elasticsearch)JavaScript (SQL)Ruby (Elasticsearch)Ruby (SQL)Go (Elasticsearch)Go (SQL)Python3 (Elasticsearch)Python3 (SQL)

```
import json, time, csv

# See https://github.com/peopledatalabs/peopledatalabs-python
from peopledatalabs import PDLPY

# Limit the number of records to pull (to prevent accidentally using 
# more credits than expected when testing this code)
MAX_NUM_RECORDS_LIMIT = 150 # The maximum number of records to retrieve
USE_MAX_NUM_RECORDS_LIMIT = True # Set to False to pull all available records

# Create a client, specifying your API key
CLIENT = PDLPY(
    api_key="YOUR API KEY",
)

# Create an Elasticsearch query
ES_QUERY = {
  "query": {
    "bool": {
        "must": [
            {"term": {"job_company_name": "amazon"}}
      ]
    }
  }
}

# Create a parameters JSON object
PARAMS = {
  'query': ES_QUERY,
  'size': 100, 
  'pretty': True
}

# Pull all results in multiple batches
batch = 1
# Store all records retreived in an array
all_records = []
# Time the process
start_time = time.time()
found_all_records = False
continue_scrolling = True

# While still scrolling through data and still records to be found
while continue_scrolling and not found_all_records: 

  # Check if we reached the maximum number of records we want
  if USE_MAX_NUM_RECORDS_LIMIT:
    num_records_to_request = MAX_NUM_RECORDS_LIMIT - len(all_records)
    # Adjust size parameter
    PARAMS['size'] = max(0, min(100, num_records_to_request))
    # Check if MAX_NUM_RECORDS_LIMIT reached
    if num_records_to_request == 0:
      print(f"Stopping - reached maximum number of records to pull "
            f"[MAX_NUM_RECORDS_LIMIT = {MAX_NUM_RECORDS_LIMIT}].")
      break

  # Pass the parameters object to the Person Search API
  response = CLIENT.person.search(**PARAMS).json()

  # Check for successful response
  if response['status'] == 200:
    # Add records retrieved to the records array
    all_records.extend(response['data'])
    print(f"Retrieved {len(response['data'])} records in batch {batch} "
          f"- {response['total'] - len(all_records)} records remaining.")
  else:
    print(f"Error retrieving some records:\n\t"
          f"[{response['status']} - {response['error']['type']}] "
          f"{response['error']['message']}")
  
  # Get scroll_token from response if exists and store it in parameters object
  if 'scroll_token' in response:
    PARAMS['scroll_token'] = response['scroll_token']
  else:
    continue_scrolling = False
    print(f"Unable to continue scrolling.")

  batch += 1
  found_all_records = (len(all_records) == response['total'])
  time.sleep(6) # Avoid hitting rate limit thresholds
 
# Calculate time required to process batches
end_time = time.time()
runtime = end_time - start_time
        
print(f"Successfully recovered {len(all_records)} profiles in "
      f"{batch} batches [{round(runtime, 2)} seconds].")

# Save profiles to CSV (utility function)
def save_profiles_to_csv(profiles, filename, fields=[], delim=','):
  # Define header fields
  if fields == [] and len(profiles) > 0:
      fields = profiles[0].keys()
  # Write CSV file
  with open(filename, 'w') as csvfile:
    writer = csv.writer(csvfile, delimiter=delim)
    # Write header
    writer.writerow(fields)
    # Write body
    count = 0
    for profile in profiles:
      writer.writerow([ profile[field] for field in fields ])
      count += 1
  print(f"Wrote {count} lines to: '{filename}'.")

# Use utility function to save all records retrieved to CSV    
csv_header_fields = ['work_email', 'full_name', "linkedin_url",
                     'job_title', 'job_company_name']
csv_filename = "all_employee_profiles.csv"
save_profiles_to_csv(all_records, csv_filename, csv_header_fields)
```

```
import json, time, csv

# See https://github.com/peopledatalabs/peopledatalabs-python
from peopledatalabs import PDLPY

# Limit the number of records to pull (to prevent accidentally using 
# more credits than expected when testing this code)
MAX_NUM_RECORDS_LIMIT = 150 # The maximum number of records to retrieve
USE_MAX_NUM_RECORDS_LIMIT = True # Set to False to pull all available records

# Create a client, specifying your API key
CLIENT = PDLPY(
    api_key="YOUR API KEY",
)

# Create an SQL query
SQL_QUERY = \
"""
 SELECT * FROM person
 WHERE job_company_name='amazon';
"""

# Create a parameters JSON object
PARAMS = {
  'sql': SQL_QUERY,
  'size': 100, 
  'pretty': True
}

# Pull all results in multiple batches
batch = 1
# Store all records retreived in an array
all_records = []
# Time the process
start_time = time.time()
found_all_records = False
continue_scrolling = True

# While still scrolling through data and still records to be found
while continue_scrolling and not found_all_records: 

  # Check if we reached the maximum number of records we want
  if USE_MAX_NUM_RECORDS_LIMIT:
    num_records_to_request = MAX_NUM_RECORDS_LIMIT - len(all_records)
    # Adjust size parameter
    PARAMS['size'] = max(0, min(100, num_records_to_request))
    # Check if MAX_NUM_RECORDS_LIMIT reached
    if num_records_to_request == 0:
      print(f"Stopping - reached maximum number of records to pull "
            f"[MAX_NUM_RECORDS_LIMIT = {MAX_NUM_RECORDS_LIMIT}].")
      break

  # Pass the parameters object to the Person Search API
  response = CLIENT.person.search(**PARAMS).json()

  # Check for successful response
  if response['status'] == 200:
    # Add records retrieved to the records array
    all_records.extend(response['data'])
    print(f"Retrieved {len(response['data'])} records in batch {batch} "
          f"- {response['total'] - len(all_records)} records remaining.")
  else:
    print(f"Error retrieving some records:\n\t"
          f"[{response['status']} - {response['error']['type']}] "
          f"{response['error']['message']}")
  
  # Get scroll_token from response if exists and store it in parameters object
  if 'scroll_token' in response:
    PARAMS['scroll_token'] = response['scroll_token']
  else:
    continue_scrolling = False
    print(f"Unable to continue scrolling.")

  batch += 1
  found_all_records = (len(all_records) == response['total'])
  time.sleep(6) # Avoid hitting rate limit thresholds
 
# Calculate time required to process batches
end_time = time.time()
runtime = end_time - start_time
        
print(f"Successfully recovered {len(all_records)} profiles in "
      f"{batch} batches [{round(runtime, 2)} seconds].")

# Save profiles to CSV (utility function)
def save_profiles_to_csv(profiles, filename, fields=[], delim=','):
  # Define header fields
  if fields == [] and len(profiles) > 0:
      fields = profiles[0].keys()
  # Write CSV file
  with open(filename, 'w') as csvfile:
    writer = csv.writer(csvfile, delimiter=delim)
    # Write header
    writer.writerow(fields)
    # Write body
    count = 0
    for profile in profiles:
      writer.writerow([ profile[field] for field in fields ])
      count += 1
  print(f"Wrote {count} lines to: '{filename}'.")

# Use utility function to save all records retrieved to CSV  
csv_header_fields = ['work_email', 'full_name', "linkedin_url",
                     'job_title', 'job_company_name']
csv_filename = "all_employee_profiles.csv"
save_profiles_to_csv(all_records, csv_filename, csv_header_fields)
```

```
// See https://github.com/peopledatalabs/peopledatalabs-js
import PDLJS from 'peopledatalabs';

// See https://www.npmjs.com/package/csv-writer
import * as csvwriter from 'csv-writer';

// Create a client, specifying your API key
const PDLJSClient = new PDLJS({ apiKey: "YOUR API KEY" });

// Limit the number of records to pull (to prevent accidentally using 
// more credits than expected when testing this code)
const maxNumRecordsLimit = 150;     // The maximum number of records to retrieve
const useMaxNumRecordsLimit = true; // Set to false to pull all available records

// Create an Elasticsearch query
const esQuery = {
  query: {
    bool: {
      must:[
        {term: {job_company_name: "amazon"}}, 
      ]
    }
  }
}

// Create a parameters JSON object
var params = {
  searchQuery: esQuery, 
  size: 100,
  scroll_token: null,
  pretty: true
}

// Pull all results in multiple batches
var batch = 1;
// Store all records retreived in an array
var allRecords = [];
// Time the process
var startTime = Date.now();
var foundAllRecords = false;
var continueScrolling = true;
var numRetrieved = 0;
// Queue parameter objects in order to iterate through batches
var paramQueue = [];
// The current scroll_token
var scrollToken = null;
var numRecordsToRequest = 100;

while (numRecordsToRequest > 0) { 

    // Check if we reached the maximum number of records we want
    if (useMaxNumRecordsLimit) {
        numRecordsToRequest = maxNumRecordsLimit - numRetrieved;
        // Adjust size parameter
        params.size = Math.max(0, Math.min(100, numRecordsToRequest));
        numRetrieved += params.size;
        // Add batch to the parameter queue
        if (params.size > 0) {       
            paramQueue.push(JSON.parse(JSON.stringify(params)));
        }
    } else {
        break;
    }
}

// Run initial batch
runBatch();

// Retrieve records associated with a batch
function runBatch() {
    // Get the parameters for the current batch
    let currParams = useMaxNumRecordsLimit ? paramQueue[batch-1] : params;
    // Set the scroll_token from the previous batch
    currParams.scroll_token = scrollToken;
    batch++;
                
    // Pass the current parameters object to the Person Search API
    PDLJSClient.person.search.elastic(currParams).then((data) => {
        // Add records retrieved to the records array
        Array.prototype.push.apply(allRecords, data.data);
            
        // Store the scroll_token if exists
        if (data['scroll_token']) {
            scrollToken = data['scroll_token'];
        } else {
            continueScrolling = false;
            console.log("Unable to continue scrolling.");
        }
            
        foundAllRecords = (allRecords.length == data['total']);
            
        console.log(`Retrieved ${data.data.length} records in batch ${(batch-1)}` +
            ` - ${(data['total'] - allRecords.length)} records remaining.`);
            
        // Run next batch recursively, if any
        if (!foundAllRecords && (batch <= paramQueue.length || !useMaxNumRecordsLimit)) {
            runBatch();
        } else {
            console.log(`Stopping - reached maximum number of records to pull [maxNumRecordsLimit = ` +
                `${maxNumRecordsLimit}].`);  
                
            // Calculate time required to process batches
            let endTime = Date.now();
            let runTime = endTime - startTime;
            console.log (`Successfully recovered ${allRecords.length} profiles in ` +
                `${(batch-1)} batches [${Math.round(runTime/1000)} seconds].`);
                
            // Set CSV fields
            let csvHeaderFields = [
                {id: "work_email", title: "work_email"},
                {id: "full_name", title: "full_name"}, 
                {id: "linkedin_url", title: "linkedin_url"},
                {id: "job_title", title: "job_title"},
                {id: "job_company_name", title: "job_company_name"}
            ];
            let csvFilename = "all_employee_profiles.csv";
            // Write records array to CSV file
            saveProfilesToCSV(allRecords, csvFilename, csvHeaderFields);           
        }
    }).catch((error) => {
        console.log(error);
    });

}

// Write CSV file using csv-writer (https://www.npmjs.com/package/csv-writer) 
// $ npm i -s csv-writer
function saveProfilesToCSV(profiles, filename, fields) {

    // Create CSV file
    const createCsvWriter = csvwriter.createObjectCsvWriter;
    const csvWriter = createCsvWriter({
        path: filename,
        header: fields
    });
      
    let data = [];
    // Iterate through records array
    for (let i = 0; i < profiles.length; i++) {
        let record = profiles[i];
        data[i] = {};
        // Store requested fields
        for (let field in fields) {
            data[i][fields[field].id] = record[fields[field].id];    
        }
     }

    // Write data to CSV file
    csvWriter
        .writeRecords(data)
        .then(()=> console.log('The CSV file was written successfully.'));
}
```

```
// See https://github.com/peopledatalabs/peopledatalabs-js
import PDLJS from 'peopledatalabs';

// See https://www.npmjs.com/package/csv-writer
import * as csvwriter from 'csv-writer';

// Create a client, specifying your API key
const PDLJSClient = new PDLJS({ apiKey: "YOUR API KEY" });

// Limit the number of records to pull (to prevent accidentally using 
// more credits than expected when testing out this code).
const maxNumRecordsLimit = 150;     // The maximum number of records to retrieve
const useMaxNumRecordsLimit = true; // Set to false to pull all available records

// Create an SQL query
const sqlQuery = `SELECT * FROM person
    WHERE job_company_name='amazon';`;

// Create a parameters JSON object
var params = {
  searchQuery: sqlQuery, 
  size: 100,
  scroll_token: null,
  pretty: true
}

// Pull all results in multiple batches
var batch = 1;
// Store all records retreived in an array
var allRecords = [];
// Time the process
var startTime = Date.now();
var foundAllRecords = false;
var continueScrolling = true;
var numRetrieved = 0;
// Queue parameter objects in order to iterate through batches
var paramQueue = [];
// The current scroll_token
var scrollToken = null;
var numRecordsToRequest = 100;

while (numRecordsToRequest > 0) { 

    // Check if we reached the maximum number of records we want
    if (useMaxNumRecordsLimit) {
        numRecordsToRequest = maxNumRecordsLimit - numRetrieved;
        // Adjust size parameter
        params.size = Math.max(0, Math.min(100, numRecordsToRequest));
        numRetrieved += params.size;
        // Add batch to the parameter queue
        if (params.size > 0) {       
            paramQueue.push(JSON.parse(JSON.stringify(params)));
        }
    } else {
        break;
    }
}

// Run initial batch
runBatch();

// Retrieve records associated with a batch
function runBatch() {
    // Get the parameters for the current batch
    let currParams = useMaxNumRecordsLimit ? paramQueue[batch-1] : params;
    // Set the scroll_token from the previous batch
    currParams.scroll_token = scrollToken;
    batch++;
                
    // Pass the current parameters object to the Person Search API
    PDLJSClient.person.search.sql(currParams).then((data) => {
        // Add records retrieved to the records array
        Array.prototype.push.apply(allRecords, data.data);
            
        // Store the scroll_token if exists
        if (data['scroll_token']) {
            scrollToken = data['scroll_token'];
        } else {
            continueScrolling = false;
            console.log("Unable to continue scrolling.");
        }
            
        foundAllRecords = (allRecords.length == data['total']);
            
        console.log(`Retrieved ${data.data.length} records in batch ${(batch-1)}` +
            ` - ${(data['total'] - allRecords.length)} records remaining.`);
            
        // Run next batch recursively, if any
        if (!foundAllRecords && (batch <= paramQueue.length || !useMaxNumRecordsLimit)) {
            runBatch();
        } else {
            console.log(`Stopping - reached maximum number of records to pull [maxNumRecordsLimit = ` +
                `${maxNumRecordsLimit}].`);  
                
            // Calculate time required to process batches
            let endTime = Date.now();
            let runTime = endTime - startTime;
            console.log (`Successfully recovered ${allRecords.length} profiles in ` +
                `${(batch-1)} batches [${Math.round(runTime/1000)} seconds].`);
                
            // Set CSV fields
            let csvHeaderFields = [
                {id: "work_email", title: "work_email"},
                {id: "full_name", title: "full_name"}, 
                {id: "linkedin_url", title: "linkedin_url"},
                {id: "job_title", title: "job_title"},
                {id: "job_company_name", title: "job_company_name"}
            ];
            let csvFilename = "all_employee_profiles.csv";
            // Write records array to CSV file
            saveProfilesToCSV(allRecords, csvFilename, csvHeaderFields);           
        }
    }).catch((error) => {
        console.log(error);
    });

}

// Write CSV file using csv-writer (https://www.npmjs.com/package/csv-writer)
// $ npm i -s csv-writer
function saveProfilesToCSV(profiles, filename, fields) {

    // Create CSV file
    const createCsvWriter = csvwriter.createObjectCsvWriter;
    const csvWriter = createCsvWriter({
        path: filename,
        header: fields
    });
    
    let data = [];
    for (let i = 0; i < profiles.length; i++) {
        let record = profiles[i];
        data[i] = {};
        // Store requested fields
        for (let field in fields) {
            data[i][fields[field].id] = record[fields[field].id];    
        }
     }

    // Write data to CSV file
    csvWriter
        .writeRecords(data)
        .then(()=> console.log('The CSV file was written successfully.'));
}
```

```
require 'json'
require 'csv'

# See https://github.com/peopledatalabs/peopledatalabs-ruby
require 'peopledatalabs'

# Set your API key
Peopledatalabs.api_key = 'YOUR API KEY'

# Limit the number of records to pull (to prevent accidentally using 
# more credits than expected when testing out this code).
MAX_NUM_RECORDS_LIMIT = 150 # The maximum number of records to retrieve
USE_MAX_NUM_RECORDS_LIMIT = true # Set to false to pull all available records

# Create an Elasticsearch query
ES_QUERY = {
  "query": {
    "bool": {
        "must": [
            {"term": {"job_company_name": "amazon"}}
      ]
    }
  }
}

# Pull all results in multiple batches
batch = 1
# Store all records retreived in an array
all_records = []
# Time the process
start_time = Time.now
found_all_records = false
continue_scrolling = true
scroll_token = {}

# While still scrolling through data and still records to be found
while continue_scrolling && !found_all_records do 

  # Check if we reached the maximum number of records we want
  if USE_MAX_NUM_RECORDS_LIMIT
    num_records_to_request = MAX_NUM_RECORDS_LIMIT - all_records.length()
    # Adjust size parameter
    size = [0, [100, num_records_to_request].min].max
    # Check if MAX_NUM_RECORDS_LIMIT reached
    if num_records_to_request == 0
      puts "Stopping - reached maximum number of records to pull "
      puts "[MAX_NUM_RECORDS_LIMIT = #{MAX_NUM_RECORDS_LIMIT}]."
      break
    end
  end

  # Pass parameters to the Person Search API
  response = Peopledatalabs::Search.person(searchType: 'elastic', query: ES_QUERY, size: size, scroll_token: scroll_token, pretty: true)

  # Check for successful response
  if response['status'] == 200
    # Add records retrieved to the records array
    all_records += response['data']
    puts "Retrieved #{response['data'].length()} records in batch #{batch} "
    puts  "- #{response['total'] - all_records.length()} records remaining."
  else
    puts "Error retrieving some records:\n\t"
    puts "[#{response['status']} - #{response['error']['type']}] "
    puts response['error']['message']
  end
  
  # Get scroll_token from response if exists and store it
  if response.key?('scroll_token')
    scroll_token = response['scroll_token']
  else
    continue_scrolling = false
    puts "Unable to continue scrolling."
  end

  batch += 1
  found_all_records = (all_records.length() == response['total'])
  sleep(6) # Avoid hitting rate limit thresholds
end

# Calculate time required to process batches
end_time = Time.now
runtime = end_time - start_time
        
puts "Successfully recovered #{all_records.length()} profiles in "
puts "#{batch} batches [#{runtime.round(2)} seconds]."

# Save profiles to CSV (utility function)
def save_profiles_to_csv(profiles, filename, fields=[], delim=',')
  # Define header fields
  if fields == [] && profiles.length() > 0
      fields = profiles[0].keys
  end
    
  count = 0
  # Write CSV file
  CSV.open(filename, 'w') do |writer|
    # Write header
    writer << fields
    # Write body
    profiles.each do |profile|
      record = []
      fields.each do |field| 
        record << profile[field]
        count += 1
      end
      writer << record
    end
  end
  puts "Wrote #{count} lines to: '#{filename}'."
end

# Use utility function to save profiles to CSV    
csv_header_fields = ['work_email', 'full_name', "linkedin_url",
                     'job_title', 'job_company_name']
csv_filename = "all_company_profiles.csv"
save_profiles_to_csv(all_records, csv_filename, csv_header_fields)
```

```
require 'json'
require 'csv'

# See https://github.com/peopledatalabs/peopledatalabs-ruby
require 'peopledatalabs'

# Set your API key
Peopledatalabs.api_key = 'YOUR API KEY'

# Limit the number of records to pull (to prevent accidentally using 
# more credits than expected when testing out this code).
MAX_NUM_RECORDS_LIMIT = 150 # The maximum number of records to retrieve
USE_MAX_NUM_RECORDS_LIMIT = true # Set to false to pull all available records

# Create an SQL query
SQL_QUERY = \
"""
 SELECT * FROM person
 WHERE job_company_name='amazon';
"""

# Pull all results in multiple batches
batch = 1
# Store all records retreived in an array
all_records = []
# Time the process
start_time = Time.now
found_all_records = false
continue_scrolling = true
scroll_token = {}

# While still scrolling through data and still records to be found
while continue_scrolling && !found_all_records do 

  # Check if we reached the maximum number of records we want
  if USE_MAX_NUM_RECORDS_LIMIT
    num_records_to_request = MAX_NUM_RECORDS_LIMIT - all_records.length()
    # Adjust size parameter
    size = [0, [100, num_records_to_request].min].max
    # Check if MAX_NUM_RECORDS_LIMIT reached
    if num_records_to_request == 0
      puts "Stopping - reached maximum number of records to pull "
      puts "[MAX_NUM_RECORDS_LIMIT = #{MAX_NUM_RECORDS_LIMIT}]."
      break
    end
  end

  # Pass parameters to the Person Search API
  response = Peopledatalabs::Search.person(searchType: 'sql', query: SQL_QUERY, size: size, scroll_token: scroll_token, pretty: true)

  # Check for successful response
  if response['status'] == 200
    # Add records retrieved to the records array
    all_records += response['data']
    puts "Retrieved #{response['data'].length()} records in batch #{batch} "
    puts  "- #{response['total'] - all_records.length()} records remaining."
  else
    puts "Error retrieving some records:\n\t"
    puts "[#{response['status']} - #{response['error']['type']}] "
    puts response['error']['message']
  end
  
  # Get scroll_token from response if exists and store it
  if response.key?('scroll_token')
    scroll_token = response['scroll_token']
  else
    continue_scrolling = false
    puts "Unable to continue scrolling."
  end

  batch += 1
  found_all_records = (all_records.length() == response['total'])
  sleep(6) # Avoid hitting rate limit thresholds
end

# Calculate time required to process batches
end_time = Time.now
runtime = end_time - start_time
        
puts "Successfully recovered #{all_records.length()} profiles in "
puts "#{batch} batches [#{runtime.round(2)} seconds]."

# Save profiles to CSV (utility function)
def save_profiles_to_csv(profiles, filename, fields=[], delim=',')
  # Define header fields
  if fields == [] && profiles.length() > 0
      fields = profiles[0].keys
  end
    
  count = 0
  # Write CSV file
  CSV.open(filename, 'w') do |writer|
    # Write header
    writer << fields
    # Write body
    profiles.each do |profile|
      record = []
      fields.each do |field| 
        record << profile[field]
        count += 1
      end
      writer << record
    end
  end
  puts "Wrote #{count} lines to: '#{filename}'."
end

# Use utility function to save profiles to CSV    
csv_header_fields = ['work_email', 'full_name', "linkedin_url",
                     'job_title', 'job_company_name']
csv_filename = "all_company_profiles.csv"
save_profiles_to_csv(all_records, csv_filename, csv_header_fields)
```

```
package main

import (
    "fmt"
    "time"
    "os"
    "math"
    "reflect"
    "encoding/json"
    "encoding/csv"
    "context"
)

// See https://github.com/peopledatalabs/peopledatalabs-go
import (
    pdl "github.com/peopledatalabs/peopledatalabs-go"
    pdlmodel "github.com/peopledatalabs/peopledatalabs-go/model"
)

func main() {
    // Set your API key
    apiKey := "YOUR API KEY"
    // Set API key as environmental variable
    // apiKey := os.Getenv("API_KEY")

    // Create a client, specifying your API key
    client := pdl.New(apiKey)

    // Limit the number of records to pull (to prevent accidentally using 
    // more credits than expected when testing out this code).
    const maxNumRecordsLimit = 150 // The maximum number of records to retrieve
    const useMaxNumRecordsLimit = true // Set to False to pull all available records

    // Create an Elasticsearch query
    elasticSearchQuery := map[string]interface{} {
        "query": map[string]interface{} {
            "bool": map[string]interface{} {
                "must": []map[string]interface{} {
                    {"term": map[string]interface{}{"job_company_name": "amazon"}},
                },
            },
        },
    }

    // Create a parameters JSON object
    p := pdlmodel.SearchParams {
        BaseParams: pdlmodel.BaseParams {
            Size: 100,
            Pretty: true,
        },
        SearchBaseParams: pdlmodel.SearchBaseParams {
            Query: elasticSearchQuery,
        },
    }

    // Pull all results in multiple batches
    batch := 1
    // Store all records retreived in an array
    var allRecords []pdlmodel.Person
    // Time the process
    startTime := time.Now()
    foundAllRecords := false
    continueScrolling := true
    var numRecordsToRequest int
    
    // While still scrolling through data and still records to be found
    for continueScrolling && !foundAllRecords {
        // Check if we reached the maximum number of records we want
        if useMaxNumRecordsLimit {
            numRecordsToRequest = maxNumRecordsLimit - len(allRecords)
            // Adjust size parameter
            p.BaseParams.Size = (int) (math.Max(0.0, math.Min(100.0, (float64) (numRecordsToRequest))))
            // Check if MAX_NUM_RECORDS_LIMIT reached
            if numRecordsToRequest == 0 {
                fmt.Printf("Stopping - reached maximum number of records to pull " +
                           "[MAX_NUM_RECORDS_LIMIT = %d].\n", maxNumRecordsLimit)
                
                break
            }
        }
        
        // Pass the parameters object to the Person Search API
        response, err := client.Person.Search(context.Background(), p)
        
        // Check for successful response
        if err == nil {
            fmt.Printf("Retrieved %d records in batch %d - %d records remaining.\n", 
                       len(response.Data), batch, response.Total - len(allRecords))
        } else {
            fmt.Println("Error retrieving some records:\n\t",
                       err)
        }
        
        // Convert response to JSON
        var data map[string]interface{}
        jsonResponse, jsonErr := json.Marshal(response)
        if jsonErr == nil {
            json.Unmarshal(jsonResponse, &data)
            // Get scroll_token from response if exists and store it in parameters object
            if scrollToken, ok := data["scroll_token"]; ok {
                p.SearchBaseParams.ScrollToken = fmt.Sprintf("%v", scrollToken)
            } else {
                continueScrolling = false
                fmt.Println("Unable to continue scrolling.")
            }
            // Add records retrieved to the records array
            allRecords = append(allRecords, response.Data...)
        }        
        batch++
        foundAllRecords = (len(allRecords) == response.Total)
        time.Sleep(6 * time.Second) // avoid hitting rate limit thresholds
    }
    
    // Calculate time required to process batches
    endTime := time.Now()
    runtime := endTime.Sub(startTime).Seconds()
        
    fmt.Printf("Successfully recovered %d profiles in %d batches [%d seconds].\n",
               len(allRecords), batch, (int) (math.Round((float64) (runtime))))
    
    // Use utility function to save profiles to CSV    
    csvHeaderFields := []string{"work_email", "full_name", "linkedin_url",
                                "job_title", "job_company_name"}
    csvFilename := "all_employee_profiles.csv"
    saveProfilesToCsv(allRecords, csvFilename, csvHeaderFields, ",")
}

// Save profiles to CSV (utility function)
func saveProfilesToCsv(profiles []pdlmodel.Person, filename string, fields []string, delim string) {
    // Define header fields
    if fields == nil && len(profiles) > 0 {
        e := reflect.ValueOf(&(profiles[0])).Elem()
        for i := 0; i < e.NumField(); i++ {
            fields = append(fields, e.Type().Field(i).Name)
        }
    }
    
    // Write CSV file
    csvFile, err := os.Create(filename)
    if err == nil {
        csvwriter := csv.NewWriter(csvFile)
        defer csvwriter.Flush()
        // Write header
        csvwriter.Write(fields)
        // Write body
        count := 0
        for i := range profiles {
            var data map[string]interface{}
            jsonResponse, jsonErr := json.Marshal(profiles[i])
            if jsonErr == nil {
                json.Unmarshal(jsonResponse, &data)
                var record []string
                for j := range fields {
                    record = append(record, fmt.Sprintf("%v", data[fields[j]]))
                }
                csvwriter.Write(record)
                count++
            }
        }
        fmt.Printf("Wrote %d lines to: %s.\n", count, filename)
    }
}
```

```
package main

import (
    "fmt"
    "time"
    "os"
    "math"
    "reflect"
    "encoding/json"
    "encoding/csv"
    "context"
)

// See https://github.com/peopledatalabs/peopledatalabs-go
import (
    pdl "github.com/peopledatalabs/peopledatalabs-go"
    pdlmodel "github.com/peopledatalabs/peopledatalabs-go/model"
)

func main() {
    // Set your API key
    apiKey := "YOUR API KEY"
    // Set API key as environmental variable
    // apiKey := os.Getenv("API_KEY")

    // Create a client, specifying your API key
    client := pdl.New(apiKey)

    // Limit the number of records to pull (to prevent accidentally using 
    // more credits than expected when testing out this code).
    const maxNumRecordsLimit = 150 // The maximum number of records to retrieve
    const useMaxNumRecordsLimit = true // Set to False to pull all available records

    // Create an SQL query
    sqlQuery := "SELECT * FROM person" +
        " WHERE job_company_name='amazon'"

    // Create a parameters JSON object
    p := pdlmodel.SearchParams {
        BaseParams: pdlmodel.BaseParams {
            Size: 100,
            Pretty: true,
        },
        SearchBaseParams: pdlmodel.SearchBaseParams {
            SQL: sqlQuery,
        },
    }

    // Pull all results in multiple batches
    batch := 1
    // Store all records retreived in an array
    var allRecords []pdlmodel.Person
    // Time the process
    startTime := time.Now()
    foundAllRecords := false
    continueScrolling := true
    var numRecordsToRequest int
    
    // While still scrolling through data and still records to be found
    for continueScrolling && !foundAllRecords {
        // Check if we reached the maximum number of records we want
        if useMaxNumRecordsLimit {
            numRecordsToRequest = maxNumRecordsLimit - len(allRecords)
            // Adjust size parameter
            p.BaseParams.Size = (int) (math.Max(0.0, math.Min(100.0, (float64) (numRecordsToRequest))))
            // Check if MAX_NUM_RECORDS_LIMIT reached
            if numRecordsToRequest == 0 {
                fmt.Printf("Stopping - reached maximum number of records to pull " +
                           "[MAX_NUM_RECORDS_LIMIT = %d].\n", maxNumRecordsLimit)
                
                break
            }
        }
        
        // Pass the parameters object to the Person Search API
        response, err := client.Person.Search(context.Background(), p)
        
        // Check for successful response
        if err == nil {
            fmt.Printf("Retrieved %d records in batch %d - %d records remaining.\n", 
                       len(response.Data), batch, response.Total - len(allRecords))
        } else {
            fmt.Println("Error retrieving some records:\n\t",
                       err)
        }
        
        // Convert response to JSON
        var data map[string]interface{}
        jsonResponse, jsonErr := json.Marshal(response)
        if jsonErr == nil {
            json.Unmarshal(jsonResponse, &data)
            // Get scroll_token from response if exists and store it in parameters object
            if scrollToken, ok := data["scroll_token"]; ok {
                p.SearchBaseParams.ScrollToken = fmt.Sprintf("%v", scrollToken)
            } else {
                continueScrolling = false
                fmt.Println("Unable to continue scrolling.")
            }
            // Add records retrieved to the records array
            allRecords = append(allRecords, response.Data...)
        }       
        batch++
        foundAllRecords = (len(allRecords) == response.Total)
        time.Sleep(6 * time.Second) // Avoid hitting rate limit thresholds
    }
    
    // Calculate time required to process batches
    endTime := time.Now()
    runtime := endTime.Sub(startTime).Seconds()
        
    fmt.Printf("Successfully recovered %d profiles in %d batches [%d seconds].\n",
               len(allRecords), batch, (int) (math.Round((float64) (runtime))))
    
    // Use utility function to save profiles to CSV    
    csvHeaderFields := []string{"work_email", "full_name", "linkedin_url",
                                "job_title", "job_company_name"}
    csvFilename := "all_employee_profiles.csv"
    saveProfilesToCsv(allRecords, csvFilename, csvHeaderFields, ",")
}

// Save profiles to CSV (utility function)
func saveProfilesToCsv(profiles []pdlmodel.Person, filename string, fields []string, delim string) {
    // Define header fields
    if fields == nil && len(profiles) > 0 {
        e := reflect.ValueOf(&(profiles[0])).Elem()
        for i := 0; i < e.NumField(); i++ {
            fields = append(fields, e.Type().Field(i).Name)
        }
    }
    
    // Write CSV file
    csvFile, err := os.Create(filename)
    if err == nil {
        csvwriter := csv.NewWriter(csvFile)
        defer csvwriter.Flush()
        // Write header
        csvwriter.Write(fields)
        // Write body
        count := 0
        for i := range profiles {
            var data map[string]interface{}
            jsonResponse, jsonErr := json.Marshal(profiles[i])
            if jsonErr == nil {
                json.Unmarshal(jsonResponse, &data)
                var record []string
                for j := range fields {
                    record = append(record, fmt.Sprintf("%v", data[fields[j]]))
                }
                csvwriter.Write(record)
                count++
            }
        }
        fmt.Printf("Wrote %d lines to: %s.\n", count, filename)
    }
}
```

```
import requests, json, time, csv

# Set your API key
API_KEY = "YOUR API KEY"

# Limit the number of records to pull (to prevent accidentally using 
# more credits than expected when testing out this code).
MAX_NUM_RECORDS_LIMIT = 150 # The maximum number of records to retrieve
USE_MAX_NUM_RECORDS_LIMIT = True # Set to False to pull all available records

# Set the Person Search API URL
PDL_URL = "https://api.peopledatalabs.com/v5/person/search"

# Set headers
HEADERS = {
  'Content-Type': "application/json",
  'X-api-key': API_KEY
}

# Create an Elasticsearch query
ES_QUERY = {
  "query": {
    "bool": {
        "must": [
            {"term": {"job_company_name": "amazon"}}
      ]
    }
  }
}

# Create a parameters JSON object
PARAMS = {
  'query': json.dumps(ES_QUERY),
  'size': 100, 
  'pretty': True
}

# Pull all results in multiple batches
batch = 1
# Store all records retreived in an array
all_records = []
# Time the process
start_time = time.time()
found_all_records = False
continue_scrolling = True

# While still scrolling through data and still records to be found
while continue_scrolling and not found_all_records: 

  # Check if we reached the maximum number of records we want
  if USE_MAX_NUM_RECORDS_LIMIT:
    num_records_to_request = MAX_NUM_RECORDS_LIMIT - len(all_records)
    # Adjust size parameter
    PARAMS['size'] = max(0, min(100, num_records_to_request))
    # Check if MAX_NUM_RECORDS_LIMIT reached
    if num_records_to_request == 0:
      print(f"Stopping - reached maximum number of records to pull "
            f"[MAX_NUM_RECORDS_LIMIT = {MAX_NUM_RECORDS_LIMIT}].")
      break

  # Pass the parameters object to the Person Search API
  response = requests.get(
    PDL_URL,
    headers=HEADERS,
    params=PARAMS
  ).json()

  # Check for successful response
  if response['status'] == 200:
    # Add records retrieved to the records array
    all_records.extend(response['data'])
    print(f"Retrieved {len(response['data'])} records in batch {batch} "
          f"- {response['total'] - len(all_records)} records remaining.")
  else:
    print(f"Error retrieving some records:\n\t"
          f"[{response['status']} - {response['error']['type']}] "
          f"{response['error']['message']}")
  
  # Get scroll_token from response if exists and store it in parameters object
  if 'scroll_token' in response:
    PARAMS['scroll_token'] = response['scroll_token']
  else:
    continue_scrolling = False
    print(f"Unable to continue scrolling.")

  batch += 1
  found_all_records = (len(all_records) == response['total'])
  time.sleep(6) # avoid hitting rate limit thresholds
 
# Calculate time required to process batches
end_time = time.time()
runtime = end_time - start_time
        
print(f"Successfully recovered {len(all_records)} profiles in "
      f"{batch} batches [{round(runtime, 2)} seconds].")

# Save profiles to CSV (utility function)
def save_profiles_to_csv(profiles, filename, fields=[], delim=','):
  # Define header fields
  if fields == [] and len(profiles) > 0:
      fields = profiles[0].keys()
  # Write CSV file
  with open(filename, 'w') as csvfile:
    writer = csv.writer(csvfile, delimiter=delim)
    # Write header
    writer.writerow(fields)
    # Write body
    count = 0
    for profile in profiles:
      writer.writerow([ profile[field] for field in fields ])
      count += 1
  print(f"Wrote {count} lines to: '{filename}'.")

# Use utility function to save profiles to CSV    
csv_header_fields = ['work_email', 'full_name', "linkedin_url",
                     'job_title', 'job_company_name']
csv_filename = "all_employee_profiles.csv"
save_profiles_to_csv(all_records, csv_filename, csv_header_fields)
```

```
import requests, json, time, csv

# Set your API key
API_KEY = "YOUR API KEY"

# Limit the number of records to pull (to prevent accidentally using 
# more credits than expected when testing out this code).
MAX_NUM_RECORDS_LIMIT = 150 # The maximum number of records to retrieve
USE_MAX_NUM_RECORDS_LIMIT = True # Set to False to pull all available records

# Set the Person Search API URL
PDL_URL = "https://api.peopledatalabs.com/v5/person/search"

# Set headers
HEADERS = {
  'Content-Type': "application/json",
  'X-api-key': API_KEY
}

# Create an SQL query
SQL_QUERY = \
"""
 SELECT * FROM person
 WHERE job_company_name='amazon';
"""

# Create a parameters JSON object
PARAMS = {
  'sql': SQL_QUERY,
  'size': 100, 
  'pretty': True
}

# Pull all results in multiple batches
batch = 1
# Store all records retreived in an array
all_records = []
# Time the process
start_time = time.time()
found_all_records = False
continue_scrolling = True

# While still scrolling through data and still records to be found
while continue_scrolling and not found_all_records: 

  # Check if we reached the maximum number of records we want
  if USE_MAX_NUM_RECORDS_LIMIT:
    num_records_to_request = MAX_NUM_RECORDS_LIMIT - len(all_records)
    # Adjust size parameter
    PARAMS['size'] = max(0, min(100, num_records_to_request))
    # Check if MAX_NUM_RECORDS_LIMIT reached
    if num_records_to_request == 0:
      print(f"Stopping - reached maximum number of records to pull "
            f"[MAX_NUM_RECORDS_LIMIT = {MAX_NUM_RECORDS_LIMIT}].")
      break

  # Pass the parameters object to the Person Search API
  response = requests.get(
    PDL_URL,
    headers=HEADERS,
    params=PARAMS
  ).json()

  # Check for successful response
  if response['status'] == 200:
    # Add records retrieved to the records array
    all_records.extend(response['data'])
    print(f"Retrieved {len(response['data'])} records in batch {batch} "
          f"- {response['total'] - len(all_records)} records remaining.")
  else:
    print(f"Error retrieving some records:\n\t"
          f"[{response['status']} - {response['error']['type']}] "
          f"{response['error']['message']}")
  
  # Get scroll_token from response if exists and store it in parameters object
  if 'scroll_token' in response:
    PARAMS['scroll_token'] = response['scroll_token']
  else:
    continue_scrolling = False
    print(f"Unable to continue scrolling.")

  batch += 1
  found_all_records = (len(all_records) == response['total'])
  time.sleep(6) # avoid hitting rate limit thresholds
 
# Calculate time required to process batches
end_time = time.time()
runtime = end_time - start_time
        
print(f"Successfully recovered {len(all_records)} profiles in "
      f"{batch} batches [{round(runtime, 2)} seconds].")

# Save profiles to CSV (utility function)
def save_profiles_to_csv(profiles, filename, fields=[], delim=','):
  # Define header fields
  if fields == [] and len(profiles) > 0:
      fields = profiles[0].keys()
  # Write CSV file
  with open(filename, 'w') as csvfile:
    writer = csv.writer(csvfile, delimiter=delim)
    # Write header
    writer.writerow(fields)
    # Write body
    count = 0
    for profile in profiles:
      writer.writerow([ profile[field] for field in fields ])
      count += 1
  print(f"Wrote {count} lines to: '{filename}'.")

# Use utility function to save profiles to CSV    
csv_header_fields = ['work_email', 'full_name', "linkedin_url",
                     'job_title', 'job_company_name']
csv_filename = "all_employee_profiles.csv"
save_profiles_to_csv(all_records, csv_filename, csv_header_fields)
```

## Sales Prospecting

*"I want to email engineering leaders at stripe.com, plaid.com, xignite.com and square.com, so that I can reach out to them about my product."*

Python3 SDK (Elasticsearch)Python3 SDK (SQL)JavaScript (Elasticsearch)JavaScript (SQL)Ruby (Elasticsearch)Ruby (SQL)Go (Elasticsearch)Go (SQL)Python3 (Elasticsearch)Python3 (SQL)

```
import json

# See https://github.com/peopledatalabs/peopledatalabs-python
from peopledatalabs import PDLPY

# Create a list of company domains to search against
DESIRED_COMPANY_DOMAINS = [
  'stripe.com', 'plaid.com', 'xignite.com', 'square.com'
]

# Create a client, specifying your API key
CLIENT = PDLPY(
    api_key="YOUR API KEY",
)

# Create an Elasticsearch query
ES_QUERY = {
    "query": {
        "bool": {
        "must": [
        {"terms": {"job_company_website": DESIRED_COMPANY_DOMAINS}},
        {"term": {"job_title_role": "engineering"}},
        {"terms": {"job_title_levels": ["vp", "director", "manager"]}},
        {"exists": {"field": "work_email"}}
      ]
    }
    }
}

# Create a parameters JSON object
PARAMS = {
  'query': ES_QUERY,
  'size': 100
}

# Pass the parameters object to the Person Search API
response = CLIENT.person.search(**PARAMS).json()

# Check for successful response
if response["status"] == 200:
  for record in response['data']:
    # Print selected fields
    print(
      record['work_email'],
      record['full_name'],
      record['job_title'],
      record['job_company_name']
    )

  print(f"Successfully grabbed {len(response['data'])} records from PDL.")
  print(f"{response['total']} total PDL records exist matching this query.")
else:
  print("NOTE: The eager beaver was not so eager. See error and try again.")
  print("error:", response)
```

```
import json

# See https://github.com/peopledatalabs/peopledatalabs-python
from peopledatalabs import PDLPY

# Create a list of company domains to search against
DESIRED_COMPANY_DOMAINS = [
  'stripe.com', 'plaid.com', 'xignite.com', 'square.com'
]

# Create a string representation of the list
COMPANY_DOMAINS_STRING_REP = ", ".join(
  (f"'{site}'" for site in DESIRED_COMPANY_DOMAINS)
)

# Create a client, specifying your API key
CLIENT = PDLPY(
    api_key="YOUR API KEY",
)

# Create an SQL query
SQL_QUERY = \
f"""
  SELECT * FROM person
  WHERE job_company_website IN ({COMPANY_DOMAINS_STRING_REP})
  AND job_title_role='engineering'
  AND job_title_levels IN ('vp', 'director', 'manager')
  AND work_email IS NOT NULL;
"""

# Create a parameters JSON object
PARAMS = {
  'sql': SQL_QUERY,
  'size': 100
}

# Pass the parameters object to the Person Search API
response = CLIENT.person.search(**PARAMS).json()

# Check for successful response
if response["status"] == 200:
  for record in response['data']:
    # Print selected fields
    print(
      record['work_email'],
      record['full_name'],
      record['job_title'],
      record['job_company_name']
    )

  print(f"Successfully grabbed {len(response['data'])} records from PDL.")
  print(f"{response['total']} total PDL records exist matching this query.")
else:
  print("NOTE: The eager beaver was not so eager. See error and try again.")
  print("error:", response)
```

```
// See https://github.com/peopledatalabs/peopledatalabs-js
import PDLJS from 'peopledatalabs';

// Create a client, specifying your API key
const PDLJSClient = new PDLJS({ apiKey: "YOUR API KEY" });

// Create a list of company domains to search against
const desiredCompanyDomains = [
    "stripe.com", "plaid.com", "xignite.com", "square.com"
];

// Create an Elasticsearch query
const esQuery = {
  query: {
    bool: {
      must:[
        {terms: {job_company_website: desiredCompanyDomains}}, 
        {term: {job_title_role: "engineering"}}, 
        {terms: {job_title_levels: ["vp", "director", "manager"]}}, 
        {exists: {field: "work_email"}} 
      ]
    }
  }
}

// Create a parameters JSON object
const params = {
  searchQuery: esQuery, 
  size: 100
}

// Pass the current parameters object to the Person Search API
PDLJSClient.person.search.elastic(params).then((data) => {
    var record
    
    for (let response in data.data) {
    
        record = data.data[response]
      
        // Print selected fields
        console.log(
            record["work_email"],
            record["full_name"],
            record["job_title"],
            record["job_company_name"],
            )
    }
    console.log(`Successfully grabbed ${data.data.length} records from PDL.`);
    console.log(`${data["total"]} total PDL records exist matching this query.`)
}).catch((error) => {
    console.log("NOTE: The eager beaver was not so eager. See error and try again.")
    console.log(error);
});
```

```
// See https://github.com/peopledatalabs/peopledatalabs-js
import PDLJS from 'peopledatalabs';

// Create a client, specifying your API key
const PDLJSClient = new PDLJS({ apiKey: "YOUR API KEY" });

// Create a list of company domains to search against
const desiredCompanyDomains = [
    "stripe.com", "plaid.com", "xignite.com", "square.com"
];

// Create a string representation of the list
var companyStringRep = "'" + desiredCompanyDomains.join("', '") + "'";

// Create an SQL query
const sqlQuery = `SELECT * FROM person
  WHERE job_company_website IN (${companyStringRep})
  AND job_title_role='engineering'
  AND job_title_levels IN ('vp', 'director', 'manager')
  AND work_email IS NOT NULL;`

// Create a parameters JSON object
const params = {
  searchQuery: sqlQuery, 
  size: 100
}

// Pass the current parameters object to the Person Search API
PDLJSClient.person.search.sql(params).then((data) => {
    var record
    
    for (let response in data.data) {
    
        record = data.data[response]
      
        // Print selected fields
        console.log(
            record["work_email"],
            record["full_name"],
            record["job_title"],
            record["job_company_name"],
            )
    }
    console.log(`Successfully grabbed ${data.data.length} records from PDL.`);
    console.log(`${data["total"]} total PDL records exist matching this query.`)
}).catch((error) => {
    console.log("NOTE: The eager beaver was not so eager. See error and try again.")
    console.log(error);
});
```

```
require 'json'

# See https://github.com/peopledatalabs/peopledatalabs-ruby
require 'peopledatalabs'

# Set your API key
Peopledatalabs.api_key = 'YOUR API KEY'

# Create a list of company domains to search against
DESIRED_COMPANY_DOMAINS = [
  'stripe.com', 'plaid.com', 'xignite.com', 'square.com'
]

# Create an Elasticsearch query
ES_QUERY = {
    "query": {
        "bool": {
        "must": [
        {"terms": {"job_company_website": DESIRED_COMPANY_DOMAINS}},
        {"term": {"job_title_role": "engineering"}},
        {"terms": {"job_title_levels": ["vp", "director", "manager"]}},
        {"exists": {"field": "work_email"}}
      ]
    }
    }
}

# Pass parameters to the Person Search API
response = Peopledatalabs::Search.person(searchType: 'elastic', query: ES_QUERY, size: 100)

# Check for successful response
if response['status'] == 200
    data = response['data']
    data.each do |record|
      # Print selected fields
      puts "#{record['work_email']} \
            #{record['full_name']} \
            #{record['job_title']} \
            #{record['job_company_name']}"
    end

    puts "Successfully grabbed #{data.length()} records from PDL."
    puts "#{response['total']} total PDL records exist matching this query."
else
    puts "NOTE: The eager beaver was not so eager. See error and try again."
    puts "Error: #{response}"
end
```

```
require 'json'

# See https://github.com/peopledatalabs/peopledatalabs-ruby
require 'peopledatalabs'

# Set your API key
Peopledatalabs.api_key = 'YOUR API KEY'

# Create a string of company domains to search against
COMPANY_DOMAINS_STRING_REP = "'stripe.com', 'plaid.com', 'xignite.com', 'square.com'"

# Create an SQL query
SQL_QUERY = \
"""
  SELECT * FROM person
  WHERE job_company_website IN (#{COMPANY_DOMAINS_STRING_REP})
  AND job_title_role='engineering'
  AND job_title_levels IN ('vp', 'director', 'manager')
  AND work_email IS NOT NULL;
"""

# Pass parameters to the Person Search API
response = Peopledatalabs::Search.person(searchType: 'sql', query: SQL_QUERY, size: 100)

# Check for successful response
if response['status'] == 200
    data = response['data']
    data.each do |record|
      # Print selected fields
      puts "#{record['work_email']} \
            #{record['full_name']} \
            #{record['job_title']} \
            #{record['job_company_name']}"
    end

    puts "Successfully grabbed #{data.length()} records from PDL."
    puts "#{response['total']} total PDL records exist matching this query."
else
    puts "NOTE: The eager beaver was not so eager. See error and try again."
    puts "Error: #{response}"
end
```

```
package main

import (
    "fmt"
    "context"
)

// See https://github.com/peopledatalabs/peopledatalabs-go
import (
    pdl "github.com/peopledatalabs/peopledatalabs-go"
    pdlmodel "github.com/peopledatalabs/peopledatalabs-go/model"
)

func main() {
    // Set your API key
    apiKey := "YOUR API KEY"
    // Set API key as environmental variable
    // apiKey := os.Getenv("API_KEY")

    // Create a client, specifying your API key
    client := pdl.New(apiKey)

    // Create a list of company domains to search against
    desiredCompanyDomains := []string{"stripe.com", "plaid.com", "xignite.com", "square.com"}
    
    // Create an Elasticsearch query
    elasticSearchQuery := map[string]interface{} {
        "query": map[string]interface{} {
            "bool": map[string]interface{} {
                "must": []map[string]interface{} {
                    {"terms": map[string]interface{}{"job_company_website": desiredCompanyDomains}},
                    {"term": map[string]interface{}{"job_title_role": "engineering"}},
                    {"terms": map[string]interface{}{"job_title_levels": []string{"vp", "director", "manager"}}},
                    {"exists": map[string]interface{}{"field": "work_email"}},
                },
            },
        },
    }

    // Create a parameters JSON object
    params := pdlmodel.SearchParams {
        BaseParams: pdlmodel.BaseParams {
            Size: 100,
        },
        SearchBaseParams: pdlmodel.SearchBaseParams {
            Query: elasticSearchQuery,
        },
    }

    // Pass the parameters object to the Person Search API
    response, err := client.Person.Search(context.Background(), params)
    
    // Check for successful response
    if err == nil {
        for i := range response.Data {
            record := response.Data[i]
            // Print selected fields
            fmt.Println(record.WorkEmail, record.FullName, record.JobTitle, record.JobCompanyName)
        }
        
        fmt.Printf("Successfully grabbed %d records from PDL.\n", len(response.Data))
        fmt.Printf("%d total PDL records exist matching this query.\n", response.Total)
   	} else {
        fmt.Println("NOTE: The eager beaver was not so eager. See error and try again.")
        fmt.Println("error:", err)
    }
}
```

```
package main

import (
    "fmt"
    "context"
)

// See https://github.com/peopledatalabs/peopledatalabs-go
import (
    pdl "github.com/peopledatalabs/peopledatalabs-go"
    pdlmodel "github.com/peopledatalabs/peopledatalabs-go/model"
)

func main() {
    // Set your API key
    apiKey := "YOUR API KEY"
    // Set API key as environmental variable
    // apiKey := os.Getenv("API_KEY")

    // Create a client, specifying your API key
    client := pdl.New(apiKey)

    // Create a string of company domains to search against
    companyDomainsStringRep := "'stripe.com', 'plaid.com', 'xignite.com', 'square.com'"
    
    // Create an SQL query
    sqlQuery := "SELECT * FROM person" +
    " WHERE job_company_website IN (" + companyDomainsStringRep + ")" +
        " AND job_title_role='engineering'" +
        " AND job_title_levels IN ('vp', 'director', 'manager')" +
        " AND work_email IS NOT NULL;"

    // Create a parameters JSON object
    params := pdlmodel.SearchParams {
        BaseParams: pdlmodel.BaseParams {
            Size: 100,
        },
        SearchBaseParams: pdlmodel.SearchBaseParams {
            SQL: sqlQuery,
        },
    }

    // Pass the parameters object to the Person Search API
    response, err := client.Person.Search(context.Background(), params)
    
    // Check for successful response
    if err == nil {
        for i := range response.Data {
            record := response.Data[i]
            // Print selected fields
            fmt.Println(record.WorkEmail, record.FullName, record.JobTitle, record.JobCompanyName)
        }
        
        fmt.Printf("Successfully grabbed %d records from PDL.\n", len(response.Data))
        fmt.Printf("%d total PDL records exist matching this query.\n", response.Total)
   	} else {
        fmt.Println("NOTE: The eager beaver was not so eager. See error and try again.")
        fmt.Println("error:", err)
    }
}
```

```
import requests, json

# Set your API key
API_KEY = "YOUR API KEY"

# Set the Person Search API URL
PDL_URL = "https://api.peopledatalabs.com/v5/person/search"

# Set headers
HEADERS = {
  'Content-Type': "application/json",
  'X-api-key': API_KEY
}

# Create a list of company domains to search against
DESIRED_COMPANY_DOMAINS = [
  'stripe.com', 'plaid.com', 'xignite.com', 'square.com'
]

# https://pdl-prod-schema.s3-us-west-2.amazonaws.com/15.0/enums/job_title_levels.txt
# for enumerated possible values of job_title_levels

# Create an Elasticsearch query
ES_QUERY = {
	"query": {
		"bool": {
    	"must": [
      	{"terms": {"job_company_website": DESIRED_COMPANY_DOMAINS}},
        {"term": {"job_title_role": "engineering"}},
        {"terms": {"job_title_levels": ["vp", "director", "manager"]}},
        {"exists": {"field": "work_email"}}
      ]
    }
	}
}

# Create a parameters JSON object
PARAMS = {
  'query': json.dumps(ES_QUERY),
  'size': 100
}

# Pass the parameters object to the Person Search API
response = requests.get(
  PDL_URL,
  headers=HEADERS,
  params=PARAMS
).json()

# Check for successful response
if response["status"] == 200:
  for record in response['data']:
    # Print selected fields
    print(
      record['work_email'],
      record['full_name'],
      record['job_title'],
      record['job_company_name']
    )

  print(f"Successfully grabbed {len(response['data'])} records from PDL.")
  print(f"{response['total']} total PDL records exist matching this query.")
else:
  print("NOTE: The eager beaver was not so eager. See error and try again.")
  print("error:", response)
```

```
import requests, json

# Set your API key
API_KEY = "YOUR API KEY"

# Set the Person Search API URL
PDL_URL = "https://api.peopledatalabs.com/v5/person/search"

# Set headers
HEADERS = {
  'Content-Type': "application/json",
  'X-api-key': API_KEY
}

# Create a list of company domains to search against
DESIRED_COMPANY_DOMAINS = [
  'stripe.com', 'plaid.com', 'xignite.com', 'square.com'
]

# Create a string representation of the list
COMPANY_DOMAINS_STRING_REP = ", ".join(
  (f"'{site}'" for site in DESIRED_COMPANY_DOMAINS)
)

# https://pdl-prod-schema.s3-us-west-2.amazonaws.com/15.0/job_title_levels.txt
# for enumerated possible values of job_title_levels

# Create an SQL query
SQL_QUERY = \
f"""
  SELECT * FROM person
  WHERE job_company_website IN ({COMPANY_DOMAINS_STRING_REP})
  AND job_title_role='engineering'
  AND job_title_levels IN ('vp', 'director', 'manager')
  AND work_email IS NOT NULL;
"""

# Create a parameters JSON object
PARAMS = {
  'sql': SQL_QUERY,
  'size': 100
}

# Pass the parameters object to the Person Search API
response = requests.get(
  PDL_URL,
  headers=HEADERS,
  params=PARAMS
).json()

# Check for successful response
if response["status"] == 200:
  
  for record in response['data']:
    # Print selected fields
    print(
      record['work_email'],
      record['full_name'],
      record['job_title'],
      record['job_company_name']
    )

  print(f"Successfully grabbed {len(response['data'])} records from PDL.")
  print(f"{response['total']} total PDL records exist matching this query.")
else:
  print("NOTE: The eager beaver was not so eager. See error and try again.")
  print("error:", response)
```

## Recruiting

*"I have a client looking for marketing managers and dishwashers in Oregon but NOT in portland (don't ask why). They want to reach out to them on LinkedIn, so they asked that each candidate have a LinkedIn URL. I want as many people as PDL can give me matching this criteria."*

Python3 SDK (Elasticsearch)Python3 SDK (SQL)JavaScript (Elasticsearch)JavaScript (SQL)Ruby (Elasticsearch)Ruby (SQL)Go (Elasticsearch)Go (SQL)Python3 (Elasticsearch)Python3 (SQL)

```
from time import sleep
import json

# See https://github.com/peopledatalabs/peopledatalabs-python
from peopledatalabs import PDLPY

# Create a client, specifying your API key
CLIENT = PDLPY(
    api_key="YOUR API KEY",
)

# Run Person searches in batches with 6-second intervals 
def get_all_pdl_records_es(query):

    PAGE_SIZE = 100

    # Store all records retreived in an array
    all_records = []
    batch = 1

    # Create a parameters JSON object
    params = {
        'query': query,
        'size': PAGE_SIZE,
        'dataset': "all"
    }

    # Keep retrieving records until unable to continue scrolling
    while batch == 1 or params['scroll_token']:

        # Pass the parameters object to the Person Search API
        response = CLIENT.person.search(**params).json()
				
        # Check for successful response
        if response['status'] == 200:
          # Add records retrieved to the records array
          all_records.extend(response['data'])
          # Store the scroll_token for next batch
          params['scroll_token'] = response['scroll_token']

          print(f"Batch {batch} success!")
          sleep(6)
          batch += 1
          
        else:
          print("Unable to continue scrolling.")
          break
    
    print("Done!")

    return all_records

if __name__ == '__main__':
    # Create an Elasticsearch query
    ES_QUERY = {
        "query": {
        "bool": {
        "must": [
            {"term": {"location_region": "oregon"}},
            {"bool": {
            "should": [
                {"match": {"job_title": "dishwasher"}},
                {"bool": {
                "must": [
                    {"term": {"job_title_role": "marketing"}},
                    {"term": {"job_title_levels": "manager"}}
                ]
                }}
            ]
            }
            },
        {"exists": {"field": "linkedin_url"}}
       ],
       "must_not":[
          {"term": {"location_locality": "portland"}},
       ]
        }
    }
    }

    # Find all records matching query
    recruiting_leads = get_all_pdl_records_es(ES_QUERY)
            
    print(f"Got {len(recruiting_leads)} recruiting leads for my wealthy client!")

    #GO make_money_with_data(recruiting_leads)!
```

```
from time import sleep
import json

# See https://github.com/peopledatalabs/peopledatalabs-python
from peopledatalabs import PDLPY

# Create a client, specifying your API key
CLIENT = PDLPY(
    api_key="YOUR API KEY",
)

# Run Person searches in batches with 6-second intervals 
def get_all_pdl_records_sql(query):

    PAGE_SIZE = 100

    # Store all records retreived in an array
    all_records = []
    batch = 1

    # Create a parameters JSON object
    params = {
        'sql': query,
        'size': PAGE_SIZE,
        'dataset': "all"
    }

    # Keep retrieving records until unable to continue scrolling
    while batch == 1 or params['scroll_token']:

        # Pass the parameters object to the Person Search API
        response = CLIENT.person.search(**params).json()
				
        # Check for successful response
        if response['status'] == 200:
          # Add records retrieved to the records array
          all_records.extend(response['data'])
          # Store the scroll_token for next batch
          params['scroll_token'] = response['scroll_token']

          print(f"Batch {batch} success!")
          sleep(6)
          batch += 1
          
        else:
          print("Unable to continue scrolling.")
          break
    
    print("Done!")

    return all_records

# Create an SQL query
SQL_QUERY = \
  """
    SELECT * FROM person
    WHERE location_region='oregon'
    AND NOT location_locality='portland'
    AND (
      job_title LIKE '%dishwasher%'
      OR (
        job_title_role='marketing'
        AND job_title_levels='manager'
      )
    )
    AND linkedin_url IS NOT NULL;
  """

# Find all records matching query
recruiting_leads = get_all_pdl_records_sql(SQL_QUERY)
            
print(f"Got {len(recruiting_leads)} recruiting leads for my wealthy client!")

#GO make_money_with_data(recruiting_leads)!
```

```
// See https://github.com/peopledatalabs/peopledatalabs-js
import PDLJS from 'peopledatalabs';

// Create a client, specifying your API key
const PDLJSClient = new PDLJS({ apiKey: "YOUR API KEY" });

// Create an Elasticsearch query
const esQuery = {
    "query": {
    "bool": {
    "must": [
        {"term": {"location_region": "oregon"}},
        {"bool": {
        "should": [
            {"match": {"job_title": "dishwasher"}},
            {"bool": {
            "must": [
                {"term": {"job_title_role": "marketing"}},
                {"term": {"job_title_levels": "manager"}}
            ]
            }}
        ]
        }
        },
        {"exists": {"field": "linkedin_url"}}
   ],
   "must_not":[
      {"term": {"location_locality": "portland"}},
   ]
   }
   }
}

// Store all records retreived in an array
var allRecords = [];
// The current scroll_token
var scrollToken = null;
var pageSize = 100;
var batch = 1;

// Create a parameters JSON object
var params = {
    searchQuery: esQuery, 
    size: pageSize,
    scroll_token: null,
    dataset: "all"
}

// Run batches recursively
runBatch();

// Run Person searches in batches
function runBatch() {

    // Store current scroll_token in parameters object
    params.scroll_token = scrollToken;
    // Pass the current parameters object to the Person Search API
    PDLJSClient.person.search.elastic(params).then((data) => {
        // Add records retrieved to the records array
        Array.prototype.push.apply(allRecords, data.data);
        
        // Store scroll_token from response
        scrollToken = data['scroll_token'];
        
        console.log(`Batch ${batch} success!`);
        batch++;
        
        // Run searches in batches with 6-second intervals 
        if (scrollToken) {
            setTimeout(function() {
                runBatch(params);
            }, 6000);
        }
    }).catch((error) => {
        console.log("Unable to continue scrolling.");
        console.log("Done!");
        console.log(`Got ${allRecords.length} recruiting leads for my wealthy client!`);
    });
}
```

```
// See https://github.com/peopledatalabs/peopledatalabs-js
import PDLJS from 'peopledatalabs';

// Create a client, specifying your API key
const PDLJSClient = new PDLJS({ apiKey: "YOUR API KEY" });

// Create an SQL query
const sqlQuery = `SELECT * FROM person
    WHERE location_region='oregon'
    AND NOT location_locality='portland'
    AND (
      job_title LIKE '%dishwasher%'
      OR (
        job_title_role='marketing'
        AND job_title_levels='manager'
      )
    )
    AND linkedin_url IS NOT NULL;`;

// Store all records retreived in an array
var allRecords = [];
// The current scroll_token
var scrollToken = null;
var pageSize = 100;
var batch = 1;

// Create a parameters JSON object
var params = {
    searchQuery: sqlQuery, 
    size: pageSize,
    scroll_token: null,
    dataset: "all"
}

// Run batches recursively
runBatch();

// Run Person searches in batches
function runBatch() {

    // Store current scroll_token in parameters object
    params.scroll_token = scrollToken;
    // Pass the current parameters object to the Person Search API
    PDLJSClient.person.search.sql(params).then((data) => {
        // Add records retrieved to the records array
        Array.prototype.push.apply(allRecords, data.data);
        
        // Store scroll_token from response
        scrollToken = data['scroll_token'];
        
        console.log(`Batch ${batch} success!`);
        batch++;
        
        // Run searches in batches with 6-second intervals
        if (scrollToken) {
            setTimeout(function() {
                runBatch(params);
            }, 6000);
        }
    }).catch((error) => {
        console.log("Unable to continue scrolling.");
        console.log("Done!");
        console.log(`Got ${allRecords.length} recruiting leads for my wealthy client!`);
    });
}
```

```
require 'json'

# See https://github.com/peopledatalabs/peopledatalabs-ruby
require 'peopledatalabs'

# Set your API key
Peopledatalabs.api_key = 'YOUR API KEY'

PAGE_SIZE = 100

# Run Person searches in batches with 6-second intervals
def get_all_pdl_records_es(query)

    # Store all records retreived in an array
    all_records = []
    batch = 1
    # The current scroll_token
    scroll_token = {}

    # Keep retrieving records until unable to continue scrolling
    while batch == 1 || !scroll_token.nil?

        # Pass parameters to the Person Search API
        response = Peopledatalabs::Search.person(searchType: 'elastic', query: query, size: PAGE_SIZE, scroll_token: scroll_token, dataset: "all")
				
        # Check for successful response
        if response['status'] == 200
          # Add records retrieved to the records array
          all_records += response['data']
          # Store the scroll_token for next batch
          scroll_token = response['scroll_token']

          puts "Batch #{batch} success!"
          sleep(6)
          batch += 1
          
        else
          puts "Unable to continue scrolling."
          break
        end
    end
    
    puts "Done!"

    return all_records
end

# Create an Elasticsearch query
ES_QUERY = {
    "query": {
    "bool": {
    "must": [
        {"term": {"location_region": "oregon"}},
        {"bool": {
        "should": [
            {"match": {"job_title": "dishwasher"}},
            {"bool": {
            "must": [
                {"term": {"job_title_role": "marketing"}},
                {"term": {"job_title_levels": "manager"}}
            ]
            }}
        ]
        }
        },
    {"exists": {"field": "linkedin_url"}}
   ],
   "must_not":[
      {"term": {"location_locality": "portland"}},
   ]
    }
}
}

# Find all records matching query
recruiting_leads = get_all_pdl_records_es(ES_QUERY)
            
puts "Got #{recruiting_leads.length()} recruiting leads for my wealthy client!"

#GO make_money_with_data(recruiting_leads)!
```

```
require 'json'

# See https://github.com/peopledatalabs/peopledatalabs-ruby
require 'peopledatalabs'

# Set your API key
Peopledatalabs.api_key = 'YOUR API KEY'

PAGE_SIZE = 100

# Run Person searches in batches with 6-second intervals
def get_all_pdl_records_sql(query)

    # Store all records retreived in an array
    all_records = []
    batch = 1
    # The current scroll_token
    scroll_token = {}

    # Keep retrieving records until unable to continue scrolling
    while batch == 1 || !scroll_token.nil?

        # Pass parameters to the Person Search API
        response = Peopledatalabs::Search.person(searchType: 'sql', query: query, size: PAGE_SIZE, scroll_token: scroll_token, dataset: "all")
				
        # Check for successful response
        if response['status'] == 200
          # Add records retrieved to the records array
          all_records += response['data']
          # Store the scroll_token for next batch
          scroll_token = response['scroll_token']

          puts "Batch #{batch} success!"
          sleep(6)
          batch += 1
          
        else
          puts "Unable to continue scrolling."
          break
        end
    end
    
    puts "Done!"

    return all_records
end

# Create an SQL query
SQL_QUERY = \
  """
    SELECT * FROM person
    WHERE location_region='oregon'
    AND NOT location_locality='portland'
    AND (
      job_title LIKE '%dishwasher%'
      OR (
        job_title_role='marketing'
        AND job_title_levels='manager'
      )
    )
    AND linkedin_url IS NOT NULL;
  """

# Find all records matching query
recruiting_leads = get_all_pdl_records_sql(SQL_QUERY)
            
puts "Got #{recruiting_leads.length()} recruiting leads for my wealthy client!"

#GO make_money_with_data(recruiting_leads)!
```

```
package main

import (
    "fmt"
    "time"
    "context"
)

// See https://github.com/peopledatalabs/peopledatalabs-go
import (
    pdl "github.com/peopledatalabs/peopledatalabs-go"
    pdlmodel "github.com/peopledatalabs/peopledatalabs-go/model"
)

func main() {
    // Create an Elasticsearch query
    elasticSearchQuery := map[string]interface{} {
        "query": map[string]interface{} {
            "bool": map[string]interface{} {
                "must": []map[string]interface{} {
                    {"term": map[string]interface{} {"location_region": "oregon"}},
                    {"bool": map[string]interface{} {
                    "should": []map[string]interface{} {
                        {"match": map[string]interface{} {"job_title": "dishwasher"}},
                        {"bool": map[string]interface{} {
                            "must": []map[string]interface{} {
                                {"term": map[string]interface{} {"job_title_role": "marketing"}},
                                {"term": map[string]interface{} {"job_title_levels": "manager"}},
                            },
                        },
                        },
                    },
                    },
                    },
                    {"exists": map[string]interface{} {"field": "linkedin_url"}},
                },
                "must_not": []map[string]interface{} {
                    {"term": map[string]interface{} {"location_locality": "portland"}},
                },
            },
        },
    }

    // Find all records matching query
    recruitingLeads := getAllPdlRecordsEs(elasticSearchQuery)
    fmt.Printf("Got %d recruiting leads for my wealthy client!\n", len(recruitingLeads))
    
    //GO make_money_with_data(recruiting_leads)!
}

// Run Person searches in batches with 6-second intervals
func getAllPdlRecordsEs(query interface{}) []pdlmodel.Person {
    // Store all records retreived in an array
    var allRecords []pdlmodel.Person
    batch := 1
    // The current scroll_token
    var scrollToken string
    const pageSize = 100    
        
    // Set your API key
    apiKey := "YOUR API KEY"
    // Set API key as environmental variable
    // apiKey := os.Getenv("API_KEY")

    // Create a client, specifying your API key
    client := pdl.New(apiKey)

    // Create a parameters JSON object
    p := pdlmodel.SearchParams {
        BaseParams: pdlmodel.BaseParams {
            Size: pageSize,
        },
        SearchBaseParams: pdlmodel.SearchBaseParams {
            Query: query,
            ScrollToken: scrollToken,
            Dataset: "all",
        },
    }
    
    // Keep retrieving records until unable to continue scrolling
    for batch == 1 || scrollToken != "" {
        // Pass the parameters object to the Person Search API
        response, err := client.Person.Search(context.Background(), p)
        
        // Check for successful response
        if err == nil {
            // Add records retrieved to the records array
            allRecords = append(allRecords, response.Data...)
            // Store scroll_token from response
            p.SearchBaseParams.ScrollToken, scrollToken = response.ScrollToken, response.ScrollToken
            
            fmt.Printf("Batch %d success!\n", batch)
            time.Sleep(6 * time.Second)
            batch++
        } else {
            fmt.Println("Unable to continue scrolling.")
            break
        }
    }
    fmt.Println("Done!")
        
    return allRecords
}
```

```
package main

import (
    "fmt"
    "time"
    "context"
)

// See https://github.com/peopledatalabs/peopledatalabs-go
import (
    pdl "github.com/peopledatalabs/peopledatalabs-go"
    pdlmodel "github.com/peopledatalabs/peopledatalabs-go/model"
)

func main() {
    // Create an SQL query
    sqlQuery := "SELECT * FROM person" +
        " WHERE location_region='oregon'" +
        " AND NOT location_locality='portland'" +
        " AND (" +
        "   job_title LIKE '%dishwasher%'" +
        "   OR (" +
        "     job_title_role='marketing'" +
        "     AND job_title_levels='manager'" +
        "   )" +
        " )" +
        " AND linkedin_url IS NOT NULL;"

    // Find all records matching query
    recruitingLeads := getAllPdlRecordsEs(sqlQuery)
    fmt.Printf("Got %d recruiting leads for my wealthy client!\n", len(recruitingLeads))
    
    //GO make_money_with_data(recruiting_leads)!
}

// Run Person searches in batches with 6-second intervals
func getAllPdlRecordsEs(query string) []pdlmodel.Person {
    // Store all records retreived in an array
    var allRecords []pdlmodel.Person
    batch := 1
    // The current scroll_token
    var scrollToken string
    const pageSize = 100    
        
    // Set your API key
    apiKey := "YOUR API KEY"
    // Set API key as environmental variable
    // apiKey := os.Getenv("API_KEY")

    // Create a client, specifying your API key
    client := pdl.New(apiKey)

    // Create a parameters JSON object
    p := pdlmodel.SearchParams {
        BaseParams: pdlmodel.BaseParams {
            Size: pageSize,
        },
        SearchBaseParams: pdlmodel.SearchBaseParams {
            SQL: query,
            ScrollToken: scrollToken,
            Dataset: "all",
        },
    }
    
    // Keep retrieving records until unable to continue scrolling
    for batch == 1 || scrollToken != "" {
        // Pass the parameters object to the Person Search API
        response, err := client.Person.Search(context.Background(), p)
        
        // Check for successful response
        if err == nil {
            // Add records retrieved to the records array
            allRecords = append(allRecords, response.Data...)
            // Store scroll_token from response
            p.SearchBaseParams.ScrollToken, scrollToken = response.ScrollToken, response.ScrollToken
            
            fmt.Printf("Batch %d success!\n", batch)
            time.Sleep(6 * time.Second)
            batch++
        } else {
            fmt.Println("Unable to continue scrolling.")
            break
        }
    }
    fmt.Println("Done!")
        
    return allRecords
}
```

```
from time import sleep
import requests, json

# Set your API key
API_KEY = "YOUR API KEY"

# Set the Person Search API URL
PDL_URL = "https://api.peopledatalabs.com/v5/person/search"

# Set headers
HEADERS = {
  'Content-Type': "application/json",
  'X-api-key': API_KEY
}

# Run Person searches in batches with 6-second intervals
def get_all_pdl_records_es(query):

    PAGE_SIZE = 100

    # Store all records retreived in an array
    all_records = []
    batch = 1

    # Create a parameters JSON object
    params = {
        'query': json.dumps(query),
        'size': PAGE_SIZE,
        'dataset': "all"
    }

    # Keep retrieving records until unable to continue scrolling
    while batch == 1 or params['scroll_token']:

        # Pass the parameters object to the Person Search API
        response = requests.get(
            PDL_URL,
            headers=HEADERS,
            params=params
        ).json()
				
        # Check for successful response
        if response['status'] == 200:
          # Add records retrieved to the records array
          all_records.extend(response['data'])
          # Store the scroll_token for next batch
          params['scroll_token'] = response['scroll_token']

          print(f"Batch {batch} success!")
          sleep(6)
          batch += 1
          
        else:
          print("Unable to continue scrolling.")
          break
    
    print("Done!")

    return all_records

if __name__ == '__main__':
    # Create an Elasticsearch query
    ES_QUERY = {
        "query": {
        "bool": {
        "must": [
            {"term": {"location_region": "oregon"}},
            {"bool": {
            "should": [
                {"match": {"job_title": "dishwasher"}},
                {"bool": {
                "must": [
                    {"term": {"job_title_role": "marketing"}},
                    {"term": {"job_title_levels": "manager"}}
                ]
                }}
            ]
            }
            },
        {"exists": {"field": "linkedin_url"}}
       ],
       "must_not":[
          {"term": {"location_locality": "portland"}},
       ]
        }
    }
    }

    # Find all records matching query
    recruiting_leads = get_all_pdl_records_es(ES_QUERY)
            
    print(f"Got {len(recruiting_leads)} recruiting leads for my wealthy client!")

    #GO make_money_with_data(recruiting_leads)!
```

```
from time import sleep 
import requests

# Set your API key
API_KEY = "YOUR API KEY"

# Set the Person Search API URL
PDL_URL = "https://api.peopledatalabs.com/v5/person/search"

# Set headers
HEADERS = {
  'Content-Type': "application/json",
  'X-api-key': API_KEY
}

# Run Person searches in batches with 6-second intervals
def get_all_pdl_records_sql(query):

    PAGE_SIZE = 100

    # Store all records retreived in an array
    all_records = []
    batch = 1

    # Create a parameters JSON object
    params = {
        'sql': query,
        'size': PAGE_SIZE,
      	'dataset': "all"
    }

    # Keep retrieving records until unable to continue scrolling
    while batch == 1 or params['scroll_token']:

        # Pass the parameters object to the Person Search API
        response = requests.get(
            PDL_URL,
            headers=HEADERS,
            params=params
        ).json()

        # Check for successful response
        if response['status'] == 200:
          # Add records retrieved to the records array
          all_records.extend(response['data'])
          # Store the scroll_token for next batch
          params['scroll_token'] = response['scroll_token']

          print(f"Batch {batch} success!")
          sleep(6)
          batch += 1
          
        else:
          print("Unable to continue scrolling.")
          break
        batch += 1
    
    print("Done!")

    return all_records

# Create an SQL query
SQL_QUERY = \
  """
    SELECT * FROM person
    WHERE location_region='oregon'
    AND NOT location_locality='portland'
    AND (
      job_title LIKE '%dishwasher%'
      OR (
        job_title_role='marketing'
        AND job_title_levels='manager'
      )
    )
    AND linkedin_url IS NOT NULL;
  """

# Find all records matching query
recruiting_leads = get_all_pdl_records_sql(SQL_QUERY)

print(f"got {len(recruiting_leads)} recruiting leads for my wealthy client!")

#GO make_money_with_data(recruiting_leads)!
```

## Ads

*"I want to sell yachts to rich people through ads on[Facebook](https://www.facebook.com/business/help/170456843145568?id=2469097953376494)."*

Python3 SDK (Elasticsearch)Python3 SDK (SQL)JavaScript (Elasticsearch)JavaScript (SQL)Ruby (Elasticsearch)Ruby (SQL)Go (Elasticsearch)Go (SQL)Python3 (Elasticsearch)Python3 (SQL)

```
from time import sleep
import json

# See https://github.com/peopledatalabs/peopledatalabs-python
from peopledatalabs import PDLPY

# Create a client, specifying your API key
CLIENT = PDLPY(
    api_key="YOUR API KEY",
)

# Run Person searches in batches with 6-second intervals
def get_all_pdl_records_es(query):

    PAGE_SIZE = 100

    # Store all records retreived in an array
    all_records = []
    batch = 1

    # Create a parameters JSON object
    params = {
        'query': query,
        'size': PAGE_SIZE,
        'dataset': "all"
    }

    # Keep retrieving records until unable to continue scrolling
    while batch == 1 or params['scroll_token']:

        # Pass the parameters object to the Person Search API
        response = CLIENT.person.search(**params).json()
				
        # Check for successful response
        if response['status'] == 200:
          # Add records retrieved to the records array
          all_records.extend(response['data'])
          # Store the scroll_token for next batch
          params['scroll_token'] = response['scroll_token']

          print(f"Batch {batch} success!")
          sleep(6)
          batch += 1
          
        else:
          print("Unable to continue scrolling.")
          break
    
    print("Done!")

    return all_records

if __name__ == '__main__':
    # Create an Elasticsearch query
    ES_QUERY = {
	   "query": {
           "bool": {
               "must": [
                    {"exists": {"field": "facebook_id"}},
                    {"prefix": {"interests": "yacht"}},
                    {"term": {"inferred_salary": ">250,000"}}
                ]
            }
        }
    }

    # Find all records matching query
    rich_yacht_people = get_all_pdl_records_es(ES_QUERY)
            
    print(f"Got {len(rich_yacht_people)} rich yacht people for my wealthy client!")

    #GO make_money_with_data(rich_yacht_people)!
```

```
from time import sleep
import json

# See https://github.com/peopledatalabs/peopledatalabs-python
from peopledatalabs import PDLPY

# Create a client, specifying your API key
CLIENT = PDLPY(
    api_key="YOUR API KEY",
)

# Run Person searches in batches with 6-second intervals
def get_all_pdl_records_sql(query):
    #runs search in batches with 6 second intervals 

    PAGE_SIZE = 100

    # Store all records retreived in an array
    all_records = []
    batch = 1

    # Create a parameters JSON object
    params = {
        'sql': query,
        'size': PAGE_SIZE,
        'dataset': "all"
    }

    # Keep retrieving records until unable to continue scrolling
    while batch == 1 or params['scroll_token']:

        # Pass the parameters object to the Person Search API
        response = CLIENT.person.search(**params).json()
				
        # Check for successful response
        if response['status'] == 200:
          # Add records retrieved to the records array
          all_records.extend(response['data'])
          # Store the scroll_token for next batch
          params['scroll_token'] = response['scroll_token']

          print(f"Batch {batch} success!")
          sleep(6)
          batch += 1
          
        else:
          print("Unable to continue scrolling.")
          break
    
    print("Done!")

    return all_records

# Create an SQL query
SQL_QUERY = \
"""
  SELECT * FROM person
  WHERE facebook_id IS NOT NULL
  AND interests LIKE 'yacht%'
  AND inferred_salary='>250,000';
"""

# Find all records matching query
rich_yacht_people = get_all_pdl_records_sql(SQL_QUERY)

print(f"got {len(rich_yacht_people)} rich yacht people for my wealthy client!")

#GO make_money_with_data(rich_yacht_people)
```

```
// See https://github.com/peopledatalabs/peopledatalabs-js
import PDLJS from 'peopledatalabs';

// Create a client, specifying your API key
const PDLJSClient = new PDLJS({ apiKey: "YOUR API KEY" });

// Create an Elasticsearch query
const esQuery = {
	   "query": {
           "bool": {
               "must": [
                    {"exists": {"field": "facebook_id"}},
                    {"prefix": {"interests": "yacht"}},
                    {"term": {"inferred_salary": ">250,000"}}
                ]
            }
        }
}

// Store all records retreived in an array
var allRecords = [];
// The current scroll_token
var scrollToken = null;
var pageSize = 100;
var batch = 1;

// Create a parameters JSON object
var params = {
    searchQuery: esQuery, 
    size: pageSize,
    scroll_token: null,
    dataset: "all"
}

// Run batches recursively
runBatch();

// Run Person searches in batches
function runBatch() {

    // Store current scroll_token in parameters object
    params.scroll_token = scrollToken;
    // Pass the current parameters object to the Person Search API
    PDLJSClient.person.search.elastic(params).then((data) => {
        // Add records retrieved to the records array
        Array.prototype.push.apply(allRecords, data.data);
        
        // Store scroll_token from response
        scrollToken = data['scroll_token'];
        
        console.log(`Batch ${batch} success!`);
        batch++;
        
        // Run searches in batches with 6-second intervals  
        if (scrollToken) {
            setTimeout(function() {
                runBatch(params);
            }, 6000);
        }
    }).catch((error) => {
        console.log("Unable to continue scrolling.");
        console.log("Done!");
        console.log(`Got ${allRecords.length} rich yacht people for my wealthy client!`);
    });
}
```

```
// See https://github.com/peopledatalabs/peopledatalabs-js
import PDLJS from 'peopledatalabs';

// Create a client, specifying your API key
const PDLJSClient = new PDLJS({ apiKey: "YOUR API KEY" });

// Create an SQL query
const sqlQuery = `SELECT * FROM person
                    WHERE facebook_id IS NOT NULL
                    AND interests LIKE 'yacht%'
                    AND inferred_salary='>250,000';`;

// Store all records retreived in an array
var allRecords = [];
// The current scroll_token
var scrollToken = null;
var pageSize = 100;
var batch = 1;

// Create a parameters JSON object
var params = {
    searchQuery: sqlQuery, 
    size: pageSize,
    scroll_token: null,
    dataset: "all"
}

// Run batches recursively
runBatch();

// Run Person searches in batches
function runBatch() {

    // Store current scroll_token in parameters object
    params.scroll_token = scrollToken;
    // Pass the current parameters object to the Person Search API
    PDLJSClient.person.search.sql(params).then((data) => {
        // Add records retrieved to the records array
        Array.prototype.push.apply(allRecords, data.data);
        
        // Store scroll_token from response
        scrollToken = data['scroll_token'];
        
        console.log(`Batch ${batch} success!`);
        batch++;
        
        // Run searches in batches with 6-second intervals 
        if (scrollToken) {
            setTimeout(function() {
                runBatch(params);
            }, 6000);
        }
    }).catch((error) => {
        console.log("Unable to continue scrolling.");
        console.log("Done!");
        console.log(`Got ${allRecords.length} rich yacht people for my wealthy client!`);
    });
}
```

```
require 'json'

# See https://github.com/peopledatalabs/peopledatalabs-ruby
require 'peopledatalabs'

# Set your API key
Peopledatalabs.api_key = 'YOUR API KEY'

PAGE_SIZE = 100

# Run Person searches in batches with 6-second intervals
def get_all_pdl_records_es(query)

    # Store all records retreived in an array
    all_records = []
    batch = 1
    # The current scroll_token
    scroll_token = {}

    # Keep retrieving records until unable to continue scrolling
    while batch == 1 || !scroll_token.nil?

        # Pass parameters to the Person Search API
        response = Peopledatalabs::Search.person(searchType: 'elastic', query: query, size: PAGE_SIZE, scroll_token: scroll_token, dataset: "all")
				
        # Check for successful response
        if response['status'] == 200
          # Add records retrieved to the records array
          all_records += response['data']
          # Store the scroll_token for next batch
          scroll_token = response['scroll_token']

          puts "Batch #{batch} success!"
          sleep(6)
          batch += 1
          
        else
          puts "Unable to continue scrolling."
          break
        end
    end
    
    puts "Done!"

    return all_records
end

# Create an Elasticsearch query
ES_QUERY = {
    "query": {
        "bool": {
           "must": [
                {"exists": {"field": "facebook_id"}},
                {"prefix": {"interests": "yacht"}},
                {"term": {"inferred_salary": ">250,000"}}
            ]
        }
    }
}

# Find all records matching query
rich_yacht_people = get_all_pdl_records_es(ES_QUERY)
            
puts "Got #{rich_yacht_people.length()} rich yacht people for my wealthy client!"

#GO make_money_with_data(rich_yacht_people)!
```

```
require 'json'

# See https://github.com/peopledatalabs/peopledatalabs-ruby
require 'peopledatalabs'

# Set your API key
Peopledatalabs.api_key = 'YOUR API KEY'

PAGE_SIZE = 100

# Run Person searches in batches with 6-second intervals
def get_all_pdl_records_sql(query)

    # Store all records retreived in an array
    all_records = []
    batch = 1
    # The current scroll_token
    scroll_token = {}

    # Keep retrieving records until unable to continue scrolling
    while batch == 1 || !scroll_token.nil?

        # Pass parameters to the Person Search API
        response = Peopledatalabs::Search.person(searchType: 'sql', query: query, size: PAGE_SIZE, scroll_token: scroll_token, dataset: "all")
				
        # Check for successful response
        if response['status'] == 200
          # Add records retrieved to the records array
          # Store the scroll_token for next batch
          all_records += response['data']
          scroll_token = response['scroll_token']

          puts "Batch #{batch} success!"
          sleep(6)
          batch += 1
          
        else
          puts "Unable to continue scrolling."
          break
        end
    end
    
    puts "Done!"

    return all_records
end

# Create an SQL query
SQL_QUERY = \
"""
  SELECT * FROM person
  WHERE facebook_id IS NOT NULL
  AND interests LIKE 'yacht%'
  AND inferred_salary='>250,000';
"""

# Find all records matching query
rich_yacht_people = get_all_pdl_records_sql(SQL_QUERY)
            
puts "Got #{rich_yacht_people.length()} rich yacht people for my wealthy client!"

#GO make_money_with_data(rich_yacht_people)!
```

```
package main

import (
    "fmt"
    "time"
    "context"
)

// See https://github.com/peopledatalabs/peopledatalabs-go
import (
    pdl "github.com/peopledatalabs/peopledatalabs-go"
    pdlmodel "github.com/peopledatalabs/peopledatalabs-go/model"
)

func main() {
    // Create an Elasticsearch query
    elasticSearchQuery := map[string]interface{} {
        "query": map[string]interface{} {
            "bool": map[string]interface{} {
                "must": []map[string]interface{} {
                    {"exists": map[string]interface{}{"field": "facebook_id"}},
                    {"prefix": map[string]interface{}{"interests": "yacht"}},
                    {"term": map[string]interface{}{"inferred_salary": ">250,000"}},
                },
            },
        },
    }

    // Find all records matching query
    richYachtPeople := getAllPdlRecordsEs(elasticSearchQuery)
    fmt.Printf("Got %d rich yacht people for my wealthy client!\n", len(richYachtPeople))
    
    //GO make_money_with_data(rich_yacht_people)!
}

// Run Person searches in batches with 6-second intervals
func getAllPdlRecordsEs(query interface{}) []pdlmodel.Person {
    // Store all records retreived in an array
    var allRecords []pdlmodel.Person
    batch := 1
    // The current scroll_token
    var scrollToken string
    const pageSize = 100    
        
    // Set your API key
    apiKey := "YOUR API KEY"
    // Set API key as environmental variable
    // apiKey := os.Getenv("API_KEY")

    // Create a client, specifying your API key
    client := pdl.New(apiKey)

    // Create a parameters JSON object
    p := pdlmodel.SearchParams {
        BaseParams: pdlmodel.BaseParams {
            Size: pageSize,
        },
        SearchBaseParams: pdlmodel.SearchBaseParams {
            Query: query,
            ScrollToken: scrollToken,
            Dataset: "all",
        },
    }
    
    // Keep retrieving records until unable to continue scrolling
    for batch == 1 || scrollToken != "" {
        // Pass the parameters object to the Person Search API
        response, err := client.Person.Search(context.Background(), p)
        
        // Check for successful response
        if err == nil {
            // Add records retrieved to the records array
            allRecords = append(allRecords, response.Data...)
            // Store scroll_token from response
            p.SearchBaseParams.ScrollToken, scrollToken = response.ScrollToken, response.ScrollToken
            
            fmt.Printf("Batch %d success!\n", batch)
            time.Sleep(6 * time.Second)
            batch++
        } else {
            fmt.Println("Unable to continue scrolling.")
            break
        }
    }
    fmt.Println("Done!")
        
    return allRecords
}
```

```
package main

import (
    "fmt"
    "time"
    "context"
)

// See https://github.com/peopledatalabs/peopledatalabs-go
import (
    pdl "github.com/peopledatalabs/peopledatalabs-go"
    pdlmodel "github.com/peopledatalabs/peopledatalabs-go/model"
)

func main() {
    // Create an SQL query
    sqlQuery := "SELECT * FROM person" +
        " WHERE facebook_id IS NOT NULL" +
        " AND interests LIKE 'yacht%'" +
        " AND inferred_salary='>250,000';"

    // Find all records matching query
    richYachtPeople := getAllPdlRecordsEs(sqlQuery)
    fmt.Printf("Got %d rich yacht people for my wealthy client!\n", len(richYachtPeople))
    
    //GO make_money_with_data(rich_yacht_people)!
}

// Run Person searches in batches with 6-second intervals
func getAllPdlRecordsEs(query string) []pdlmodel.Person {
    // Store all records retreived in an array
    var allRecords []pdlmodel.Person
    batch := 1
    // The current scroll_token
    var scrollToken string
    const pageSize = 100    
        
    // Set your API key
    apiKey := "YOUR API KEY"
    // Set API key as environmental variable
    // apiKey := os.Getenv("API_KEY")

    // Create a client, specifying your API key
    client := pdl.New(apiKey)

    // Create a parameters JSON object
    p := pdlmodel.SearchParams {
        BaseParams: pdlmodel.BaseParams {
            Size: pageSize,
        },
        SearchBaseParams: pdlmodel.SearchBaseParams {
            SQL: query,
            ScrollToken: scrollToken,
            Dataset: "all",
        },
    }
    
    // Keep retrieving records until unable to continue scrolling
    for batch == 1 || scrollToken != "" {
        // Pass the parameters object to the Person Search API
        response, err := client.Person.Search(context.Background(), p)
        
        // Check for successful response
        if err == nil {
            // Add records retrieved to the records array
            allRecords = append(allRecords, response.Data...)
            // Store scroll_token from response
            p.SearchBaseParams.ScrollToken, scrollToken = response.ScrollToken, response.ScrollToken
            
            fmt.Printf("Batch %d success!\n", batch)
            time.Sleep(6 * time.Second)
            batch++
        } else {
            fmt.Println("Unable to continue scrolling.")
            break
        }
    }
    fmt.Println("Done!")
        
    return allRecords
}
```

```
from time import sleep
import requests, json

# Set your API key
API_KEY = "YOUR API KEY"

# Set the Person Search API URL
PDL_URL = "https://api.peopledatalabs.com/v5/person/search"

# Set headers
HEADERS = {
  'Content-Type': "application/json",
  'X-api-key': API_KEY
}

# Run Person searches in batches with 6-second intervals
def get_all_pdl_records_es(query):

    PAGE_SIZE = 100

    # Store all records retreived in an array
    all_records = []
    batch = 1

    # Create a parameters JSON object
    params = {
        'query': json.dumps(query),
        'size': PAGE_SIZE,
        'dataset': "all"
    }

    # Keep retrieving records until unable to continue scrolling
    while batch == 1 or params['scroll_token']:

        # Pass the parameters object to the Person Search API
        response = requests.get(
            PDL_URL,
            headers=HEADERS,
            params=params
        ).json()
				
        # Check for successful response
        if response['status'] == 200:
          # Add records retrieved to the records array
          all_records.extend(response['data'])
          # Store the scroll_token for next batch
          params['scroll_token'] = response['scroll_token']

          print(f"Batch {batch} success!")
          sleep(6)
          batch += 1
          
        else:
          print("Unable to continue scrolling.")
          break
    
    print("Done!")

    return all_records

if __name__ == '__main__':
    # Create an Elasticsearch query
    ES_QUERY = {
	   "query": {
           "bool": {
               "must": [
                    {"exists": {"field": "facebook_id"}},
                    {"prefix": {"interests": "yacht"}},
                    {"term": {"inferred_salary": ">250,000"}}
                ]
            }
        }
    }

    # Find all records matching query
    rich_yacht_people = get_all_pdl_records_es(ES_QUERY)
            
    print(f"Got {len(rich_yacht_people)} rich yacht people for my wealthy client!")

    #GO make_money_with_data(rich_yacht_people)!
```

```
from time import sleep
import requests, json

# Set your API key
API_KEY = "YOUR API KEY"

# Set the Person Search API URL
PDL_URL = "https://api.peopledatalabs.com/v5/person/search"

# Set headers
HEADERS = {
  'Content-Type': "application/json",
  'X-api-key': API_KEY
}

# Run Person searches in batches with 6-second intervals
def get_all_pdl_records_sql(query):

    PAGE_SIZE = 100

    # Store all records retreived in an array
    all_records = []
    batch = 1

    # Create a parameters JSON object
    params = {
        'sql': query,
        'size': PAGE_SIZE,
      	'dataset': "all"
    }

    # Keep retrieving records until unable to continue scrolling
    while batch == 1 or params['scroll_token']:

        # Pass the parameters object to the Person Search API
        response = requests.get(
            PDL_URL,
            headers=HEADERS,
            params=params
        ).json()

        # Check for successful response
        if response['status'] == 200:
          # Add records retrieved to the records array
          all_records.extend(response['data'])
          # Store the scroll_token for next batch
          params['scroll_token'] = response['scroll_token']

          print(f"Batch {batch} success!")
          sleep(6)
          batch += 1
          
        else:
          print("Unable to continue scrolling.")
          break
    
    print("Done!")

    return all_records

# Create an SQL query
SQL_QUERY = \
"""
  SELECT * FROM person
  WHERE facebook_id IS NOT NULL
  AND interests LIKE 'yacht%'
  AND inferred_salary='>250,000';
"""

# Find all records matching query
rich_yacht_people = get_all_pdl_records_sql(SQL_QUERY)

print(f"got {len(rich_yacht_people)} rich yacht people for my wealthy client!")

#GO make_money_with_data(rich_yacht_people)
```

## Customer Insights

*"I want information about my biggest customer ([Zenefits](http://www.zenefits.com).)"*

Python3 SDK (Elasticsearch)Python3 SDK (SQL)JavaScript (Elasticsearch)JavaScript (SQL)Ruby (Elasticsearch)Ruby (SQL)Go (Elasticsearch)Go (SQL)Python3 (Elasticsearch)Python3 (SQL)

```
from time import sleep
import json

# See https://github.com/peopledatalabs/peopledatalabs-python
from peopledatalabs import PDLPY

# Create a client, specifying your API key
CLIENT = PDLPY(
    api_key="YOUR API KEY",
)

# Run Person searches in batches with 6-second intervals
def get_all_pdl_records_es(query):

    PAGE_SIZE = 100

    # Store all records retreived in an array
    all_records = []
    batch = 1

    # Create a parameters JSON object
    params = {
        'query': query,
        'size': PAGE_SIZE,
        'dataset': "all"
    }

    # Keep retrieving records until unable to continue scrolling
    while batch == 1 or params['scroll_token']:

        # Pass the parameters object to the Person Search API
        response = CLIENT.person.search(**params).json()
				
        # Check for successful response
        if response['status'] == 200:
          # Add records retrieved to the records array
          all_records.extend(response['data'])
          # Store the scroll_token for next batch
          params['scroll_token'] = response['scroll_token']

          print(f"Batch {batch} success!")
          sleep(6)
          batch += 1
          
        else:
          print("Unable to continue scrolling.")
          break
    
    print("Done!")

    return all_records

if __name__ == '__main__':
    # Create an Elasticsearch query
    ES_QUERY = {
        "query": {
            "term": {"job_company_website": "zenefits.com"}
        }
    }

    # Find all records matching query
    all_zenefits_employees = get_all_pdl_records_es(ES_QUERY)

    # Create aggregate objects
    skills_agg = {}
    titles_agg = {}
    schools_agg = {}
    other_companies_agg = {}

    # Iterate through records array for aggregation
    for record in all_zenefits_employees:
        # Aggregate skills
        for skill in record['skills']:
            skills_agg.setdefault(skill, 0)
            skills_agg[skill] += 1
        # Aggregate job titles
        if record['job_title']:
            titles_agg.setdefault(record['job_title'], 0)
            titles_agg[record['job_title']] += 1
        # Aggregate schools
        for edu in record['education']:
            if edu['school'] and edu['school']['type'] == "post-secondary institution":
                schools_agg.setdefault(edu['school']['name'], 0)
                schools_agg[edu['school']['name']] += 1
        # Aggregate other companies
        for exp in record['experience']:
            if exp['company'] and exp['company']['name'] != 'zenefits':
                other_companies_agg.setdefault(exp['company']['name'], 0)
                other_companies_agg[exp['company']['name']] += 1

    # Sort aggregate objects by count and print top 10 for each
    print("Top 10 skills for zenefits employees:")
    for skill, count in sorted(
        skills_agg.items(), key = lambda x: x[1], reverse=True
    )[:10]:
        print(count, skill)

    print("Top 10 titles for zenefits employees:")
    for title, count in sorted(
        titles_agg.items(), key = lambda x: x[1], reverse=True
    )[:10]:
        print(count, title)
 
    print("Top 10 universities for zenefits employees:")
    for school, count in sorted(
        schools_agg.items(), key = lambda x: x[1], reverse=True
    )[:10]:
        print(count, school)
  
    print("Top 10 former companies for zenefits employees:")
    for company, count in sorted(
        other_companies_agg.items(), key = lambda x: x[1], reverse=True
    )[:10]:
        print(count, company)
```

```
from time import sleep
import json

# See https://github.com/peopledatalabs/peopledatalabs-python
from peopledatalabs import PDLPY

# Create a client, specifying your API key
CLIENT = PDLPY(
    api_key="YOUR API KEY",
)

# Run Person searches in batches with 6-second intervals
def get_all_pdl_records_sql(query):

    PAGE_SIZE = 100

    # Store all records retreived in an array
    all_records = []
    batch = 1

    # Create a parameters JSON object
    params = {
        'sql': query,
        'size': PAGE_SIZE,
        'dataset': "all"
    }

    # Keep retrieving records until unable to continue scrolling
    while batch == 1 or params['scroll_token']:

        # Pass the parameters object to the Person Search API
        response = CLIENT.person.search(**params).json()
				
        # Check for successful response
        if response['status'] == 200:
          # Add records retrieved to the records array
          all_records.extend(response['data'])
          # Store the scroll_token for next batch
          params['scroll_token'] = response['scroll_token']

          print(f"Batch {batch} success!")
          sleep(6)
          batch += 1
          
        else:
          print("Unable to continue scrolling.")
          break
    
    print("Done!")

    return all_records

# Create an SQL query
SQL_QUERY = \
"""
  SELECT * FROM person
  WHERE job_company_website='zenefits.com';
"""

# Find all records matching query
all_zenefits_employees = get_all_pdl_records_sql(SQL_QUERY)

# Create aggregate objects
skills_agg = {}
titles_agg = {}
schools_agg = {}
other_companies_agg = {}

# Iterate through records array for aggregation
for record in all_zenefits_employees:
  # Aggregate skills
  for skill in record['skills']:
    skills_agg.setdefault(skill, 0)
    skills_agg[skill] += 1
  # Aggregate job titles
  if record['job_title']:
    titles_agg.setdefault(record['job_title'], 0)
    titles_agg[record['job_title']] += 1
  # Aggregate schools
  for edu in record['education']:
    if edu['school'] and edu['school']['type'] == "post-secondary institution":
      schools_agg.setdefault(edu['school']['name'], 0)
      schools_agg[edu['school']['name']] += 1
  # Aggregate other companies
  for exp in record['experience']:
    if exp['company'] and exp['company']['name'] != 'zenefits':
      other_companies_agg.setdefault(exp['company']['name'], 0)
      other_companies_agg[exp['company']['name']] += 1

# Sort aggregate objects by count and print top 10 for each
print("Top 10 skills for zenefits employees:")
for skill, count in sorted(
  skills_agg.items(), key = lambda x: x[1], reverse=True
)[:10]:
  print(count, skill)

print("Top 10 titles for zenefits employees:")
for title, count in sorted(
  titles_agg.items(), key = lambda x: x[1], reverse=True
)[:10]:
  print(count, title)
 
print("Top 10 universities for zenefits employees:")
for school, count in sorted(
  schools_agg.items(), key = lambda x: x[1], reverse=True
)[:10]:
  print(count, school)
  
print("Top 10 former companies for zenefits employees:")
for company, count in sorted(
  other_companies_agg.items(), key = lambda x: x[1], reverse=True
)[:10]:
  print(count, company)
```

```
// See https://github.com/peopledatalabs/peopledatalabs-js
import PDLJS from 'peopledatalabs';

// Create a client, specifying your API key
const PDLJSClient = new PDLJS({ apiKey: "YOUR API KEY" });

// Create an Elasticsearch query
const esQuery = {
	   "query": {
            "term": {"job_company_website": "zenefits.com"}
        }
}

// Store all records retreived in an array
var allRecords = [];
// The current scroll_token
var scrollToken = null;
var pageSize = 100;
var batch = 1;

// Create a parameters JSON object
var params = {
    searchQuery: esQuery, 
    size: pageSize,
    scroll_token: null,
    dataset: "all"
}

// Run batches recursively
runBatch();

// Run Person searches in batches
function runBatch() {

    // Store current scroll_token in parameters object
    params.scroll_token = scrollToken;
    // Pass the current parameters object to the Person Search API
    PDLJSClient.person.search.elastic(params).then((data) => {
        // Add records retrieved to the records array
        Array.prototype.push.apply(allRecords, data.data);
        
        // Store scroll_token from response
        scrollToken = data['scroll_token'];
        
        console.log(`Batch ${batch} success!`);
        batch++;
        
        // Run searches in batches with 6-second intervals  
        if (scrollToken) {
            setTimeout(function() {
                runBatch(params);
            }, 6000);
        }
    }).catch((error) => {
        console.log("Unable to continue scrolling.");
        console.log("Done!");
        printResults();
    });
}

// Aggregate, sort and print data
function printResults() {

    // Create aggregate objects
    var skillsAgg = {};
    var titlesAgg = {};
    var schoolsAgg = {};
    var otherCompaniesAgg = {};
    
    // Iterate through records array for aggregation
    for (let record in allRecords) {
        // Aggregate skills
        for (let skill in allRecords[record]["skills"]) {
            if (!skillsAgg[allRecords[record]["skills"][skill]]) {
                skillsAgg[allRecords[record]["skills"][skill]] = 0;
            }
            skillsAgg[allRecords[record]["skills"][skill]]++;
        }
        // Aggregate job titles
        if (allRecords[record]["job_title"]) {
            if (!titlesAgg[allRecords[record]["job_title"]]) {
                titlesAgg[allRecords[record]["job_title"]] = 0;
            }
            titlesAgg[allRecords[record]["job_title"]]++;
        }
        // Aggregate schools
        for (let edu in allRecords[record]["education"]) {
           if (allRecords[record]["education"][edu]["school"] && 
               allRecords[record]["education"][edu]["school"]["type"] == "post-secondary institution") {
                   if (!schoolsAgg[allRecords[record]["education"][edu]["school"]["name"]]) {
                       schoolsAgg[allRecords[record]["education"][edu]["school"]["name"]] = 0;
                   }
                   schoolsAgg[allRecords[record]["education"][edu]["school"]["name"]]++;
           }
        }
        // Aggregate other companies
        for (let exp in allRecords[record]["experience"]) {
            if (allRecords[record]["experience"][exp]["company"] && 
                allRecords[record]["experience"][exp]["company"]["name"] != "zenefits") {
                    if (!otherCompaniesAgg[allRecords[record]["experience"][exp]["company"]["name"]]) {
                        otherCompaniesAgg[allRecords[record]["experience"][exp]["company"]["name"]] = 0;
                    }
                    otherCompaniesAgg[allRecords[record]["experience"][exp]["company"]["name"]]++
            }
        }
    }
    
    console.log("Top 10 skills for zenefits employees:");
    sortAndPrint(skillsAgg);
    
    console.log("Top 10 titles for zenefits employees:");
    sortAndPrint(titlesAgg);
    
    console.log("Top 10 universities for zenefits employees:");
    sortAndPrint(schoolsAgg);
    
    console.log("Top 10 former companies for zenefits employees:");
    sortAndPrint(otherCompaniesAgg);
}

// Sort object and print top 10
function sortAndPrint(object) {
    var sortable = [];
    
    for (let field in object) {
        sortable.push([field, object[field]]);
    }

    sortable.sort(function(a, b) {
        return b[1] - a[1];
        });
    for (let i = 0; i < 10; i++) {
        console.log(sortable[i][0]);    
    }
}
```

```
// See https://github.com/peopledatalabs/peopledatalabs-js
import PDLJS from 'peopledatalabs';

// Create a client, specifying your API key
const PDLJSClient = new PDLJS({ apiKey: "YOUR API KEY" });

// Create an SQL query
const sqlQuery = `SELECT * FROM person
                    WHERE job_company_website='zenefits.com';`;

// Store all records retreived in an array
var allRecords = [];
// The current scroll_token
var scrollToken = null;
var pageSize = 100;
var batch = 1;

// Create a parameters JSON object
var params = {
    searchQuery: sqlQuery, 
    size: pageSize,
    scroll_token: null,
    dataset: "all"
}

// Run batches recursively
runBatch();

// Run Person searches in batches
function runBatch() {

    // Store current scroll_token in parameters object
    params.scroll_token = scrollToken;
    // Pass the current parameters object to the Person Search API
    PDLJSClient.person.search.sql(params).then((data) => {
        // Add records retrieved to the records array
        Array.prototype.push.apply(allRecords, data.data);
        
        // Store scroll_token from response
        scrollToken = data['scroll_token'];
        
        console.log(`Batch ${batch} success!`);
        batch++;
        
        // Run searches in batches with 6-second intervals 
        if (scrollToken) {
            setTimeout(function() {
                runBatch(params);
            }, 6000);
        }
    }).catch((error) => {
        console.log("Unable to continue scrolling.");
        console.log("Done!");
        printResults();
    });
}

// Aggregate, sort and print data
function printResults() {

    // Create aggregate objects
    var skillsAgg = {};
    var titlesAgg = {};
    var schoolsAgg = {};
    var otherCompaniesAgg = {};
    
    // Iterate through records array for aggregation
    for (let record in allRecords) {
        // Aggregate skills
        for (let skill in allRecords[record]["skills"]) {
            if (!skillsAgg[allRecords[record]["skills"][skill]]) {
                skillsAgg[allRecords[record]["skills"][skill]] = 0;
            }
            skillsAgg[allRecords[record]["skills"][skill]]++;
        }
        // Aggregate job titles
        if (allRecords[record]["job_title"]) {
            if (!titlesAgg[allRecords[record]["job_title"]]) {
                titlesAgg[allRecords[record]["job_title"]] = 0;
            }
            titlesAgg[allRecords[record]["job_title"]]++;
        }
        // Aggregate schools
        for (let edu in allRecords[record]["education"]) {
           if (allRecords[record]["education"][edu]["school"] && 
               allRecords[record]["education"][edu]["school"]["type"] == "post-secondary institution") {
                   if (!schoolsAgg[allRecords[record]["education"][edu]["school"]["name"]]) {
                       schoolsAgg[allRecords[record]["education"][edu]["school"]["name"]] = 0;
                   }
                   schoolsAgg[allRecords[record]["education"][edu]["school"]["name"]]++;
           }
        }
        // Aggregate other companies
        for (let exp in allRecords[record]["experience"]) {
            if (allRecords[record]["experience"][exp]["company"] && 
                allRecords[record]["experience"][exp]["company"]["name"] != "zenefits") {
                    if (!otherCompaniesAgg[allRecords[record]["experience"][exp]["company"]["name"]]) {
                        otherCompaniesAgg[allRecords[record]["experience"][exp]["company"]["name"]] = 0;
                    }
                    otherCompaniesAgg[allRecords[record]["experience"][exp]["company"]["name"]]++
            }
        }
    }
    
    console.log("Top 10 skills for zenefits employees:");
    sortAndPrint(skillsAgg);
    
    console.log("Top 10 titles for zenefits employees:");
    sortAndPrint(titlesAgg);
    
    console.log("Top 10 universities for zenefits employees:");
    sortAndPrint(schoolsAgg);
    
    console.log("Top 10 former companies for zenefits employees:");
    sortAndPrint(otherCompaniesAgg);
}

// Sort object and print top 10
function sortAndPrint(object) {
    var sortable = [];
    
    for (let field in object) {
        sortable.push([field, object[field]]);
    }

    sortable.sort(function(a, b) {
        return b[1] - a[1];
        });
    for (let i = 0; i < 10; i++) {
        console.log(sortable[i][0]);    
    }
}
```

```
# See https://github.com/peopledatalabs/peopledatalabs-ruby
require 'peopledatalabs'

# Set your API key
Peopledatalabs.api_key = 'YOUR API KEY'

PAGE_SIZE = 100

# Run Person searches in batches with 6-second intervals
def get_all_pdl_records_es(query)

    # Store all records retreived in an array
    all_records = []
    batch = 1
    # The current scroll_token
    scroll_token = {}

    # Keep retrieving records until unable to continue scrolling
    while batch == 1 || !scroll_token.nil?

        # Pass parameters to the Person Search API
        response = Peopledatalabs::Search.person(searchType: 'elastic', query: query, size: PAGE_SIZE, scroll_token: scroll_token, dataset: "all")
				
        # Check for successful response
        if response['status'] == 200
          # Add records retrieved to the records array
          all_records += response['data']
          # Store the scroll_token for next batch
          scroll_token = response['scroll_token']

          puts "Batch #{batch} success!"
          sleep(6)
          batch += 1
          
        else
          puts "Unable to continue scrolling."
          break
        end
    end
    
    puts "Done!"

    return all_records
end

# Create an Elasticsearch query
ES_QUERY = {
    "query": {
        "term": {"job_company_website": "zenefits.com"}
    }
}

# Find all records matching query
all_zenefits_employees = get_all_pdl_records_es(ES_QUERY)

# Create aggregate objects
skills_agg = {}
titles_agg = {}
schools_agg = {}
other_companies_agg = {}

# Iterate through records array for aggregation
all_zenefits_employees.each do |record|
    # Aggregate skills
    record['skills'].each do |skill|
        skills_agg[skill] = skills_agg.fetch(skill, 0)
        skills_agg[skill] += 1
    end
    # Aggregate job titles
    if record.key?('job_title')
        titles_agg[record['job_title']] = titles_agg.fetch(record['job_title'], 0)
        titles_agg[record['job_title']] += 1
    end
    # Aggregate schools
    record['education'].each do |edu|
        if edu.key?('school') && !edu['school'].nil? && edu['school']['type'] == "post-secondary institution"
            schools_agg[edu['school']['name']] = schools_agg.fetch(edu['school']['name'], 0)
            schools_agg[edu['school']['name']] += 1
        end
    end
    # Aggregate other companies
    record['experience'].each do |exp|
        if exp.key?('company') && !exp['company'].nil? && exp['company']['name'] != 'zenefits'
            other_companies_agg[exp['company']['name']] = other_companies_agg.fetch(exp['company']['name'], 0)
            other_companies_agg[exp['company']['name']] += 1
        end
    end
end

# Sort aggregate objects by count and print top 10 for each
puts "Top 10 skills for zenefits employees:"
skills_agg.sort_by(&:last).reverse.first(10).each { |key, value| puts "#{key} #{value}" }

puts "Top 10 titles for zenefits employees:"
titles_agg.sort_by(&:last).reverse.first(10).each { |key, value| puts "#{key} #{value}" }

puts "Top 10 universities for zenefits employees:"
schools_agg.sort_by(&:last).reverse.first(10).each { |key, value| puts "#{key} #{value}" }
 
puts "Top 10 former companies for zenefits employees:"
other_companies_agg.sort_by(&:last).reverse.first(10).each { |key, value| puts "#{key} #{value}" }
```

```
# See https://github.com/peopledatalabs/peopledatalabs-ruby
require 'peopledatalabs'

# Set your API key
Peopledatalabs.api_key = 'YOUR API KEY'

PAGE_SIZE = 100

# Run Person searches in batches with 6-second intervals
def get_all_pdl_records_sql(query)

    # Store all records retreived in an array
    all_records = []
    batch = 1
    # The current scroll_token
    scroll_token = {}

    # Keep retrieving records until unable to continue scrolling
    while batch == 1 || !scroll_token.nil?

        # Pass parameters to the Person Search API
        response = Peopledatalabs::Search.person(searchType: 'sql', query: query, size: PAGE_SIZE, scroll_token: scroll_token, dataset: "all")
				
        # Check for successful response
        if response['status'] == 200
          # Add records retrieved to the records array
          all_records += response['data']
          # Store the scroll_token for next batch
          scroll_token = response['scroll_token']

          puts "Batch #{batch} success!"
          sleep(6)
          batch += 1
          
        else
          puts "Unable to continue scrolling."
          break
        end
    end
    
    puts "Done!"

    return all_records
end

# Create an SQL query
SQL_QUERY = \
"""
  SELECT * FROM person
  WHERE job_company_website='zenefits.com';
"""

# Find all records matching query
all_zenefits_employees = get_all_pdl_records_sql(SQL_QUERY)

# Create aggregate objects
skills_agg = {}
titles_agg = {}
schools_agg = {}
other_companies_agg = {}

# Iterate through records array for aggregation
all_zenefits_employees.each do |record|
    # Aggregate skills
    record['skills'].each do |skill|
        skills_agg[skill] = skills_agg.fetch(skill, 0)
        skills_agg[skill] += 1
    end
    # Aggregate job titles
    if record.key?('job_title')
        titles_agg[record['job_title']] = titles_agg.fetch(record['job_title'], 0)
        titles_agg[record['job_title']] += 1
    end
    # Aggregate schools
    record['education'].each do |edu|
        if edu.key?('school') && !edu['school'].nil? && edu['school']['type'] == "post-secondary institution"
            schools_agg[edu['school']['name']] = schools_agg.fetch(edu['school']['name'], 0)
            schools_agg[edu['school']['name']] += 1
        end
    end
    # Aggregate other companies
    record['experience'].each do |exp|
        if exp.key?('company') && !exp['company'].nil? && exp['company']['name'] != 'zenefits'
            other_companies_agg[exp['company']['name']] = other_companies_agg.fetch(exp['company']['name'], 0)
            other_companies_agg[exp['company']['name']] += 1
        end
    end
end

# Sort aggregate objects by count and print top 10 for each
puts "Top 10 skills for zenefits employees:"
skills_agg.sort_by(&:last).reverse.first(10).each { |key, value| puts "#{key} #{value}" }

puts "Top 10 titles for zenefits employees:"
titles_agg.sort_by(&:last).reverse.first(10).each { |key, value| puts "#{key} #{value}" }

puts "Top 10 universities for zenefits employees:"
schools_agg.sort_by(&:last).reverse.first(10).each { |key, value| puts "#{key} #{value}" }
 
puts "Top 10 former companies for zenefits employees:"
other_companies_agg.sort_by(&:last).reverse.first(10).each { |key, value| puts "#{key} #{value}" }
```

```
package main

import (
    "fmt"
    "time"
    "sort"
    "context"
)

// See https://github.com/peopledatalabs/peopledatalabs-go
import (
    pdl "github.com/peopledatalabs/peopledatalabs-go"
    pdlmodel "github.com/peopledatalabs/peopledatalabs-go/model"
)

func main() {
    // Create an Elasticsearch query
    elasticSearchQuery := map[string]interface{} {
        "query": map[string]interface{} {
            "bool": map[string]interface{} {
                "must": []map[string]interface{} {
                    {"term": map[string]interface{}{"job_company_website": "zenefits.com"}},
                },
            },
        },
    }

    // Find all records matching query
    allZenefitsEmployees := getAllPdlRecordsEs(elasticSearchQuery)
    
    // Create aggregate objects
    skillsAgg := make(map[string]int)
    titlesAgg := make(map[string]int)
    schoolsAgg := make(map[string]int)
    otherCompaniesAgg := make(map[string]int)
    
    // Iterate through records array for aggregation
    for _, record := range allZenefitsEmployees {
        // Aggregate skills
        for _, skill := range record.Skills {
            skillsAgg[skill]++
        }
        // Aggregate job titles
        if record.JobTitle != "" {
            titlesAgg[record.JobTitle]++
        }
        // Aggregate schools
        for _, edu := range record.Education {
            if edu.School.Name != "" && edu.School.Type == "post-secondary institution" {
                schoolsAgg[edu.School.Name]++
            }
        }
        // Aggregate other companies
        for _, exp := range record.Experience {
            if exp.Company.Name != "zenefits" {
                otherCompaniesAgg[exp.Company.Name]++
            }
        }
    }
    
    // Sort aggregate objects by count and print top 10 for each
    fmt.Println("Top 10 skills for zenefits employees:")
    for _, skill := range rank(skillsAgg) {
        fmt.Println(skill, skillsAgg[skill])
    }
    
    fmt.Println("Top 10 titles for zenefits employees:")
    for _, title := range rank(titlesAgg) {
        fmt.Println(title, titlesAgg[title])
    }
    
    fmt.Println("Top 10 universities for zenefits employees:")
    for _, school := range rank(schoolsAgg) {
        fmt.Println(school, schoolsAgg[school])
    }
    
    fmt.Println("Top 10 former companies for zenefits employees:")
    for _, company := range rank(otherCompaniesAgg) {
        fmt.Println(company, otherCompaniesAgg[company])
    }
    
}

// Run Person searches in batches with 6-second intervals
func getAllPdlRecordsEs(query interface{}) []pdlmodel.Person {
    // Store all records retreived in an array
    var allRecords []pdlmodel.Person
    batch := 1
    // The current scroll_token
    var scrollToken string
    const pageSize = 100    
        
    // Set your API key
    apiKey := "YOUR API KEY"
    // Set API key as environmental variable
    // apiKey := os.Getenv("API_KEY")

    // Create a client, specifying your API key
    client := pdl.New(apiKey)

    // Create a parameters JSON object
    p := pdlmodel.SearchParams {
        BaseParams: pdlmodel.BaseParams {
            Size: pageSize,
        },
        SearchBaseParams: pdlmodel.SearchBaseParams {
            Query: query,
            ScrollToken: scrollToken,
            Dataset: "all",
        },
    }
    
    // Keep retrieving records until unable to continue scrolling
    for batch == 1 || scrollToken != "" {
        // Pass the parameters object to the Person Search API
        response, err := client.Person.Search(context.Background(), p)
        
        // Check for successful response
        if err == nil {
            // Add records retrieved to the records array
            allRecords = append(allRecords, response.Data...)
            // Store scroll_token from response
            p.SearchBaseParams.ScrollToken, scrollToken = response.ScrollToken, response.ScrollToken
            
            fmt.Printf("Batch %d success!\n", batch)
            time.Sleep(6 * time.Second)
            batch++
        } else {
            fmt.Println("Unable to continue scrolling.")
            break
        }
    }
    fmt.Println("Done!")
        
    return allRecords
}

// Sort map in reverse order
func rank(values map[string]int) []string {
    type kv struct {
        Key   string
        Value int
    }
    var ss []kv
    
    for k, v := range values {
        ss = append(ss, kv{k, v})
    }
    sort.Slice(ss, func(i, j int) bool {
        return ss[i].Value > ss[j].Value
    })
    ranked := make([]string, len(values))
    for i, kv := range ss {
        ranked[i] = kv.Key
    }
    
    return ranked
}
```

```
package main

import (
    "fmt"
    "time"
    "sort"
    "context"
)

// See https://github.com/peopledatalabs/peopledatalabs-go
import (
    pdl "github.com/peopledatalabs/peopledatalabs-go"
    pdlmodel "github.com/peopledatalabs/peopledatalabs-go/model"
)

func main() {
    // Create an SQL query
    sqlQuery := "SELECT * FROM person" +
        " WHERE job_company_website='zenefits.com'"

    // Find all records matching query
    allZenefitsEmployees := getAllPdlRecordsEs(sqlQuery)
    
    // Create aggregate objects
    skillsAgg := make(map[string]int)
    titlesAgg := make(map[string]int)
    schoolsAgg := make(map[string]int)
    otherCompaniesAgg := make(map[string]int)
    
    // Iterate through records array for aggregation
    for _, record := range allZenefitsEmployees {
        // Aggregate skills
        for _, skill := range record.Skills {
            skillsAgg[skill]++
        }
        // Aggregate job titles
        if record.JobTitle != "" {
            titlesAgg[record.JobTitle]++
        }
        // Aggregate schools
        for _, edu := range record.Education {
            if edu.School.Name != "" && edu.School.Type == "post-secondary institution" {
                schoolsAgg[edu.School.Name]++
            }
        }
        // Aggregate other companies
        for _, exp := range record.Experience {
            if exp.Company.Name != "zenefits" {
                otherCompaniesAgg[exp.Company.Name]++
            }
        }
    }
    
    // Sort aggregate objects by count and print top 10 for each
    fmt.Println("Top 10 skills for zenefits employees:")
    for _, skill := range rank(skillsAgg) {
        fmt.Println(skill, skillsAgg[skill])
    }
    
    fmt.Println("Top 10 titles for zenefits employees:")
    for _, title := range rank(titlesAgg) {
        fmt.Println(title, titlesAgg[title])
    }
    
    fmt.Println("Top 10 universities for zenefits employees:")
    for _, school := range rank(schoolsAgg) {
        fmt.Println(school, schoolsAgg[school])
    }
    
    fmt.Println("Top 10 former companies for zenefits employees:")
    for _, company := range rank(otherCompaniesAgg) {
        fmt.Println(company, otherCompaniesAgg[company])
    }
    
}

// Run Person searches in batches with 6-second intervals
func getAllPdlRecordsEs(query string) []pdlmodel.Person {
    // Store all records retreived in an array
    var allRecords []pdlmodel.Person
    batch := 1
    // The current scroll_token
    var scrollToken string
    const pageSize = 100    
        
    // Set your API key
    apiKey := "YOUR API KEY"
    // Set API key as environmental variable
    // apiKey := os.Getenv("API_KEY")

    // Create a client, specifying your API key
    client := pdl.New(apiKey)

    // Create a parameters JSON object
    p := pdlmodel.SearchParams {
        BaseParams: pdlmodel.BaseParams {
            Size: pageSize,
        },
        SearchBaseParams: pdlmodel.SearchBaseParams {
            SQL: query,
            ScrollToken: scrollToken,
            Dataset: "all",
        },
    }
    
    // Keep retrieving records until unable to continue scrolling
    for batch == 1 || scrollToken != "" {
        // Pass the parameters object to the Person Search API
        response, err := client.Person.Search(context.Background(), p)
        
        // Check for successful response
        if err == nil {
            // Add records retrieved to the records array
            allRecords = append(allRecords, response.Data...)
            // Store scroll_token from response
            p.SearchBaseParams.ScrollToken, scrollToken = response.ScrollToken, response.ScrollToken
            
            fmt.Printf("Batch %d success!\n", batch)
            time.Sleep(6 * time.Second)
            batch++
        } else {
            fmt.Println("Unable to continue scrolling.")
            break
        }
    }
    fmt.Println("Done!")
        
    return allRecords
}

// Sort map in reverse order
func rank(values map[string]int) []string {
    type kv struct {
        Key   string
        Value int
    }
    var ss []kv
    
    for k, v := range values {
        ss = append(ss, kv{k, v})
    }
    sort.Slice(ss, func(i, j int) bool {
        return ss[i].Value > ss[j].Value
    })
    ranked := make([]string, len(values))
    for i, kv := range ss {
        ranked[i] = kv.Key
    }
    
    return ranked
}
```

```
from time import sleep
import requests, json

# Set your API key
API_KEY = "YOUR API KEY"

# Set the Person Search API URL
PDL_URL = "https://api.peopledatalabs.com/v5/person/search"

# Set headers
HEADERS = {
  'Content-Type': "application/json",
  'X-api-key': API_KEY
}

# Run Person searches in batches with 6-second intervals
def get_all_pdl_records_es(query):

    PAGE_SIZE = 100

    # Store all records retreived in an array
    all_records = []
    batch = 1

    # Create a parameters JSON object
    params = {
        'query': json.dumps(query),
        'size': PAGE_SIZE,
        'dataset': "all"
    }

    # Keep retrieving records until unable to continue scrolling
    while batch == 1 or params['scroll_token']:

        # Pass the parameters object to the Person Search API
        response = requests.get(
            PDL_URL,
            headers=HEADERS,
            params=params
        ).json()
				
        # Check for successful response
        if response['status'] == 200:
          # Add records retrieved to the records array
          all_records.extend(response['data'])
          # Store the scroll_token for next batch
          params['scroll_token'] = response['scroll_token']

          print(f"Batch {batch} success!")
          sleep(6)
          batch += 1
          
        else:
          print("Unable to continue scrolling.")
          break
    
    print("Done!")

    return all_records


if __name__ == '__main__':
    # Create an Elasticsearch query
    ES_QUERY = {
        "query": {
            "term": {"job_company_website": "zenefits.com"}
        }
    }

    # Find all records matching query
    all_zenefits_employees = get_all_pdl_records_es(ES_QUERY)

    # Create aggregate objects
    skills_agg = {}
    titles_agg = {}
    schools_agg = {}
    other_companies_agg = {}

    # Iterate through records array for aggregation
    for record in all_zenefits_employees:
        # Aggregate skills
        for skill in record['skills']:
            skills_agg.setdefault(skill, 0)
            skills_agg[skill] += 1
        # Aggregate job titles
        if record['job_title']:
            titles_agg.setdefault(record['job_title'], 0)
            titles_agg[record['job_title']] += 1
        # Aggregate schools
        for edu in record['education']:
            if edu['school'] and edu['school']['type'] == "post-secondary institution":
                schools_agg.setdefault(edu['school']['name'], 0)
                schools_agg[edu['school']['name']] += 1
        # Aggregate other companies
        for exp in record['experience']:
            if exp['company'] and exp['company']['name'] != 'zenefits':
                other_companies_agg.setdefault(exp['company']['name'], 0)
                other_companies_agg[exp['company']['name']] += 1

    # Sort aggregate objects by count and print top 10 for each
    print("Top 10 skills for zenefits employees:")
    for skill, count in sorted(
        skills_agg.items(), key = lambda x: x[1], reverse=True
    )[:10]:
        print(count, skill)

    print("Top 10 titles for zenefits employees:")
    for title, count in sorted(
        titles_agg.items(), key = lambda x: x[1], reverse=True
    )[:10]:
        print(count, title)
 
    print("Top 10 universities for zenefits employees:")
    for school, count in sorted(
        schools_agg.items(), key = lambda x: x[1], reverse=True
    )[:10]:
        print(count, school)
  
    print("Top 10 former companies for zenefits employees:")
    for company, count in sorted(
        other_companies_agg.items(), key = lambda x: x[1], reverse=True
    )[:10]:
        print(count, company)
```

```
from time import sleep
import requests, json

# Set your API key
API_KEY = "YOUR API KEY"

# Set the Person Search API URL
PDL_URL = "https://api.peopledatalabs.com/v5/person/search"

# Set headers
HEADERS = {
  'Content-Type': "application/json",
  'X-api-key': API_KEY
}

# Run Person searches in batches with 6-second intervals
def get_all_pdl_records_sql(query):

    PAGE_SIZE = 100

    # Store all records retreived in an array
    all_records = []
    batch = 1

    # Create a parameters JSON object
    params = {
        'sql': query,
        'size': PAGE_SIZE,
      	'dataset': "all"
    }

    # Keep retrieving records until unable to continue scrolling
    while batch == 1 or params['scroll_token']:

        # Pass the parameters object to the Person Search API
        response = requests.get(
            PDL_URL,
            headers=HEADERS,
            params=params
        ).json()

        # Check for successful response
        if response['status'] == 200:
          # Add records retrieved to the records array
          all_records.extend(response['data'])
          # Store the scroll_token for next batch
          params['scroll_token'] = response['scroll_token']

          print(f"Batch {batch} success!")
          sleep(6)
          batch += 1
          
        else:
          print("Unable to continue scrolling.")
          break
    
    print("Done!")

    return all_records

# Create an SQL query
SQL_QUERY = \
"""
  SELECT * FROM person
  WHERE job_company_website='zenefits.com';
"""

# Find all records matching query
all_zenefits_employees = get_all_pdl_records_sql(SQL_QUERY)

# Create aggregate objects
skills_agg = {}
titles_agg = {}
schools_agg = {}
other_companies_agg = {}

# Iterate through records array for aggregation
for record in all_zenefits_employees:
  # Aggregate skills
  for skill in record['skills']:
    skills_agg.setdefault(skill, 0)
    skills_agg[skill] += 1
  # Aggregate job titles
  if record['job_title']:
    titles_agg.setdefault(record['job_title'], 0)
    titles_agg[record['job_title']] += 1
  # Aggregate schools
  for edu in record['education']:
    if edu['school'] and edu['school']['type'] == "post-secondary institution":
      schools_agg.setdefault(edu['school']['name'], 0)
      schools_agg[edu['school']['name']] += 1
  # Aggregate other companies
  for exp in record['experience']:
    if exp['company'] and exp['company']['name'] != 'zenefits':
      other_companies_agg.setdefault(exp['company']['name'], 0)
      other_companies_agg[exp['company']['name']] += 1

# Sort aggregate objects by count and print top 10 for each
print("Top 10 skills for zenefits employees:")
for skill, count in sorted(
  skills_agg.items(), key = lambda x: x[1], reverse=True
)[:10]:
  print(count, skill)

print("Top 10 titles for zenefits employees:")
for title, count in sorted(
  titles_agg.items(), key = lambda x: x[1], reverse=True
)[:10]:
  print(count, title)
 
print("Top 10 universities for zenefits employees:")
for school, count in sorted(
  schools_agg.items(), key = lambda x: x[1], reverse=True
)[:10]:
  print(count, school)
  
print("Top 10 former companies for zenefits employees:")
for company, count in sorted(
  other_companies_agg.items(), key = lambda x: x[1], reverse=True
)[:10]:
  print(count, company)
```

## Advanced Examples

### Company Enrichment and Person Search

*"I want to find X number of people at each company in my list."*

Python SDK (Elasticsearch)Python SDK (SQL)JavaScript (Elasticsearch)JavaScript (SQL)Ruby (Elasticsearch)Ruby (SQL)Go (Elasticsearch)Go (SQL)Python3 (Elasticsearch)Python3 (SQL)

```
import json

# See https://github.com/peopledatalabs/peopledatalabs-python
from peopledatalabs import PDLPY

# Create a client, specifying your API key
CLIENT = PDLPY(
    api_key="YOUR API KEY",
)

# Create a list a companies to search
COMPANY_WEBSITES = [
    "facebook.com",
    "amazon.com",
    "apple.com",
    "netflix.com",
    "google.com"
]

# Set the maximum people to search at each company
MAX_NUM_PEOPLE = 100

# Enrich each company then find people at that company
for company_website in COMPANY_WEBSITES:

    # Create a parameters JSON object for the Company Enrichment API
    query_string = { "website": company_website }

    # Pass the parameters object to the Company Enrichment API
    response = CLIENT.company.enrichment(**query_string).json()

    # Check for successful response
    if response['status'] == 200:
        # Store enriched company
        enriched_company = response
    else:
        enriched_company = {}
        print(f"Company Enrichment Error for [{company_website}]: {response.text}")

    # Store employees at each company
    company_employee_matches = {}

    # Check for an enriched company
    if enriched_company:
        # Create an Elasticsearch query
        es_query = {
        "query": {
            "bool": {
                "must": [
                        {"term": {"job_company_id": enriched_company["id"]}},
                    ]
                }
            }
        }

        # Create a parameters JSON object for the Person Search API
        params = {
            'query': es_query,
            'size': MAX_NUM_PEOPLE
        }

        # Pass the parameters object to the Person Search API
        response = CLIENT.person.search(**params).json()

        # Check for successful response
        if response['status'] == 200:
            # Get employees from response
            company_employee_matches = response['data']
        else:
            company_employee_matches = {}
            print(f"Person Search Error for [{company_website}]: {response.text}")

    print(f"Found {len(company_employee_matches)} employee profiles at {company_website}.")
```

```
import json

# See https://github.com/peopledatalabs/peopledatalabs-python
from peopledatalabs import PDLPY

# Create a client, specifying your API key
CLIENT = PDLPY(
    api_key="YOUR API KEY",
)

# Create a list a companies to search
COMPANY_WEBSITES = [
    "facebook.com",
    "amazon.com",
    "apple.com",
    "netflix.com",
    "google.com"
]

# Set the maximum people to search at each company
MAX_NUM_PEOPLE = 100

# Enrich each company then find people at that company
for company_website in COMPANY_WEBSITES:

    # Create a parameters JSON object for the Company Enrichment API
    query_string = { "website": company_website }

    # Pass the parameters object to the Company Enrichment API
    response = CLIENT.company.enrichment(**query_string).json()

    # Check for successful response
    if response['status'] == 200:
        # Store enriched company
        enriched_company = response
    else:
        enriched_company = {}
        print(f"Company Enrichment Error for [{company_website}]: {response.text}")

    # Store employees at each company
    company_employee_matches = {}

    # Check for an enriched company
    if enriched_company:
        sql_query = f"""
        SELECT * FROM person
        WHERE job_company_id = '{enriched_company['id']}'
        """

        # Create a parameters JSON object for the Person Search API
        params = {
            'sql': sql_query,
            'size': MAX_NUM_PEOPLE
        }

        # Pass the parameters object to the Person Search API
        response = CLIENT.person.search(**params).json()

        # Check for successful response
        if response['status'] == 200:
            # Get employees from response
            company_employee_matches = response['data']
        else:
            company_employee_matches = {}
            print(f"Person Search Error for [{company_website}]: {response.text}")

    print(f"Found {len(company_employee_matches)} employee profiles at {company_website}.")
```

```
// See https://github.com/peopledatalabs/peopledatalabs-js
import PDLJS from 'peopledatalabs';

// Create a client, specifying your API key
const PDLJSClient = new PDLJS({ apiKey: "YOUR API KEY" });

// Create a list a companies to search
const companyWebsites = [
    "facebook.com",
    "amazon.com",
    "apple.com",
    "netflix.com",
    "google.com"
];

// Set the maximum people to search at each company
const maxMumPeople = 100;

// Enrich each company then find people at that company
for (let companyWebsite = 0; companyWebsite < companyWebsites.length; companyWebsite++) {

    // Create a parameters JSON object for the Company Enrichment API
    let queryString = { "website": companyWebsites[companyWebsite] };
    
    let enrichedCompany = {};
    // Store employees at each company
    let companyEmployeeMatches = {};
    
    // Pass the parameters object to the Company Enrichment API
    PDLJSClient.company.enrichment(queryString).then((enrichedCompany) => {

        // Create an Elasticsearch query    
        let esQuery = {
            query: {
                bool: {
                    must:[
                        {term: {job_company_id: enrichedCompany.id}}, 
                    ]
                }
            }
        }
        
        // Create a parameters JSON object for the Person Search API
        let params = {
            searchQuery: esQuery, 
            size: maxMumPeople
        }
        
        // Pass the parameters object to the Person Search API
        PDLJSClient.person.search.elastic(params).then((data) => {    
            // Get employees from response
            companyEmployeeMatches = data.data;
            console.log(`Found ${companyEmployeeMatches.length}` +  
                        ` employee profiles at ${companyWebsites[companyWebsite]}.`);
          }).catch((error) => {
                console.log(`Person Seach Error for ${companyWebsites[companyWebsite]}` + 
                            `: ${error}`);
        }); 
        
    }).catch((error) => {
        console.log(`Company Enrichment Error for ${companyWebsites[companyWebsite]}` + 
                    `: ${error}`);
    }); 
}
```

```
// See https://github.com/peopledatalabs/peopledatalabs-js
import PDLJS from 'peopledatalabs';

// Create a client, specifying your API key
const PDLJSClient = new PDLJS({ apiKey: "YOUR API KEY" });

// Create a list a companies to search
const companyWebsites = [
    "facebook.com",
    "amazon.com",
    "apple.com",
    "netflix.com",
    "google.com"
];

// Set the maximum people to search at each company
const maxMumPeople = 100;

// Enrich each company then find people at that company
for (let companyWebsite = 0; companyWebsite < companyWebsites.length; companyWebsite++) {

    // Create a parameters JSON object for the Company Enrichment API
    let queryString = { "website": companyWebsites[companyWebsite] };
    
    let enrichedCompany = {};
    // Store employees at each company
    let companyEmployeeMatches = {};
    
    // Pass the parameters object to the Company Enrichment API
    PDLJSClient.company.enrichment(queryString).then((enrichedCompany) => {

        // Create an SQL query
        let sqlQuery = `SELECT * FROM person
            WHERE job_company_id = '${enrichedCompany.id}';`;
        
        // Create a parameters JSON object for the Person Search API
        let params = {
            searchQuery: sqlQuery, 
            size: maxMumPeople
        }
        
        // Pass the parameters object to the Person Search API
        PDLJSClient.person.search.sql(params).then((data) => {   
            // Get employees from response
            companyEmployeeMatches = data.data;
            console.log(`Found ${companyEmployeeMatches.length}` +  
                        ` employee profiles at ${companyWebsites[companyWebsite]}.`);
          }).catch((error) => {
                console.log(`Person Seach Error for ${companyWebsites[companyWebsite]}` + 
                            `: ${error}`);
        }); 
        
    }).catch((error) => {
        console.log(`Company Enrichment Error for ${companyWebsites[companyWebsite]}` + 
                    `: ${error}`);
    }); 
}
```

```
# See https://github.com/peopledatalabs/peopledatalabs-ruby
require 'peopledatalabs'

# Set your API key
Peopledatalabs.api_key = 'YOUR API KEY'

# Create a list a companies to search
COMPANY_WEBSITES = [
    "facebook.com",
    "amazon.com",
    "apple.com",
    "netflix.com",
    "google.com"
]

# Set the maximum people to search at each company
MAX_NUM_PEOPLE = 100

# Enrich each company then find people at that company
COMPANY_WEBSITES.each do |company_website|

    # Create a parameters JSON object for the Company Enrichment API
    query_string = { "website": company_website }

    # Pass the parameters object to the Company Enrichment API
    response = Peopledatalabs::Enrichment.company(params: query_string)

    # Check for successful response
    if response['status'] == 200
        # Store enriched company
        enriched_company = response
    else
        enriched_company = {}
        puts "Company Enrichment Error for [#{company_website}]: #{response}"
    end

    # Store employees at each company
    company_employee_matches = {}

    # Check for an enriched company
    if !enriched_company.nil?
        # Create an Elasticsearch query
        es_query = {
        "query": {
            "bool": {
                "must": [
                        {"term": {"job_company_id": enriched_company["id"]}},
                    ]
                }
            }
        }

        # Pass parameters to the Person Search API
        response = Peopledatalabs::Search.person(searchType: 'elastic', query: es_query, size: MAX_NUM_PEOPLE)

        # Check for successful response
        if response['status'] == 200
            # Get employees from response
            company_employee_matches = response['data']
        else
            company_employee_matches = {}
            puts "Person Search Error for [#{company_website}]: #{response}"
        end
    end

    puts "Found #{company_employee_matches.length()} employee profiles at #{company_website}."
end
```

```
# See https://github.com/peopledatalabs/peopledatalabs-ruby
require 'peopledatalabs'

# Set your API key
Peopledatalabs.api_key = 'YOUR API KEY'

# Create a list a companies to search
COMPANY_WEBSITES = [
    "facebook.com",
    "amazon.com",
    "apple.com",
    "netflix.com",
    "google.com"
]

# Set the maximum people to search at each company
MAX_NUM_PEOPLE = 100

# Enrich each company then find people at that company
COMPANY_WEBSITES.each do |company_website|

    # Create a parameters JSON object for the Company Enrichment API
    query_string = { "website": company_website }

    # Pass the parameters object to the Company Enrichment API
    response = Peopledatalabs::Enrichment.company(params: query_string)

    # Check for successful response
    if response['status'] == 200
        # Store enriched company
        enriched_company = response
    else
        enriched_company = {}
        puts "Company Enrichment Error for [#{company_website}]: #{response}"
    end

    # Store employees at each company
    company_employee_matches = {}

    # Check for an enriched company
    if !enriched_company.nil?
        # Create an SQL query
        sql_query = """
        SELECT * FROM person
        WHERE job_company_id = '#{enriched_company['id']}'
        """

        # Pass parameters to the Person Search API
        response = Peopledatalabs::Search.person(searchType: 'sql', query: sql_query, size: MAX_NUM_PEOPLE)

        # Check for successful response
        if response['status'] == 200
            # Get employees from response
            company_employee_matches = response['data']
        else
            company_employee_matches = {}
            puts "Person Search Error for [#{company_website}]: #{response}"
        end
    end

    puts "Found #{company_employee_matches.length()} employee profiles at #{company_website}."
end
```

```
package main

import (
    "fmt"
    "reflect"
    "context"
)

// See https://github.com/peopledatalabs/peopledatalabs-go
import (
    pdl "github.com/peopledatalabs/peopledatalabs-go"
    pdlmodel "github.com/peopledatalabs/peopledatalabs-go/model"
)

func main() {
    // Set your API key
    apiKey := "YOUR API KEY"
    // Set API key as environmental variable
    // apiKey := os.Getenv("API_KEY")

    // Create a client, specifying your API key
    client := pdl.New(apiKey)
    
    // Create a list a companies to search
    companyWebsites := 
        []string{"facebook.com","amazon.com","apple.com","netflix.com","google.com"}

    // Set the maximum people to search at each company
    const maxNumPeople = 100
    
    // Enrich each company then find people at that company
    for _, companyWebsite := range companyWebsites {
        
        var enrichedCompany pdlmodel.EnrichCompanyResponse
        
        // Create a parameters JSON object for the Company Enrichment API
        queryString := pdlmodel.CompanyParams{Website: companyWebsite}
        
        paramsCompany := pdlmodel.EnrichCompanyParams {
            CompanyParams: queryString,
        }
    
        // Pass the parameters object to the Company Enrichment API
        responseCompany, errCompany := client.Company.Enrich(context.Background(), paramsCompany)

        // Check for successful response
        if errCompany == nil {
            // Store enriched company
            enrichedCompany = responseCompany
        } else {
            fmt.Printf("Company Enrichment Error for [%s]: %s\n", companyWebsite, errCompany)
        }
        
        // Store employees at each company
        var companyEmployeeMatches []pdlmodel.Person
        
        // Check for an enriched company
        if !reflect.DeepEqual(enrichedCompany, pdlmodel.EnrichCompanyResponse{}) {
            // Create an Elasticsearch query
            elasticSearchQuery := map[string]interface{} {
                "query": map[string]interface{} {
                    "bool": map[string]interface{} {
                        "must": []map[string]interface{} {
                            {"term": map[string]interface{}{"job_company_id": enrichedCompany.Id}},
                        },
                    },
                },
            }

            // Create a parameters JSON object for the Person Search API
            paramsPerson := pdlmodel.SearchParams {
                BaseParams: pdlmodel.BaseParams {
                    Size: maxNumPeople,
                },
                SearchBaseParams: pdlmodel.SearchBaseParams {
                    Query: elasticSearchQuery,
                },
            }
            
            // Pass the parameters object to the Person Search API
            responsePerson, errPerson := client.Person.Search(context.Background(), paramsPerson)
            
            // Check for successful response
            if errPerson == nil {
                // Get employees from response
                companyEmployeeMatches = responsePerson.Data
            } else {
                fmt.Printf("Person Search Error for [%s]: %s\n", companyWebsite, errPerson)
            }
        }
        fmt.Printf("Found %d employee profiles at %s.\n", len(companyEmployeeMatches), companyWebsite)
    }
}
```

```
package main

import (
    "fmt"
    "reflect"
    "context"
)

// See https://github.com/peopledatalabs/peopledatalabs-go
import (
    pdl "github.com/peopledatalabs/peopledatalabs-go"
    pdlmodel "github.com/peopledatalabs/peopledatalabs-go/model"
)

func main() {
    // Set your API key
    apiKey := "YOUR API KEY"
    // Set API key as environmental variable
    // apiKey := os.Getenv("API_KEY")

    // Create a client, specifying your API key
    client := pdl.New(apiKey)
    
    // Create a list a companies to search
    companyWebsites := 
        []string{"facebook.com","amazon.com","apple.com","netflix.com","google.com"}

    // Set the maximum people to search at each company
    const maxNumPeople = 100
    
    // Enrich each company then find people at that company
    for _, companyWebsite := range companyWebsites {
        
        var enrichedCompany pdlmodel.EnrichCompanyResponse
        
        // Create a parameters JSON object for the Company Enrichment API
        queryString := pdlmodel.CompanyParams{Website: companyWebsite}
        
        paramsCompany := pdlmodel.EnrichCompanyParams {
            CompanyParams: queryString,
        }
    
        // Pass the parameters object to the Company Enrichment API
        responseCompany, errCompany := client.Company.Enrich(context.Background(), paramsCompany)

        // Check for successful response
        if errCompany == nil {
            // Store enriched company
            enrichedCompany = responseCompany
        } else {
            fmt.Printf("Company Enrichment Error for [%s]: %s\n", companyWebsite, errCompany)
        }
        
        // Store employees at each company
        var companyEmployeeMatches []pdlmodel.Person
        
        // Check for an enriched company
        if !reflect.DeepEqual(enrichedCompany, pdlmodel.EnrichCompanyResponse{}) {
            // Create an SQL query
            sqlQuery := "SELECT * FROM person" +
                " WHERE job_company_id = '" + enrichedCompany.Id + "'"
 
            // Create a parameters JSON object for the Person Search API
            paramsPerson := pdlmodel.SearchParams {
                BaseParams: pdlmodel.BaseParams {
                    Size: maxNumPeople,
                },
                SearchBaseParams: pdlmodel.SearchBaseParams {
                    SQL: sqlQuery,
                },
            }
            
            // Pass the parameters object to the Person Search API
            responsePerson, errPerson := client.Person.Search(context.Background(), paramsPerson)
            
            // Check for successful response
            if errPerson == nil {
                // Get employees from response
                companyEmployeeMatches = responsePerson.Data
            } else {
                fmt.Printf("Person Search Error for [%s]: %s\n", companyWebsite, errPerson)
            }
        }
        fmt.Printf("Found %d employee profiles at %s.\n", len(companyEmployeeMatches), companyWebsite)
    }
}
```

```
import json
import requests

# Set the Company Enrichment API URL
PDL_COMPANY_ENRICH_URL = "https://api.peopledatalabs.com/v5/company/enrich"
# Set the Person Search API URL
PDL_PERSON_SEARCH_URL = "https://api.peopledatalabs.com/v5/person/search"

# Set your API key
API_KEY = "YOUR API KEY"

# Create a list a companies to search
COMPANY_WEBSITES = [
    "facebook.com",
    "amazon.com",
    "apple.com",
    "netflix.com",
    "google.com"
]

# Set the maximum people to search at each company
MAX_NUM_PEOPLE = 100

# Enrich each company then find people at that company
for company_website in COMPANY_WEBSITES:

    # Create a parameters JSON object for the Company Enrichment API
    query_string = { "website": company_website }

    # Set headers
    headers = {
        'accept': "application/json",
        'content-type': "application/json",
        'x-api-key': API_KEY
    }

    # Pass the parameters object to the Company Enrichment API
    response = requests.request("GET", PDL_COMPANY_ENRICH_URL, headers=headers, params=query_string)

    # Check for successful response
    if response.status_code == 200:
        # Store enriched company
        enriched_company = response.json()
    else:
        enriched_company = {}
        print(f"Company Enrichment Error for [{company_website}]: {response.text}")

    # Store employees at each company
    company_employee_matches = {}

    # Check for an enriched company
    if enriched_company:
        # Set headers
        headers = {
            'Content-Type': "application/json",
            'X-api-key': API_KEY
        }

        # Create an Elasticsearch query
        es_query = {
        "query": {
            "bool": {
                "must": [
                        {"term": {"job_company_id": enriched_company["id"]}},
                    ]
                }
            }
        }

        # Create a parameters JSON object for the Person Search API
        params = {
            'query': json.dumps(es_query),
            'size': MAX_NUM_PEOPLE
        }

        # Pass the parameters object to the Person Search API
        response = requests.get( PDL_PERSON_SEARCH_URL, headers=headers, params=params)

        # Check for successful response
        if response.status_code == 200:
            # Get employees from response
            company_employee_matches = response.json()['data']
        else:
            company_employee_matches = {}
            print(f"Person Search Error for [{company_website}]: {response.text}")

    print(f"Found {len(company_employee_matches)} employee profiles at {company_website}.")
```

```
import json
import requests

# Set the Company Enrichment API URL
PDL_COMPANY_ENRICH_URL = "https://api.peopledatalabs.com/v5/company/enrich"
# Set the Person Search API URL
PDL_PERSON_SEARCH_URL = "https://api.peopledatalabs.com/v5/person/search"

# Set your API key
API_KEY = "YOUR API KEY"

# Create a list a companies to search
COMPANY_WEBSITES = [
    "facebook.com",
    "amazon.com",
    "apple.com",
    "netflix.com",
    "google.com"
]

# Set the maximum people to search at each company
MAX_NUM_PEOPLE = 100

# Enrich each company then find people at that company
for company_website in COMPANY_WEBSITES:

    # Create a parameters JSON object for the Company Enrichment API
    query_string = { "website": company_website }

    # Set headers
    headers = {
        'accept': "application/json",
        'content-type': "application/json",
        'x-api-key': API_KEY
    }

    # Pass the parameters object to the Company Enrichment API
    response = requests.request("GET", PDL_COMPANY_ENRICH_URL, headers=headers, params=query_string)

    # Check for successful response
    if response.status_code == 200:
        # Store enriched company
        enriched_company = response.json()
    else:
        enriched_company = {}
        print(f"Company Enrichment Error for [{company_website}]: {response.text}")

    # Store employees at each company
    company_employee_matches = {}

    # Check for an enriched company
    if enriched_company:
        # Set headers
        headers = {
            'Content-Type': "application/json",
            'X-api-key': API_KEY
        }

        # Create an SQL query
        sql_query = f"""
        SELECT * FROM person
        WHERE job_company_id = '{enriched_company['id']}'
        """

        # Create a parameters JSON object for the Person Search API
        params = {
            'sql': sql_query,
            'size': MAX_NUM_PEOPLE
        }

        # Pass the parameters object to the Person Search API
        response = requests.get( PDL_PERSON_SEARCH_URL, headers=headers, params=params)

        # Check for successful response
        if response.status_code == 200:
            # Get employees from response
            company_employee_matches = response.json()['data']
        else:
            company_employee_matches = {}
            print(f"Person Search Error for [{company_website}]: {response.text}")

    print(f"Found {len(company_employee_matches)} employee profiles at {company_website}.")
```

Updated 4 months ago

---

Did this page help you?

Yes

No

---
# https://docs.peopledatalabs.com/docs/output-response-job-title-enrichment-api

## Response Data Structure

Here is the structure of an example response from the Job Title Enrichment API:

JSON

```
{
  "cleaned_job_title": "supply manager",
  "similar_job_titles": [
    "senior supply manager",
    "supply chain manager",
    "supply specialist",
    "supply supervisor",
    "supply coordinator"
  ],
  "relevant_skills": [
    "supply management",
    "spend analysis",
    "supplier development",
    "demand planning",
    "strategic sourcing"
  ]
}
```

## Response Fields

### `cleaned_job_title`

| Type | Description |
| --- | --- |
| `String` | The job title that matches the API input `job_title` after passing it through our internal job title cleaner. |

  

### `similar_job_titles`

| Type | Description |
| --- | --- |
| `Array [String]` | A list of up to five of the most contextually-similar job titles to the `cleaned_job_title`, determined using our global resume data. |

  

### `relevant_skills`

| Type | Description |
| --- | --- |
| `Array [String]` | A list of up to five of the most contextually-similar skills to the `cleaned_job_title`, determined using our global resume data. |

Updated 4 months ago

---

Did this page help you?

Yes

No

---
# https://docs.peopledatalabs.com/docs/mobile-phone-stats

## Description

The Mobile Phone Slice Dataset is a subset of our full [Person Dataset](/docs/stats) and is composed of all the records containing a mobile phone number. The table below summarizes some key statistics and fill rates for fields within this dataset. Premium fields are not accessible by default.

**Common Use Cases**  
*Direct Dial Outreach, Caller ID*

| Field | Count | Numeric | Fill Percentage |
| --- | --- | --- | --- |
| `Total` | 479,855,809 | 479855809 | 100.0% |
| `birth_date` | 43,347,013 | 43347013 | 9.0% |
| `birth_year` | 78,642,977 | 78642977 | 16.4% |
| `certifications` | 9,410,939 | 9410939 | 2.0% |
| `certifications.end_date` | 6,955,796 | 6955796 | 1.4% |
| `certifications.name` | 9,410,939 | 9410939 | 2.0% |
| `certifications.organization` | 9,187,143 | 9187143 | 1.9% |
| `certifications.start_date` | 7,435,584 | 7435584 | 1.5% |
| `countries` | 278,483,956 | 278483956 | 58.0% |
| `education` | 122,619,584 | 122619584 | 25.6% |
| `education.degrees` | 28,342,176 | 28342176 | 5.9% |
| `education.end_date` | 36,511,575 | 36511575 | 7.6% |
| `education.gpa` | 2,370,350 | 2370350 | 0.5% |
| `education.majors` | 38,106,301 | 38106301 | 7.9% |
| `education.minors` | 651,655 | 651655 | 0.1% |
| `education.raw` | 51,062,879 | 51062879 | 10.6% |
| `education.school` | 122,580,885 | 122580885 | 25.5% |
| `education.school.domain` | 86,756,385 | 86756385 | 18.1% |
| `education.school.facebook_url` | 54,105,071 | 54105071 | 11.3% |
| `education.school.id` | 90,277,259 | 90277259 | 18.8% |
| `education.school.linkedin_id` | 90,277,259 | 90277259 | 18.8% |
| `education.school.linkedin_url` | 90,275,547 | 90275547 | 18.8% |
| `education.school.location` | 76,568,789 | 76568789 | 16.0% |
| `education.school.location.continent` | 76,568,789 | 76568789 | 16.0% |
| `education.school.location.country` | 76,568,788 | 76568788 | 16.0% |
| `education.school.location.locality` | 74,455,815 | 74455815 | 15.5% |
| `education.school.location.name` | 76,568,789 | 76568789 | 16.0% |
| `education.school.location.region` | 75,416,791 | 75416791 | 15.7% |
| `education.school.name` | 122,580,791 | 122580791 | 25.5% |
| `education.school.raw` | 122,485,825 | 122485825 | 25.5% |
| `education.school.twitter_url` | 53,084,023 | 53084023 | 11.1% |
| `education.school.type` | 99,649,235 | 99649235 | 20.8% |
| `education.school.website` | 86,756,385 | 86756385 | 18.1% |
| `education.start_date` | 30,808,902 | 30808902 | 6.4% |
| `education.summary` | 11,884,618 | 11884618 | 2.5% |
| `emails` | 100,214,910 | 100214910 | 20.9% |
| `emails.address` | 100,214,910 | 100214910 | 20.9% |
| `emails.first_seen` | 100,214,910 | 100214910 | 20.9% |
| `emails.last_seen` | 100,214,910 | 100214910 | 20.9% |
| `emails.md5_hash` | 100,214,910 | 100214910 | 20.9% |
| `emails.num_sources` | 100,214,910 | 100214910 | 20.9% |
| `emails.sha_256_hash` | 100,214,910 | 100214910 | 20.9% |
| `emails.type` | 95,766,518 | 95766518 | 20.0% |
| `experience` | 115,114,445 | 115114445 | 24.0% |
| `experience.company` | 113,237,884 | 113237884 | 23.6% |
| `experience.company.facebook_url` | 52,897,326 | 52897326 | 11.0% |
| `experience.company.founded` | 60,864,576 | 60864576 | 12.7% |
| `experience.company.id` | 76,794,122 | 76794122 | 16.0% |
| `experience.company.industry` | 74,257,729 | 74257729 | 15.5% |
| `experience.company.industry_v2` | 71,715,086 | 71715086 | 14.9% |
| `experience.company.linkedin_id` | 76,794,122 | 76794122 | 16.0% |
| `experience.company.linkedin_url` | 76,794,122 | 76794122 | 16.0% |
| `experience.company.location` | 74,823,051 | 74823051 | 15.6% |
| `experience.company.location.address_line_2` | 16,883,246 | 16883246 | 3.5% |
| `experience.company.location.continent` | 74,679,675 | 74679675 | 15.6% |
| `experience.company.location.country` | 74,822,954 | 74822954 | 15.6% |
| `experience.company.location.geo` | 71,786,822 | 71786822 | 15.0% |
| `experience.company.location.locality` | 72,180,793 | 72180793 | 15.0% |
| `experience.company.location.metro` | 54,285,437 | 54285437 | 11.3% |
| `experience.company.location.name` | 74,823,051 | 74823051 | 15.6% |
| `experience.company.location.postal_code` | 66,511,138 | 66511138 | 13.9% |
| `experience.company.location.region` | 72,455,288 | 72455288 | 15.1% |
| `experience.company.location.street_address` | 64,613,609 | 64613609 | 13.5% |
| `experience.company.name` | 113,235,289 | 113235289 | 23.6% |
| `experience.company.raw` | 113,237,567 | 113237567 | 23.6% |
| `experience.company.size` | 76,794,122 | 76794122 | 16.0% |
| `experience.company.ticker` | 19,095,949 | 19095949 | 4.0% |
| `experience.company.twitter_url` | 47,873,918 | 47873918 | 10.0% |
| `experience.company.type` | 76,794,122 | 76794122 | 16.0% |
| `experience.company.website` | 70,912,206 | 70912206 | 14.8% |
| `experience.end_date` | 39,099,217 | 39099217 | 8.1% |
| `experience.first_seen` | 115,114,445 | 115114445 | 24.0% |
| `experience.is_primary` | 115,114,445 | 115114445 | 24.0% |
| `experience.last_seen` | 115,114,445 | 115114445 | 24.0% |
| `experience.location_names` | 55,148,484 | 55148484 | 11.5% |
| `experience.num_sources` | 115,114,445 | 115114445 | 24.0% |
| `experience.start_date` | 64,857,873 | 64857873 | 13.5% |
| `experience.summary` | 28,897,145 | 28897145 | 6.0% |
| `experience.title` | 85,995,719 | 85995719 | 17.9% |
| `experience.title.class` | 67,029,752 | 67029752 | 14.0% |
| `experience.title.levels` | 38,328,836 | 38328836 | 8.0% |
| `experience.title.name` | 85,995,719 | 85995719 | 17.9% |
| `experience.title.raw` | 85,995,719 | 85995719 | 17.9% |
| `experience.title.role` | 67,029,752 | 67029752 | 14.0% |
| `experience.title.sub_role` | 60,963,373 | 60963373 | 12.7% |
| `facebook_friends` | 11,553,901 | 11553901 | 2.4% |
| `facebook_id` | 375,849,657 | 375849657 | 78.3% |
| `facebook_url` | 180,496,577 | 180496577 | 37.6% |
| `facebook_username` | 180,496,577 | 180496577 | 37.6% |
| `first_name` | 479,855,809 | 479855809 | 100.0% |
| `first_seen` | 479,855,809 | 479855809 | 100.0% |
| `full_name` | 479,855,809 | 479855809 | 100.0% |
| `github_url` | 388,454 | 388454 | 0.1% |
| `github_username` | 388,454 | 388454 | 0.1% |
| `headline` | 29,763,419 | 29763419 | 6.2% |
| `id` | 479,855,809 | 479855809 | 100.0% |
| `industry` | 49,035,129 | 49035129 | 10.2% |
| `inferred_salary` | 36,197,774 | 36197774 | 7.5% |
| `inferred_years_experience` | 64,496,969 | 64496969 | 13.4% |
| `interests` | 26,881,587 | 26881587 | 5.6% |
| `job_company_12mo_employee_growth_rate` | 40,000,918 | 40000918 | 8.3% |
| `job_company_employee_count` | 40,261,843 | 40261843 | 8.4% |
| `job_company_facebook_url` | 23,387,402 | 23387402 | 4.9% |
| `job_company_founded` | 29,714,335 | 29714335 | 6.2% |
| `job_company_id` | 40,265,326 | 40265326 | 8.4% |
| `job_company_industry` | 38,774,386 | 38774386 | 8.1% |
| `job_company_industry_v2` | 36,797,135 | 36797135 | 7.7% |
| `job_company_inferred_revenue` | 40,261,843 | 40261843 | 8.4% |
| `job_company_linkedin_id` | 40,265,326 | 40265326 | 8.4% |
| `job_company_linkedin_url` | 40,265,326 | 40265326 | 8.4% |
| `job_company_location_address_line_2` | 5,182,684 | 5182684 | 1.1% |
| `job_company_location_continent` | 38,620,852 | 38620852 | 8.0% |
| `job_company_location_country` | 38,748,169 | 38748169 | 8.1% |
| `job_company_location_geo` | 36,863,229 | 36863229 | 7.7% |
| `job_company_location_locality` | 37,093,831 | 37093831 | 7.7% |
| `job_company_location_metro` | 28,004,220 | 28004220 | 5.8% |
| `job_company_location_name` | 38,748,282 | 38748282 | 8.1% |
| `job_company_location_postal_code` | 32,525,115 | 32525115 | 6.8% |
| `job_company_location_region` | 37,297,405 | 37297405 | 7.8% |
| `job_company_location_street_address` | 31,361,527 | 31361527 | 6.5% |
| `job_company_name` | 57,355,578 | 57355578 | 12.0% |
| `job_company_size` | 40,265,326 | 40265326 | 8.4% |
| `job_company_ticker` | 6,301,169 | 6301169 | 1.3% |
| `job_company_total_funding_raised` | 10,319,703 | 10319703 | 2.2% |
| `job_company_twitter_url` | 19,428,177 | 19428177 | 4.0% |
| `job_company_type` | 40,265,326 | 40265326 | 8.4% |
| `job_company_website` | 36,374,740 | 36374740 | 7.6% |
| `job_history` | 115,146,115 | 115146115 | 24.0% |
| `job_history.company_id` | 79,062,448 | 79062448 | 16.5% |
| `job_history.company_name` | 113,387,357 | 113387357 | 23.6% |
| `job_history.first_seen` | 115,146,115 | 115146115 | 24.0% |
| `job_history.last_seen` | 115,146,115 | 115146115 | 24.0% |
| `job_history.num_sources` | 115,146,115 | 115146115 | 24.0% |
| `job_history.title` | 86,046,128 | 86046128 | 17.9% |
| `job_last_changed` | 58,570,706 | 58570706 | 12.2% |
| `job_last_verified` | 58,570,706 | 58570706 | 12.2% |
| `job_onet_broad_occupation` | 29,900,276 | 29900276 | 6.2% |
| `job_onet_code` | 29,900,276 | 29900276 | 6.2% |
| `job_onet_major_group` | 29,900,276 | 29900276 | 6.2% |
| `job_onet_minor_group` | 29,900,276 | 29900276 | 6.2% |
| `job_onet_specific_occupation` | 29,900,276 | 29900276 | 6.2% |
| `job_onet_specific_occupation_detail` | 11,434,303 | 11434303 | 2.4% |
| `job_start_date` | 47,812,664 | 47812664 | 10.0% |
| `job_summary` | 12,489,883 | 12489883 | 2.6% |
| `job_title` | 54,408,880 | 54408880 | 11.3% |
| `job_title_class` | 40,057,175 | 40057175 | 8.3% |
| `job_title_levels` | 20,020,548 | 20020548 | 4.2% |
| `job_title_role` | 40,057,175 | 40057175 | 8.3% |
| `job_title_sub_role` | 33,328,594 | 33328594 | 6.9% |
| `languages` | 66,069,951 | 66069951 | 13.8% |
| `languages.name` | 66,069,951 | 66069951 | 13.8% |
| `languages.proficiency` | 1,627,594 | 1627594 | 0.3% |
| `last_initial` | 479,855,809 | 479855809 | 100.0% |
| `last_name` | 479,578,431 | 479578431 | 99.9% |
| `linkedin_connections` | 52,737,690 | 52737690 | 11.0% |
| `linkedin_id` | 49,809,491 | 49809491 | 10.4% |
| `linkedin_url` | 52,131,383 | 52131383 | 10.9% |
| `linkedin_username` | 52,131,383 | 52131383 | 10.9% |
| `location_address_line_2` | 11,968,395 | 11968395 | 2.5% |
| `location_continent` | 278,484,144 | 278484144 | 58.0% |
| `location_country` | 278,483,771 | 278483771 | 58.0% |
| `location_geo` | 259,847,606 | 259847606 | 54.2% |
| `location_last_updated` | 176,705,000 | 176705000 | 36.8% |
| `location_locality` | 260,477,547 | 260477547 | 54.3% |
| `location_metro` | 136,290,200 | 136290200 | 28.4% |
| `location_name` | 278,484,144 | 278484144 | 58.0% |
| `location_names` | 260,655,579 | 260655579 | 54.3% |
| `location_postal_code` | 92,779,325 | 92779325 | 19.3% |
| `location_region` | 275,865,560 | 275865560 | 57.5% |
| `location_street_address` | 91,462,004 | 91462004 | 19.1% |
| `middle_initial` | 123,489,631 | 123489631 | 25.7% |
| `middle_name` | 81,056,041 | 81056041 | 16.9% |
| `mobile_phone` | 479,855,809 | 479855809 | 100.0% |
| `name_aliases` | 27,880,493 | 27880493 | 5.8% |
| `num_records` | 479,855,809 | 479855809 | 100.0% |
| `num_sources` | 479,855,809 | 479855809 | 100.0% |
| `personal_emails` | 74,059,192 | 74059192 | 15.4% |
| `phone_numbers` | 479,855,809 | 479855809 | 100.0% |
| `phones` | 479,855,809 | 479855809 | 100.0% |
| `phones.first_seen` | 479,855,809 | 479855809 | 100.0% |
| `phones.last_seen` | 479,855,809 | 479855809 | 100.0% |
| `phones.num_sources` | 479,855,809 | 479855809 | 100.0% |
| `phones.number` | 479,855,809 | 479855809 | 100.0% |
| `possible_birth_dates` | 41,005,629 | 41005629 | 8.5% |
| `possible_emails` | 34,771,594 | 34771594 | 7.2% |
| `possible_emails.address` | 34,771,594 | 34771594 | 7.2% |
| `possible_emails.first_seen` | 34,771,594 | 34771594 | 7.2% |
| `possible_emails.last_seen` | 34,771,594 | 34771594 | 7.2% |
| `possible_emails.md5_hash` | 34,771,594 | 34771594 | 7.2% |
| `possible_emails.num_sources` | 34,771,594 | 34771594 | 7.2% |
| `possible_emails.sha_256_hash` | 34,771,594 | 34771594 | 7.2% |
| `possible_emails.type` | 30,670,002 | 30670002 | 6.4% |
| `possible_location_names` | 209,708,626 | 209708626 | 43.7% |
| `possible_phones` | 13,555,331 | 13555331 | 2.8% |
| `possible_phones.first_seen` | 13,555,331 | 13555331 | 2.8% |
| `possible_phones.last_seen` | 13,555,331 | 13555331 | 2.8% |
| `possible_phones.num_sources` | 13,555,331 | 13555331 | 2.8% |
| `possible_phones.number` | 13,555,331 | 13555331 | 2.8% |
| `possible_profiles` | 20,577,455 | 20577455 | 4.3% |
| `possible_profiles.first_seen` | 20,577,455 | 20577455 | 4.3% |
| `possible_profiles.id` | 16,383,067 | 16383067 | 3.4% |
| `possible_profiles.last_seen` | 20,577,455 | 20577455 | 4.3% |
| `possible_profiles.network` | 20,577,455 | 20577455 | 4.3% |
| `possible_profiles.num_sources` | 20,577,455 | 20577455 | 4.3% |
| `possible_profiles.url` | 20,577,455 | 20577455 | 4.3% |
| `possible_profiles.username` | 11,423,762 | 11423762 | 2.4% |
| `possible_street_addresses` | 9,657,710 | 9657710 | 2.0% |
| `possible_street_addresses.address_line_2` | 2,414,886 | 2414886 | 0.5% |
| `possible_street_addresses.continent` | 9,657,710 | 9657710 | 2.0% |
| `possible_street_addresses.country` | 9,657,710 | 9657710 | 2.0% |
| `possible_street_addresses.first_seen` | 9,657,710 | 9657710 | 2.0% |
| `possible_street_addresses.geo` | 9,657,468 | 9657468 | 2.0% |
| `possible_street_addresses.last_seen` | 9,657,710 | 9657710 | 2.0% |
| `possible_street_addresses.locality` | 9,657,632 | 9657632 | 2.0% |
| `possible_street_addresses.metro` | 8,470,494 | 8470494 | 1.8% |
| `possible_street_addresses.name` | 9,657,710 | 9657710 | 2.0% |
| `possible_street_addresses.num_sources` | 9,657,710 | 9657710 | 2.0% |
| `possible_street_addresses.postal_code` | 9,570,478 | 9570478 | 2.0% |
| `possible_street_addresses.region` | 9,657,659 | 9657659 | 2.0% |
| `possible_street_addresses.street_address` | 9,657,710 | 9657710 | 2.0% |
| `profiles` | 421,009,503 | 421009503 | 87.7% |
| `profiles.first_seen` | 421,009,503 | 421009503 | 87.7% |
| `profiles.id` | 410,338,701 | 410338701 | 85.5% |
| `profiles.last_seen` | 421,009,503 | 421009503 | 87.7% |
| `profiles.network` | 421,009,503 | 421009503 | 87.7% |
| `profiles.num_sources` | 421,009,503 | 421009503 | 87.7% |
| `profiles.url` | 421,009,503 | 421009503 | 87.7% |
| `profiles.username` | 218,594,653 | 218594653 | 45.6% |
| `recommended_personal_email` | 74,055,296 | 74055296 | 15.4% |
| `regions` | 276,128,275 | 276128275 | 57.5% |
| `sex` | 358,050,217 | 358050217 | 74.6% |
| `skills` | 29,378,829 | 29378829 | 6.1% |
| `street_addresses` | 95,812,134 | 95812134 | 20.0% |
| `street_addresses.address_line_2` | 41,309,112 | 41309112 | 8.6% |
| `street_addresses.continent` | 95,812,134 | 95812134 | 20.0% |
| `street_addresses.country` | 95,812,134 | 95812134 | 20.0% |
| `street_addresses.first_seen` | 95,812,134 | 95812134 | 20.0% |
| `street_addresses.geo` | 95,597,887 | 95597887 | 19.9% |
| `street_addresses.last_seen` | 95,812,134 | 95812134 | 20.0% |
| `street_addresses.locality` | 95,603,451 | 95603451 | 19.9% |
| `street_addresses.metro` | 87,015,674 | 87015674 | 18.1% |
| `street_addresses.name` | 95,812,134 | 95812134 | 20.0% |
| `street_addresses.num_sources` | 95,812,134 | 95812134 | 20.0% |
| `street_addresses.postal_code` | 95,349,516 | 95349516 | 19.9% |
| `street_addresses.region` | 95,627,195 | 95627195 | 19.9% |
| `street_addresses.street_address` | 95,812,134 | 95812134 | 20.0% |
| `summary` | 20,650,743 | 20650743 | 4.3% |
| `twitter_url` | 3,941,333 | 3941333 | 0.8% |
| `twitter_username` | 3,941,333 | 3941333 | 0.8% |
| `work_email` | 18,676,783 | 18676783 | 3.9% |

*Stats shown are accurate as of data version 33.1*

Updated 6 days ago

---

Did this page help you?

Yes

No

---
# https://docs.peopledatalabs.com/docs/data-delivery-using-snowflake

# How to Request Snowflake Delivery

You can receive delivery through Snowflake by requesting a PDL subscription for our Person Data License. Here's how:

1. Log into your Snowflake account (or create one at <https://app.snowflake.com> if you don't have an account yet).
2. Click on your name in the bottom left corner of the screen and select the specific account where you want your data delivered.
3. Click "View account details" to access your account information.
4. From the account details page, locate your "Account Identifier" and share this information with your Customer Success Manager or Solutions Engineer.

---

# How To Access a Private Listing

To access a private listing that was shared with you, do the following:

1. Sign in to Snowflake.
2. Select `â€œData Productsâ€` Â» `â€œPrivate Sharingâ€`.
3. On the `â€œShared with Meâ€` page under `â€œPrivate Listingsâ€`, select the listing you want to access.
4. Select `â€œGetâ€`.

[ðŸ“º Watch a Demo](https://youtu.be/jrdPMyPjAno?feature=shared&t=167)

> ðŸ“˜
>
> Note: You must use the **ACCOUNTADMIN** role or another role with the `CREATE DATABASE` and `IMPORT SHARE` privileges to access a listing.

---

# Tabular Schemas

Snowflake license deliveries will use our Tabular Data License Schema for Person and Company data. These schema can be found here: [Table (Flattened) Data License Format](/docs/table-flattened-data-license-format#schema)

Updated 4 months ago

---

Did this page help you?

Yes

No

---
# https://docs.peopledatalabs.com/docs/reference-person-identify-api

# Endpoint

The endpoint for the Person Identify API is `https://api.peopledatalabs.com/v5/person/identify`.

# Person Identify API Access and Billing

You can access the Person Identify API through our [self-signup dashboard](https://peopledatalabs.com/signup/)

When the API finds a matching person, it returns up to 20 profiles sorted by match score along with an HTTP response code of `200`. When it doesn't find a matching person, it returns an HTTP response code of `404`. We charge **per 200 & 404**.

> ðŸš§
>
> ### Warning: Credit Usage
>
> Each call that you make to the Person Identify API will consume one credit, **regardless of the number of profiles that the API returns**.
>
> This behavior differs from that of our other APIs, which consume one credit for each profile that they return.

# Rate Limiting

The default rate limit for all customers is 10 calls per minute.

# Input Parameters

> ðŸ“˜
>
> ### For More Details, See [Person Identify API - Input Parameters](/docs/input-parameters-person-identify-api)
>
> You can also click on the individual parameter names in the table below to view more information on them.

| Parameter Name | Required | Description | Default | Example |
| --- | --- | --- | --- | --- |
| [`name`](/docs/input-parameters-person-identify-api#name) | No\* | The person's full name (at least the first and the last.) |  | Jennifer C. Jackson |
| [`first_name`](/docs/input-parameters-person-identify-api#first_name) | No\* | The person's first name. |  | Jennifer |
| [`last_name`](/docs/input-parameters-person-identify-api#last_name) | No\* | The person's last name. |  | Jackson |
| [`middle_name`](/docs/input-parameters-person-identify-api#middle_name) | No | The person's middle name. |  | Cassandra |
| [`location`](/docs/input-parameters-person-identify-api#location) | No\* | The location in which a person lives, which can be anything from a street address to a country name. |  | Medford, OR USA |
| [`street_address`](/docs/input-parameters-person-identify-api#street_address) | No\* | The street address at which the person lives. |  | 1234 Main Street |
| [`locality`](/docs/input-parameters-person-identify-api#locality) | No\* | The locality in which the person lives. |  | Boise |
| [`region`](/docs/input-parameters-person-identify-api#region) | No\* | The state or region in which the person lives. |  | Idaho |
| [`country`](/docs/input-parameters-person-identify-api#country) | No | The country in which the person lives. |  | United States |
| [`postal_code`](/docs/input-parameters-person-identify-api#postal_code) | No\* | The postal code in which the person lives. If there is no value for country, we assume that the postal code is in the US. |  | 83701 |
| [`company`](/docs/input-parameters-person-identify-api#company) | No\* | The name, website or social URL of a company where the person has worked. |  | Amazon Web Services |
| [`school`](/docs/input-parameters-person-identify-api#school) | No\* | The name, website or social URL of a university or college that the person has attended. |  | university of iowa |
| [`phone`](/docs/input-parameters-person-identify-api#phone) | No\* | A phone number the person has used. \*\*Input must begin with`+[country code]` for a match to be returned. \*\* |  | +1 555-234-1234 |
| [`email`](/docs/input-parameters-person-identify-api#email) | No\* | The email that the person has used. |  | [sean.thorne@talentiq.co](mailto:sean.thorne@talentiq.co) |
| [`email_hash`](/docs/input-parameters-person-identify-api#email_hash) | No\* | The sha256 or md5 email hash. |  | e206e6cd7fa5f9499fd6d2d943dcf7d9c1469bad351061483f5ce7181663b8d4 |
| [`profile`](/docs/input-parameters-person-identify-api#profile) | No\* | The social profile that the person has used (see the [list of available social profiles](/docs/social-networks)). |  | `https://linkedin.com/in/seanthorne` |
| [`lid`](/docs/input-parameters-person-identify-api#lid) | No\* | The LinkedIn numerical ID |  | 145991517 |
| [`birth_date`](/docs/input-parameters-person-identify-api#birth_date) | No | The person's birth date: either a year or a full birth date. |  | 35339 |
| [`titlecase`](/docs/input-parameters-person-identify-api#titlecase) | No | The API returns all text in the data object of responses as lowercase by default. Setting `titlecase` to `true` will titlecase the person data in `200` responses. | `false` | `true` |
| [`pretty`](/docs/input-parameters-person-identify-api#pretty) | No | Whether the output should have human-readable indentation. | `false` | `true` |
| [`api_key`](/docs/input-parameters-person-identify-api#api_key) | No\* | Your secret API key.     While we do not require this as part of the request parameters, if you do not provide it here, then you must provide it using an alternative means, such as in the headers using the `x-api-key` field. For more information, see the [Authentication](/docs/authentication) page. | None |  |
| [`include_if_matched`](/docs/input-parameters-person-identify-api#include_if_matched) | No | If set to `true`, the output will contain the [`matches.matched_on`](/docs/output-response-person-identify-api#matchesmatched_on) field which will list the fields in each profile that matched the input query. | `false` | `true` |

> **Note** (\*): While we don't require any of these parameters individually, you must provide a sufficient combination of them as inputs. For more details, see the [minimum required inputs](/docs/input-parameters-person-identify-api#required-parameters).

# Output Response

## Response Fields

> ðŸ“˜
>
> ### For More Details, See [Person Identify API - Output Response](/docs/output-response-person-identify-api)
>
> You can also click on the individual parameter names in the table below to view more information on them.

| Field Name | Type | Description |
| --- | --- | --- |
| [`status`](/docs/output-response-person-identify-api#status) | `Integer` | The [API response code](/docs/errors). |
| [`matches`](/docs/output-response-person-identify-api#matches) | `Array [Object]` | A list of up to 20 profiles matching the input criteria from the API request. The API only returns profiles with a [match\_score](/docs/output-response-person-identify-api#matchesmatch_score) greater than 5 (out of 100.) |
| [`matches.match_score`](/docs/output-response-person-identify-api#matchesmatch_score) | `Integer` | An integer between `1-99` drawn from a probability-like distribution representing the matching strength between a profile and the input criteria. In other words, the probability that this record is the record that you are looking for based on your query. |
| [`matches.data`](/docs/output-response-person-identify-api#matchesdata) | `Array [Object]` | The field attributes associated with this profile. For a list of fields, see the [Person Schema](/docs/fields). |
| [`matches.matched_on`](/docs/output-response-person-identify-api#matchesmatched_on) | `Array [String]` | A list of data fields that the API matched for this profile. The API only returns this if you set the [`include_if_matched`](/docs/input-parameters-person-identify-api#include_if_matched) input parameter to `true`. |

## Response Data Structure

The response from the Person Identify API will be in this format:

JSON

```
{
  "status": 200,
  "matches": [
    {
      "data": {
        ...
      },
      "match_score": 92,
      "matched_on": [
        "company",
        "name"
      ]
    },
    {
      "data": {
        ...
      },
      "match_score": 5,
      "matched_on": [
        "name"
      ]
    },
    ...
  ]
}
```

## Errors

If the request encounters an error, it will instead return an Error Response in the format described in [Errors](/docs/errors).

Updated 4 months ago

---

Did this page help you?

Yes

No

---
# https://docs.peopledatalabs.com/docs/job-title-enrichment-api

## Overview

The Job Title Enrichment API lets you enrich data on a job title by performing a one-to-one match of this job title with those included in our [Job Title](/docs/job-title-schema) Dataset. Once matched, you can search for profiles with less context. For example, instead of explicitly searching for "supply managers, supply chain managers, supply specialists and supply coordinators," you can search for "supply managers and similar job titles."

**Note**: Our current Job Title Dataset only contains job titles seen at least 100 times across our global resume data.

  

## Expected Usage

This API functions primarily as a support for our [Person Search API](/docs/person-search-api). Once you enhance a job title, you can use the returned information in your Person Search query to find better matches in our Person Dataset.

We expect the flow for using the Job Title Enrichment and Person Search APIs to broadly follow one of the two patterns shown in the diagrams below:

Flow 1: Using the Job Title Enrichment API to search for people with similar job titles.



Flow 2: Using the Job Title Enrichment API to search for people with skills relevant to the job title.

  
  

## What's Next

Please check out the following pages for more information on the Job Title Enrichment API:

| Page | Description |
| --- | --- |
| [Quickstart](/docs/quickstart-job-title-enrichment-api) | A quick hands-on introduction to the API with simple code examples. |
| [Reference](/docs/reference-job-title-enrichment-api) | Detailed descriptions of the technical specifications and usage constraints. |
| [Input Parameters](/docs/input-parameters-job-title-enrichment-api) | In-depth explanations of the input parameters that the API supports. |
| [Output Response](/docs/output-response-job-title-enrichment-api) | In-depth explanations of the output response object that the API returns. |
| [Examples](/docs/examples-job-title-enrichment-api) | A collection of functional code examples and walkthroughs illustrating various use cases and applications of the API. |

---



*Know someone whoâ€™d thrive building data products and helping us launch whatâ€™s next? Weâ€™d love to meet!*

*Check out our[open roles](https://www.peopledatalabs.com/company?utm_source=docs&utm_medium=footer&utm_campaign=cta#jobs) â†’*

Updated 4 months ago

---

Did this page help you?

Yes

No

---
# https://docs.peopledatalabs.com/docs/identify-api-reference

# Endpoint

The endpoint for the Person Identify API is `https://api.peopledatalabs.com/v5/person/identify`.

# Person Identify API Access and Billing

You can access the Person Identify API through our [self-signup dashboard](https://peopledatalabs.com/signup/)

When the API finds a matching person, it returns up to 20 profiles sorted by match score along with an HTTP response code of `200`. When it doesn't find a matching person, it returns an HTTP response code of `404`. We charge **per 200 & 404**.

> ðŸš§
>
> ### Warning: Credit Usage
>
> Each call that you make to the Person Identify API will consume one credit, **regardless of the number of profiles that the API returns**.
>
> This behavior differs from that of our other APIs, which consume one credit for each profile that they return.

# Rate Limiting

The default rate limit for all customers is 10 calls per minute.

# Input Parameters

> ðŸ“˜
>
> ### For More Details, See [Person Identify API - Input Parameters](/docs/input-parameters-person-identify-api)
>
> You can also click on the individual parameter names in the table below to view more information on them.

| Parameter Name | Required | Description | Default | Example |
| --- | --- | --- | --- | --- |
| [`name`](/docs/input-parameters-person-identify-api#name) | No\* | The person's full name (at least the first and the last.) |  | Jennifer C. Jackson |
| [`first_name`](/docs/input-parameters-person-identify-api#first_name) | No\* | The person's first name. |  | Jennifer |
| [`last_name`](/docs/input-parameters-person-identify-api#last_name) | No\* | The person's last name. |  | Jackson |
| [`middle_name`](/docs/input-parameters-person-identify-api#middle_name) | No | The person's middle name. |  | Cassandra |
| [`location`](/docs/input-parameters-person-identify-api#location) | No\* | The location in which a person lives, which can be anything from a street address to a country name. |  | Medford, OR USA |
| [`street_address`](/docs/input-parameters-person-identify-api#street_address) | No\* | The street address at which the person lives. |  | 1234 Main Street |
| [`locality`](/docs/input-parameters-person-identify-api#locality) | No\* | The locality in which the person lives. |  | Boise |
| [`region`](/docs/input-parameters-person-identify-api#region) | No\* | The state or region in which the person lives. |  | Idaho |
| [`country`](/docs/input-parameters-person-identify-api#country) | No | The country in which the person lives. |  | United States |
| [`postal_code`](/docs/input-parameters-person-identify-api#postal_code) | No\* | The postal code in which the person lives. If there is no value for country, we assume that the postal code is in the US. |  | 83701 |
| [`company`](/docs/input-parameters-person-identify-api#company) | No\* | The name, website or social URL of a company where the person has worked. |  | Amazon Web Services |
| [`school`](/docs/input-parameters-person-identify-api#school) | No\* | The name, website or social URL of a university or college that the person has attended. |  | university of iowa |
| [`phone`](/docs/input-parameters-person-identify-api#phone) | No\* | A phone number the person has used. \*\*Input must begin with`+[country code]` for a match to be returned. \*\* |  | +1 555-234-1234 |
| [`email`](/docs/input-parameters-person-identify-api#email) | No\* | The email that the person has used. |  | [sean.thorne@talentiq.co](mailto:sean.thorne@talentiq.co) |
| [`email_hash`](/docs/input-parameters-person-identify-api#email_hash) | No\* | The sha256 or md5 email hash. |  | e206e6cd7fa5f9499fd6d2d943dcf7d9c1469bad351061483f5ce7181663b8d4 |
| [`profile`](/docs/input-parameters-person-identify-api#profile) | No\* | The social profile that the person has used (see the [list of available social profiles](/docs/social-networks)). |  | `https://linkedin.com/in/seanthorne` |
| [`lid`](/docs/input-parameters-person-identify-api#lid) | No\* | The LinkedIn numerical ID |  | 145991517 |
| [`birth_date`](/docs/input-parameters-person-identify-api#birth_date) | No | The person's birth date: either a year or a full birth date. |  | 35339 |
| [`titlecase`](/docs/input-parameters-person-identify-api#titlecase) | No | The API returns all text in the data object of responses as lowercase by default. Setting `titlecase` to `true` will titlecase the person data in `200` responses. | `false` | `true` |
| [`pretty`](/docs/input-parameters-person-identify-api#pretty) | No | Whether the output should have human-readable indentation. | `false` | `true` |
| [`api_key`](/docs/input-parameters-person-identify-api#api_key) | No\* | Your secret API key.     While we do not require this as part of the request parameters, if you do not provide it here, then you must provide it using an alternative means, such as in the headers using the `x-api-key` field. For more information, see the [Authentication](/docs/authentication) page. | None |  |
| [`include_if_matched`](/docs/input-parameters-person-identify-api#include_if_matched) | No | If set to `true`, the output will contain the [`matches.matched_on`](/docs/output-response-person-identify-api#matchesmatched_on) field which will list the fields in each profile that matched the input query. | `false` | `true` |

> **Note** (\*): While we don't require any of these parameters individually, you must provide a sufficient combination of them as inputs. For more details, see the [minimum required inputs](/docs/input-parameters-person-identify-api#required-parameters).

# Output Response

## Response Fields

> ðŸ“˜
>
> ### For More Details, See [Person Identify API - Output Response](/docs/output-response-person-identify-api)
>
> You can also click on the individual parameter names in the table below to view more information on them.

| Field Name | Type | Description |
| --- | --- | --- |
| [`status`](/docs/output-response-person-identify-api#status) | `Integer` | The [API response code](/docs/errors). |
| [`matches`](/docs/output-response-person-identify-api#matches) | `Array [Object]` | A list of up to 20 profiles matching the input criteria from the API request. The API only returns profiles with a [match\_score](/docs/output-response-person-identify-api#matchesmatch_score) greater than 5 (out of 100.) |
| [`matches.match_score`](/docs/output-response-person-identify-api#matchesmatch_score) | `Integer` | An integer between `1-99` drawn from a probability-like distribution representing the matching strength between a profile and the input criteria. In other words, the probability that this record is the record that you are looking for based on your query. |
| [`matches.data`](/docs/output-response-person-identify-api#matchesdata) | `Array [Object]` | The field attributes associated with this profile. For a list of fields, see the [Person Schema](/docs/fields). |
| [`matches.matched_on`](/docs/output-response-person-identify-api#matchesmatched_on) | `Array [String]` | A list of data fields that the API matched for this profile. The API only returns this if you set the [`include_if_matched`](/docs/input-parameters-person-identify-api#include_if_matched) input parameter to `true`. |

## Response Data Structure

The response from the Person Identify API will be in this format:

JSON

```
{
  "status": 200,
  "matches": [
    {
      "data": {
        ...
      },
      "match_score": 92,
      "matched_on": [
        "company",
        "name"
      ]
    },
    {
      "data": {
        ...
      },
      "match_score": 5,
      "matched_on": [
        "name"
      ]
    },
    ...
  ]
}
```

## Errors

If the request encounters an error, it will instead return an Error Response in the format described in [Errors](/docs/errors).

Updated 4 months ago

---

Did this page help you?

Yes

No

---
# https://docs.peopledatalabs.com/docs/input-parameters-autocomplete-api

## Required Parameters

### `api_key`

| Type | Description | Default | Example |
| --- | --- | --- | --- |
| `String` | Your secret API key. |  |  |

Your API Key **must** be included in either the request header or the `api_key` parameter. For more information about request authentication, see the [Authentication](/docs/authentication) page.

  

### `field`

| Type | Description |
| --- | --- |
| `Enum (String)` | The field that the API will generate autocomplete suggestions for. |

Autocomplete suggestions will be generated based on the corresponding field(s) in the [Person Schema](/docs/fields).

For example, setting `field=industry` will generate autocomplete suggestions for the [`industry`](/docs/fields#industry), [`job_company_industry`](/docs/fields#job_company_industry), and [`experience.company.industry`](/docs/fields#experiencecompany) person fields.

See the table below for the supported Autocomplete `field` values and their corresponding Person fields:

| Autocomplete `field` Value | Corresponding Person Fields |
| --- | --- |
| `all_location` | Variable based on the type of location returned  (see `country`, `region`, `location_name`) |
| `class` | â€¢ [`job_title_class`](doc:fields#job_title_class) â€¢ [`experience.title.class`](doc:fields#experiencetitle) |
| `company` | â€¢ [`job_company_name`](doc:fields#job_company_name) â€¢ [`experience.company.name`](doc:fields#experiencecompany) |
| `country` | â€¢ [`location_country`](doc:fields#location_country) â€¢ [`countries`](doc:fields#countries) â€¢ [`street_addresses.country`](doc:fields#street_addresses) â€¢ [`job_company_location_country`](doc:fields#job_company_location_country) â€¢ [`experience.company.location.country`](doc:fields#experiencecompany) |
| `industry` | â€¢ [`industry`](doc:fields#industry) â€¢ [`job_company_industry`](doc:fields#job_company_industry) â€¢ [`experience.company.industry`](doc:fields#experiencecompany) |
| `location` (**DEPRECATED** - use `location_name` instead) | â€¢ [`location_name`](doc:fields#location_name) â€¢ [`location_names`](doc:fields#location_names) â€¢ [`street_addresses.name`](doc:fields#street_addresses) â€¢ [`job_company_location_name`](doc:fields#job_company_location_name) â€¢ [`experience.location_names`](doc:fields#experience) â€¢ [`experience.company.location.name`](doc:fields#experiencecompany) |
| `location_name` | â€¢ [`location_name`](doc:fields#location_name) â€¢ [`location_names`](doc:fields#location_names) â€¢ [`street_addresses.name`](doc:fields#street_addresses) â€¢ [`job_company_location_name`](doc:fields#job_company_location_name) â€¢ [`experience.location_names`](doc:fields#experience) â€¢ [`experience.company.location.name`](doc:fields#experiencecompany) |
| `major` | â€¢ [`education.majors`](doc:fields#education) â€¢ [`education.minors`](doc:fields#education) |
| `region` | â€¢ [`location_region`](doc:fields#location_region) â€¢ [`regions`](doc:fields#regions) â€¢ [`street_addresses.region`](doc:fields#street_addresses) â€¢ [`job_company_location_region`](doc:fields#job_company_location_region) â€¢ [`experience.company.location.region`](doc:fields#experiencecompany) |
| `role` | â€¢ [`job_title_role`](doc:fields#job_title_role) â€¢ [`experience.title.role`](doc:fields#experiencetitle) |
| `school` | â€¢ [`education.school.name`](doc:fields#educationschool) |
| `sub_role` | â€¢ [`job_title_sub_role`](doc:fields#job_title_sub_role) â€¢ [`experience.title.sub_role`](doc:fields#experiencetitle) |
| `skill` | â€¢ [`skills`](doc:fields#skills) |
| `title` | â€¢ [`job_title`](doc:fields#job_title) â€¢ [`experience.title.name`](doc:fields#experiencetitle) |
| `website` | â€¢ [`job_company_website`](doc:fields#job_company_website) â€¢ [`experience.company.website`](doc:fields#experiencecompany) |

---

## Optional Parameters

### `text`

| Type | Description | Default |
| --- | --- | --- |
| `String` | The starting text to use for autocompletion. | `""` |

**Example**

Let's see how the Autocomplete API behaves when we progressively build out `tesla` in the `text` field. Each call below represents a separate Autocomplete API call, where we keep updating the `text` field while keeping all other input parameters the same. For each call, we show the input parameters and the top returned result.

> ðŸ“˜
>
> ### Note: Click the Triangles To Expand Each of the API Calls Below
>
> Each call demonstrates the input parameters and the top result that the Autocomplete API returns.

**API Call 1:**

text = ""

Input Parameters:

JSON

```
params = {
    "field": "company",
    "text": "",
    "pretty": true,
    "api_key": API_KEY,
}
```

Top Autocomplete Result:

JSON

```
"data": [
    {
      "count": 501510,
      "name": "ibm",
      "meta": {
        "website": "ibm.com",
        "industry": "information technology and services",
        "location": "new york, new york, united states"
      }
    },
```

**API Call 2:**

text = "t"

Input Parameters:

JSON

```
params = {
    "field": "company",
    "text": "t",
    "pretty": true,
    "api_key": API_KEY,
}
```

Top Autocomplete Result:

JSON

```
"data": [
    {
      "count": 361642,
      "name": "tata consultancy services",
      "meta": {
        "website": "tcs.com",
        "industry": "information technology and services",
        "location": "bombay, maharashtra, india"
      }
    },
```

**API Call 3:**

text = "te"

Input Parameters:

JSON

```
params = {
    "field": "company",
    "text": "te",
    "pretty": true,
    "api_key": API_KEY,
}
```

Top Autocomplete Result:

JSON

```
"data": [
    {
      "count": 102762,
      "name": "tech mahindra",
      "meta": {
        "website": "techmahindra.com",
        "industry": "information technology and services",
        "location": "pune, maharashtra, india"
      }
    },
```

**API Call 4:**

text = "tes"

Input Parameters:

JSON

```
params = {
    "field": "company",
    "text": "tes",
    "pretty": true,
    "api_key": API_KEY,
}
```

Top Autocomplete Result:

JSON

```
"data": [
    {
      "count": 49735,
      "name": "tesco",
      "meta": {
        "website": "tescoplc.com",
        "industry": "retail",
        "location": "welwyn garden city, hertfordshire, united kingdom"
      }
    },
```

**API Call 5:**

text = "tesl"

Input Parameters:

JSON

```
params = {
    "field": "company",
    "text": "tesl",
    "pretty": true,
    "api_key": API_KEY,
}
```

Top Autocomplete Result:

JSON

```
"data": [
    {
      "count": 39992,
      "name": "tesla",
      "meta": {
        "website": "tesla.com",
        "industry": "automotive",
        "location": "palo alto, california, united states"
      }
    },
```

**API Call 6:**

text = "tesla"

Input Parameters:

JSON

```
params = {
    "field": "company",
    "text": "tesla",
    "pretty": true,
    "api_key": API_KEY,
}
```

Top Autocomplete Result:

JSON

```
"data": [
    {
      "count": 39992,
      "name": "tesla",
      "meta": {
        "website": "tesla.com",
        "industry": "automotive",
        "location": "palo alto, california, united states"
      }
    },
```

  

### `size`

| Type | Description | Default | Example |
| --- | --- | --- | --- |
| `Integer` | The number of results that the API should return. Must be between `1` and `100`. | `10` | `25` |

  

### `titlecase`

| Type | Description | Default | Example |
| --- | --- | --- | --- |
| `Boolean` | All text in API responses returns as lowercase by default. Setting `titlecase` to `true` will titlecase any records returned instead. | `false` | `true` |

  

### `pretty`

| Type | Description | Default | Example |
| --- | --- | --- | --- |
| `Boolean` | Whether the output should have [human-readable](http://jsonprettyprint.net/) indentation. | `false` | `true` |

  

### `updated_title_roles`

| Type | Description | Default | Example |
| --- | --- | --- | --- |
| `Boolean` | Temporary parameter. Set to true to return the updated values for role and subrole along with the new class field. | `false` | `true` |

Updated 4 months ago

---

Did this page help you?

Yes

No

---
# https://docs.peopledatalabs.com/docs/reference-autocomplete-api

# Endpoint

The endpoint for the Autocomplete API is: `https://api.peopledatalabs.com/v5/autocomplete`.

# Autocomplete API Access and Billing

By default, all active API keys have free access to the Autocomplete API.

When monitoring usage, each call to the Autocomplete API counts against the daily rate limit, regardless of the records available.

# Rate Limiting

Our default limit for self-serve customers is 60 requests per minute and 1,000 requests per day. For enterprise customers, we offer rate limits of up to 1,200 requests per minute. If you are interested in higher rate limits, please [reach out to us](https://www.peopledatalabs.com/talk-to-sales).

# Input Parameters

> ðŸ“˜
>
> ### For More Details, See [Input Parameters - Autocomplete API](/docs/input-parameters-autocomplete-api).
>
> You can also click on the individual parameter names in the table below to view more information on them.

| Parameter Name | Required | Description | Default | Example |
| --- | --- | --- | --- | --- |
| [`field`](/docs/input-parameters-autocomplete-api#field) | Yes | The field that the API will perform autocompletion upon. | None | `title` |
| [`text`](/docs/input-parameters-autocomplete-api#text) | No | The text that the API will use as the seed for autocompletion. | `""` | `tesl` |
| [`size`](/docs/input-parameters-autocomplete-api#size) | No | The number of results that the API should return, which must be between `1` and `100`. | `10` | `100` |
| [`titlecase`](/docs/input-parameters-autocomplete-api#titlecase) | No | All text in API responses returns as lowercase by default. Setting titlecase to `true` will titlecase any records returned instead. | `false` | `true` |
| [`pretty`](/docs/input-parameters-autocomplete-api#pretty) | No | Whether the output should have human-readable indentation. | `false` | `true` |
| [`api_key`](/docs/input-parameters-autocomplete-api#api_key) | No\* | Your secret API key.  While we do not require this as part of the request parameters, if you do not provide it here, then you must provide it using an alternative means, such as in the headers using the `x-api-key` field. For more information, see the [Authentication](/docs/authentication) page. | None |  |

# Output Response

> ðŸ“˜
>
> ### For More Details, See [Output Response - Autocomplete API](/docs/output-response-autocomplete-api)
>
> You can also click the field names in the table below to view more information on them.

| Field Name | Type | Description |
| --- | --- | --- |
| [`fields`](/docs/output-response-autocomplete-api#fields) | `Array (String)` | The list of fields in the [Person Schema](/docs/fields) that the Autocomplete API has returned suggestions for. It determines these based on the value that you used for the [`field` input parameter](/docs/input-parameters-autocomplete-api#field). |
| [`data`](/docs/output-response-autocomplete-api#data) | `Array (Object)` | The list of suggestions that the Autocomplete API has returned. It sorts results in descending order based on the `data.count` subfield (with the highest counts first.) The [`size` input parameter](/docs/input-parameters-autocomplete-api#size) determines the size of the list. |
| [`data.count`](/docs/output-response-autocomplete-api#datacount) | `Int` | The number of records in our [Person Dataset (resume slice)](/docs/resume-stats) for this Autocomplete API suggestion. The API uses this field for sorting elements in the `data` array. |
| [`data.name`](/docs/output-response-autocomplete-api#dataname) | `String` | The plain text name of the Autocomplete API suggestion. For example, company name, school name, location name, title and so forth. The prefix of this field will match the value of the [`text` input parameter](/docs/input-parameters-autocomplete-api#text). |
| [`data.meta`](/docs/output-response-autocomplete-api#datameta) | `Object` | A set of additional fields that the API returns for each result in the data array. The metadata fields depend on the [`field` input parameter](/docs/input-parameters-autocomplete-api#field). See the mapping between `field` values (input parameter) and `meta` (output fields) [here](/docs/output-response-autocomplete-api#datameta). |
| [`status`](/docs/output-response-autocomplete-api#status) | `Int` | The [API response code](/docs/errors). |

## Abridged Response Data Structure

Here is an example response from the Autocomplete API when querying for `field = "company"` and `text = "goog"` (See a full example response in the [next section](#full-example-response-autocomplete-api---school-index).)

JSON

```
{
  "data": [
    {
      "name": "Google",
      "count": 197302,
      "meta": {
        "id": "aKCIYBNF9ey6o5CjHCCO4goHYKlf",
        "website": "google.com",
        "industry": "Internet",
        "location_name": "Mountain View, California, United States",
        "display_name": "Google",
        "display_name_history": [
          "Google"
        ],
        "alternative_names": [
          "\u8c37\u6b4c",
          "Google, Social Marketing Tools",
          "\uad6c\uae00",
          "Google Inc.",
          "Google Pay",
          "Google, Inc.",
          "Google Deepmind",
          "Google Inc",
          "Google Digital Skills for Africa",
          "Google, Inc"
        ]
      }
    },
   ...
  ],
  "fields": [
    "job_company_name",
    "experience.company.name"
  ],
  "status": 200
}
```

## Full Example Response (Autocomplete API - School Index)

Input Query (click to toggle)

Python

```
import json

# See https://github.com/peopledatalabs/peopledatalabs-python
from peopledatalabs import PDLPY

# Create a client, specifying an API key
client = PDLPY(
    api_key="YOUR API KEY",
)

params = {
    "field": "school",
    "text": "harv",
    "size": 10,
    "pretty": True
}

json_response = client.autocomplete(**params).json()

print(json_response)
```

Output Response (full):

JSON

```
{
  "data": [
    {
      "name": "harvard university",
      "count": 1927529,
      "meta": {
        "id": "3533/1_nmK6OO9uG-7wiyTDSIrDiA_0",
        "website": "harvard.edu",
        "location_name": "cambridge, massachusetts, united states"
      }
    },
    {
      "name": "harvard business school",
      "count": 220817,
      "meta": {
        "id": "3533/1_qBjTBJNpBK2gzteZ59vd8A_0",
        "website": "hbs.edu",
        "location_name": "boston, massachusetts, united states"
      }
    },
    {
      "name": "harvard - westlake school",
      "count": 124263,
      "meta": {
        "id": "3533/1_NH1qPhIlKjFKZ1nf2Qgt3g_0",
        "website": "hw.com",
        "location_name": "studio city, california, united states"
      }
    },
    {
      "name": "harvard law school",
      "count": 96958,
      "meta": {
        "id": "3533/1_teCnNBZuJ7ec9lfQzEOvyg_0",
        "website": "hls.harvard.edu",
        "location_name": "cambridge, massachusetts, united states"
      }
    },
    {
      "name": "harvard business school online",
      "count": 70877,
      "meta": {
        "id": "3533/1_UB212jNfQFFVng4KfGkYlQ_0",
        "website": "online.hbs.edu",
        "location_name": "boston, massachusetts, united states"
      }
    },
    {
      "name": "harvard medical school",
      "count": 61403,
      "meta": {
        "id": "3533/1_YNnwi4r2jhgVlAvd7O400Q_0",
        "website": "hms.harvard.edu",
        "location_name": "boston, massachusetts, united states"
      }
    },
    {
      "name": "harvard extension school",
      "count": 38259,
      "meta": {
        "id": "3861/1_hJfk3w2iEDrBWBdwlSOyzg_0"
      }
    },
    {
      "name": "harvard graduate school of education",
      "count": 31485,
      "meta": {
        "id": "3533/1_R-t9DblDP5zWHDnIlJjY9g_0",
        "website": "gse.harvard.edu",
        "location_name": "cambridge, massachusetts, united states"
      }
    },
    {
      "name": "harvard kennedy school",
      "count": 30697,
      "meta": {
        "id": "3533/1_nTJjAd36aI1cfDBojvtlHA_0",
        "website": "hks.harvard.edu",
        "location_name": "cambridge, massachusetts, united states"
      }
    },
    {
      "name": "harvard business school executive education",
      "count": 27768,
      "meta": {
        "id": "3533/1_HTv2bAJvLvwEEeG0ai63BQ_0",
        "website": "hbs.me",
        "location_name": "boston, massachusetts, united states"
      }
    }
  ],
  "fields": [
    "education.school.name"
  ],
  "status": 200
}
```

## Errors

If the request encounters an error, it will instead return an Error Response in the format described in [Errors](/docs/errors).

Updated 4 months ago

---

Did this page help you?

Yes

No

---
# https://docs.peopledatalabs.com/docs/input-parameters-company-enrichment-api

## Required Parameters

The request must have enough data points to find a clear match. A valid request must include **at least one** of: OR [`pdl_id`](#pdl_id) OR [`name`](#name) OR [`ticker`](#ticker) OR [`website`](#website) OR [`profile`](#profile).

### `api_key`

| Type | Description | Default | Example |
| --- | --- | --- | --- |
| `String` | Your secret API key. |  |  |

Your API Key **must** be included in either the request header or the api\_key parameter. For more information about request authentication, see the [Authentication](/docs/authentication) page.

---

## Optional Parameters

### `pdl_id`

| Type | Description | Example |
| --- | --- | --- |
| `String` | The PDL ID or `linkedin_slug` for a record in our Company Dataset.    **Note**: If you enrich using `pdl_id` and anything else, only the `pdl_id` field is used and the other inputs for matching are ignored. | `aKCIYBNF9ey6o5CjHCCO4goHYKlf`or `google` |

### `name`

| Type | Description | Example |
| --- | --- | --- |
| `String` | The company's name. | `Google, Inc.` |

### `profile`

| Type | Description | Example |
| --- | --- | --- |
| `String` | The company's social profile. | `linkedin.com/company/google` |

### `ticker`

| Type | Description | Example |
| --- | --- | --- |
| `String` | The company's stock ticker, if publicly traded. | `GOOGL` |

### `website`

| Type | Description | Example |
| --- | --- | --- |
| `String` | The company's website. | `google.com` |

### `location`

| Type | Description | Example |
| --- | --- | --- |
| `String` | The location of the company's headquarters. This can be anything from a street address to a country name. | `1600 Amphitheatre Pkwy, Mountain View, CA 94043` |

You can input multiple location values.

### `street_address`

| Type | Description | Example |
| --- | --- | --- |
| `String` | The company HQ's street address. | `1600 Amphitheatre Pkwy` |

### `locality`

| Type | Description | Example |
| --- | --- | --- |
| `String` | The company HQ's locality. | `Mountain View` |

### `region`

| Type | Description | Example |
| --- | --- | --- |
| `String` | The company HQ's region. | `California` |

### `country`

| Type | Description | Example |
| --- | --- | --- |
| `String` | The company HQ's country. | `United States` |

### `postal_code`

| Type | Description | Example |
| --- | --- | --- |
| `String` | The company HQ's postal code. | `83701` |

### `data_include`

| Type | Description | Default | Example |
| --- | --- | --- | --- |
| `String` | A comma-separated string of [company fields](/docs/company-schema) that you want the response to include. |  | `"name,location.metro"` |

If this input parameter is not included, the full [company profile](/docs/company-schema) will be returned.

Include multiple fields by separating each with a comma. Include specific subfields by using dot notation (ex: `location.metro`).

Exclude field(s) by using `-` as the first character. Entering `-` will exclude all of the comma-separated fields following the character and needs to be entered only once. For example, `"-founded,location"` will remove the `founded` and `location` fields from the enriched profile response.

To exclude all data from being returned, use `data_include=""`.

### `pretty`

| Type | Description | Default | Example |
| --- | --- | --- | --- |
| `Boolean` | Whether the output should have [human-readable](http://jsonprettyprint.net/) indentation. | `false` | `true` |

### `titlecase`

| Type | Description | Default | Example |
| --- | --- | --- | --- |
| `Boolean` | All text in API responses returns as lowercase by default. Setting `titlecase` to `true` will titlecase response data instead. | `false` | `true` |

### `include_if_matched`

| Type | Description | Default | Example |
| --- | --- | --- | --- |
| `Boolean` | If `true`, the response will include the top-level field `matched` that contains a list of every input that matched this profile. | `false` | `true` |

As an example, if we wanted to enrich PDL using the following query:

JSON

```
{
   "name": "people data labs",
   "profile": "linkedin.com/company/peopledatalabs",
   "country": "abu dhabi",
   "include_if_matched": true
}
```

The response would contain:

JSON

```
{
   "matched": [
        "name",
        "profile"
    ]
}
```

### `min_likelihood`

| Type | Description | Default | Example |
| --- | --- | --- | --- |
| `Integer` | The minimum likelihood score that a profile must have in order for it to count as a match. Will be between `1-10`. | `2` | `6` |

This parameter allows you to balance precision and recall. In other words, using a high `min_likelihood` value will only return very strong matches but at the risk of not returning any match at all if none can be found above the `min_likelihood` threshold. Alternatively, using a low `min_likelihood` value is more likely to give you a match but at the cost of returning a potentially weaker match.

By default, match recall is kept very high, so a response that returns a likelihood score of `2` will have roughly a 10-30% chance of being the company requested. Adding more data points to your requests will increase the probability of a successful match (high likelihood score and is actually the requested company).

Here are some general rules of thumb for setting this parameter:

* For use cases which rely on a high degree of data accuracy, use a value â‰¥ `6`.
* Requests made with only a few less-specific data points, such as a name alone, will return lower scores.
* Requests made with just a name return a score between `2` and `5`, based on the quality of the match.

**Example**

Python3 SDKcURLJavaScriptRubyGoPython3

```
# See https://github.com/peopledatalabs/peopledatalabs-python
from peopledatalabs import PDLPY

# Create a client, specifying your API key
CLIENT = PDLPY(
    api_key="YOUR_API_KEY",
)

# Create a parameters JSON object
QUERY_STRING = {
              	"website":"google.com",
              	"min_likelihood": 5
               }

# Pass the parameters object to the Company Enrichment API
response = CLIENT.company.enrichment(**QUERY_STRING)

# Print the API response
print(response.text)
```

```
curl -X GET -G \
  'https://api.peopledatalabs.com/v5/company/enrich'\
  -H 'X-Api-Key: xxxx'\
  --data-urlencode 'website=google.com'
  --data-urlencode 'min_likelihood=5'
```

```
// See https://github.com/peopledatalabs/peopledatalabs-js
import PDLJS from 'peopledatalabs';

// Create a client, specifying your API key
const PDLJSClient = new PDLJS({ apiKey: "YOUR API KEY" });

// Create a parameters JSON object
const queryString = {
                        "website":"google.com",
                        "min_likelihood": 5
                    }

// Pass the parameters object to the Company Enrichment API
PDLJSClient.company.enrichment(queryString).then((data) => {
    // Print the API response
    console.log(data);
}).catch((error) => {
    console.log(error);
});
```

```
# See https://github.com/peopledatalabs/peopledatalabs-ruby
require 'peopledatalabs'

# Set your API key
Peopledatalabs.api_key = 'YOUR API KEY'

# Create a parameters JSON object
QUERY_STRING = {
                "website":"google.com",
                "min_likelihood": 5
               }

# Pass the parameters object to the Company Enrichment API
response = Peopledatalabs::Enrichment.company(params: QUERY_STRING)

# Print the API response
puts response
```

```
package main

import (
    "fmt"
    "context"
)

// See https://github.com/peopledatalabs/peopledatalabs-go
import (
    pdl "github.com/peopledatalabs/peopledatalabs-go"
    pdlmodel "github.com/peopledatalabs/peopledatalabs-go/model"
)

func main() {
    // Set your API key
    apiKey := "YOUR API KEY"
    // Set API key as environmental variable
    // apiKey := os.Getenv("API_KEY")

    // Create a client, specifying your API key
    client := pdl.New(apiKey)
    
    // Create a parameters JSON object
    queryString := pdlmodel.CompanyParams{Website: "google.com"}
    
    params := pdlmodel.EnrichCompanyParams{
        CompanyParams: queryString,
        AdditionalParams: pdlmodel.AdditionalParams {
            MinLikelihood: 5,
        },
    }
    
    // Pass the parameters object to the Company Enrichment API
    response, err := client.Company.Enrich(context.Background(), params)
    // Check for successful response
    if err == nil {
        // Print the API response
        fmt.Println(response)
    }  
}
```

```
import requests

# Set your API key
API_KEY = "YOUR API KEY"

# Set the Company Enrichment API URL
PDL_URL = "https://api.peopledatalabs.com/v5/company/enrich"

# Create a parameters JSON object
QUERY_STRING = {
              	"website":"google.com",
              	"min_likelihood": 5
               }

# Set headers
HEADERS = {
    'accept': "application/json",
    'content-type': "application/json",
    'x-api-key': API_KEY
    }

# Pass the parameters object to the Company Enrichment API
response = requests.request("GET", PDL_URL, headers=HEADERS, params=QUERY_STRING)

# Print the API response
print(response.text)
```

### `required`

| Type | Description | Default | Example |
| --- | --- | --- | --- |
| `String` | The fields a response must have in order to count as a match. |  | `location AND (website OR linkedin_url)` |

This parameter ensures that we only charge for responses that include the data fields that you're interested in. You can use any top-level [company fields](/docs/company-fields) except those that you use as search parameters and input fields. If you include a field in both the request and the `required` parameter, the `required` parameter will not work.

Format the value as a boolean statement.

**Examples**

*The response must contain a Linkedin URL*:

cURL

```
required=linkedin_url
```

*The response must contain location and a website*:

cURL

```
required=location AND website
```

*The response must contain a location or website*:

cURL

```
required=location OR website
```

*The response must contain a location and either a website or linkedin\_url*:

cURL

```
required=location AND (website OR linkedin_url)
```

Python3 SDKcURLJavaScriptRubyGoPython3

```
# See https://github.com/peopledatalabs/peopledatalabs-python
from peopledatalabs import PDLPY

# Create a client, specifying your API key
CLIENT = PDLPY(
    api_key="YOUR_API_KEY",
)

# Create a parameters JSON object
QUERY_STRING = {
              	"website":"google.com",
              	"required": "size"
               }

# Pass the parameters object to the Company Enrichment API
response = CLIENT.company.enrichment(**QUERY_STRING)

# Print the API response
print(response.text)
```

```
curl -X GET -G \
  'https://api.peopledatalabs.com/v5/company/enrich'\
  -H 'X-Api-Key: xxxx'\
  --data-urlencode 'website=google.com'
  --data-urlencode 'required=size'
```

```
// See https://github.com/peopledatalabs/peopledatalabs-js
import PDLJS from 'peopledatalabs';

const PDLJSClient = new PDLJS({ apiKey: "YOUR API KEY" });

const queryString = {
                        "website":"google.com",
                        "required": "size"
                    }

PDLJSClient.company.enrichment(queryString).then((data) => {
    console.log(data);
}).catch((error) => {
    console.log(error);
});
```

```
# See https://github.com/peopledatalabs/peopledatalabs-ruby
require 'peopledatalabs'

# Set your API key
Peopledatalabs.api_key = 'YOUR API KEY'

# Create a parameters JSON object
QUERY_STRING = {
                "website":"google.com",
              	"required": "size"
               }

# Pass the parameters object to the Company Enrichment API
response = Peopledatalabs::Enrichment.company(params: QUERY_STRING)

# Print the API response
puts response
```

```
package main

import (
    "fmt"
    "context"
)

// See https://github.com/peopledatalabs/peopledatalabs-go
import (
    pdl "github.com/peopledatalabs/peopledatalabs-go"
    pdlmodel "github.com/peopledatalabs/peopledatalabs-go/model"
)

func main() {
    // Set your API key
    apiKey := "YOUR API KEY"
    // Set API key as environmental variable
    // apiKey := os.Getenv("API_KEY")

    // Create a client, specifying your API key
    client := pdl.New(apiKey)
    
    // Create a parameters JSON object
    queryString := pdlmodel.CompanyParams{Website: "google.com"}
    
    params := pdlmodel.EnrichCompanyParams{
        CompanyParams: queryString,
        AdditionalParams: pdlmodel.AdditionalParams {
            Required: "size",
        },
    }
    
    // Pass the parameters object to the Company Enrichment API
    response, err := client.Company.Enrich(context.Background(), params)
    // Check for successful response
    if err == nil {
        // Print the API response
        fmt.Println(response)
    }  
}
```

```
import requests

# Set your API key
API_KEY = "YOUR API KEY"

# Set the Company Enrichment API URL
PDL_URL = "https://api.peopledatalabs.com/v5/company/enrich"

# Create a parameters JSON object
QUERY_STRING = {
              	"website":"google.com",
              	"required": "size"
               }

HEADERS = {
    'accept': "application/json",
    'content-type': "application/json",
    'x-api-key': API_KEY
    }

response = requests.request("GET", PDL_URL, headers=HEADERS, params=QUERY_STRING)

print(response.text)
```

### `size`

> ðŸš§
>
> ### Warning: Enterprise-Only Parameter
>
> The following parameter is only available for Enterprise customers. To enable the `size` parameter, speak with your Data Consultant.

| Type | Description | Default | Example |
| --- | --- | --- | --- |
| `Integer` | The maximum number of results to return (between 1-100). | `1` | `10` |

If this parameter is included in the request with a value greater than 1, that number of matching results will be returned sorted from highest [likelihood score](/docs/output-response-company-enrichment-api#likelihood) to lowest (within the [`min_likelihood`](#min_likelihood) score threshold).

Using this parameter will change the response type to an **array of objects** as shown in the example below.

**NOTE:** Each profile that is returned in the `data` array will cost 1 Company Enrichment credit, so use caution when setting this parameter.

**Example**

JSON

```
{
  "name": "MRI",
  "size": 2
}
```

JSON

```
{
  "status": 200,
  "size": 2,
  "data":  [
    {
      "name": "mri software",
      "display_name": "MRI Software",
      "size": "1001-5000",
      "employee_count": 3710,
      "id": "E33En1BC79vpLcvFkn1N5gDHWOBW",
      "founded": 1971,
      "industry": "information technology and services",
      ...
      "likelihood": 6
    },
    {
      "name": "mri systems",
      "display_name": "mri systems",
      "size": "1001-5000",
      "employee_count": 3710,
      "id": "E33En1BC79vpLcvFkn1N5gDHWOBW",
      "founded": 1971,
      "industry": "information technology and services",
      ...
      "likelihood": 4
    }
   ]
}
```

Updated 4 months ago

---

Did this page help you?

Yes

No

---
# https://docs.peopledatalabs.com/docs/stats

## Description

Our API Dataset is our full Person Dataset and is composed of records containing at least a name and one other piece of PII. The table below summarizes some key statistics and fill rates for fields within this dataset. Premium fields are not accessible by default.

**Common Use Cases**  
*Enrichment*

  

| Field | Count | Numeric | Fill Percentage |
| --- | --- | --- | --- |
| `Total` | 2,453,435,765 | 2453435765 | 100.0% |
| `birth_date` | 174,042,928 | 174042928 | 7.1% |
| `birth_year` | 352,163,909 | 352163909 | 14.4% |
| `certifications` | 65,736,713 | 65736713 | 2.7% |
| `certifications.end_date` | 51,522,333 | 51522333 | 2.1% |
| `certifications.name` | 65,736,713 | 65736713 | 2.7% |
| `certifications.organization` | 64,593,547 | 64593547 | 2.6% |
| `certifications.start_date` | 54,822,845 | 54822845 | 2.2% |
| `countries` | 1,815,088,381 | 1815088381 | 74.0% |
| `education` | 738,862,067 | 738862067 | 30.1% |
| `education.degrees` | 190,770,515 | 190770515 | 7.8% |
| `education.end_date` | 334,341,027 | 334341027 | 13.6% |
| `education.gpa` | 11,868,336 | 11868336 | 0.5% |
| `education.majors` | 246,956,117 | 246956117 | 10.1% |
| `education.minors` | 1,747,377 | 1747377 | 0.1% |
| `education.raw` | 395,128,654 | 395128654 | 16.1% |
| `education.school` | 737,870,088 | 737870088 | 30.1% |
| `education.school.domain` | 504,486,711 | 504486711 | 20.6% |
| `education.school.facebook_url` | 326,913,062 | 326913062 | 13.3% |
| `education.school.id` | 526,403,442 | 526403442 | 21.5% |
| `education.school.linkedin_id` | 526,403,442 | 526403442 | 21.5% |
| `education.school.linkedin_url` | 526,383,233 | 526383233 | 21.5% |
| `education.school.location` | 477,284,944 | 477284944 | 19.5% |
| `education.school.location.continent` | 477,284,944 | 477284944 | 19.5% |
| `education.school.location.country` | 477,284,867 | 477284867 | 19.5% |
| `education.school.location.locality` | 453,614,065 | 453614065 | 18.5% |
| `education.school.location.name` | 477,284,944 | 477284944 | 19.5% |
| `education.school.location.region` | 465,468,840 | 465468840 | 19.0% |
| `education.school.name` | 737,837,083 | 737837083 | 30.1% |
| `education.school.raw` | 735,075,205 | 735075205 | 30.0% |
| `education.school.twitter_url` | 309,023,214 | 309023214 | 12.6% |
| `education.school.type` | 603,813,320 | 603813320 | 24.6% |
| `education.school.website` | 504,486,711 | 504486711 | 20.6% |
| `education.start_date` | 318,091,361 | 318091361 | 13.0% |
| `education.summary` | 71,823,966 | 71823966 | 2.9% |
| `emails` | 634,278,896 | 634278896 | 25.9% |
| `emails.address` | 634,278,896 | 634278896 | 25.9% |
| `emails.first_seen` | 634,278,896 | 634278896 | 25.9% |
| `emails.last_seen` | 634,278,896 | 634278896 | 25.9% |
| `emails.md5_hash` | 634,278,896 | 634278896 | 25.9% |
| `emails.num_sources` | 634,278,896 | 634278896 | 25.9% |
| `emails.sha_256_hash` | 634,278,896 | 634278896 | 25.9% |
| `emails.type` | 562,224,395 | 562224395 | 22.9% |
| `experience` | 919,904,464 | 919904464 | 37.5% |
| `experience.company` | 878,456,293 | 878456293 | 35.8% |
| `experience.company.facebook_url` | 358,137,265 | 358137265 | 14.6% |
| `experience.company.founded` | 458,789,229 | 458789229 | 18.7% |
| `experience.company.id` | 601,654,212 | 601654212 | 24.5% |
| `experience.company.industry` | 574,973,605 | 574973605 | 23.4% |
| `experience.company.industry_v2` | 550,796,081 | 550796081 | 22.4% |
| `experience.company.linkedin_id` | 601,654,212 | 601654212 | 24.5% |
| `experience.company.linkedin_url` | 601,654,212 | 601654212 | 24.5% |
| `experience.company.location` | 576,590,930 | 576590930 | 23.5% |
| `experience.company.location.address_line_2` | 91,291,522 | 91291522 | 3.7% |
| `experience.company.location.continent` | 575,427,867 | 575427867 | 23.5% |
| `experience.company.location.country` | 576,587,869 | 576587869 | 23.5% |
| `experience.company.location.geo` | 536,252,419 | 536252419 | 21.9% |
| `experience.company.location.locality` | 543,783,551 | 543783551 | 22.2% |
| `experience.company.location.metro` | 241,790,470 | 241790470 | 9.9% |
| `experience.company.location.name` | 576,590,930 | 576590930 | 23.5% |
| `experience.company.location.postal_code` | 473,789,479 | 473789479 | 19.3% |
| `experience.company.location.region` | 549,769,203 | 549769203 | 22.4% |
| `experience.company.location.street_address` | 448,300,672 | 448300672 | 18.3% |
| `experience.company.name` | 878,440,842 | 878440842 | 35.8% |
| `experience.company.raw` | 878,436,339 | 878436339 | 35.8% |
| `experience.company.size` | 601,654,212 | 601654212 | 24.5% |
| `experience.company.ticker` | 126,402,491 | 126402491 | 5.2% |
| `experience.company.twitter_url` | 307,256,851 | 307256851 | 12.5% |
| `experience.company.type` | 601,654,212 | 601654212 | 24.5% |
| `experience.company.website` | 546,100,990 | 546100990 | 22.3% |
| `experience.end_date` | 279,472,907 | 279472907 | 11.4% |
| `experience.first_seen` | 919,904,464 | 919904464 | 37.5% |
| `experience.is_primary` | 919,904,464 | 919904464 | 37.5% |
| `experience.last_seen` | 919,904,464 | 919904464 | 37.5% |
| `experience.location_names` | 344,195,299 | 344195299 | 14.0% |
| `experience.num_sources` | 919,904,464 | 919904464 | 37.5% |
| `experience.start_date` | 442,866,411 | 442866411 | 18.1% |
| `experience.summary` | 188,141,835 | 188141835 | 7.7% |
| `experience.title` | 775,635,372 | 775635372 | 31.6% |
| `experience.title.class` | 523,365,593 | 523365593 | 21.3% |
| `experience.title.levels` | 261,929,727 | 261929727 | 10.7% |
| `experience.title.name` | 775,635,372 | 775635372 | 31.6% |
| `experience.title.raw` | 775,635,372 | 775635372 | 31.6% |
| `experience.title.role` | 523,365,593 | 523365593 | 21.3% |
| `experience.title.sub_role` | 449,385,521 | 449385521 | 18.3% |
| `facebook_friends` | 38,651,608 | 38651608 | 1.6% |
| `facebook_id` | 1,004,228,437 | 1004228437 | 40.9% |
| `facebook_url` | 714,981,062 | 714981062 | 29.1% |
| `facebook_username` | 714,981,062 | 714981062 | 29.1% |
| `first_name` | 2,453,435,765 | 2453435765 | 100.0% |
| `first_seen` | 2,453,435,765 | 2453435765 | 100.0% |
| `full_name` | 2,453,435,765 | 2453435765 | 100.0% |
| `github_url` | 3,528,906 | 3528906 | 0.1% |
| `github_username` | 3,528,906 | 3528906 | 0.1% |
| `headline` | 186,391,542 | 186391542 | 7.6% |
| `id` | 2,453,435,765 | 2453435765 | 100.0% |
| `industry` | 426,691,553 | 426691553 | 17.4% |
| `inferred_salary` | 278,542,838 | 278542838 | 11.4% |
| `inferred_years_experience` | 436,110,362 | 436110362 | 17.8% |
| `interests` | 100,459,421 | 100459421 | 4.1% |
| `job_company_12mo_employee_growth_rate` | 346,675,076 | 346675076 | 14.1% |
| `job_company_employee_count` | 351,625,419 | 351625419 | 14.3% |
| `job_company_facebook_url` | 169,350,353 | 169350353 | 6.9% |
| `job_company_founded` | 246,725,895 | 246725895 | 10.1% |
| `job_company_id` | 351,660,167 | 351660167 | 14.3% |
| `job_company_industry` | 332,609,624 | 332609624 | 13.6% |
| `job_company_industry_v2` | 317,198,426 | 317198426 | 12.9% |
| `job_company_inferred_revenue` | 351,625,419 | 351625419 | 14.3% |
| `job_company_linkedin_id` | 351,660,167 | 351660167 | 14.3% |
| `job_company_linkedin_url` | 351,660,167 | 351660167 | 14.3% |
| `job_company_location_address_line_2` | 30,969,344 | 30969344 | 1.3% |
| `job_company_location_continent` | 330,042,113 | 330042113 | 13.5% |
| `job_company_location_country` | 330,923,787 | 330923787 | 13.5% |
| `job_company_location_geo` | 299,058,942 | 299058942 | 12.2% |
| `job_company_location_locality` | 305,781,977 | 305781977 | 12.5% |
| `job_company_location_metro` | 103,511,757 | 103511757 | 4.2% |
| `job_company_location_name` | 330,927,954 | 330927954 | 13.5% |
| `job_company_location_postal_code` | 243,046,534 | 243046534 | 9.9% |
| `job_company_location_region` | 311,170,473 | 311170473 | 12.7% |
| `job_company_location_street_address` | 227,853,422 | 227853422 | 9.3% |
| `job_company_name` | 520,278,423 | 520278423 | 21.2% |
| `job_company_size` | 351,660,167 | 351660167 | 14.3% |
| `job_company_ticker` | 50,758,215 | 50758215 | 2.1% |
| `job_company_total_funding_raised` | 70,460,598 | 70460598 | 2.9% |
| `job_company_twitter_url` | 131,665,755 | 131665755 | 5.4% |
| `job_company_type` | 351,660,167 | 351660167 | 14.3% |
| `job_company_website` | 306,477,527 | 306477527 | 12.5% |
| `job_history` | 920,841,782 | 920841782 | 37.5% |
| `job_history.company_id` | 613,272,704 | 613272704 | 25.0% |
| `job_history.company_name` | 880,815,807 | 880815807 | 35.9% |
| `job_history.first_seen` | 920,841,782 | 920841782 | 37.5% |
| `job_history.last_seen` | 920,841,782 | 920841782 | 37.5% |
| `job_history.num_sources` | 920,841,782 | 920841782 | 37.5% |
| `job_history.title` | 776,799,343 | 776799343 | 31.7% |
| `job_last_changed` | 551,344,369 | 551344369 | 22.5% |
| `job_last_verified` | 551,344,369 | 551344369 | 22.5% |
| `job_onet_broad_occupation` | 243,983,236 | 243983236 | 9.9% |
| `job_onet_code` | 243,983,236 | 243983236 | 9.9% |
| `job_onet_major_group` | 243,983,236 | 243983236 | 9.9% |
| `job_onet_minor_group` | 243,983,236 | 243983236 | 9.9% |
| `job_onet_specific_occupation` | 243,983,236 | 243983236 | 9.9% |
| `job_onet_specific_occupation_detail` | 96,328,524 | 96328524 | 3.9% |
| `job_start_date` | 331,689,451 | 331689451 | 13.5% |
| `job_summary` | 77,689,590 | 77689590 | 3.2% |
| `job_title` | 534,703,959 | 534703959 | 21.8% |
| `job_title_class` | 316,190,214 | 316190214 | 12.9% |
| `job_title_levels` | 131,334,025 | 131334025 | 5.4% |
| `job_title_role` | 316,190,214 | 316190214 | 12.9% |
| `job_title_sub_role` | 250,110,575 | 250110575 | 10.2% |
| `languages` | 301,289,939 | 301289939 | 12.3% |
| `languages.name` | 301,289,939 | 301289939 | 12.3% |
| `languages.proficiency` | 24,068,001 | 24068001 | 1.0% |
| `last_initial` | 2,453,435,765 | 2453435765 | 100.0% |
| `last_name` | 2,429,734,531 | 2429734531 | 99.0% |
| `linkedin_connections` | 518,631,799 | 518631799 | 21.1% |
| `linkedin_id` | 593,390,643 | 593390643 | 24.2% |
| `linkedin_url` | 761,163,539 | 761163539 | 31.0% |
| `linkedin_username` | 761,163,539 | 761163539 | 31.0% |
| `location_address_line_2` | 69,046,582 | 69046582 | 2.8% |
| `location_continent` | 1,815,117,772 | 1815117772 | 74.0% |
| `location_country` | 1,815,065,338 | 1815065338 | 74.0% |
| `location_geo` | 1,478,935,019 | 1478935019 | 60.3% |
| `location_last_updated` | 1,124,491,467 | 1124491467 | 45.8% |
| `location_locality` | 1,494,380,694 | 1494380694 | 60.9% |
| `location_metro` | 616,101,696 | 616101696 | 25.1% |
| `location_name` | 1,815,117,772 | 1815117772 | 74.0% |
| `location_names` | 1,499,416,226 | 1499416226 | 61.1% |
| `location_postal_code` | 494,714,734 | 494714734 | 20.2% |
| `location_region` | 1,600,270,048 | 1600270048 | 65.2% |
| `location_street_address` | 466,843,745 | 466843745 | 19.0% |
| `middle_initial` | 614,668,150 | 614668150 | 25.1% |
| `middle_name` | 414,183,026 | 414183026 | 16.9% |
| `mobile_phone` | 503,147,900 | 503147900 | 20.5% |
| `name_aliases` | 129,039,507 | 129039507 | 5.3% |
| `num_records` | 2,453,435,765 | 2453435765 | 100.0% |
| `num_sources` | 2,453,435,765 | 2453435765 | 100.0% |
| `personal_emails` | 428,928,429 | 428928429 | 17.5% |
| `phone_numbers` | 891,072,874 | 891072874 | 36.3% |
| `phones` | 891,072,874 | 891072874 | 36.3% |
| `phones.first_seen` | 891,072,874 | 891072874 | 36.3% |
| `phones.last_seen` | 891,072,874 | 891072874 | 36.3% |
| `phones.num_sources` | 891,072,874 | 891072874 | 36.3% |
| `phones.number` | 891,072,874 | 891072874 | 36.3% |
| `possible_birth_dates` | 173,689,073 | 173689073 | 7.1% |
| `possible_emails` | 115,998,213 | 115998213 | 4.7% |
| `possible_emails.address` | 115,998,213 | 115998213 | 4.7% |
| `possible_emails.first_seen` | 115,998,213 | 115998213 | 4.7% |
| `possible_emails.last_seen` | 115,998,213 | 115998213 | 4.7% |
| `possible_emails.md5_hash` | 115,998,213 | 115998213 | 4.7% |
| `possible_emails.num_sources` | 115,998,213 | 115998213 | 4.7% |
| `possible_emails.sha_256_hash` | 115,998,213 | 115998213 | 4.7% |
| `possible_emails.type` | 97,210,875 | 97210875 | 4.0% |
| `possible_location_names` | 975,567,984 | 975567984 | 39.8% |
| `possible_phones` | 49,030,755 | 49030755 | 2.0% |
| `possible_phones.first_seen` | 49,030,755 | 49030755 | 2.0% |
| `possible_phones.last_seen` | 49,030,755 | 49030755 | 2.0% |
| `possible_phones.num_sources` | 49,030,755 | 49030755 | 2.0% |
| `possible_phones.number` | 49,030,755 | 49030755 | 2.0% |
| `possible_profiles` | 65,026,900 | 65026900 | 2.7% |
| `possible_profiles.first_seen` | 65,026,900 | 65026900 | 2.7% |
| `possible_profiles.id` | 46,887,377 | 46887377 | 1.9% |
| `possible_profiles.last_seen` | 65,026,900 | 65026900 | 2.7% |
| `possible_profiles.network` | 65,026,900 | 65026900 | 2.7% |
| `possible_profiles.num_sources` | 65,026,900 | 65026900 | 2.7% |
| `possible_profiles.url` | 65,026,900 | 65026900 | 2.7% |
| `possible_profiles.username` | 46,508,824 | 46508824 | 1.9% |
| `possible_street_addresses` | 41,779,334 | 41779334 | 1.7% |
| `possible_street_addresses.address_line_2` | 8,219,782 | 8219782 | 0.3% |
| `possible_street_addresses.continent` | 41,779,334 | 41779334 | 1.7% |
| `possible_street_addresses.country` | 41,779,334 | 41779334 | 1.7% |
| `possible_street_addresses.first_seen` | 41,779,334 | 41779334 | 1.7% |
| `possible_street_addresses.geo` | 41,777,484 | 41777484 | 1.7% |
| `possible_street_addresses.last_seen` | 41,779,334 | 41779334 | 1.7% |
| `possible_street_addresses.locality` | 41,778,758 | 41778758 | 1.7% |
| `possible_street_addresses.metro` | 35,501,664 | 35501664 | 1.4% |
| `possible_street_addresses.name` | 41,779,334 | 41779334 | 1.7% |
| `possible_street_addresses.num_sources` | 41,779,334 | 41779334 | 1.7% |
| `possible_street_addresses.postal_code` | 41,506,829 | 41506829 | 1.7% |
| `possible_street_addresses.region` | 41,778,963 | 41778963 | 1.7% |
| `possible_street_addresses.street_address` | 41,779,334 | 41779334 | 1.7% |
| `profiles` | 1,867,327,516 | 1867327516 | 76.1% |
| `profiles.first_seen` | 1,867,327,516 | 1867327516 | 76.1% |
| `profiles.id` | 1,589,188,070 | 1589188070 | 64.8% |
| `profiles.last_seen` | 1,867,327,516 | 1867327516 | 76.1% |
| `profiles.network` | 1,867,327,516 | 1867327516 | 76.1% |
| `profiles.num_sources` | 1,867,327,516 | 1867327516 | 76.1% |
| `profiles.url` | 1,867,327,516 | 1867327516 | 76.1% |
| `profiles.username` | 1,559,462,436 | 1559462436 | 63.6% |
| `recommended_personal_email` | 428,868,820 | 428868820 | 17.5% |
| `regions` | 1,609,019,874 | 1609019874 | 65.6% |
| `sex` | 1,737,656,518 | 1737656518 | 70.8% |
| `skills` | 146,485,418 | 146485418 | 6.0% |
| `street_addresses` | 475,740,565 | 475740565 | 19.4% |
| `street_addresses.address_line_2` | 170,375,696 | 170375696 | 6.9% |
| `street_addresses.continent` | 475,740,565 | 475740565 | 19.4% |
| `street_addresses.country` | 475,740,565 | 475740565 | 19.4% |
| `street_addresses.first_seen` | 475,740,565 | 475740565 | 19.4% |
| `street_addresses.geo` | 474,931,222 | 474931222 | 19.4% |
| `street_addresses.last_seen` | 475,740,565 | 475740565 | 19.4% |
| `street_addresses.locality` | 475,048,047 | 475048047 | 19.4% |
| `street_addresses.metro` | 408,735,820 | 408735820 | 16.7% |
| `street_addresses.name` | 475,740,565 | 475740565 | 19.4% |
| `street_addresses.num_sources` | 475,740,565 | 475740565 | 19.4% |
| `street_addresses.postal_code` | 472,713,473 | 472713473 | 19.3% |
| `street_addresses.region` | 475,137,472 | 475137472 | 19.4% |
| `street_addresses.street_address` | 475,740,565 | 475740565 | 19.4% |
| `summary` | 185,676,835 | 185676835 | 7.6% |
| `twitter_url` | 55,981,475 | 55981475 | 2.3% |
| `twitter_username` | 55,981,475 | 55981475 | 2.3% |
| `work_email` | 66,143,624 | 66143624 | 2.7% |

*Stats shown are accurate as of data version 33.1*

Updated 6 days ago

---

Did this page help you?

Yes

No

---
# https://docs.peopledatalabs.com/docs/elasticsearch-mapping-company

The following is the full Elasticsearch field mapping for Company data. Use the mapping when writing Elasticsearch queries with the [Company Search API](/docs/company-search-api) to fine-tune your results.

For more information about Elasticsearch fields, see <https://www.elastic.co/guide/en/elasticsearch/reference/current/mapping-types.html>.

JSON

```
{
  "properties": {
    "id": {
      "type": "keyword",
      "index": true,
      "doc_values": true
    },
    "linkedin_slug": {
      "type": "keyword",
      "index": true,
      "doc_values": true
    },
    "website": {
      "type": "keyword",
      "index": true,
      "doc_values": true
    },
    "name": {
      "type": "keyword",
      "index": true,
      "ignore_above": 256,
      "fields": {
        "text": {
          "type": "text",
          "doc_values": false
        }
      }
    },
    "display_name": {
      "type": "keyword",
      "index": true,
      "doc_values": true
    },
    "founded": {
      "type": "date",
      "index": true,
      "format": "yyyy-MM-dd||yyyy-MM||yyyy",
      "ignore_malformed": true
    },
    "size": {
      "type": "keyword",
      "index": true,
      "doc_values": true
    },
    "linkedin_follower_count": {
      "type": "integer",
      "index": true,
      "doc_values": false
    },
    "location": {
      "properties": {
        "name": {
          "type": "keyword",
          "index": true,
          "doc_values": true
        },
        "locality": {
          "type": "keyword",
          "index": true,
          "doc_values": true
        },
        "region": {
          "type": "keyword",
          "index": true,
          "doc_values": true
        },
        "metro": {
          "type": "keyword",
          "index": true,
          "doc_values": true
        },
        "country": {
          "type": "keyword",
          "index": true,
          "doc_values": true
        },
        "continent": {
          "type": "keyword",
          "index": true,
          "doc_values": true
        },
        "street_address": {
          "type": "keyword",
          "index": true,
          "doc_values": true
        },
        "address_line_2": {
          "type": "keyword",
          "index": true,
          "doc_values": true
        },
        "postal_code": {
          "type": "keyword",
          "index": true,
          "doc_values": true
        },
        "geo": {
          "type": "geo_point",
          "index": true,
          "doc_values": false
        }
      }
    },
    "locations": {
      "properties": {
        "name": {
          "type": "keyword",
          "index": true,
          "doc_values": true
        },
        "locality": {
          "type": "keyword",
          "index": true,
          "doc_values": true
        },
        "region": {
          "type": "keyword",
          "index": true,
          "doc_values": true
        },
        "metro": {
          "type": "keyword",
          "index": true,
          "doc_values": true
        },
        "country": {
          "type": "keyword",
          "index": true,
          "doc_values": true
        },
        "continent": {
          "type": "keyword",
          "index": true,
          "doc_values": true
        },
        "street_address": {
          "type": "keyword",
          "index": true,
          "doc_values": true
        },
        "address_line_2": {
          "type": "keyword",
          "index": true,
          "doc_values": true
        },
        "postal_code": {
          "type": "keyword",
          "index": true,
          "doc_values": true
        },
        "geo": {
          "type": "keyword",
          "index": true,
          "doc_values": true
        },
        "is_primary": {
          "type": "boolean",
          "index": true,
          "doc_values": false
        },
        "is_active": {
          "type": "boolean",
          "index": true,
          "doc_values": false
        },
        "first_seen": {
          "type": "keyword",
          "index": true,
          "doc_values": true
        },
        "last_seen": {
          "type": "keyword",
          "index": true,
          "doc_values": true
        }
      }
    },
    "num_total_locations": {
      "type": "integer",
      "index": true,
      "doc_values": false
    },
    "num_active_locations": {
      "type": "integer",
      "index": true,
      "doc_values": false
    },
    "industry": {
      "type": "keyword",
      "index": true,
      "doc_values": true
    },
    "industry_v2": {
      "type": "keyword",
      "index": true,
      "doc_values": true
    },
    "facebook_url": {
      "type": "keyword",
      "index": true,
      "doc_values": true
    },
    "twitter_url": {
      "type": "keyword",
      "index": true,
      "doc_values": true
    },
    "linkedin_url": {
      "type": "keyword",
      "index": true,
      "doc_values": true
    },
    "linkedin_id": {
      "type": "keyword",
      "index": true,
      "doc_values": true
    },
    "ticker": {
      "type": "keyword",
      "index": true,
      "doc_values": true,
      "normalizer": "lowercase"
    },
    "mic_exchange": {
      "type": "keyword",
      "index": true,
      "doc_values": true
    },
    "type": {
      "type": "keyword",
      "index": true,
      "doc_values": true
    },
    "profiles": {
      "type": "keyword",
      "index": true,
      "doc_values": true
    },
    "tags": {
      "type": "keyword",
      "index": true,
      "ignore_above": 256,
      "fields": {
        "text": {
          "type": "text",
          "doc_values": false
        }
      }
    },
    "summary": {
      "type": "text",
      "index": true,
      "doc_values": false
    },
    "headline": {
      "type": "text",
      "index": true,
      "doc_values": false
    },
    "alternative_names": {
      "type": "keyword",
      "index": true,
      "ignore_above": 256,
      "fields": {
        "text": {
          "type": "text",
          "doc_values": false
        }
      }
    },
    "alternative_domains": {
      "type": "keyword",
      "index": true,
      "doc_values": true
    },
    "affiliated_profiles": {
      "type": "keyword",
      "index": true,
      "doc_values": true
    },
    "ultimate_parent": {
      "type": "keyword",
      "index": true,
      "doc_values": true
    },
    "immediate_parent": {
      "type": "keyword",
      "index": true,
      "doc_values": true
    },
    "direct_subsidiaries": {
      "type": "keyword",
      "index": true,
      "doc_values": true
    },
    "all_subsidiaries": {
      "type": "keyword",
      "index": true,
      "doc_values": true
    },
    "ultimate_parent_ticker": {
      "type": "keyword",
      "index": true,
      "doc_values": true
    },
    "ultimate_parent_mic_exchange": {
      "type": "keyword",
      "index": true,
      "doc_values": true
    },
    "total_funding_raised": {
      "type": "float",
      "index": true,
      "doc_values": false
    },
    "funding_stages": {
      "type": "keyword",
      "index": true,
      "doc_values": true
    },
    "latest_funding_stage": {
      "type": "keyword",
      "index": true,
      "doc_values": true
    },
    "number_funding_rounds": {
      "type": "integer",
      "index": true,
      "doc_values": false
    },
    "last_funding_date": {
      "type": "date",
      "index": true,
      "format": "yyyy-MM-dd||yyyy-MM||yyyy",
      "ignore_malformed": true
    },
    "funding_details": {
      "properties": {
        "funding_round_date": {
          "type": "keyword",
          "index": false,
          "doc_values": true
        },
        "funding_raised": {
          "type": "float",
          "index": false,
          "doc_values": false
        },
        "funding_currency": {
          "type": "keyword",
          "index": false,
          "doc_values": true
        },
        "funding_type": {
          "type": "keyword",
          "index": false,
          "doc_values": true
        },
        "investing_companies": {
          "type": "keyword",
          "index": false,
          "doc_values": true
        },
        "investing_individuals": {
          "type": "keyword",
          "index": true,
          "doc_values": true
        }
      }
    },
    "sic": {
      "properties": {
        "sic_code": {
          "type": "keyword",
          "index": true,
          "doc_values": true
        },
        "major_group": {
          "type": "keyword",
          "index": true,
          "doc_values": true
        },
        "industry_group": {
          "type": "keyword",
          "index": true,
          "doc_values": true
        },
        "industry_sector": {
          "type": "keyword",
          "index": true,
          "doc_values": true
        }
      }
    },
    "naics": {
      "properties": {
        "naics_code": {
          "type": "keyword",
          "index": true,
          "doc_values": true
        },
        "sector": {
          "type": "keyword",
          "index": true,
          "doc_values": true
        },
        "sub_sector": {
          "type": "keyword",
          "index": true,
          "doc_values": true
        },
        "industry_group": {
          "type": "keyword",
          "index": true,
          "doc_values": true
        },
        "naics_industry": {
          "type": "keyword",
          "index": true,
          "doc_values": true
        },
        "national_industry": {
          "type": "keyword",
          "index": true,
          "doc_values": true
        }
      }
    },
    "dataset_version": {
      "type": "keyword",
      "index": true,
      "doc_values": true
    },
    "affiliated_entities": {
      "properties": {
        "affiliated_id": {
          "type": "keyword",
          "index": true,
          "doc_values": true
        },
        "display_name": {
          "type": "keyword",
          "index": false,
          "doc_values": true
        },
        "relationship": {
          "type": "keyword",
          "index": false,
          "doc_values": true
        },
        "relationship_catalyst": {
          "type": "keyword",
          "index": true,
          "doc_values": true
        },
        "relationship_status": {
          "type": "keyword",
          "index": false,
          "doc_values": true
        },
        "start_date": {
          "type": "keyword",
          "index": false,
          "doc_values": true
        },
        "end_date": {
          "type": "keyword",
          "index": false,
          "doc_values": true
        },
        "relationship_citations": {
          "type": "keyword",
          "index": false,
          "doc_values": true
        },
        "relationship_internal_inferred": {
          "type": "keyword",
          "index": true,
          "doc_values": true
        }
      }
    },
    "active_job_postings": {
      "type": "integer",
      "index": true,
      "doc_values": true
    },
    "deactivated_job_postings": {
      "type": "integer",
      "index": true,
      "doc_values": true
    },
    "employee_growth_rate": {
      "properties": {
        "3_month": {
          "type": "float",
          "index": true,
          "doc_values": true
        },
        "6_month": {
          "type": "float",
          "index": true,
          "doc_values": true
        },
        "12_month": {
          "type": "float",
          "index": true,
          "doc_values": true
        },
        "24_month": {
          "type": "float",
          "index": true,
          "doc_values": true
        }
      }
    },
    "employee_churn_rate": {
      "properties": {
        "3_month": {
          "type": "float",
          "index": true,
          "doc_values": true
        },
        "6_month": {
          "type": "float",
          "index": true,
          "doc_values": true
        },
        "12_month": {
          "type": "float",
          "index": true,
          "doc_values": true
        },
        "24_month": {
          "type": "float",
          "index": true,
          "doc_values": true
        }
      }
    },
    "employee_count": {
      "type": "long",
      "index": true
    },
    "inferred_revenue": {
      "type": "keyword",
      "index": true,
      "normalizer": "lowercase"
    }
  }
}
```

Updated 29 days ago

---

Did this page help you?

Yes

No

---
# https://docs.peopledatalabs.com/docs/sandbox-apis-examples

We've provided code samples in Python, Ruby, Go and JavaScript.

> ðŸ’¡
>
> ### We want your feedback!
>
> Do you see a bug? Is there an example you'd like to see that's not listed here?
>
> Head over to the public roadmap and submit a [bug ticket](https://peopledatalabs.canny.io/bugs) or a [feature request](https://peopledatalabs.canny.io/feature-requests) and receive automatic notifications as your bug is resolved or your request is implemented.

## Sandbox Person Enrichment API

To use the Sandbox Person Enrichment API in URL, set `https://sandbox.api.peopledatalabs.com/v5/person/enrich` as the URL and then use the Person Enrichment API as usual.

To use the Sandbox Person Enrichment API with our SDKs, see [SDK usage](/docs/sandbox-apis-reference#sdk-usage).

After implementing one of the two mechanisms above, you can make use of any of the [examples for the Person Enrichment API](/docs/examples-person-enrichment-api). **However, since the Sandbox APIs only use the[Sandbox Dataset](/docs/sandbox-apis-reference#sandbox-dataset), you can only enrich profiles from that dataset**. For example, here is how to perform enrichment on an email address from the [Sandbox Dataset](/docs/sandbox-apis-reference#sandbox-dataset) following the [Email example](/docs/examples-person-enrichment-api#email):

### Basic Usage

Python3 SDKJavaScriptRubyGoPython3

```
import json

# See https://github.com/peopledatalabs/peopledatalabs-python
from peopledatalabs import PDLPY

# Create a client, specifying your API key
CLIENT = PDLPY(
    api_key="YOUR API KEY",
    # Use Sandbox API
    sandbox=True,
)

# Create a parameters JSON object
PARAMS = {
    "email": ["irussell@example.org"],
    "min_likelihood": 6
}

# Pass the parameters object to the Person Enrichment API
json_response = CLIENT.person.enrichment(**PARAMS).json()

# Check for successful response
if json_response["status"] == 200:
  record = json_response['data']

  # Print selected fields
  print(
    record['work_email'],
    record['full_name'],
    record['job_title'],
    record['job_company_name']
  )

  print(f"Successfully enriched profile with PDL data.")

  # Save enrichment data to JSON file
  with open("my_pdl_enrichment.jsonl", "w") as out:
    out.write(json.dumps(record) + "\n")
else:
  print("Enrichment unsuccessful. See error and try again.")
  print("error:", json_response)
```

```
// See https://github.com/peopledatalabs/peopledatalabs-js
import PDLJS from 'peopledatalabs';

import fs from 'fs';

// Create a client, specifying your API key
const PDLJSClient = new PDLJS({ apiKey: "YOUR API KEY" });

// Create a parameters JSON object
const params = {
  email: "irussell@example.org",
  min_likelihood: 6,
  // Use Sandbox API
  sandbox: true
}

// Pass the parameters object to the Person Enrichment API
PDLJSClient.person.enrichment(params).then((data) => {
    var record = data.data
    
    // Print selected fields
    console.log(
        record["work_email"],
        record["full_name"],
        record["job_title"],
        record["job_company_name"],
        )
        
    console.log("Successfully enriched profile with PDL data.")
    
    // Save enrichment data to JSON file
    fs.writeFile("my_pdl_enrichment.jsonl", Buffer.from(JSON.stringify(record)), (err) => {
        if (err) throw err;
    });
}).catch((error) => {
    console.log("Enrichment unsuccessful. See error and try again.")
    console.log(error);
});
```

```
require 'json'

# See https://github.com/peopledatalabs/peopledatalabs-ruby
require 'peopledatalabs'

# Set your API key
Peopledatalabs.api_key = 'YOUR API KEY'

# Use Sandbox API
Peopledatalabs.sandbox = true

# Create a parameters JSON object
PARAMS = {
    "email": ["irussell@example.org"],
    "min_likelihood": 6
}

# Pass the parameters object to the Person Enrichment API
json_response = Peopledatalabs::Enrichment.person(params: PARAMS)

# Check for successful response
if json_response['status'] == 200
    record = json_response['data']
    
    # Print selected fields
    puts \
        "#{record['work_email']}\
        #{record['full_name']}\
        #{record['job_title']}\
        #{record['job_company_name']}"
    
    puts "Successfully enriched profile with PDL data."
    
    # Save enrichment data to JSON file
    File.open("my_pdl_enrichment.jsonl", "w") do |out|
        out.write(JSON.dump(record) + "\n")
    end
else
    puts "Enrichment unsuccessful. See error and try again."
    puts "error: #{json_response}"
end
```

```
package main

import (
    "fmt"
    "os"
    "encoding/json"
    "context"
)

// See https://github.com/peopledatalabs/peopledatalabs-go
import (
    pdl "github.com/peopledatalabs/peopledatalabs-go"
    "github.com/peopledatalabs/peopledatalabs-go/api"
    pdlmodel "github.com/peopledatalabs/peopledatalabs-go/model"
)

func main() {
    // Set your API key
    apiKey := "YOUR API KEY"
    // Set API key as environmental variable
    // apiKey := os.Getenv("API_KEY")
    
    // Create a client, specifying your API key and sandbox usage
    client := pdl.New(apiKey,
                      api.ClientOptions(func(c *api.Client) {
                                    c.Sandbox = true
                      }))
    
    // Create a parameters JSON object
    params := pdlmodel.EnrichPersonParams {
        PersonParams: pdlmodel.PersonParams {
            Email: []string{"irussell@example.org"},
        },
         AdditionalParams: pdlmodel.AdditionalParams {
            MinLikelihood: 6,
        },
    }
    
    // Pass the parameters object to the Person Enrichment API
    response, err := client.Person.Enrich(context.Background(), params)
    
    // Check for successful response
    if err == nil {
        // Convert the API response to JSON
        jsonResponse, jsonErr := json.Marshal(response.Data)
        if jsonErr == nil {
            var record map[string]interface{}
            json.Unmarshal(jsonResponse, &record)
            // Print selected fields
            fmt.Println(
                       record["work_email"], 
                       record["full_name"], 
                       record["job_title"], 
                       record["job_company_name"])
        
            fmt.Println("Successfully enriched profile with PDL data.")
        
            // Save enrichment data to JSON file
            out, outErr := os.Create("my_pdl_enrichment.jsonl")
            defer out.Close()
            if outErr == nil {
                out.WriteString(string(jsonResponse) + "\n")
            }
            out.Sync()
        }
   	} else {
        fmt.Println("Enrichment unsuccessful. See error and try again.")
        fmt.Println("error:", err)
    }
}
```

```
import requests, json

# Set your API key
API_KEY = "YOUR API KEY"

# Set the Person Enrichment API URL
PDL_URL = "https://sandbox.api.peopledatalabs.com/v5/person/enrich" # Sandbox Person Enrichment API
# PDL_URL = "https://api.peopledatalabs.com/v5/person/enrich" # Production Person Enrichment API

# Create a parameters JSON object
PARAMS = {
    "api_key": API_KEY,
    "email": ["irussell@example.org"],
    "min_likelihood": 6
}

# Pass the parameters object to the Sandbox Person Enrichment API
json_response = requests.get(PDL_URL,  params=PARAMS).json()

# Check for successful response
if json_response["status"] == 200:
  record = json_response['data']

  # Print selected fields
  print(
    record['work_email'],
    record['full_name'],
    record['job_title'],
    record['job_company_name']
  )

  print(f"Successfully enriched profile with PDL data.")

  # Save enrichment data to JSON file
  with open("my_pdl_enrichment.jsonl", "w") as out:
    out.write(json.dumps(record) + "\n")
else:
  print("Enrichment unsuccessful. See error and try again.")
  print("error:", json_response)
```

See [Examples - Person Enrichment API](/docs/examples-person-enrichment-api) for additonal examples.

## Sandbox Person Search API

To use the Sandbox Person Search API in URL, set `https://sandbox.api.peopledatalabs.com/v5/person/search` as the URL and then use the Person Search API as usual.

To use the Sandbox Person Search API with our SDKs, see [SDK usage](/docs/sandbox-apis-reference#sdk-usage).

After implementing one of the two mechanisms above, you can make use of any of the [examples for the Person Search API](/docs/examples-person-search-api). **However, since the Sandbox APIs only use the[Sandbox Dataset](/docs/sandbox-apis-reference#sandbox-dataset), you can only search for profiles from that dataset**. For example, here is how to perform a simple query following the [Basic Usage example](/docs/examples-person-search-api#basic-usage):

### Basic Usage

Python3 SDK (Elasticsearch)JavaScript (Elasticsearch)Ruby (Elasticsearch)Go (Elasticsearch)Python3 (Elasticsearch)

```
import json

# See https://github.com/peopledatalabs/peopledatalabs-python
from peopledatalabs import PDLPY

# Create a client, specifying your API key
CLIENT = PDLPY(
    api_key="YOUR API KEY",
    # Use Sandbox API
    sandbox=True,
)

# Create an Elasticsearch query
ES_QUERY = {
  "query": {
    "bool": {
        "must": [
            {"term": {"location_country": "mexico"}},
            {"exists": {"field": "emails"}}
      ]
    }
  }
}

# Create a parameters JSON object
PARAMS = {
  'query': ES_QUERY,
  'size': 10,
  'pretty': True
}

# Pass the parameters object to the Person Search API
response = CLIENT.person.search(**PARAMS).json()

# Check for successful response
if response["status"] == 200:
  data = response['data']
  # Write out each profile found to file
  with open("my_pdl_search.jsonl", "w") as out:
    for record in data:
      out.write(json.dumps(record) + "\n")
  print(f"Successfully grabbed {len(data)} records from PDL.")
  print(f"{response['total']} total PDL records exist matching this query.")
else:
  print("NOTE: The carrier pigeons lost motivation in flight. See error and try again.")
  print("Error:", response)
```

```
// See https://github.com/peopledatalabs/peopledatalabs-js
import PDLJS from 'peopledatalabs';

import fs from 'fs';

// Create a client, specifying your API key
const PDLJSClient = new PDLJS({ apiKey: "YOUR API KEY" });

// Create an Elasticsearch query
const esQuery = {
  query: {
    bool: {
      must:[
        {term: {location_country: "mexico"}}, 
        {exists: {field: "emails"}}
      ]
    }
  }
}

// Create a parameters JSON object
const params = {
  searchQuery: esQuery, 
  size: 10,
  pretty: true,
  // Use Sandbox API
  sandbox: true
}

// Pass the parameters object to the Person Search API
PDLJSClient.person.search.elastic(params).then((data) => {
    // Write out all profiles found to file
    fs.writeFile("my_pdl_search.jsonl", Buffer.from(JSON.stringify(data.data)), (err) => {
        if (err) throw err;
    });
    console.log(`Successfully grabbed ${data.data.length} records from PDL.`);
    console.log(`${data["total"]} total PDL records exist matching this query.`)
}).catch((error) => {
    console.log("NOTE: The carrier pigeons lost motivation in flight. See error and try again.")
    console.log(error);
});
```

```
require 'json'

# See https://github.com/peopledatalabs/peopledatalabs-ruby
require 'peopledatalabs'

# Set your API key
Peopledatalabs.api_key = 'YOUR API KEY'

# Use Sandbox API
Peopledatalabs.sandbox = true

# Create an Elasticsearch query
ES_QUERY = {
  "query": {
    "bool": {
        "must": [
            {"term": {"location_country": "mexico"}},
           {"exists": {"field": "emails"}}
      ]
    }
  }
}

# Pass parameters to the Person Search API
response = Peopledatalabs::Search.person(searchType: 'elastic', query: ES_QUERY, size: 10, pretty: true)

# Check for successful response
if response['status'] == 200
    data = response['data']
    # Write out each profile found to file
    File.open("my_pdl_search.jsonl", "w") do |out|
        data.each { |record| out.write(JSON.dump(record) + "\n") }
    end
    puts "Successfully grabbed #{data.length()} records from PDL."
    puts "#{response['total']} total PDL records exist matching this query."
else
    puts "NOTE: The carrier pigeons lost motivation in flight. See error and try again."
    puts "Error: #{response}"
end
```

```
package main

import (
    "fmt"
    "os"
    "encoding/json"
    "context"
)

// See https://github.com/peopledatalabs/peopledatalabs-go
import (
    pdl "github.com/peopledatalabs/peopledatalabs-go"
    "github.com/peopledatalabs/peopledatalabs-go/api"
    pdlmodel "github.com/peopledatalabs/peopledatalabs-go/model"
)

func main() {
    // Set your API key
    apiKey := "YOUR API KEY"
    // Set API key as environmental variable
    // apiKey := os.Getenv("API_KEY")

    // Create a client, specifying your API key and sandbox usage
    client := pdl.New(apiKey,
                      api.ClientOptions(func(c *api.Client) {
                                    c.Sandbox = true
                      }))

    // Create an Elasticsearch query
    elasticSearchQuery := map[string]interface{} {
        "query": map[string]interface{} {
            "bool": map[string]interface{} {
                "must": []map[string]interface{} {
                    {"term": map[string]interface{}{"location_country": "mexico"}},
                    {"exists": map[string]interface{}{"field": "emails"}},
                },
            },
        },
    }

    // Create a parameters JSON object
    params := pdlmodel.SearchParams {
        BaseParams: pdlmodel.BaseParams {
            Size: 10,
            Pretty: true,
        },
        SearchBaseParams: pdlmodel.SearchBaseParams {
            Query: elasticSearchQuery,
        },
    }
    
    // Pass the parameters object to the Person Search API
    response, err := client.Person.Search(context.Background(), params)
    // Check for successful response
    if err == nil {
        data := response.Data
        // Create file
        out, outErr := os.Create("my_pdl_search.jsonl")
        defer out.Close()
        if (outErr == nil) {
            for i := range data {
                // Convert each profile found to JSON
                record, jsonErr := json.Marshal(data[i])
                // Write out each profile to file
                if (jsonErr == nil) {
                    out.WriteString(string(record) + "\n")
                }
            }
            out.Sync()
        }
        fmt.Printf("Successfully grabbed %d records from PDL.\n", len(data))
        fmt.Printf("%d total PDL records exist matching this query.\n", response.Total)
    } else {
        fmt.Println("NOTE: The carrier pigeons lost motivation in flight. See error and try again.")
        fmt.Println("Error:", err)
    } 
}
```

```
import requests, json

# Set your API key
API_KEY = "YOUR API KEY"

# Set the Person Search API URL
PDL_URL = "https://sandbox.api.peopledatalabs.com/v5/person/search" # Sandbox Person Search API
# PDL_URL = "https://api.peopledatalabs.com/v5/person/search" # Production Person Search API

# Set headers
HEADERS = {
  'Content-Type': "application/json",
  'X-api-key': API_KEY
}

# Create an Elasticsearch query
ES_QUERY = {
  "query": {
    "bool": {
        "must": [
            {"term": {"location_country": "mexico"}},
            {"exists": {"field": "emails"}}
      ]
    }
  }
}

# Create a parameters JSON object
PARAMS = {
  'query': json.dumps(ES_QUERY),
  'size': 10,
  'pretty': True
}

# Pass the parameters object to the Sandbox Person Search API
response = requests.get(
  PDL_URL,
  headers=HEADERS,
  params=PARAMS
).json()

# Check for successful response
if response["status"] == 200:
  data = response['data']
  # Write out each profile found to file
  with open("my_pdl_search.jsonl", "w") as out:
    for record in data:
      out.write(json.dumps(record) + "\n")
  print(f"Successfully grabbed {len(data)} records from PDL.")
  print(f"{response['total']} total PDL records exist matching this query.")
else:
  print("NOTE: The carrier pigeons lost motivation in flight. See error and try again.")
  print("Error:", response)
```

See [Examples - Person Search API](/docs/examples-person-search-api) for additional examples.

## Sandbox Person Identify API

To use the Sandbox Person Identify API in URL, set `https://sandbox.api.peopledatalabs.com/v5/person/identify` as the URL and then use the Person Identify API as usual.

To use the Sandbox Person Identify API with our SDKs, see [SDK usage](/docs/sandbox-apis-reference#sdk-usage).

After implementing one of the two mechanisms above, you can make use of any of the [examples for the Person Identify API](/docs/identify-api-examples). **However, since the Sandbox APIs only use the[Sandbox Dataset](/docs/sandbox-apis-reference#sandbox-dataset), you can only match profiles from that dataset**. For example, here is how to perform a query following the [Basic Usage example](/docs/identify-api-examples#basic-usage):

### Basic Usage

Python3 SDKJavaScriptRubyGoPython3

```
import json

# See https://github.com/peopledatalabs/peopledatalabs-python
from peopledatalabs import PDLPY

# Create a client, specifying your API key
CLIENT = PDLPY(
    api_key="YOUR API KEY",
    # Use Sandbox API
    sandbox=True,
)

# Create a parameters JSON object
PARAMS = {
 "company": "walmart",
 "pretty": True
}

# Pass the parameters object to the Person Identify API
response_data = CLIENT.person.identify(**PARAMS).json()

# Create a list of matches
identities = response_data['matches']

# Print the matches in JSON format
print(identities)
print(f"Found {len(identities)} identities!")
```

```
// See https://github.com/peopledatalabs/peopledatalabs-js
import PDLJS from 'peopledatalabs';

// Create a client, specifying your API key
const PDLJSClient = new PDLJS({ apiKey: "YOUR API KEY" });

// Create a parameters JSON object
const params = {
  company: "walmart",
  pretty: true,
  // Use Sandbox API
  sandbox: true
}

// Pass the parameters object to the Person Identify API
PDLJSClient.person.identify(params).then((data) => {
  // Create a list of matches
  var identities = data["matches"]
  
  // Print the matches in JSON format
  console.log(identities);
  console.log(`Found ${identities.length} identities!`)
}).catch((error) => {
  console.log(error);
});
```

```
# See https://github.com/peopledatalabs/peopledatalabs-ruby
require 'peopledatalabs'

# Set your API key
Peopledatalabs.api_key = 'YOUR API KEY'

# Use Sandbox API
Peopledatalabs.sandbox = true

# Create a parameters JSON object
PARAMS = {
 "company": "walmart",
 "pretty": true
}

# Pass the parameters object to the Person Identify API
response = Peopledatalabs::Identify.person(params: PARAMS)

# Create a list of matches
identities = response['matches']

# Print the matches in JSON format
puts identities
puts "Found #{identities.length()} identities!"
```

```
package main

import (
    "fmt"
    "encoding/json"
    "context"
)

// See https://github.com/peopledatalabs/peopledatalabs-go
import (
    pdl "github.com/peopledatalabs/peopledatalabs-go"
    "github.com/peopledatalabs/peopledatalabs-go/api"
    pdlmodel "github.com/peopledatalabs/peopledatalabs-go/model"
)

func main() {
    // Set your API key
    apiKey := "YOUR API KEY"
    // Set API key as environmental variable
    // apiKey := os.Getenv("API_KEY")

    // Create a client, specifying your API key and sandbox usage
    client := pdl.New(apiKey,
                      api.ClientOptions(func(c *api.Client) {
                                    c.Sandbox = true
                      }))
    
    // Create a parameters JSON object
    params := pdlmodel.IdentifyPersonParams {
        BaseParams: pdlmodel.BaseParams {
            Pretty: true,
        },
        PersonParams: pdlmodel.PersonParams {
             Company: []string{"walmart"},
        },
    }
    
    // Pass the parameters object to the Person Identify API
    response, err := client.Person.Identify(context.Background(), params)
    // Check for successful response
    if err == nil {
        // Create a list of matches
        identities := response.Matches
        // Convert the matches to JSON
        jsonResponse, jsonErr := json.Marshal(identities)
        // Print the matches
        if (jsonErr == nil) {
            fmt.Println(string(jsonResponse))
        }
        
        fmt.Printf("Found %d identities!\n", len(identities))
    } else {
        fmt.Println(err)
    }
}
```

```
import requests

# Set your API key
API_KEY = "YOUR API KEY"

# Set the Person Identify API URL
PDL_URL = "https://sandbox.api.peopledatalabs.com/v5/person/identify" # Sandbox Identify API 
# PDL_URL = "https://api.peopledatalabs.com/v5/person/identify" # Production Identify API

# Create a parameters JSON object
PARAMS = {
  "company": "walmart",
  "pretty": True,
  "api_key": API_KEY
}

# Pass the parameters object to the Sandbox Person Identify API
response = requests.request("GET", PDL_URL, params=PARAMS)

response_data = response.json()

# Create a list of matches
identities = response_data['matches']

# Print the matches in JSON format
print(identities)
print(f"Found {len(identities)} identities!")
```

See [Examples - Person Identify API](/docs/identify-api) for additional examples.

Updated 4 months ago

---

Did this page help you?

Yes

No

---
# https://docs.peopledatalabs.com/docs/faqs-company-search-api

> â“
>
> ### Have a Question You Want Answered? Ask Us!
>
> Head over to the [Help Center](https://support.peopledatalabs.com) and search for your question. If you still can't find what you're looking for, create a support ticket and we will get it answered for you!

---

## Can I use the Company Search API to enrich data?

The Company Search API ignores the matching logic in our Company Enrichment API. We don't do any preprocessing (cleaning) of the inputs to the Company Search API, so you're almost guaranteed to have a lower match rate.

What's more, Company Search API queries and Company Enrichment API queries are structured differently. When you make a Company Enrichment API request, we have a custom-built query that takes the different input parameters and weights them differently, only returning a match in certain cases while using stack ranking in cases where there are multiple matches.

## Should I use SQL or Elasticsearch for the Company Search API?

Use **Elasticsearch** when:

1. You have complicated boolean queries.
2. You want to maximize the control that you have over text-based matching (titles, summaries and so forth.)
3. You are comfortable writing Elasticsearch queries.

Use **SQL** when:

1. You are running simple searches with only a few parameters.
2. You're exclusively using ENUM parameters from our data (location, industry, etc.)
3. You are comfortable writing SQL queries.

## Can I use wildcards in my search query?

Yes, wildcard terms are supported. However, we have a hard limit of 20 wildcards per query. See the relevant sections for more information about the limitations in [Elasticsearch](/docs/input-parameters-person-search-api#elasticsearch-query-limitations) and [SQL](/docs/input-parameters-person-search-api#sql-query-limitations) search queries.

## Why is there a 1MB limit on the API requests and the response body?

The error message that you are receiving has occurred because the query is too large and cURL can't handle the response. Calling the API with Python should alleviate this issue as Python compresses the extra space within an Elasticsearch query. Additional ways to decrease the query size are to reduce the profile count parameter from `100` to `60` for each call and to remove the `pretty` tag. You can get around this limitation by [Using POST Requests](/docs/examples-person-search-api#using-post-requests).

## Can I exclude PDL IDs in a Company Search call to avoid spending duplicate credits?

You can technically exclude up to 1,000 PDL IDs in a single search query, however you will eventually run into limitations due to our infrastructure. While the PDL ID is mostly persistent, it's possible that the IDs can get merged, deleted, or opted out from our dataset across releases. Additionally, we will truncate extremely long queries in our internal logs, making it more difficult to assist you should you need technical support. At some point in the future, we will place limitations on query length and/or performance time to avoid these costly queries.

## Will I be charged for retrieving the same profile multiple times?

Yes. PDL will charge for the retrieval of the same profile.

Example 1  
You search for companies in California then conduct another search for companies in San Francisco. You will be charged for the overlap in the second request.

Example 2  
You search for companies in California and search again for companies in California. You will be charged the same amount for each request.

Example 1 is a bit more difficult to handle for programmatically and likely needs a UI/UX approach to limit overlapping queries.

To handle for situations demonstrated in Example 2, PDL recommends duplicate call detection. You can use methods like unique key constraints. For example, you can hash the request, storing the hash, and checking for a duplicate call before sending it to the API to avoid the second situation above.

Updated 4 months ago

---

Did this page help you?

Yes

No

---
# https://docs.peopledatalabs.com/docs/output-response-person-search-api

## Response Data Structure

The response from the Person Search API will be in this format:

JSON

```
{
    "status": 200,
    "data": [
        {
            "id": "qEnOZ5Oh0poWnQ1luFBfVw_0000",
            "full_name": "sean thorne",
            ...
        },
        ...
    ],
    "scroll_token": "1117$12.176522",
    "total": 99
}
```

See [Example Person Record](/docs/example-record) for a full example of the fields included in the `data` object.

## Response Fields

### `data.*`

| Type | Description |
| --- | --- |
| `Array (Object)` | The person response objects that match the input query in the format described in our [Person Schema](/docs/fields). |

The `data` list is made up of objects that contain the entire [PDL profile](/docs/fields) for each person that matches the Search API request. Any profile field that we do not have data for will have a `null` value.

  

### `status`

| Type | Description |
| --- | --- |
| `Integer` | The [API response code](/docs/errors). |

  

### `total`

| Type | Description |
| --- | --- |
| `Integer` | The total number of records that matched the input query. |

  

### `scroll_token`

| Type | Description |
| --- | --- |
| `String` | The scroll token to use to fetch the next batch of results for the query. |

For more information on using `scroll_token`, see [here](/docs/input-parameters-person-search-api#scroll_token).

## Errors

Any request that does not return a `200` success response will instead use the format described in [Errors](/docs/errors).

Updated 4 months ago

---

Did this page help you?

Yes

No

---
# https://docs.peopledatalabs.com/docs/output-response-cleaner-apis

## Company Cleaner API Response

Here is an example response from the Company Cleaner API:

JSON

```
{
    "status": 200,
    "name": "people data labs",
    "size": "51-200",
    "id": "tnHcNHbCv8MKeLh92946LAkX6PKg",
    "founded": 2015,
    "industry": "computer software",
    "location": {
        "name": "san francisco, california, united states",
        "locality": "san francisco",
        "region": "california",
        "metro": "san francisco, california",
        "country": "united states",
        "continent": "north america",
        "street_address": "455 market street",
        "address_line_2": "suite 1670",
        "postal_code": "94105",
        "geo": "37.77,-122.41"
    },
    "linkedin_url": "linkedin.com/company/peopledatalabs",
    "linkedin_id": "18170482",
    "facebook_url": "facebook.com/peopledatalabs",
    "twitter_url": "twitter.com/peopledatalabs",
    "website": "peopledatalabs.com",
    "ticker": null,
    "type": "private",
    "raw": [
        "people data labs"
    ],
    "score": 4.0,
    "fuzzy_match": false
}
```

If the Company Cleaner API finds a matching company, a `200` response returns along with the company record in JSON format. The schema of the response matches the Company Schema in the Person record. If the API does not find a matching company, a  `404` returns.

For querying the Company Schema, you can use the the following field mapping:

| company field | person fields |
| --- | --- |
| `id` | `job_company_id`, `experience.company.id` |

## Location Cleaner API Response

Here is an example response from the Location Cleaner API:

JSON

```
{
  "name": "portland, oregon, united states",
  "locality": "portland",
  "region": "oregon",
  "subregion": "multnomah county",
  "country": "united states",
  "continent": "north america",
  "type": "locality",
  "geo": "45.52,-122.67",
}
```

If the Location Cleaner API parses the location, a `200` response returns along with the parsed location in JSON format. The schema of the response matches the Location Schema in the Person record. If the API cannot parse the location, a  `404` returns.

For querying the Location Schema, you can use the the following field mapping:

| location field | person fields |
| --- | --- |
| `name` | `job_company_location_name`, `location_name`, `location_names`, `street_addresses.name`, `experience.location_names`, `experience.company.location.name`, `education.school.location.name` |

## School Cleaner API Response

Here is an example response from the School Cleaner API:

JSON

```
{
  "name": "university of california, los angeles",
  "type": "post-secondary institution",
  "id": "72978d72-275a-49c8-b9b9-f227ccfb1361",
  "location": {
    "name": "los angeles, california, united states",
    "locality": "los angeles",
    "region": "california",
    "country": "united states",
    "continent": "north america"
  },
  "linkedin_url": "linkedin.com/school/ucla",
  "facebook_url": null,
  "twitter_url": null,
  "linkedin_id": "17950",
  "website": "ucla.edu",
  "domain": "ucla.edu"
}
```

If the School Cleaner API finds a matching school, a `200` response returns along with the cleaned school in JSON format. The schema of the response matches the School Schema in the Person record. If the API doesn't find a matching school, a  `404` returns.

For querying the School Schema, you can use the the following field mapping:

| school field | person field |
| --- | --- |
| `id` | `education.school.id` |

Updated 4 months ago

---

Did this page help you?

Yes

No

---
# https://docs.peopledatalabs.com/docs/autocomplete-api-faqs

> ðŸ‘
>
> ### Want a Question Answered? Ask Us!
>
> You can either use the `Suggest Edits` button in the top right-hand corner of this page to ask a question or you can post your question in our [Roadmap Board](https://feedback.peopledatalabs.com/).

## What is the metadata field in the API response?

The [metadata field](/docs/output-response-autocomplete-api#datameta) is a set of contextual information associated with each autocomplete suggestion, which you can use to further identify the entity suggested. For example, when requesting company autocomplete suggestions, metadata such as `website`, `industry` and `location` can help identify exactly what company a suggestion is referring to.

**Note**: not all responses will have metadata. It depends on the type of [Input Parameters - Autocomplete API](/docs/input-parameters-autocomplete-api#fields) that you specified in the input request. Some fields, such as `industry` and `skills`, do not contain metadata because there is no other contextual information that can further identify each suggestion beyond the name. For example, there's not much context that you can provide on the skill `JavaScript` beyond its name.

You can see a detailed list of the metadata fields associated with each type of input field [here](/docs/output-response-autocomplete-api#metadata-fields-for-company).

Updated 4 months ago

---

Did this page help you?

Yes

No

---
# https://docs.peopledatalabs.com/docs/response

## Overview

This Quickstart is a brief introduction to our data and APIs.

Donâ€™t worry if youâ€™ve never used an API before, as with a little copy-and-paste magic weâ€™ll get you up and running quickly.

In just a few minutes, you will be retrieving and accessing real person and company data directly from our datasets.

Hereâ€™s what weâ€™ll cover:

1. Creating an account
2. Sending your first Person Enrichment API request
3. Sending your first Company Enrichment API request

Updated 4 months ago

---

* [Create an account](/docs/create-an-account)

Did this page help you?

Yes

No

---
# https://docs.peopledatalabs.com/docs/overview

We offer the following SDKs:

* [Python SDK](/docs/python-sdk)
* [JavaScript SDK](/docs/javascript-sdk)
* [Ruby SDK](/docs/ruby-sdk)
* [Go SDK](/docs/go-sdk)
* [Rust SDK](/docs/rust-sdk)
* [React Component for Autocomplete](/docs/react-component-for-autocomplete)

Updated 4 months ago

---

Did this page help you?

Yes

No

---
# https://docs.peopledatalabs.com/docs/person-identify-api

## Overview

The Person Identify API allows you to use broad search inputs to retrieve multiple records from our person dataset. In particular, this endpoint enables functionality such as searching through a single identifying attribute, such as name, email, phone number, company, school or location, in addition to using any combination of these attributes [and more](/docs/reference-person-identify-api#input-parameters). The API then scores and sorts all matching records that it returns based on the [strength of their association with the input parameters](/docs/output-response-person-identify-api#matchesmatch_score).

> ðŸ“˜
>
> ### How Does the Person Identify API Compare with Other Person-Related Endpoints?
>
> See our [Introduction](/docs/introduction#the-differences-between-our-person-related-apis) for a detailed breakdown regarding the differences between the Person Identify API and our other person-related products.

## Use Cases

A key use case for this endpoint is building comprehensive profiles for specific individuals, such as in the areas of:

* Investigations and forensics
* Fraud risk modeling
* Identity modeling for customer onboarding and other [KYC](https://en.wikipedia.org/wiki/Know_your_customer) applications

## How it Works

At a high level, the Person Identify API works as follows:

1. You specify some characteristics about the identity that you are interested in and pass these as [input parameters](/docs/identify-api-input-parameters) to the API.
2. The API [cleans](/docs/cleaner-apis) the input parameter values and searches our Person Dataset for matching profiles using fuzzy-matching logic.
3. The API returns up to 20 of the the best matching profiles in its response while ranking them by their [match score](/docs/identify-api-output-response#matchesmatch_score).

## What's Next

Please check out the following pages for more information on the Person Identify API:

| Page | Description |
| --- | --- |
| [Quickstart](/docs/quickstart-person-identify-api) | A quick hands-on introduction to the API with simple code examples. |
| [Reference](/docs/reference-person-identify-api) | Detailed descriptions of the technical specifications and usage constraints. |
| [Input Parameters](/docs/input-parameters-person-identify-api) | In-depth explanations of the input parameters that the API supports. |
| [Output Response](/docs/output-response-person-identify-api) | In-depth explanations of the output response object that the API returns. |
| [Examples](/docs/examples-person-identify-api) | A collection of functional code examples and walkthroughs that illustrate various use cases and applications of the API. |
| [FAQs](/docs/faqs-person-identify-api) | Answers to commonly asked questions and other good-to-know information. |

---



*Know someone whoâ€™d thrive building data products and helping us launch whatâ€™s next? Weâ€™d love to meet!*

*Check out our[open roles](https://www.peopledatalabs.com/company?utm_source=docs&utm_medium=footer&utm_campaign=cta#jobs) â†’*

Updated 4 months ago

---

Did this page help you?

Yes

No

---
# https://docs.peopledatalabs.com/docs/quickstart-person-search-api

## Getting Started

In order to use our Person Search API, you must have an active API key. You can look up your API key by logging into our [self-serve dashboard](https://www.peopledatalabs.com/main/api-keys) and going to the **API Keys** section.

> ðŸ‘
>
> ### Need an API Key?
>
> If you don't have an API key, you can easily create one by [signing up](https://peopledatalabs.com/signup) for a self-serve account. For more information, check out our [Self-Serve Quickstart Guide](https://blog.peopledatalabs.com/post/self-signup-api-quickstart), which walks you through the sign-up process as well as shows you how to use the self-serve API dashboard.

## Simple Example

As mentioned in the [Overview](/docs/person-search-api#overview), the Person Search API is a means of filtering and segmenting individual profiles included in our [Person Dataset](/docs/fields). In order to use the Person Search API, **you will need to use either an[Elasticsearch query](/docs/input-parameters-person-search-api#query) or an [SQL query](/docs/input-parameters-person-search-api#sql)**.

Here's a quick example to search for profiles whose `location_country` is `mexico`, whose `job_title_role` is `health`, and whose record includes at least one `phone_numbers`:

> â—ï¸
>
> ### Heads Up! Credit Usage
>
> Person Search API calls cost the number of **total search results** returned.
>
> If you are making a search that could have a large number of results, make sure to use the [`size` parameter](/docs/input-parameters-person-search-api#size) to set the maximum number of results and cap your credit usage.

Python3 SDK (Elasticsearch)Python3 SDK (SQL)cURLJavaScript (Elasticsearch)JavaScript (SQL)Ruby (Elasticsearch)Ruby (SQL)Go (Elasticsearch)Go (SQL)Python3 (Elasticsearch)Python3 (SQL)

```
import json

# See https://github.com/peopledatalabs/peopledatalabs-python
from peopledatalabs import PDLPY

# Create a client, specifying your API key
CLIENT = PDLPY(
    api_key="YOUR API KEY",
)

# Create an Elasticsearch query
ES_QUERY = {
  'query': {
    'bool': {
        'must': [
            {'term': {'location_country': "mexico"}},
            {'term': {'job_title_role': "health"}},
            {'exists': {'field': "phone_numbers"}}
      ]
    }
  }
}

# Create a parameters JSON object
PARAMS = {
  'query': ES_QUERY,
  'size': 10,
  'pretty': True
}

# Pass the parameters object to the Person Search API
response = CLIENT.person.search(**PARAMS).json()

# Check for successful response
if response["status"] == 200:
  data = response['data']
  # Write out each profile found to file
  with open("my_pdl_search.jsonl", "w") as out:
    for record in data:
      out.write(json.dumps(record) + "\n")
  print(f"Successfully grabbed {len(data)} records from PDL.")
  print(f"{response['total']} total PDL records exist matching this query.")
else:
  print("NOTE: The carrier pigeons lost motivation in flight. See error and try again.")
  print("Error:", response)
```

```
import json

# See https://github.com/peopledatalabs/peopledatalabs-python
from peopledatalabs import PDLPY

# Create a client, specifying your API key
CLIENT = PDLPY(
    api_key="YOUR API KEY",
)

# Create an SQL query
SQL_QUERY = \
"""
  SELECT * FROM person
  WHERE location_country='mexico'
  AND job_title_role='health'
  AND phone_numbers IS NOT NULL;
 """

# Create a parameters JSON object
PARAMS = {
  'sql': SQL_QUERY,
  'size': 10,
  'pretty': True
}

# Pass the parameters object to the Person Search API
response = CLIENT.person.search(**PARAMS).json()

# Check for successful response
if response["status"] == 200:
  data = response['data']
  # Write out each profile found to file
  with open("my_pdl_search.jsonl", "w") as out:
    for record in data:
      out.write(json.dumps(record) + "\n")
  print(f"Successfully grabbed {len(data)} records from PDL.")
  print(f"{response['total']} total PDL records exist matching this query.")
else:
  print("NOTE: The carrier pigeons lost motivation in flight. See error and try again.")
  print("Error:", response)
```

```
# Elasticsearch
curl -X GET 'https://api.peopledatalabs.com/v5/person/search' \
-H 'X-Api-Key: xxxx' \
--data-raw '{
  "size": 10,
  "query": {
    "bool": {
      "must": [
        {"term": {"location_country": "mexico"}},
        {"term": {"job_title_role": "health"}},
        {"exists": {"field": "phone_numbers"}}
      ]
    }
  }
}'

# SQL
curl -X GET \
  'https://api.peopledatalabs.com/v5/person/search' \
  -H 'X-Api-Key: xxxx' \
  --data-raw '{
    "size": 10,
    "sql": "SELECT * FROM person WHERE location_country='\''mexico'\'' AND job_title_role='\''health'\'' AND phone_numbers IS NOT NULL;"
}'
```

```
// See https://github.com/peopledatalabs/peopledatalabs-js
import PDLJS from 'peopledatalabs';

import fs from 'fs';

// Create a client, specifying your API key
const PDLJSClient = new PDLJS({ apiKey: "YOUR API KEY" });

// Create an Elasticsearch query
const esQuery = {
  query: {
    bool: {
      must:[
        {term: {location_country: "mexico"}}, 
        {term: {job_title_role: "health"}}, 
        {exists: {field: "phone_numbers"}}
      ]
    }
  }
}

// Create a parameters JSON object
const params = {
  searchQuery: esQuery, 
  size: 10,
  pretty: true
}

// Pass the parameters object to the Person Search API
PDLJSClient.person.search.elastic(params).then((data) => {
    // Write out all profiles found to file
    fs.writeFile("my_pdl_search.jsonl", Buffer.from(JSON.stringify(data.data)), (err) => {
        if (err) throw err;
    });
    console.log(`Successfully grabbed ${data.data.length} records from PDL.`);
    console.log(`${data["total"]} total PDL records exist matching this query.`)
}).catch((error) => {
    console.log("NOTE: The carrier pigeons lost motivation in flight. See error and try again.")
    console.log(error);
});
```

```
// See https://github.com/peopledatalabs/peopledatalabs-js
import PDLJS from 'peopledatalabs';

import fs from 'fs';

// Create a client, specifying your API key
const PDLJSClient = new PDLJS({ apiKey: "YOUR API KEY" });

// Create an SQL query
const sqlQuery = `SELECT * FROM person 
                  WHERE location_country='mexico' 
                  AND job_title_role='health'
                  AND phone_numbers IS NOT NULL;`

// Create a parameters JSON object
const params = {
  searchQuery: sqlQuery, 
  size: 10,
  pretty: true
}

// Pass the parameters object to the Person Search API
PDLJSClient.person.search.sql(params).then((data) => {
    // Write out all profiles found to file
    fs.writeFile("my_pdl_search.jsonl", Buffer.from(JSON.stringify(data.data)), (err) => {
        if (err) throw err;
    });
    console.log(`Successfully grabbed ${data.data.length} records from PDL.`);
    console.log(`${data["total"]} total PDL records exist matching this query.`)
}).catch((error) => {
    console.log("NOTE: The carrier pigeons lost motivation in flight. See error and try again.")
    console.log(error);
});
```

```
require 'json'

# See https://github.com/peopledatalabs/peopledatalabs-ruby
require 'peopledatalabs'

# Set your API key
Peopledatalabs.api_key = 'YOUR API KEY'

# Create an Elasticsearch query
ES_QUERY = {
  "query": {
    "bool": {
        "must": [
            {"term": {"location_country": "mexico"}},
            {"term": {"job_title_role": "health"}},
            {"exists": {"field": "phone_numbers"}}
      ]
    }
  }
}

# Pass parameters to the Person Search API
response = Peopledatalabs::Search.person(searchType: 'elastic', query: ES_QUERY, size: 10, pretty: true)

# Check for successful response
if response['status'] == 200
    data = response['data']
    # Write out each profile found to file
    File.open("my_pdl_search.jsonl", "w") do |out|
        data.each { |record| out.write(JSON.dump(record) + "\n") }
    end
    puts "Successfully grabbed #{data.length()} records from PDL."
    puts "#{response['total']} total PDL records exist matching this query."
else
    puts "NOTE: The carrier pigeons lost motivation in flight. See error and try again."
    puts "Error: #{response}"
end
```

```
require 'json'

# See https://github.com/peopledatalabs/peopledatalabs-ruby
require 'peopledatalabs'

# Set your API key
Peopledatalabs.api_key = 'YOUR API KEY'

# Create an SQL query
SQL_QUERY = \
"""
  SELECT * FROM person
  WHERE location_country='mexico'
  AND job_title_role='health'
  AND phone_numbers IS NOT NULL;
 """

# Pass parameters to the Person Search API
response = Peopledatalabs::Search.person(searchType: 'sql', query: SQL_QUERY, size: 10, pretty: true)

# Check for successful response
if response['status'] == 200
    data = response['data']
    # Write out each profile found to file
    File.open("my_pdl_search.jsonl", "w") do |out|
        data.each { |record| out.write(JSON.dump(record) + "\n") }
    end
    puts "Successfully grabbed #{data.length()} records from PDL."
    puts "#{response['total']} total PDL records exist matching this query."
else
    puts "NOTE: The carrier pigeons lost motivation in flight. See error and try again."
    puts "Error: #{response}"
end
```

```
package main

import (
    "fmt"
    "os"
    "encoding/json"
    "context"
)

// See https://github.com/peopledatalabs/peopledatalabs-go
import (
    pdl "github.com/peopledatalabs/peopledatalabs-go"
    pdlmodel "github.com/peopledatalabs/peopledatalabs-go/model"
)

func main() {
    // Set your API key
    apiKey := "YOUR API KEY"
    // Set API key as environmental variable
    // apiKey := os.Getenv("API_KEY")

    // Create a client, specifying your API key
    client := pdl.New(apiKey)
    
    // Create an Elasticsearch query
    elasticSearchQuery := map[string]interface{} {
        "query": map[string]interface{} {
            "bool": map[string]interface{} {
                "must": []map[string]interface{} {
                    {"term": map[string]interface{}{"location_country": "mexico"}},
                    {"term": map[string]interface{}{"job_title_role": "health"}},
                    {"exists": map[string]interface{}{"field": "phone_numbers"}},
                },
            },
        },
    }

    // Create a parameters JSON object
    params := pdlmodel.SearchParams {
        BaseParams: pdlmodel.BaseParams {
            Size: 10,
            Pretty: true,
        },
        SearchBaseParams: pdlmodel.SearchBaseParams {
            Query: elasticSearchQuery,
        },
    }
    
    // Pass the parameters object to the Person Search API
    response, err := client.Person.Search(context.Background(), params)
    // Check for successful response
    if err == nil {
        data := response.Data
        // Create file
        out, outErr := os.Create("my_pdl_search.jsonl")
        defer out.Close()
        if (outErr == nil) {
            for i := range data {
                // Convert each profile found to JSON
                record, jsonErr := json.Marshal(data[i])
                // Write out each profile to file
                if (jsonErr == nil) {
                    out.WriteString(string(record) + "\n")
                }
            }
            out.Sync()
        }
        fmt.Printf("Successfully grabbed %d records from PDL.\n", len(data))
        fmt.Printf("%d total PDL records exist matching this query.\n", response.Total)
    } else {
        fmt.Println("NOTE: The carrier pigeons lost motivation in flight. See error and try again.")
        fmt.Println("Error:", err)
    }  
}
```

```
package main

import (
    "fmt"
    "os"
    "encoding/json"
    "context"
)

// See https://github.com/peopledatalabs/peopledatalabs-go
import (
    pdl "github.com/peopledatalabs/peopledatalabs-go"
    pdlmodel "github.com/peopledatalabs/peopledatalabs-go/model"
)

func main() {
    // Set your API key
    apiKey := "YOUR API KEY"
    // Set API key as environmental variable
    // apiKey := os.Getenv("API_KEY")

    // Create a client, specifying your API key
    client := pdl.New(apiKey)
    
    // Create an SQL query
    sqlQuery := "SELECT * FROM person" +
        " WHERE location_country='mexico'" +
        " AND job_title_role='health'" +
        " AND phone_numbers IS NOT NULL;"

    // Create a parameters JSON object
    params := pdlmodel.SearchParams {
        BaseParams: pdlmodel.BaseParams {
            Size: 10,
            Pretty: true,
        },
        SearchBaseParams: pdlmodel.SearchBaseParams {
            SQL: sqlQuery,
        },
    }
    
    // Pass the parameters object to the Person Search API
    response, err := client.Person.Search(context.Background(), params)
    // Check for successful response
    if err == nil {
        data := response.Data
        // Create file
        out, outErr := os.Create("my_pdl_search.jsonl")
        defer out.Close()
        if (outErr == nil) {
            for i := range data {
                // Convert each profile found to JSON
                record, jsonErr := json.Marshal(data[i])
                // Write out each profile to file
                if (jsonErr == nil) {
                    out.WriteString(string(record) + "\n")
                }
            }
            out.Sync()
        }
        fmt.Printf("Successfully grabbed %d records from PDL.\n", len(data))
        fmt.Printf("%d total PDL records exist matching this query.\n", response.Total)
    } else {
        fmt.Println("NOTE: The carrier pigeons lost motivation in flight. See error and try again.")
        fmt.Println("Error:", err)
    }  
}
```

```
import requests, json

# Set your API key
API_KEY = "YOUR API KEY"

# Set the Person Search API URL
PDL_URL = "https://api.peopledatalabs.com/v5/person/search"

# Set headers
HEADERS = {
  'Content-Type': "application/json",
  'X-api-key': API_KEY
}

# Create an Elasticsearch query
ES_QUERY = {
  'query': {
    'bool': {
        'must': [
            {'term': {'location_country': "mexico"}},
            {'term': {'job_title_role': "health"}},
            {'exists': {'field': "phone_numbers"}}
      ]
    }
  }
}

# Create a parameters JSON object
PARAMS = {
  'query': json.dumps(ES_QUERY),
  'size': 10,
  'pretty': True
}

# Pass the parameters object to the Person Search API
response = requests.get(
  PDL_URL,
  headers=HEADERS,
  params=PARAMS
).json()

# Check for successful response
if response["status"] == 200:
  data = response['data']
  # Write out each profile found to file
  with open("my_pdl_search.jsonl", "w") as out:
    for record in data:
      out.write(json.dumps(record) + "\n")
  print(f"Successfully grabbed {len(data)} records from PDL.")
  print(f"{response['total']} total PDL records exist matching this query.")
else:
  print("NOTE: The carrier pigeons lost motivation in flight. See error and try again.")
  print("Error:", response)
```

```
import requests, json

# Set your API key
API_KEY = "YOUR API KEY"

# Set the Person Search API URL
PDL_URL = "https://api.peopledatalabs.com/v5/person/search"

# Set headers
HEADERS = {
  'Content-Type': "application/json",
  'X-api-key': API_KEY
}

# Create an SQL query
SQL_QUERY = \
"""
  SELECT * FROM person
  WHERE location_country='mexico'
  AND job_title_role='health'
  AND phone_numbers IS NOT NULL;
 """

# Create a parameters JSON object
PARAMS = {
  'sql': SQL_QUERY,
  'size': 10,
  'pretty': True
}

# Pass the parameters object to the Person Search API
response = requests.get(
  PDL_URL,
  headers=HEADERS,
  params=PARAMS
).json()

# Check for successful response
if response["status"] == 200:
  data = response['data']
  # Write out each profile found to file
  with open("my_pdl_search.jsonl", "w") as out:
    for record in data:
      out.write(json.dumps(record) + "\n")
  print(f"Successfully grabbed {len(data)} records from PDL.")
  print(f"{response['total']} total PDL records exist matching this query.")
else:
  print("NOTE: The carrier pigeons lost motivation in flight. See error and try again.")
  print("Error:", response)
```

The returned API response is a list of the records in our dataset that match the request query in the format:

JSON

```
{
  "status": 200,
  "data": [
    {
      "id": "qEnOZ5Oh0poWnQ1luFBfVw_0000",
      "full_name": "sean thorne",
      ...
    },
    ...
  ],
"scroll_token": "1117$12.176522"  
"total": 94
}
```

The objects in the `data` array will follow the [Person Schema](/docs/fields). For a full example, see the [Example Person Record](/docs/example-record).

### Troubleshooting

If you don't get this response, check out our [Errors](/docs/errors) page for more information.

---

Updated 4 months ago

---

Did this page help you?

Yes

No

---
# https://docs.peopledatalabs.com/docs/faqs-person-search-api

> â“
>
> ### Have a Question You Want Answered? Ask Us!
>
> Head over to the [Help Center](https://support.peopledatalabs.com) and search for your question. If you still can't find what you're looking for, create a support ticket and we will get it answered for you!

---

## What is the difference between the various Person APIs?

See [this section](/docs/person-endpoints#the-differences-between-our-person-related-apis) for a detailed breakdown of the differences between our Person APIs.

## Can I get a likelihood score in the Person Search API?

The likelihood score that we return in our Enrichment APIs represents the likelihood of the matching logic given the input parameters, so it wouldn't be relevant in the Person Search API.

## Can I use the Person Search API to enrich data?

The Person Search API ignores the [nuances in our Person Enrichment API matching logic](https://www.notion.so/Enrichment-API-Tips-and-Tricks-52a19eaf2b7e412790232f205d63bcab). We don't do any preprocessing (cleaning) of the inputs to the Person Search API, so you're almost guaranteed to have a lower match rate.

What's more, Person Search API queries and Person Enrichment API queries are structured differently. When you make a Person Enrichment API request, we have a custom-built query that takes the different input parameters and weights them differently, only returning a match in certain cases while using stack ranking in cases where there are multiple matches (for example, John Smith in San Francisco.)

## Should I use SQL or Elasticsearch for the Person Search API?

Use **Elasticsearch** when:

1. You have complicated boolean queries.
2. You want to maximize the control that you have over text-based matching (titles, summaries and so forth.)
3. You are comfortable writing Elasticsearch queries.

Use **SQL** when:

1. You are running simple searches with only a few parameters.
2. You're exclusively using ENUM parameters from our data (location, company, major and so forth.)
3. You are comfortable writing SQL queries.

## Can I use wildcards in my search query?

Yes, wildcard terms are supported. However, we have a hard limit of 20 wildcards per query. See the relevant sections for more information about the limitations in [Elasticsearch](/docs/input-parameters-person-search-api#elasticsearch-query-limitations) and [SQL](/docs/input-parameters-person-search-api#sql-query-limitations) search queries.

## Why is there a 1MB limit on the API requests and the response body?

The error message that you are receiving has occurred because the query is too large and cURL can't handle the response. Calling the API with Python should alleviate this issue as Python compresses the extra space within an Elasticsearch query. Additional ways to decrease the query size are to reduce the profile count parameter from `100` to `60` for each call and to remove the `pretty` tag. You can get around this limitation by [Using POST Requests](/docs/examples-person-search-api#using-post-requests).

## Can I exclude PDL IDs in a Person Search call to avoid spending duplicate credits?

You can technically exclude up to 1,000 PDL IDs in a single search query, however you will eventually run into limitations due to our infrastructure. While the PDL ID is mostly persistent, it's possible that the IDs can get merged, deleted, or opted out from our dataset across releases. Additionally, we will truncate extremely long queries in our internal logs, making it more difficult to assist you should you need technical support. At some point in the future, we will place limitations on query length and/or performance time to avoid these costly queries.

## Will I be charged for retrieving the same profile multiple times?

Yes. PDL will charge for the retrieval of the same profile.

Example 1  
You search for Engineers in California then conduct another search for Engineers in San Francisco. You will be charged for the overlap in the second request.

Example 2  
You search for Engineers in California and search again for Engineers in California. You will be charged the same amount for each request.

Example 1 is a bit more difficult to handle for programmatically and likely needs a UI/UX approach to limit overlapping queries.

To handle for situations demonstrated in Example 2, PDL recommends duplicate call detection. You can use methods like unique key constraints. For example, you can hash the request, storing the hash, and checking for a duplicate call before sending it to the API to avoid the second situation above.

Updated 4 months ago

---

Did this page help you?

Yes

No

---
# https://docs.peopledatalabs.com/docs/quickstart-company-search-api

## Getting Started

In order to use our Company Search API, you must have an active API key. You can look up your API key by logging into our [self-serve dashboard](https://www.peopledatalabs.com/main/api-keys) and going to the **API Keys** section.

> ðŸ‘
>
> ### Need an API Key?
>
> If you don't have an API key, you can easily create one by [signing up](https://peopledatalabs.com/signup) for a self-serve account. For more information, check out our [Self-Serve Quickstart Guide](https://blog.peopledatalabs.com/post/self-signup-api-quickstart), which walks you through the sign-up process as well as shows you how to use the self-serve API dashboard.

## Simple Example

As mentioned in the [Overview](/docs/company-search-api#overview), the Company Search API is a means of filtering and segmenting profiles included in our [Company](/docs/company-schema) Dataset. In order to use the Company Search API, **you will need to use either an[Elasticsearch](/docs/input-parameters-company-search-api#query) query or a [SQL](/docs/input-parameters-company-search-api#sql) query**.

Here's a quick example to search for company profiles whose `website` is `peopledatalabs.com`:

> â—ï¸
>
> ### Heads Up! Credit Usage
>
> Company Search API calls cost the number of **total search results** returned.
>
> If you are making a search that could have a large number of results, make sure to use the [`size` parameter](/docs/input-parameters-company-search-api#size) to set the maximum number of results and cap your credit usage.

Python3 SDK (Elasticsearch)Python3 SDK (SQL)cURLJavaScript (Elasticsearch)JavaScript (SQL)Ruby (Elasticsearch)Ruby (SQL)Go (Elasticsearch)Go (SQL)Python3 (Elasticsearch)Python3 (SQL)

```
import json

# See https://github.com/peopledatalabs/peopledatalabs-python
from peopledatalabs import PDLPY

# Create a client, specifying your API key
CLIENT = PDLPY(
    api_key="YOUR API KEY",
)

# Create an Elasticsearch query
ES_QUERY = {
  "query": {
    "bool": {
      "must": [
        {"term": {"website": "peopledatalabs.com"}},
      ]
    }
  }
}

# Create a parameters JSON object
PARAMS = {
  'query': ES_QUERY,
  'size': 10,
  'pretty': True
}

# Pass the parameters object to the Company Search API
response = CLIENT.company.search(**PARAMS).json()

# Check for successful response
if response["status"] == 200:
  data = response['data']
  # Write out each profile found to file
  with open("my_pdl_search.jsonl", "w") as out:
    for record in data:
      out.write(json.dumps(record) + "\n")
  print(f"Successfully grabbed {len(data)} records from PDL.")
  print(f"{response['total']} total PDL records exist matching this query.")
else:
  print("NOTE: The carrier pigeons lost motivation in flight. See error and try again.")
  print("Error:", response)
```

```
import json

# See https://github.com/peopledatalabs/peopledatalabs-python
from peopledatalabs import PDLPY

# Create a client, specifying your API key
CLIENT = PDLPY(
    api_key="YOUR API KEY",
)

# Create an SQL query
SQL_QUERY = \
"""
  SELECT * FROM company
  WHERE website='peopledatalabs.com';
 """

# Create a parameters JSON object
PARAMS = {
  'sql': SQL_QUERY,
  'size': 10,
  'pretty': True
}

# Pass the parameters object to the Company Search API
response = CLIENT.company.search(**PARAMS).json()

# Check for successful response
if response["status"] == 200:
  data = response['data']
  # Write out each profile found to file
  with open("my_pdl_search.jsonl", "w") as out:
    for record in data:
      out.write(json.dumps(record) + "\n")
  print(f"Successfully grabbed {len(data)} records from PDL.")
  print(f"{response['total']} total PDL records exist matching this query.")
else:
  print("NOTE: The carrier pigeons lost motivation in flight. See error and try again.")
  print("Error:", response)
```

```
# Elasticsearch
curl -X GET 'https://api.peopledatalabs.com/v5/company/search' \
-H 'X-Api-Key: xxxx' \
--data-raw '{
  "size": 10,
  "query": {
    "bool": {
      "must": [
        {"term": {"website": "peopledatalabs.com"}},
      ]
    }
  }
}'

# SQL
curl -X GET \
  'https://api.peopledatalabs.com/v5/company/search' \
  -H 'X-Api-Key: xxxx' \
  --data-raw '{
    "size": 10,
    "sql": "SELECT * FROM company WHERE website='\''google.com'\'';"
}'
```

```
// See https://github.com/peopledatalabs/peopledatalabs-js
import PDLJS from 'peopledatalabs';

import fs from 'fs';

// Create a client, specifying your API key
const PDLJSClient = new PDLJS({ apiKey: "YOUR API KEY" });

// Create an Elasticsearch query
const esQuery = {
  query: {
    bool: {
      must:[
        {"term": {"website": "peopledatalabs.com"}} 
      ]
    }
  }
}

// Create a parameters JSON object
const params = {
  searchQuery: esQuery, 
  size: 10,
  pretty: true
}

// Pass the parameters object to the Company Search API
PDLJSClient.company.search.elastic(params).then((data) => {
    // Write out all profiles found to file
    fs.writeFile("my_pdl_search.jsonl", Buffer.from(JSON.stringify(data.data)), (err) => {
        if (err) throw err;
    });
    console.log(`Successfully grabbed ${data.data.length} records from PDL.`);
    console.log(`${data["total"]} total PDL records exist matching this query.`)
}).catch((error) => {
    console.log("NOTE: The carrier pigeons lost motivation in flight. See error and try again.")
    console.log(error);
});
```

```
// See https://github.com/peopledatalabs/peopledatalabs-js
import PDLJS from 'peopledatalabs';

import fs from 'fs';

// Create a client, specifying your API key
const PDLJSClient = new PDLJS({ apiKey: "YOUR API KEY" });

// Create an SQL query
const sqlQuery = `SELECT * FROM company
                    WHERE website='peopledatalabs.com';`;

// Create a parameters JSON object
const params = {
    searchQuery: sqlQuery, 
    size: 10,
    pretty: true
}

// Pass the parameters object to the Company Search API
PDLJSClient.company.search.sql(params).then((data) => {
    // Write out all profiles found to file
    fs.writeFile("my_pdl_search.jsonl", Buffer.from(JSON.stringify(data.data)), (err) => {
        if (err) throw err;
    });
    console.log(`Successfully grabbed ${data.data.length} records from PDL.`);
    console.log(`${data["total"]} total PDL records exist matching this query.`)
}).catch((error) => {
    console.log("NOTE: The carrier pigeons lost motivation in flight. See error and try again.")
    console.log(error);
});
```

```
require 'json'

# See https://github.com/peopledatalabs/peopledatalabs-ruby
require 'peopledatalabs'

# Set your API key
Peopledatalabs.api_key = 'YOUR API KEY'

# Create an Elasticsearch query
ES_QUERY = {
  "query": {
    "bool": {
      "must": [
        {"term": {"website": "peopledatalabs.com"}},
      ]
    }
  }
}

# Pass parameters to the Company Search API
response = Peopledatalabs::Search.company(searchType: 'elastic', query: ES_QUERY, size: 10, pretty: true)

# Check for successful response
if response['status'] == 200
    data = response['data']
    # Write out each profile found to file
    File.open("my_pdl_search.jsonl", "w") do |out|
        data.each { |record| out.write(JSON.dump(record) + "\n") }
    end
    puts "Successfully grabbed #{data.length()} records from PDL."
    puts "#{response['total']} total PDL records exist matching this query."
else
    puts "NOTE: The carrier pigeons lost motivation in flight. See error and try again."
    puts "Error: #{response}"
end
```

```
require 'json'

# See https://github.com/peopledatalabs/peopledatalabs-ruby
require 'peopledatalabs'

# Set your API key
Peopledatalabs.api_key = 'YOUR API KEY'

# Create an SQL query
SQL_QUERY = \
"""
  SELECT * FROM company
  WHERE website='peopledatalabs.com';
 """

# Pass parameters to the Company Search API
response = Peopledatalabs::Search.company(searchType: 'sql', query: SQL_QUERY, size: 10, pretty: true)

# Check for successful response
if response['status'] == 200
    data = response['data']
    # Write out each profile found to file
    File.open("my_pdl_search.jsonl", "w") do |out|
        data.each { |record| out.write(JSON.dump(record) + "\n") }
    end
    puts "Successfully grabbed #{data.length()} records from PDL."
    puts "#{response['total']} total PDL records exist matching this query."
else
    puts "NOTE: The carrier pigeons lost motivation in flight. See error and try again."
    puts "Error: #{response}"
end
```

```
package main

import (
    "fmt"
    "os"
    "encoding/json"
    "context"
)

// See https://github.com/peopledatalabs/peopledatalabs-go
import (
    pdl "github.com/peopledatalabs/peopledatalabs-go"
    pdlmodel "github.com/peopledatalabs/peopledatalabs-go/model"
)

func main() {
    // Set your API key
    apiKey := "YOUR API KEY"
    // Set API key as environmental variable
    // apiKey := os.Getenv("API_KEY")

    // Create a client, specifying your API key
    client := pdl.New(apiKey)
    
    // Create an Elasticsearch query
    elasticSearchQuery := map[string]interface{} {
        "query": map[string]interface{} {
            "bool": map[string]interface{} {
                "must": []map[string]interface{} {
                    {"term": map[string]interface{}{"website": "peopledatalabs.com"}},
                },
            },
        },
    }

    // Create a parameters JSON object
    params := pdlmodel.SearchParams {
        BaseParams: pdlmodel.BaseParams {
            Size: 10,
            Pretty: true,
        },
        SearchBaseParams: pdlmodel.SearchBaseParams {
            Query: elasticSearchQuery,
        },
    }
    
    // Pass the parameters object to the Company Search API
    response, err := client.Company.Search(context.Background(), params)
    // Check for successful response
    if err == nil {
        data := response.Data
        // Create file
        out, outErr := os.Create("my_pdl_search.jsonl")
        defer out.Close()
        if (outErr == nil) {
            for i := range data {
                // Convert each profile found to JSON
                record, jsonErr := json.Marshal(data[i])
                // Write out each profile to file
                if (jsonErr == nil) {
                    out.WriteString(string(record) + "\n")
                }
            }
            out.Sync()
        }
        fmt.Printf("Successfully grabbed %d records from PDL.\n", len(data))
        fmt.Printf("%d total PDL records exist matching this query.\n", response.Total)
    } else {
        fmt.Println("NOTE: The carrier pigeons lost motivation in flight. See error and try again.")
        fmt.Println("Error:", err)
    } 
}
```

```
package main

import (
    "fmt"
    "os"
    "encoding/json"
    "context"
)

// See https://github.com/peopledatalabs/peopledatalabs-go
import (
    pdl "github.com/peopledatalabs/peopledatalabs-go"
    pdlmodel "github.com/peopledatalabs/peopledatalabs-go/model"
)

func main() {
     // Set your API key
    apiKey := "YOUR API KEY"
    // Set API key as environmental variable
    // apiKey := os.Getenv("API_KEY")

    // Create a client, specifying your API key
    client := pdl.New(apiKey)
    
    // Create an SQL query
    sqlQuery := "SELECT * FROM company" +
        " WHERE website='peopledatalabs.com';"

    // Create a parameters JSON object
    params := pdlmodel.SearchParams {
        BaseParams: pdlmodel.BaseParams {
            Size: 10,
            Pretty: true,
        },
        SearchBaseParams: pdlmodel.SearchBaseParams {
            SQL: sqlQuery,
        },
    }
    
    // Pass the parameters object to the Company Search API
    response, err := client.Company.Search(context.Background(), params)
    // Check for successful response
    if err == nil {
        data := response.Data
        // Create file
        out, outErr := os.Create("my_pdl_search.jsonl")
        defer out.Close()
        if (outErr == nil) {
            for i := range data {
                // Convert each profile found to JSON
                record, jsonErr := json.Marshal(data[i])
                // Write out each profile to file
                if (jsonErr == nil) {
                    out.WriteString(string(record) + "\n")
                }
            }
            out.Sync()
        }
        fmt.Printf("Successfully grabbed %d records from PDL.\n", len(data))
        fmt.Printf("%d total PDL records exist matching this query.\n", response.Total)
    } else {
        fmt.Println("NOTE: The carrier pigeons lost motivation in flight. See error and try again.")
        fmt.Println("Error:", err)
    } 
}
```

```
import requests, json

# Set your API key
API_KEY = "YOUR API KEY"

# Set the Company Search API URL
PDL_URL = "https://api.peopledatalabs.com/v5/company/search"

# Set headers
HEADERS = {
  'Content-Type': "application/json",
  'X-api-key': API_KEY
}

# Create an Elasticsearch query
ES_QUERY = {
  "query": {
    "bool": {
      "must": [
        {"term": {"website": "peopledatalabs.com"}},
      ]
    }
  }
}

# Create a parameters JSON object
PARAMS = {
  'query': json.dumps(ES_QUERY),
  'size': 10,
  'pretty': True
}

# Pass the parameters object to the Company Search API
response = requests.get(
  PDL_URL,
  headers=HEADERS,
  params=PARAMS
).json()

# Check for successful response
if response["status"] == 200:
  data = response['data']
  # Write out each profile found to file
  with open("my_pdl_search.jsonl", "w") as out:
    for record in data:
      out.write(json.dumps(record) + "\n")
  print(f"Successfully grabbed {len(data)} records from PDL.")
  print(f"{response['total']} total PDL records exist matching this query.")
else:
  print("NOTE: The carrier pigeons lost motivation in flight. See error and try again.")
  print("Error:", response)
```

```
import requests, json

# Set your API key
API_KEY = "YOUR API KEY"

# Set the Company Search API URL
PDL_URL = "https://api.peopledatalabs.com/v5/company/search"

# Set headers
HEADERS = {
  'Content-Type': "application/json",
  'X-api-key': API_KEY
}

# Create an SQL query
SQL_QUERY = \
"""
  SELECT * FROM company
  WHERE website='peopledatalabs.com';
 """

# Create a parameters JSON object
PARAMS = {
  'sql': SQL_QUERY,
  'size': 10,
  'pretty': True
}

# Pass the parameters object to the Company Search API
response = requests.get(
  PDL_URL,
  headers=HEADERS,
  params=PARAMS
).json()

# Check for successful response
if response["status"] == 200:
  data = response['data']
  # Write out each profile found to file
  with open("my_pdl_search.jsonl", "w") as out:
    for record in data:
      out.write(json.dumps(record) + "\n")
  print(f"Successfully grabbed {len(data)} records from PDL.")
  print(f"{response['total']} total PDL records exist matching this query.")
else:
  print("NOTE: The carrier pigeons lost motivation in flight. See error and try again.")
  print("error:", response)
```

The returned API response is a list of the company records in our dataset that match the request query in the format:

JSON

```
{
  "status": 200,
  "data": [
    {
      "id": "tnHcNHbCv8MKeLh92946LAkX6PKg",
      "name": "people data labs",
      ...
    }
  ],
  "scroll_token": "13.312621$5439277"
  "total": 6
}
```

The objects in the `data` array will follow the [Company Schema](/docs/company-schema). For a full example, see the [Example Company Record](/docs/example-company-record).

If you don't get this response, check out our [Errors](/docs/errors) page for more information.

---

Updated 4 months ago

---

Did this page help you?

Yes

No

---
# https://docs.peopledatalabs.com/docs/output-response-skill-enrichment-api

> â—ï¸
>
> ### The Skill Enrichment API is now fully removed
>
> This endpoint was removed in our April 2025 (v30.0) Release and is no longer available. This page is retained for historical documentation purposes.
>
> For more information, please see our [April 2025 Release Notes (v30.0)](/changelog/april-2025-release-notes-v300).

## Response Data Structure

Here is the structure of an example response from the Skill Enrichment API:

JSON

```
{
  "cleaned_skill": "ai",
  "similar_skills": [
    "machine learning",
    "artificial intelligence",
    "deep learning",
    "data science",
    "iot"
  ],
  "relevant_job_titles": [
    "data scientist",
    "software engineer",
    "senior data scientist",
    "chief technology officer",
    "senior software engineer"
  ]
}
```

## Response Fields

### `cleaned_skill`

| Type | Description |
| --- | --- |
| `String` | The skill that matches the API input `skill` after passing it through our internal skill cleaner. |

  

### `similar_skills`

| Type | Description |
| --- | --- |
| `Array [String]` | A list of to five of the most contextually-similar skills to the `cleaned_skill`, determined using our global resume data. |

  

### `relevant_job_titles`

| Type | Description |
| --- | --- |
| `Array [String]` | A list of up to five of the most contextually-similar job titles to the `cleaned_skill`, determined using our global resume data. |

Updated 4 months ago

---

Did this page help you?

Yes

No

---
# https://docs.peopledatalabs.com/docs/examples-person-identify-api

We've provided code samples in Python, cURL, Ruby, Go and JavaScript. If you aren't comfortable working in any of these languages, feel free to use this [handy tool](https://curl.trillworks.com/) to convert code from cURL to the language of your choice.

> ðŸ’¡
>
> ### We want your feedback!
>
> Do you see a bug? Is there an example you'd like to see that's not listed here?
>
> Head over to the public roadmap and submit a [bug ticket](https://peopledatalabs.canny.io/bugs) or a [feature request](https://peopledatalabs.canny.io/feature-requests) and receive automatic notifications as your bug is resolved or your request is implemented.

## Basic Usage

*I would like to find the most strongly associated profiles for the name "Sean Thorne."*

Python3 SDKcURLJavaScriptRubyGoPython3

```
import json

# See https://github.com/peopledatalabs/peopledatalabs-python
from peopledatalabs import PDLPY

# Create a client, specifying your API key
CLIENT = PDLPY(
    api_key="YOUR API KEY",
)

# Create a parameters JSON object
PARAMS = {
 "first_name": "sean", 
 "last_name": "thorne", 
 "company": "people data labs",
 "pretty": True
}

# Pass the parameters object to the Person Identify API
response_data = CLIENT.person.identify(**PARAMS).json()

# Check for successful response
if json_response["status"] == 200:
   # Create a list of matches
   identities = response_data['matches']

   # Print the matches in JSON format
   print(identities)
   print(f"Found {len(identities)} identities!")
else:
   print("Identify unsuccessful. See error and try again.")
   print("error:", json_response)
```

```
API_KEY="ENTER YOUR API KEY HERE"
curl -X GET -G \
 "https://api.peopledatalabs.com/v5/person/identify"\
 -H "X-Api-Key: ${API_KEY}" \
 --data-urlencode 'first_name=sean'\
 --data-urlencode 'last_name=thorne'\
 --data-urlencode 'company="people data labs"'\
 --data-urlencode 'pretty=True'
```

```
// See https://github.com/peopledatalabs/peopledatalabs-js
import PDLJS from 'peopledatalabs';

// Create a client, specifying your API key
const PDLJSClient = new PDLJS({ apiKey: "YOUR API KEY" });

// Create a parameters JSON object
const params = {
  first_name: "sean", 
  last_name: "thorne", 
  company: "people data labs",
  pretty: true,
}

// Pass the parameters object to the Person Identify API
PDLJSClient.person.identify(params).then((data) => {
  // Create a list of matches
  var identities = data["matches"]
  
  // Print the matches in JSON format
  console.log(identities);
  console.log(`Found ${identities.length} identities!`)
}).catch((error) => {
  console.log("Identify unsuccessful. See error and try again.")
  console.log(error);
});
```

```
# See https://github.com/peopledatalabs/peopledatalabs-ruby
require 'peopledatalabs'

# Set your API key
Peopledatalabs.api_key = 'YOUR API KEY'

# Create a parameters JSON object
PARAMS = {
 "first_name": "sean", 
 "last_name": "thorne", 
 "company": "people data labs",
 "pretty": true
}

# Pass the parameters object to the Person Identify API
response = Peopledatalabs::Identify.person(params: PARAMS)

# Check for successful response
if json_response['status'] == 200

    # Create a list of matches
    identities = response['matches']

    # Print the matches in JSON format
    puts identities
    puts "Found #{identities.length()} identities!"
    end
else
    puts "Identify unsuccessful. See error and try again."
    puts "error: #{json_response}"
end
```

```
package main

import (
    "fmt"
    "encoding/json"
    "context"
)

// See https://github.com/peopledatalabs/peopledatalabs-go
import (
    pdl "github.com/peopledatalabs/peopledatalabs-go"
    pdlmodel "github.com/peopledatalabs/peopledatalabs-go/model"
)

func main() {
    // Set your API key
    apiKey := "YOUR API KEY"
    // Set API key as environmental variable
    // apiKey := os.Getenv("API_KEY")

    // Create a client, specifying your API key
    client := pdl.New(apiKey)
    
    // Create a parameters JSON object
    params := pdlmodel.IdentifyPersonParams {
        BaseParams: pdlmodel.BaseParams {
            Pretty: true,
        },
        PersonParams: pdlmodel.PersonParams {
            FirstName: []string{"sean"},
            LastName: []string{"thorne"},
            Company: []string{"people data labs"},
        },
    }
    
    // Pass the parameters object to the Person Identify API
    response, err := client.Person.Identify(context.Background(), params)
    // Check for successful response
    if err == nil {
        // Create a list of matches
        identities := response.Matches
        // Convert the matches to JSON
        jsonResponse, jsonErr := json.Marshal(identities)
        // Print the matches
        if (jsonErr == nil) {
            fmt.Println(string(jsonResponse))
        }
        
        fmt.Printf("Found %d identities!\n", len(identities))
    } else {
        fmt.Println("Identify unsuccessful. See error and try again.")
        fmt.Println("error:", err)
    }
}
```

```
import requests

# Set your API key
API_KEY = "YOUR API KEY"

# Set the Person Identify API URL
PDL_URL = "https://api.peopledatalabs.com/v5/person/identify"

# Create a parameters JSON object
PARAMS = {
 "first_name": "sean", 
 "last_name": "thorne", 
 "company": "people data labs",
 "pretty": True,
 "api_key": API_KEY
}

# Pass the parameters object to the Person Identify API
json_response = requests.get(PDL_URL, params=PARAMS).json()

# Check for successful response
if json_response['status'] == 200:
   # Create a list of matches
   identities = json_response['matches']

   # Print the matches in JSON format
   print(identities)
   print(f"Found {len(identities)} identities!")

else:
   print("Identify unsuccessful. See error and try again.")
   print("error:", json_response)
```

## Associated LinkedIn Profiles

*I would like to find the most strongly associated profiles for a particular LinkedIn account.*

Python3 SDKcURLJavaScriptRubyGoPython3

```
import json

# See https://github.com/peopledatalabs/peopledatalabs-python
from peopledatalabs import PDLPY

# Create a client, specifying your API key
CLIENT = PDLPY(
    api_key="YOUR API KEY",
)

# Create a parameters JSON object
PARAMS = {
 "profile": "linkedin.com/in/seanthorne",
 "pretty": True
}

# Pass the parameters object to the Person Identify API
response_data = CLIENT.person.identify(**PARAMS).json()

# Check for successful response
if json_response["status"] == 200:
   # Create a list of matches
   identities = response_data['matches']

   # Print the matches in JSON format
   print(identities)
   print(f"Found {len(identities)} identities!")
else:
   print("Identify unsuccessful. See error and try again.")
   print("error:", json_response)
```

```
API_KEY="ENTER YOUR API KEY HERE"
curl -X GET -G \
 "https://api.peopledatalabs.com/v5/person/identify"\
 -H "X-Api-Key: ${API_KEY}" \
 --data-urlencode 'profile=linkedin.com/in/seanthorne'\
 --data-urlencode 'pretty=True'
```

```
// See https://github.com/peopledatalabs/peopledatalabs-js
import PDLJS from 'peopledatalabs';

// Create a client, specifying your API key
const PDLJSClient = new PDLJS({ apiKey: "YOUR API KEY" });

// Create a parameters JSON object
const params = {
  profile: "linkedin.com/in/seanthorne",
  pretty: true,
}

// Pass the parameters object to the Person Identify API
PDLJSClient.person.identify(params).then((data) => {
  // Create a list of matches
  var identities = data["matches"]
  
  // Print the matches in JSON format
  console.log(identities);
  console.log(`Found ${identities.length} identities!`)
}).catch((error) => {
  console.log("Identify unsuccessful. See error and try again.")
  console.log(error);
});
```

```
# See https://github.com/peopledatalabs/peopledatalabs-ruby
require 'peopledatalabs'

# Set your API key
Peopledatalabs.api_key = 'YOUR API KEY'

# Create a parameters JSON object
PARAMS = {
 "profile": "linkedin.com/in/seanthorne",
 "pretty": true
}

# Pass the parameters object to the Person Identify API
response = Peopledatalabs::Identify.person(params: PARAMS)

# Check for successful response
if json_response['status'] == 200

    # Create a list of matches
    identities = response['matches']

    # Print the matches in JSON format
    puts identities
    puts "Found #{identities.length()} identities!"
    end
else
    puts "Identify unsuccessful. See error and try again."
    puts "error: #{json_response}"
end
```

```
package main

import (
    "fmt"
    "encoding/json"
    "context"
)

// See https://github.com/peopledatalabs/peopledatalabs-go
import (
    pdl "github.com/peopledatalabs/peopledatalabs-go"
    pdlmodel "github.com/peopledatalabs/peopledatalabs-go/model"
)

func main() {
    // Set your API key
    apiKey := "YOUR API KEY"
    // Set API key as environmental variable
    // apiKey := os.Getenv("API_KEY")

    // Create a client, specifying your API key
    client := pdl.New(apiKey)
    
    // Create a parameters JSON object
    params := pdlmodel.IdentifyPersonParams {
        BaseParams: pdlmodel.BaseParams {
            Pretty: true,
        },
        PersonParams: pdlmodel.PersonParams {
            Profile: []string{"linkedin.com/in/seanthorne"},
        },
    }
    
    // Pass the parameters object to the Person Identify API
    response, err := client.Person.Identify(context.Background(), params)
    // Check for successful response
    if err == nil {
        // Create a list of matches
        identities := response.Matches
        // Convert the matches to JSON
        jsonResponse, jsonErr := json.Marshal(identities)
        // Print the matches
        if (jsonErr == nil) {
            fmt.Println(string(jsonResponse))
        }
        
        fmt.Printf("Found %d identities!\n", len(identities))
    } else {
        fmt.Println("Identify unsuccessful. See error and try again.")
        fmt.Println("error:", err)
    }
}
```

```
import requests

# Set your API key
API_KEY = "YOUR API KEY"

# Set the Person Identify API URL
PDL_URL = "https://api.peopledatalabs.com/v5/person/identify"

# Create a parameters JSON object
PARAMS = {
 "profile": "linkedin.com/in/seanthorne",
 "pretty": True,
 "api_key": API_KEY
}

# Pass the parameters object to the Person Identify API
json_response = requests.get(PDL_URL, params=PARAMS).json()

# Check for successful response
if json_response['status'] == 200:
   # Create a list of matches
   identities = json_response['matches']

   # Print the matches in JSON format
   print(identities)
   print(f"Found {len(identities)} identities!")

else:
   print("Identify unsuccessful. See error and try again.")
   print("error:", json_response)
```

Updated 4 months ago

---

Did this page help you?

Yes

No

---
# https://docs.peopledatalabs.com/docs/resume-stats

## Description

The Resume Slice Dataset is a subset of our full [Person Dataset](/docs/stats) and is composed of all the records containing a LinkedIn URL in the profiles array. The table below summarizes some key statistics and fill rates for fields within this dataset. Premium fields are not accessible by default.

**Common Use Cases**  
*Candidate Search, Prospect Search, Custom Audiences, Career Path Prediction/Labor Force Modeling, Investment Sourcing*

| Field | Count | Numeric | Fill Percentage |
| --- | --- | --- | --- |
| `Total` | 798,953,930 | 798953930 | 100.0% |
| `birth_date` | 9,602,472 | 9602472 | 1.2% |
| `birth_year` | 15,649,238 | 15649238 | 2.0% |
| `certifications` | 65,599,017 | 65599017 | 8.2% |
| `certifications.end_date` | 51,441,071 | 51441071 | 6.4% |
| `certifications.name` | 65,599,017 | 65599017 | 8.2% |
| `certifications.organization` | 64,468,599 | 64468599 | 8.1% |
| `certifications.start_date` | 54,717,655 | 54717655 | 6.8% |
| `countries` | 788,263,810 | 788263810 | 98.7% |
| `education` | 362,939,617 | 362939617 | 45.4% |
| `education.degrees` | 178,294,926 | 178294926 | 22.3% |
| `education.end_date` | 311,412,140 | 311412140 | 39.0% |
| `education.gpa` | 10,905,828 | 10905828 | 1.4% |
| `education.majors` | 218,051,891 | 218051891 | 27.3% |
| `education.minors` | 1,708,288 | 1708288 | 0.2% |
| `education.raw` | 325,397,046 | 325397046 | 40.7% |
| `education.school` | 362,178,028 | 362178028 | 45.3% |
| `education.school.domain` | 300,417,596 | 300417596 | 37.6% |
| `education.school.facebook_url` | 215,897,400 | 215897400 | 27.0% |
| `education.school.id` | 307,923,065 | 307923065 | 38.5% |
| `education.school.linkedin_id` | 307,923,065 | 307923065 | 38.5% |
| `education.school.linkedin_url` | 307,922,662 | 307922662 | 38.5% |
| `education.school.location` | 296,772,829 | 296772829 | 37.1% |
| `education.school.location.continent` | 296,772,829 | 296772829 | 37.1% |
| `education.school.location.country` | 296,772,752 | 296772752 | 37.1% |
| `education.school.location.locality` | 283,981,209 | 283981209 | 35.5% |
| `education.school.location.name` | 296,772,829 | 296772829 | 37.1% |
| `education.school.location.region` | 290,871,828 | 290871828 | 36.4% |
| `education.school.name` | 362,145,026 | 362145026 | 45.3% |
| `education.school.raw` | 359,384,041 | 359384041 | 45.0% |
| `education.school.twitter_url` | 204,874,555 | 204874555 | 25.6% |
| `education.school.type` | 328,893,007 | 328893007 | 41.2% |
| `education.school.website` | 300,417,596 | 300417596 | 37.6% |
| `education.start_date` | 317,639,263 | 317639263 | 39.8% |
| `education.summary` | 71,625,698 | 71625698 | 9.0% |
| `emails` | 199,473,626 | 199473626 | 25.0% |
| `emails.address` | 199,473,626 | 199473626 | 25.0% |
| `emails.first_seen` | 199,473,626 | 199473626 | 25.0% |
| `emails.last_seen` | 199,473,626 | 199473626 | 25.0% |
| `emails.md5_hash` | 199,473,626 | 199473626 | 25.0% |
| `emails.num_sources` | 199,473,626 | 199473626 | 25.0% |
| `emails.sha_256_hash` | 199,473,626 | 199473626 | 25.0% |
| `emails.type` | 181,458,024 | 181458024 | 22.7% |
| `experience` | 575,794,679 | 575794679 | 72.1% |
| `experience.company` | 547,025,494 | 547025494 | 68.5% |
| `experience.company.facebook_url` | 273,306,302 | 273306302 | 34.2% |
| `experience.company.founded` | 343,590,737 | 343590737 | 43.0% |
| `experience.company.id` | 431,821,996 | 431821996 | 54.0% |
| `experience.company.industry` | 415,801,686 | 415801686 | 52.0% |
| `experience.company.industry_v2` | 400,736,971 | 400736971 | 50.2% |
| `experience.company.linkedin_id` | 431,821,996 | 431821996 | 54.0% |
| `experience.company.linkedin_url` | 431,821,996 | 431821996 | 54.0% |
| `experience.company.location` | 415,042,013 | 415042013 | 51.9% |
| `experience.company.location.address_line_2` | 76,653,849 | 76653849 | 9.6% |
| `experience.company.location.continent` | 414,381,063 | 414381063 | 51.9% |
| `experience.company.location.country` | 415,039,896 | 415039896 | 51.9% |
| `experience.company.location.geo` | 387,724,359 | 387724359 | 48.5% |
| `experience.company.location.locality` | 393,060,586 | 393060586 | 49.2% |
| `experience.company.location.metro` | 159,446,252 | 159446252 | 20.0% |
| `experience.company.location.name` | 415,042,013 | 415042013 | 51.9% |
| `experience.company.location.postal_code` | 343,719,341 | 343719341 | 43.0% |
| `experience.company.location.region` | 397,122,664 | 397122664 | 49.7% |
| `experience.company.location.street_address` | 327,365,629 | 327365629 | 41.0% |
| `experience.company.name` | 547,016,899 | 547016899 | 68.5% |
| `experience.company.raw` | 547,023,465 | 547023465 | 68.5% |
| `experience.company.size` | 431,821,996 | 431821996 | 54.0% |
| `experience.company.ticker` | 102,857,158 | 102857158 | 12.9% |
| `experience.company.twitter_url` | 229,907,181 | 229907181 | 28.8% |
| `experience.company.type` | 431,821,996 | 431821996 | 54.0% |
| `experience.company.website` | 394,936,177 | 394936177 | 49.4% |
| `experience.end_date` | 256,172,507 | 256172507 | 32.1% |
| `experience.first_seen` | 575,794,679 | 575794679 | 72.1% |
| `experience.is_primary` | 575,794,679 | 575794679 | 72.1% |
| `experience.last_seen` | 575,794,679 | 575794679 | 72.1% |
| `experience.location_names` | 237,651,153 | 237651153 | 29.7% |
| `experience.num_sources` | 575,794,679 | 575794679 | 72.1% |
| `experience.start_date` | 353,431,733 | 353431733 | 44.2% |
| `experience.summary` | 170,639,541 | 170639541 | 21.4% |
| `experience.title` | 573,669,109 | 573669109 | 71.8% |
| `experience.title.class` | 398,397,592 | 398397592 | 49.9% |
| `experience.title.levels` | 200,677,989 | 200677989 | 25.1% |
| `experience.title.name` | 573,669,109 | 573669109 | 71.8% |
| `experience.title.raw` | 573,669,109 | 573669109 | 71.8% |
| `experience.title.role` | 398,397,592 | 398397592 | 49.9% |
| `experience.title.sub_role` | 343,396,186 | 343396186 | 43.0% |
| `facebook_friends` | 6,265,409 | 6265409 | 0.8% |
| `facebook_id` | 30,767,024 | 30767024 | 3.9% |
| `facebook_url` | 29,838,807 | 29838807 | 3.7% |
| `facebook_username` | 29,838,807 | 29838807 | 3.7% |
| `first_name` | 798,953,930 | 798953930 | 100.0% |
| `first_seen` | 798,953,930 | 798953930 | 100.0% |
| `full_name` | 798,953,930 | 798953930 | 100.0% |
| `github_url` | 961,449 | 961449 | 0.1% |
| `github_username` | 961,449 | 961449 | 0.1% |
| `headline` | 186,300,358 | 186300358 | 23.3% |
| `id` | 798,953,930 | 798953930 | 100.0% |
| `industry` | 419,638,170 | 419638170 | 52.5% |
| `inferred_salary` | 262,086,926 | 262086926 | 32.8% |
| `inferred_years_experience` | 347,655,934 | 347655934 | 43.5% |
| `interests` | 35,250,852 | 35250852 | 4.4% |
| `job_company_12mo_employee_growth_rate` | 324,658,424 | 324658424 | 40.6% |
| `job_company_employee_count` | 329,507,127 | 329507127 | 41.2% |
| `job_company_facebook_url` | 158,282,495 | 158282495 | 19.8% |
| `job_company_founded` | 232,012,902 | 232012902 | 29.0% |
| `job_company_id` | 329,534,663 | 329534663 | 41.2% |
| `job_company_industry` | 311,911,815 | 311911815 | 39.0% |
| `job_company_industry_v2` | 297,266,417 | 297266417 | 37.2% |
| `job_company_inferred_revenue` | 329,507,127 | 329507127 | 41.2% |
| `job_company_linkedin_id` | 329,534,663 | 329534663 | 41.2% |
| `job_company_linkedin_url` | 329,534,663 | 329534663 | 41.2% |
| `job_company_location_address_line_2` | 29,430,316 | 29430316 | 3.7% |
| `job_company_location_continent` | 309,127,147 | 309127147 | 38.7% |
| `job_company_location_country` | 309,944,808 | 309944808 | 38.8% |
| `job_company_location_geo` | 279,851,993 | 279851993 | 35.0% |
| `job_company_location_locality` | 286,194,524 | 286194524 | 35.8% |
| `job_company_location_metro` | 95,075,780 | 95075780 | 11.9% |
| `job_company_location_name` | 309,948,851 | 309948851 | 38.8% |
| `job_company_location_postal_code` | 226,785,995 | 226785995 | 28.4% |
| `job_company_location_region` | 291,313,979 | 291313979 | 36.5% |
| `job_company_location_street_address` | 212,732,531 | 212732531 | 26.6% |
| `job_company_name` | 465,565,035 | 465565035 | 58.3% |
| `job_company_size` | 329,534,663 | 329534663 | 41.2% |
| `job_company_ticker` | 47,764,563 | 47764563 | 6.0% |
| `job_company_total_funding_raised` | 65,789,905 | 65789905 | 8.2% |
| `job_company_twitter_url` | 122,750,321 | 122750321 | 15.4% |
| `job_company_type` | 329,534,663 | 329534663 | 41.2% |
| `job_company_website` | 287,513,083 | 287513083 | 36.0% |
| `job_history` | 576,731,722 | 576731722 | 72.2% |
| `job_history.company_id` | 437,726,578 | 437726578 | 54.8% |
| `job_history.company_name` | 549,386,585 | 549386585 | 68.8% |
| `job_history.first_seen` | 576,731,722 | 576731722 | 72.2% |
| `job_history.last_seen` | 576,731,722 | 576731722 | 72.2% |
| `job_history.num_sources` | 576,731,722 | 576731722 | 72.2% |
| `job_history.title` | 574,832,387 | 574832387 | 71.9% |
| `job_last_changed` | 495,090,779 | 495090779 | 62.0% |
| `job_last_verified` | 495,090,779 | 495090779 | 62.0% |
| `job_onet_broad_occupation` | 225,084,057 | 225084057 | 28.2% |
| `job_onet_code` | 225,084,057 | 225084057 | 28.2% |
| `job_onet_major_group` | 225,084,057 | 225084057 | 28.2% |
| `job_onet_minor_group` | 225,084,057 | 225084057 | 28.2% |
| `job_onet_specific_occupation` | 225,084,057 | 225084057 | 28.2% |
| `job_onet_specific_occupation_detail` | 89,273,254 | 89273254 | 11.2% |
| `job_start_date` | 275,525,120 | 275525120 | 34.5% |
| `job_summary` | 73,819,132 | 73819132 | 9.2% |
| `job_title` | 493,450,988 | 493450988 | 61.8% |
| `job_title_class` | 295,046,030 | 295046030 | 36.9% |
| `job_title_levels` | 123,883,217 | 123883217 | 15.5% |
| `job_title_role` | 295,046,030 | 295046030 | 36.9% |
| `job_title_sub_role` | 232,969,283 | 232969283 | 29.2% |
| `languages` | 86,574,068 | 86574068 | 10.8% |
| `languages.name` | 86,574,068 | 86574068 | 10.8% |
| `languages.proficiency` | 24,017,585 | 24017585 | 3.0% |
| `last_initial` | 798,953,930 | 798953930 | 100.0% |
| `last_name` | 775,458,237 | 775458237 | 97.1% |
| `linkedin_connections` | 485,890,558 | 485890558 | 60.8% |
| `linkedin_id` | 577,237,502 | 577237502 | 72.2% |
| `linkedin_url` | 742,707,590 | 742707590 | 93.0% |
| `linkedin_username` | 742,707,590 | 742707590 | 93.0% |
| `location_address_line_2` | 3,498,095 | 3498095 | 0.4% |
| `location_continent` | 788,276,921 | 788276921 | 98.7% |
| `location_country` | 788,240,815 | 788240815 | 98.7% |
| `location_geo` | 532,378,936 | 532378936 | 66.6% |
| `location_last_updated` | 768,059,257 | 768059257 | 96.1% |
| `location_locality` | 544,838,067 | 544838067 | 68.2% |
| `location_metro` | 149,080,974 | 149080974 | 18.7% |
| `location_name` | 788,276,921 | 788276921 | 98.7% |
| `location_names` | 549,867,826 | 549867826 | 68.8% |
| `location_postal_code` | 26,751,613 | 26751613 | 3.3% |
| `location_region` | 580,822,328 | 580822328 | 72.7% |
| `location_street_address` | 27,069,257 | 27069257 | 3.4% |
| `middle_initial` | 129,849,446 | 129849446 | 16.3% |
| `middle_name` | 116,343,119 | 116343119 | 14.6% |
| `mobile_phone` | 55,523,457 | 55523457 | 6.9% |
| `name_aliases` | 43,891,470 | 43891470 | 5.5% |
| `num_records` | 798,953,930 | 798953930 | 100.0% |
| `num_sources` | 798,953,930 | 798953930 | 100.0% |
| `personal_emails` | 91,321,645 | 91321645 | 11.4% |
| `phone_numbers` | 77,610,359 | 77610359 | 9.7% |
| `phones` | 77,610,359 | 77610359 | 9.7% |
| `phones.first_seen` | 77,610,359 | 77610359 | 9.7% |
| `phones.last_seen` | 77,610,359 | 77610359 | 9.7% |
| `phones.num_sources` | 77,610,359 | 77610359 | 9.7% |
| `phones.number` | 77,610,359 | 77610359 | 9.7% |
| `possible_birth_dates` | 7,896,867 | 7896867 | 1.0% |
| `possible_emails` | 72,652,579 | 72652579 | 9.1% |
| `possible_emails.address` | 72,652,579 | 72652579 | 9.1% |
| `possible_emails.first_seen` | 72,652,579 | 72652579 | 9.1% |
| `possible_emails.last_seen` | 72,652,579 | 72652579 | 9.1% |
| `possible_emails.md5_hash` | 72,652,579 | 72652579 | 9.1% |
| `possible_emails.num_sources` | 72,652,579 | 72652579 | 9.1% |
| `possible_emails.sha_256_hash` | 72,652,579 | 72652579 | 9.1% |
| `possible_emails.type` | 62,474,958 | 62474958 | 7.8% |
| `possible_location_names` | 336,934,219 | 336934219 | 42.2% |
| `possible_phones` | 21,889,145 | 21889145 | 2.7% |
| `possible_phones.first_seen` | 21,889,145 | 21889145 | 2.7% |
| `possible_phones.last_seen` | 21,889,145 | 21889145 | 2.7% |
| `possible_phones.num_sources` | 21,889,145 | 21889145 | 2.7% |
| `possible_phones.number` | 21,889,145 | 21889145 | 2.7% |
| `possible_profiles` | 15,335,892 | 15335892 | 1.9% |
| `possible_profiles.first_seen` | 15,335,892 | 15335892 | 1.9% |
| `possible_profiles.id` | 10,922,148 | 10922148 | 1.4% |
| `possible_profiles.last_seen` | 15,335,892 | 15335892 | 1.9% |
| `possible_profiles.network` | 15,335,892 | 15335892 | 1.9% |
| `possible_profiles.num_sources` | 15,335,892 | 15335892 | 1.9% |
| `possible_profiles.url` | 15,335,892 | 15335892 | 1.9% |
| `possible_profiles.username` | 14,497,059 | 14497059 | 1.8% |
| `possible_street_addresses` | 9,850,220 | 9850220 | 1.2% |
| `possible_street_addresses.address_line_2` | 3,511,753 | 3511753 | 0.4% |
| `possible_street_addresses.continent` | 9,850,220 | 9850220 | 1.2% |
| `possible_street_addresses.country` | 9,850,220 | 9850220 | 1.2% |
| `possible_street_addresses.first_seen` | 9,850,220 | 9850220 | 1.2% |
| `possible_street_addresses.geo` | 9,850,066 | 9850066 | 1.2% |
| `possible_street_addresses.last_seen` | 9,850,220 | 9850220 | 1.2% |
| `possible_street_addresses.locality` | 9,850,172 | 9850172 | 1.2% |
| `possible_street_addresses.metro` | 8,962,666 | 8962666 | 1.1% |
| `possible_street_addresses.name` | 9,850,220 | 9850220 | 1.2% |
| `possible_street_addresses.num_sources` | 9,850,220 | 9850220 | 1.2% |
| `possible_street_addresses.postal_code` | 9,814,647 | 9814647 | 1.2% |
| `possible_street_addresses.region` | 9,850,193 | 9850193 | 1.2% |
| `possible_street_addresses.street_address` | 9,850,220 | 9850220 | 1.2% |
| `profiles` | 798,953,930 | 798953930 | 100.0% |
| `profiles.first_seen` | 798,953,930 | 798953930 | 100.0% |
| `profiles.id` | 605,076,410 | 605076410 | 75.7% |
| `profiles.last_seen` | 798,953,930 | 798953930 | 100.0% |
| `profiles.network` | 798,953,930 | 798953930 | 100.0% |
| `profiles.num_sources` | 798,953,930 | 798953930 | 100.0% |
| `profiles.url` | 798,953,930 | 798953930 | 100.0% |
| `profiles.username` | 798,953,930 | 798953930 | 100.0% |
| `recommended_personal_email` | 91,320,041 | 91320041 | 11.4% |
| `regions` | 589,169,663 | 589169663 | 73.7% |
| `sex` | 559,491,856 | 559491856 | 70.0% |
| `skills` | 138,561,276 | 138561276 | 17.3% |
| `street_addresses` | 35,319,343 | 35319343 | 4.4% |
| `street_addresses.address_line_2` | 16,409,387 | 16409387 | 2.1% |
| `street_addresses.continent` | 35,319,343 | 35319343 | 4.4% |
| `street_addresses.country` | 35,319,343 | 35319343 | 4.4% |
| `street_addresses.first_seen` | 35,319,343 | 35319343 | 4.4% |
| `street_addresses.geo` | 34,594,437 | 34594437 | 4.3% |
| `street_addresses.last_seen` | 35,319,343 | 35319343 | 4.4% |
| `street_addresses.locality` | 34,631,947 | 34631947 | 4.3% |
| `street_addresses.metro` | 31,194,371 | 31194371 | 3.9% |
| `street_addresses.name` | 35,319,343 | 35319343 | 4.4% |
| `street_addresses.num_sources` | 35,319,343 | 35319343 | 4.4% |
| `street_addresses.postal_code` | 33,379,518 | 33379518 | 4.2% |
| `street_addresses.region` | 34,719,746 | 34719746 | 4.3% |
| `street_addresses.street_address` | 35,319,343 | 35319343 | 4.4% |
| `summary` | 164,148,072 | 164148072 | 20.5% |
| `twitter_url` | 12,776,174 | 12776174 | 1.6% |
| `twitter_username` | 12,776,174 | 12776174 | 1.6% |
| `work_email` | 64,587,835 | 64587835 | 8.1% |

*Stats shown are accurate as of data version 33.1*

Updated 6 days ago

---

Did this page help you?

Yes

No

---
# https://docs.peopledatalabs.com/docs/javascript-sdk

# The People Data Labs JavaScript Helper Library

The People Data Labs JavaScript Helper Library makes it easy to interact with our APIs from your JavaScript application. You can find the [most recent version of the library on npm](https://www.npmjs.com/package/peopledatalabs).

## How To Install the Library

This library is available as an [npm](https://www.npmjs.com/package/peopledatalabs) package, and you can install it like this:

NPMYarn

```
npm i -S peopledatalabs
```

```
yarn add peopledatalabs
```

## Using the Library

Make sure that you sign up for a [free PDL API key](https://www.peopledatalabs.com/signup) if you don't already have one.

JavaScript

```
// See https://github.com/peopledatalabs/peopledatalabs-js
import PDLJS from 'peopledatalabs';

// Create a client, specifying your API key
const PDLClient = new PDLJS({ apiKey: YOUR_API_KEY });

// Chaining Implementation
PDLClient.person.enrichment({ profile: 'linkedin.com/in/seanthorne' }).then((response) => {
  // Print the API response in JSON format
  console.log(response?.data);
}).catch((error) => {
  console.log(error);
});

// Async/Await Implementation
try {
  const getPersonRecord = async () => {
    const response = await PDLClient.person.enrichment({ profile: 'linkedin.com/in/seanthorne' });
    // Print the API response in JSON format
    console.log(response?.data);
  }
  
  getPersonRecord();
} catch (error) {
  console.log(error);
}
```

## TypeScript Support

The People Data Labs JavaScript Helper Library ships with TypeScript types. You can use these to gain the benefits of using TypeScript without having to write your own types.

## More Information, Pull Requests, Feature Suggestions and Bug Reports

We've open-sourced the library, which is available on GitHub. Go there to view more information. You can also submit pull requests, feature suggestions and bug reports.

[github.com

GitHub - peopledatalabs/peopledatalabs-js: A universal JS client with TypeScript support for the People Data Labs API](https://github.com/peopledatalabs/peopledatalabs-js)

Updated 4 months ago

---

Did this page help you?

Yes

No

---
# https://docs.peopledatalabs.com/docs/output-response-person-identify-api

## Response Data Structure

The response from the Person Identify API will be in this format:

JSON

```
{
  "status": 200,
  "matches": [
    {
      "data": {
        ...
      },
      "match_score": 92,
      "matched_on": [
        "company",
        "name"
      ]
    },
    {
      "data": {
        ...
      },
      "match_score": 5,
      "matched_on": [
        "name"
      ]
    },
    ...
  ]
}
```

## Response Fields

### `status`

| Type | Description |
| --- | --- |
| `Integer` | The [API response code](/docs/errors). |

  

### `matches`

| Type | Description |
| --- | --- |
| `Array (Object)` | A list of up to 20 profiles matching the input criteria from the API request. Only returns profiles with a [`match_score`](#matchesmatch_score) greater than 5. |

Each object returned in the matches array will have the following attributes:

  

### `matches.match_score`

| Type | Description |
| --- | --- |
| `Integer` | How likely that this record is the record you're looking for based on your query. Will be between `1-99`. |

`match_score` measures how strongly a profile matches the input search criteria. The score is used to rank matching profiles and filter out profiles below a given score (default 5).

The more specific the input criteria is, the more useful the match\_score becomes. For example, if you wanted to find "John Smith", there would be too many possible matches. However, if you searched for "John Smith in New York City with the email address \_\_\_", it is much more likely that the profile with the highest `match_score` is the person you're looking for.

  

### `matches.data`

| Type | Description |
| --- | --- |
| `Object` | The full [person profile](/docs/fields) of the match. |

  

### `matches.matched_on`

| Type | Description |
| --- | --- |
| `Array (String)` | Which fields in the input query match the results in the returned profile.   * \*IMPORTANT:\*\* This field will only be included in the response if the [`include_if_matched` flag](/docs/input-parameters-person-identify-api#include_if_matched) is set to `true`. |

See the [`include_if_matched` input parameter](/docs/input-parameters-person-identify-api#include_if_matched) for more details.

  

## Errors

Any request that does not return a `200` success response will instead use the format described in [Errors](/docs/errors).

Updated 4 months ago

---

Did this page help you?

Yes

No

---
# https://docs.peopledatalabs.com/docs/street-address-stats

## Description

The Street Address Slice Dataset is a subset of our full [Person Dataset](/docs/stats) and is composed of all the records containing a street address. The table below summarizes some key statistics and fill rates for fields within this dataset. Premium fields are not accessible by default.

**Common Use Cases**  
*Contact Info Enrichment, Sales and Marketing, Skiptracing, Background Checks, People Search*

| Field | Count | Numeric | Fill Percentage |
| --- | --- | --- | --- |
| `Total` | 218,071,308 | 218071308 | 100.0% |
| `birth_date` | 137,598,077 | 137598077 | 63.1% |
| `birth_year` | 205,542,489 | 205542489 | 94.3% |
| `certifications` | 1,734,850 | 1734850 | 0.8% |
| `certifications.end_date` | 1,236,286 | 1236286 | 0.6% |
| `certifications.name` | 1,734,850 | 1734850 | 0.8% |
| `certifications.organization` | 1,686,263 | 1686263 | 0.8% |
| `certifications.start_date` | 1,334,425 | 1334425 | 0.6% |
| `countries` | 218,071,308 | 218071308 | 100.0% |
| `education` | 15,771,758 | 15771758 | 7.2% |
| `education.degrees` | 5,611,065 | 5611065 | 2.6% |
| `education.end_date` | 7,696,795 | 7696795 | 3.5% |
| `education.gpa` | 531,698 | 531698 | 0.2% |
| `education.majors` | 7,376,253 | 7376253 | 3.4% |
| `education.minors` | 136,051 | 136051 | 0.1% |
| `education.raw` | 9,196,713 | 9196713 | 4.2% |
| `education.school` | 15,768,630 | 15768630 | 7.2% |
| `education.school.domain` | 13,656,103 | 13656103 | 6.3% |
| `education.school.facebook_url` | 9,071,575 | 9071575 | 4.2% |
| `education.school.id` | 14,130,178 | 14130178 | 6.5% |
| `education.school.linkedin_id` | 14,130,178 | 14130178 | 6.5% |
| `education.school.linkedin_url` | 14,130,164 | 14130164 | 6.5% |
| `education.school.location` | 11,999,239 | 11999239 | 5.5% |
| `education.school.location.continent` | 11,999,239 | 11999239 | 5.5% |
| `education.school.location.country` | 11,999,239 | 11999239 | 5.5% |
| `education.school.location.locality` | 11,864,429 | 11864429 | 5.4% |
| `education.school.location.name` | 11,999,239 | 11999239 | 5.5% |
| `education.school.location.region` | 11,904,633 | 11904633 | 5.5% |
| `education.school.name` | 15,768,621 | 15768621 | 7.2% |
| `education.school.raw` | 15,749,889 | 15749889 | 7.2% |
| `education.school.twitter_url` | 9,070,121 | 9070121 | 4.2% |
| `education.school.type` | 14,533,271 | 14533271 | 6.7% |
| `education.school.website` | 13,656,103 | 13656103 | 6.3% |
| `education.start_date` | 5,989,450 | 5989450 | 2.7% |
| `education.summary` | 2,379,333 | 2379333 | 1.1% |
| `emails` | 99,398,604 | 99398604 | 45.6% |
| `emails.address` | 99,398,604 | 99398604 | 45.6% |
| `emails.first_seen` | 99,398,604 | 99398604 | 45.6% |
| `emails.last_seen` | 99,398,604 | 99398604 | 45.6% |
| `emails.md5_hash` | 99,398,604 | 99398604 | 45.6% |
| `emails.num_sources` | 99,398,604 | 99398604 | 45.6% |
| `emails.sha_256_hash` | 99,398,604 | 99398604 | 45.6% |
| `emails.type` | 94,598,451 | 94598451 | 43.4% |
| `experience` | 19,970,633 | 19970633 | 9.2% |
| `experience.company` | 19,663,753 | 19663753 | 9.0% |
| `experience.company.facebook_url` | 9,176,485 | 9176485 | 4.2% |
| `experience.company.founded` | 10,371,041 | 10371041 | 4.8% |
| `experience.company.id` | 12,927,567 | 12927567 | 5.9% |
| `experience.company.industry` | 12,565,285 | 12565285 | 5.8% |
| `experience.company.industry_v2` | 12,139,660 | 12139660 | 5.6% |
| `experience.company.linkedin_id` | 12,927,567 | 12927567 | 5.9% |
| `experience.company.linkedin_url` | 12,927,567 | 12927567 | 5.9% |
| `experience.company.location` | 12,661,719 | 12661719 | 5.8% |
| `experience.company.location.address_line_2` | 3,302,972 | 3302972 | 1.5% |
| `experience.company.location.continent` | 12,636,899 | 12636899 | 5.8% |
| `experience.company.location.country` | 12,661,705 | 12661705 | 5.8% |
| `experience.company.location.geo` | 12,242,775 | 12242775 | 5.6% |
| `experience.company.location.locality` | 12,281,114 | 12281114 | 5.6% |
| `experience.company.location.metro` | 10,882,519 | 10882519 | 5.0% |
| `experience.company.location.name` | 12,661,719 | 12661719 | 5.8% |
| `experience.company.location.postal_code` | 11,608,076 | 11608076 | 5.3% |
| `experience.company.location.region` | 12,313,891 | 12313891 | 5.6% |
| `experience.company.location.street_address` | 11,304,716 | 11304716 | 5.2% |
| `experience.company.name` | 19,663,063 | 19663063 | 9.0% |
| `experience.company.raw` | 19,663,473 | 19663473 | 9.0% |
| `experience.company.size` | 12,927,567 | 12927567 | 5.9% |
| `experience.company.ticker` | 3,465,684 | 3465684 | 1.6% |
| `experience.company.twitter_url` | 8,315,434 | 8315434 | 3.8% |
| `experience.company.type` | 12,927,567 | 12927567 | 5.9% |
| `experience.company.website` | 12,031,950 | 12031950 | 5.5% |
| `experience.end_date` | 7,157,276 | 7157276 | 3.3% |
| `experience.first_seen` | 19,970,633 | 19970633 | 9.2% |
| `experience.is_primary` | 19,970,633 | 19970633 | 9.2% |
| `experience.last_seen` | 19,970,633 | 19970633 | 9.2% |
| `experience.location_names` | 9,728,562 | 9728562 | 4.5% |
| `experience.num_sources` | 19,970,633 | 19970633 | 9.2% |
| `experience.start_date` | 10,281,235 | 10281235 | 4.7% |
| `experience.summary` | 5,918,442 | 5918442 | 2.7% |
| `experience.title` | 14,296,663 | 14296663 | 6.6% |
| `experience.title.class` | 12,171,028 | 12171028 | 5.6% |
| `experience.title.levels` | 7,559,418 | 7559418 | 3.5% |
| `experience.title.name` | 14,296,663 | 14296663 | 6.6% |
| `experience.title.raw` | 14,296,663 | 14296663 | 6.6% |
| `experience.title.role` | 12,171,028 | 12171028 | 5.6% |
| `experience.title.sub_role` | 11,224,212 | 11224212 | 5.1% |
| `facebook_friends` | 3,298,448 | 3298448 | 1.5% |
| `facebook_id` | 22,041,079 | 22041079 | 10.1% |
| `facebook_url` | 19,856,035 | 19856035 | 9.1% |
| `facebook_username` | 19,856,035 | 19856035 | 9.1% |
| `first_name` | 218,071,308 | 218071308 | 100.0% |
| `first_seen` | 218,071,308 | 218071308 | 100.0% |
| `full_name` | 218,071,308 | 218071308 | 100.0% |
| `github_url` | 125,398 | 125398 | 0.1% |
| `github_username` | 125,398 | 125398 | 0.1% |
| `headline` | 5,724,683 | 5724683 | 2.6% |
| `id` | 218,071,308 | 218071308 | 100.0% |
| `industry` | 13,283,232 | 13283232 | 6.1% |
| `inferred_salary` | 6,227,625 | 6227625 | 2.9% |
| `inferred_years_experience` | 10,241,333 | 10241333 | 4.7% |
| `interests` | 36,716,921 | 36716921 | 16.8% |
| `job_company_12mo_employee_growth_rate` | 6,425,412 | 6425412 | 2.9% |
| `job_company_employee_count` | 6,461,141 | 6461141 | 3.0% |
| `job_company_facebook_url` | 3,792,637 | 3792637 | 1.7% |
| `job_company_founded` | 4,774,447 | 4774447 | 2.2% |
| `job_company_id` | 6,461,696 | 6461696 | 3.0% |
| `job_company_industry` | 6,229,494 | 6229494 | 2.9% |
| `job_company_industry_v2` | 5,898,849 | 5898849 | 2.7% |
| `job_company_inferred_revenue` | 6,461,141 | 6461141 | 3.0% |
| `job_company_linkedin_id` | 6,461,696 | 6461696 | 3.0% |
| `job_company_linkedin_url` | 6,461,696 | 6461696 | 3.0% |
| `job_company_location_address_line_2` | 873,613 | 873613 | 0.4% |
| `job_company_location_continent` | 6,187,899 | 6187899 | 2.8% |
| `job_company_location_country` | 6,210,331 | 6210331 | 2.8% |
| `job_company_location_geo` | 5,926,392 | 5926392 | 2.7% |
| `job_company_location_locality` | 5,956,320 | 5956320 | 2.7% |
| `job_company_location_metro` | 4,995,705 | 4995705 | 2.3% |
| `job_company_location_name` | 6,210,339 | 6210339 | 2.8% |
| `job_company_location_postal_code` | 5,301,935 | 5301935 | 2.4% |
| `job_company_location_region` | 5,986,960 | 5986960 | 2.7% |
| `job_company_location_street_address` | 5,092,160 | 5092160 | 2.3% |
| `job_company_name` | 9,061,321 | 9061321 | 4.2% |
| `job_company_size` | 6,461,696 | 6461696 | 3.0% |
| `job_company_ticker` | 1,039,361 | 1039361 | 0.5% |
| `job_company_total_funding_raised` | 1,697,574 | 1697574 | 0.8% |
| `job_company_twitter_url` | 3,169,091 | 3169091 | 1.5% |
| `job_company_type` | 6,461,696 | 6461696 | 3.0% |
| `job_company_website` | 5,837,217 | 5837217 | 2.7% |
| `job_history` | 19,982,049 | 19982049 | 9.2% |
| `job_history.company_id` | 13,392,367 | 13392367 | 6.1% |
| `job_history.company_name` | 19,719,319 | 19719319 | 9.0% |
| `job_history.first_seen` | 19,982,049 | 19982049 | 9.2% |
| `job_history.last_seen` | 19,982,049 | 19982049 | 9.2% |
| `job_history.num_sources` | 19,982,049 | 19982049 | 9.2% |
| `job_history.title` | 14,314,604 | 14314604 | 6.6% |
| `job_last_changed` | 9,326,120 | 9326120 | 4.3% |
| `job_last_verified` | 9,326,120 | 9326120 | 4.3% |
| `job_onet_broad_occupation` | 5,029,898 | 5029898 | 2.3% |
| `job_onet_code` | 5,029,898 | 5029898 | 2.3% |
| `job_onet_major_group` | 5,029,898 | 5029898 | 2.3% |
| `job_onet_minor_group` | 5,029,898 | 5029898 | 2.3% |
| `job_onet_specific_occupation` | 5,029,898 | 5029898 | 2.3% |
| `job_onet_specific_occupation_detail` | 1,825,436 | 1825436 | 0.8% |
| `job_start_date` | 7,428,570 | 7428570 | 3.4% |
| `job_summary` | 2,446,412 | 2446412 | 1.1% |
| `job_title` | 9,012,230 | 9012230 | 4.1% |
| `job_title_class` | 6,998,408 | 6998408 | 3.2% |
| `job_title_levels` | 3,794,485 | 3794485 | 1.7% |
| `job_title_role` | 6,998,408 | 6998408 | 3.2% |
| `job_title_sub_role` | 5,869,855 | 5869855 | 2.7% |
| `languages` | 85,658,853 | 85658853 | 39.3% |
| `languages.name` | 85,658,853 | 85658853 | 39.3% |
| `languages.proficiency` | 253,086 | 253086 | 0.1% |
| `last_initial` | 218,071,308 | 218071308 | 100.0% |
| `last_name` | 218,066,033 | 218066033 | 100.0% |
| `linkedin_connections` | 20,420,328 | 20420328 | 9.4% |
| `linkedin_id` | 13,101,053 | 13101053 | 6.0% |
| `linkedin_url` | 13,447,923 | 13447923 | 6.2% |
| `linkedin_username` | 13,447,923 | 13447923 | 6.2% |
| `location_address_line_2` | 29,003,269 | 29003269 | 13.3% |
| `location_continent` | 218,071,308 | 218071308 | 100.0% |
| `location_country` | 218,071,306 | 218071306 | 100.0% |
| `location_geo` | 218,025,231 | 218025231 | 100.0% |
| `location_last_updated` | 204,696,097 | 204696097 | 93.9% |
| `location_locality` | 218,030,918 | 218030918 | 100.0% |
| `location_metro` | 176,766,111 | 176766111 | 81.1% |
| `location_name` | 218,071,308 | 218071308 | 100.0% |
| `location_names` | 218,071,261 | 218071261 | 100.0% |
| `location_postal_code` | 217,111,789 | 217111789 | 99.6% |
| `location_region` | 218,034,568 | 218034568 | 100.0% |
| `location_street_address` | 217,060,392 | 217060392 | 99.5% |
| `middle_initial` | 180,698,567 | 180698567 | 82.9% |
| `middle_name` | 58,953,302 | 58953302 | 27.0% |
| `mobile_phone` | 61,459,539 | 61459539 | 28.2% |
| `name_aliases` | 75,003,361 | 75003361 | 34.4% |
| `num_records` | 218,071,308 | 218071308 | 100.0% |
| `num_sources` | 218,071,308 | 218071308 | 100.0% |
| `personal_emails` | 93,180,050 | 93180050 | 42.7% |
| `phone_numbers` | 214,232,436 | 214232436 | 98.2% |
| `phones` | 214,232,436 | 214232436 | 98.2% |
| `phones.first_seen` | 214,232,436 | 214232436 | 98.2% |
| `phones.last_seen` | 214,232,436 | 214232436 | 98.2% |
| `phones.num_sources` | 214,232,436 | 214232436 | 98.2% |
| `phones.number` | 214,232,436 | 214232436 | 98.2% |
| `possible_birth_dates` | 101,307,113 | 101307113 | 46.5% |
| `possible_emails` | 18,542,134 | 18542134 | 8.5% |
| `possible_emails.address` | 18,542,134 | 18542134 | 8.5% |
| `possible_emails.first_seen` | 18,542,134 | 18542134 | 8.5% |
| `possible_emails.last_seen` | 18,542,134 | 18542134 | 8.5% |
| `possible_emails.md5_hash` | 18,542,134 | 18542134 | 8.5% |
| `possible_emails.num_sources` | 18,542,134 | 18542134 | 8.5% |
| `possible_emails.sha_256_hash` | 18,542,134 | 18542134 | 8.5% |
| `possible_emails.type` | 14,000,572 | 14000572 | 6.4% |
| `possible_location_names` | 184,784,743 | 184784743 | 84.7% |
| `possible_phones` | 14,567,182 | 14567182 | 6.7% |
| `possible_phones.first_seen` | 14,567,182 | 14567182 | 6.7% |
| `possible_phones.last_seen` | 14,567,182 | 14567182 | 6.7% |
| `possible_phones.num_sources` | 14,567,182 | 14567182 | 6.7% |
| `possible_phones.number` | 14,567,182 | 14567182 | 6.7% |
| `possible_profiles` | 11,780,035 | 11780035 | 5.4% |
| `possible_profiles.first_seen` | 11,780,035 | 11780035 | 5.4% |
| `possible_profiles.id` | 8,593,614 | 8593614 | 3.9% |
| `possible_profiles.last_seen` | 11,780,035 | 11780035 | 5.4% |
| `possible_profiles.network` | 11,780,035 | 11780035 | 5.4% |
| `possible_profiles.num_sources` | 11,780,035 | 11780035 | 5.4% |
| `possible_profiles.url` | 11,780,035 | 11780035 | 5.4% |
| `possible_profiles.username` | 11,615,368 | 11615368 | 5.3% |
| `possible_street_addresses` | 4,263,720 | 4263720 | 2.0% |
| `possible_street_addresses.address_line_2` | 758,326 | 758326 | 0.3% |
| `possible_street_addresses.continent` | 4,263,720 | 4263720 | 2.0% |
| `possible_street_addresses.country` | 4,263,720 | 4263720 | 2.0% |
| `possible_street_addresses.first_seen` | 4,263,720 | 4263720 | 2.0% |
| `possible_street_addresses.geo` | 4,263,570 | 4263570 | 2.0% |
| `possible_street_addresses.last_seen` | 4,263,720 | 4263720 | 2.0% |
| `possible_street_addresses.locality` | 4,263,663 | 4263663 | 2.0% |
| `possible_street_addresses.metro` | 3,581,079 | 3581079 | 1.6% |
| `possible_street_addresses.name` | 4,263,720 | 4263720 | 2.0% |
| `possible_street_addresses.num_sources` | 4,263,720 | 4263720 | 2.0% |
| `possible_street_addresses.postal_code` | 4,188,306 | 4188306 | 1.9% |
| `possible_street_addresses.region` | 4,263,702 | 4263702 | 2.0% |
| `possible_street_addresses.street_address` | 4,263,720 | 4263720 | 2.0% |
| `profiles` | 29,228,608 | 29228608 | 13.4% |
| `profiles.first_seen` | 29,228,608 | 29228608 | 13.4% |
| `profiles.id` | 28,900,415 | 28900415 | 13.3% |
| `profiles.last_seen` | 29,228,608 | 29228608 | 13.4% |
| `profiles.network` | 29,228,608 | 29228608 | 13.4% |
| `profiles.num_sources` | 29,228,608 | 29228608 | 13.4% |
| `profiles.url` | 29,228,608 | 29228608 | 13.4% |
| `profiles.username` | 27,381,267 | 27381267 | 12.6% |
| `recommended_personal_email` | 93,174,616 | 93174616 | 42.7% |
| `regions` | 218,071,278 | 218071278 | 100.0% |
| `sex` | 198,085,577 | 198085577 | 90.8% |
| `skills` | 8,398,134 | 8398134 | 3.9% |
| `street_addresses` | 218,071,308 | 218071308 | 100.0% |
| `street_addresses.address_line_2` | 117,905,710 | 117905710 | 54.1% |
| `street_addresses.continent` | 218,071,308 | 218071308 | 100.0% |
| `street_addresses.country` | 218,071,308 | 218071308 | 100.0% |
| `street_addresses.first_seen` | 218,071,308 | 218071308 | 100.0% |
| `street_addresses.geo` | 218,071,051 | 218071051 | 100.0% |
| `street_addresses.last_seen` | 218,071,308 | 218071308 | 100.0% |
| `street_addresses.locality` | 218,071,252 | 218071252 | 100.0% |
| `street_addresses.metro` | 199,340,260 | 199340260 | 91.4% |
| `street_addresses.name` | 218,071,308 | 218071308 | 100.0% |
| `street_addresses.num_sources` | 218,071,308 | 218071308 | 100.0% |
| `street_addresses.postal_code` | 218,069,467 | 218069467 | 100.0% |
| `street_addresses.region` | 218,071,270 | 218071270 | 100.0% |
| `street_addresses.street_address` | 218,071,308 | 218071308 | 100.0% |
| `summary` | 4,004,585 | 4004585 | 1.8% |
| `twitter_url` | 1,289,127 | 1289127 | 0.6% |
| `twitter_username` | 1,289,127 | 1289127 | 0.6% |
| `work_email` | 3,436,163 | 3436163 | 1.6% |

*Stats shown are accurate as of data version 33.1*

Updated 6 days ago

---

Did this page help you?

Yes

No

---
# https://docs.peopledatalabs.com/docs/email-stats

## Description

The Email Slice Dataset is a subset of our full [Person Dataset](/docs/stats) and is composed of all the records containing at least one email address. The table below summarizes some key statistics and fill rates for fields within this dataset. Premium fields are not accessible by default.

**Common Use Cases**  
*Email Enrichment, Sales Lead Generation, Candidate Outreach*

| Field | Count | Numeric | Fill Percentage |
| --- | --- | --- | --- |
| `Total` | 587,237,067 | 587237067 | 100.0% |
| `birth_date` | 69,923,791 | 69923791 | 11.9% |
| `birth_year` | 139,754,201 | 139754201 | 23.8% |
| `certifications` | 28,198,125 | 28198125 | 4.8% |
| `certifications.end_date` | 21,707,447 | 21707447 | 3.7% |
| `certifications.name` | 28,198,125 | 28198125 | 4.8% |
| `certifications.organization` | 27,648,603 | 27648603 | 4.7% |
| `certifications.start_date` | 23,245,933 | 23245933 | 4.0% |
| `countries` | 451,383,797 | 451383797 | 76.9% |
| `education` | 139,502,310 | 139502310 | 23.8% |
| `education.degrees` | 73,178,081 | 73178081 | 12.5% |
| `education.end_date` | 104,496,209 | 104496209 | 17.8% |
| `education.gpa` | 5,550,349 | 5550349 | 0.9% |
| `education.majors` | 84,215,644 | 84215644 | 14.3% |
| `education.minors` | 1,139,705 | 1139705 | 0.2% |
| `education.raw` | 115,596,792 | 115596792 | 19.7% |
| `education.school` | 139,396,841 | 139396841 | 23.7% |
| `education.school.domain` | 120,245,640 | 120245640 | 20.5% |
| `education.school.facebook_url` | 91,361,545 | 91361545 | 15.6% |
| `education.school.id` | 122,595,347 | 122595347 | 20.9% |
| `education.school.linkedin_id` | 122,595,347 | 122595347 | 20.9% |
| `education.school.linkedin_url` | 122,594,754 | 122594754 | 20.9% |
| `education.school.location` | 115,858,973 | 115858973 | 19.7% |
| `education.school.location.continent` | 115,858,973 | 115858973 | 19.7% |
| `education.school.location.country` | 115,858,953 | 115858953 | 19.7% |
| `education.school.location.locality` | 112,811,888 | 112811888 | 19.2% |
| `education.school.location.name` | 115,858,973 | 115858973 | 19.7% |
| `education.school.location.region` | 114,524,640 | 114524640 | 19.5% |
| `education.school.name` | 139,394,575 | 139394575 | 23.7% |
| `education.school.raw` | 138,626,797 | 138626797 | 23.6% |
| `education.school.twitter_url` | 88,953,120 | 88953120 | 15.1% |
| `education.school.type` | 128,827,024 | 128827024 | 21.9% |
| `education.school.website` | 120,245,640 | 120245640 | 20.5% |
| `education.start_date` | 96,249,993 | 96249993 | 16.4% |
| `education.summary` | 32,236,934 | 32236934 | 5.5% |
| `emails` | 587,237,067 | 587237067 | 100.0% |
| `emails.address` | 587,237,067 | 587237067 | 100.0% |
| `emails.first_seen` | 587,237,067 | 587237067 | 100.0% |
| `emails.last_seen` | 587,237,067 | 587237067 | 100.0% |
| `emails.md5_hash` | 587,237,067 | 587237067 | 100.0% |
| `emails.num_sources` | 587,237,067 | 587237067 | 100.0% |
| `emails.sha_256_hash` | 587,237,067 | 587237067 | 100.0% |
| `emails.type` | 520,710,871 | 520710871 | 88.7% |
| `experience` | 251,605,067 | 251605067 | 42.8% |
| `experience.company` | 247,211,296 | 247211296 | 42.1% |
| `experience.company.facebook_url` | 142,506,684 | 142506684 | 24.3% |
| `experience.company.founded` | 166,552,891 | 166552891 | 28.4% |
| `experience.company.id` | 203,549,230 | 203549230 | 34.7% |
| `experience.company.industry` | 197,925,387 | 197925387 | 33.7% |
| `experience.company.industry_v2` | 187,778,113 | 187778113 | 32.0% |
| `experience.company.linkedin_id` | 203,549,230 | 203549230 | 34.7% |
| `experience.company.linkedin_url` | 203,549,230 | 203549230 | 34.7% |
| `experience.company.location` | 198,637,610 | 198637610 | 33.8% |
| `experience.company.location.address_line_2` | 43,456,945 | 43456945 | 7.4% |
| `experience.company.location.continent` | 198,213,686 | 198213686 | 33.8% |
| `experience.company.location.country` | 198,636,437 | 198636437 | 33.8% |
| `experience.company.location.geo` | 189,013,402 | 189013402 | 32.2% |
| `experience.company.location.locality` | 190,392,590 | 190392590 | 32.4% |
| `experience.company.location.metro` | 122,841,694 | 122841694 | 20.9% |
| `experience.company.location.name` | 198,637,610 | 198637610 | 33.8% |
| `experience.company.location.postal_code` | 174,107,580 | 174107580 | 29.6% |
| `experience.company.location.region` | 191,417,913 | 191417913 | 32.6% |
| `experience.company.location.street_address` | 168,800,876 | 168800876 | 28.7% |
| `experience.company.name` | 247,208,882 | 247208882 | 42.1% |
| `experience.company.raw` | 247,193,089 | 247193089 | 42.1% |
| `experience.company.size` | 203,549,230 | 203549230 | 34.7% |
| `experience.company.ticker` | 55,162,843 | 55162843 | 9.4% |
| `experience.company.twitter_url` | 128,625,529 | 128625529 | 21.9% |
| `experience.company.type` | 203,549,230 | 203549230 | 34.7% |
| `experience.company.website` | 193,827,473 | 193827473 | 33.0% |
| `experience.end_date` | 100,725,039 | 100725039 | 17.2% |
| `experience.first_seen` | 251,605,067 | 251605067 | 42.8% |
| `experience.is_primary` | 251,605,067 | 251605067 | 42.8% |
| `experience.last_seen` | 251,605,067 | 251605067 | 42.8% |
| `experience.location_names` | 154,246,629 | 154246629 | 26.3% |
| `experience.num_sources` | 251,605,067 | 251605067 | 42.8% |
| `experience.start_date` | 129,147,034 | 129147034 | 22.0% |
| `experience.summary` | 81,035,799 | 81035799 | 13.8% |
| `experience.title` | 234,481,643 | 234481643 | 39.9% |
| `experience.title.class` | 190,051,598 | 190051598 | 32.4% |
| `experience.title.levels` | 121,264,601 | 121264601 | 20.7% |
| `experience.title.name` | 234,481,643 | 234481643 | 39.9% |
| `experience.title.raw` | 234,481,643 | 234481643 | 39.9% |
| `experience.title.role` | 190,051,598 | 190051598 | 32.4% |
| `experience.title.sub_role` | 169,098,433 | 169098433 | 28.8% |
| `facebook_friends` | 8,022,851 | 8022851 | 1.4% |
| `facebook_id` | 58,343,137 | 58343137 | 9.9% |
| `facebook_url` | 52,176,360 | 52176360 | 8.9% |
| `facebook_username` | 52,176,360 | 52176360 | 8.9% |
| `first_name` | 587,237,067 | 587237067 | 100.0% |
| `first_seen` | 587,237,067 | 587237067 | 100.0% |
| `full_name` | 587,237,067 | 587237067 | 100.0% |
| `github_url` | 2,264,258 | 2264258 | 0.4% |
| `github_username` | 2,264,258 | 2264258 | 0.4% |
| `headline` | 83,657,425 | 83657425 | 14.2% |
| `id` | 587,237,067 | 587237067 | 100.0% |
| `industry` | 167,612,386 | 167612386 | 28.5% |
| `inferred_salary` | 96,344,549 | 96344549 | 16.4% |
| `inferred_years_experience` | 128,573,765 | 128573765 | 21.9% |
| `interests` | 53,552,143 | 53552143 | 9.1% |
| `job_company_12mo_employee_growth_rate` | 113,343,041 | 113343041 | 19.3% |
| `job_company_employee_count` | 113,961,840 | 113961840 | 19.4% |
| `job_company_facebook_url` | 65,466,861 | 65466861 | 11.1% |
| `job_company_founded` | 86,884,816 | 86884816 | 14.8% |
| `job_company_id` | 113,967,621 | 113967621 | 19.4% |
| `job_company_industry` | 110,258,290 | 110258290 | 18.8% |
| `job_company_industry_v2` | 104,251,193 | 104251193 | 17.8% |
| `job_company_inferred_revenue` | 113,961,840 | 113961840 | 19.4% |
| `job_company_linkedin_id` | 113,967,621 | 113967621 | 19.4% |
| `job_company_linkedin_url` | 113,967,621 | 113967621 | 19.4% |
| `job_company_location_address_line_2` | 12,561,115 | 12561115 | 2.1% |
| `job_company_location_continent` | 108,529,822 | 108529822 | 18.5% |
| `job_company_location_country` | 108,903,004 | 108903004 | 18.5% |
| `job_company_location_geo` | 100,840,996 | 100840996 | 17.2% |
| `job_company_location_locality` | 102,374,912 | 102374912 | 17.4% |
| `job_company_location_metro` | 52,366,789 | 52366789 | 8.9% |
| `job_company_location_name` | 108,904,467 | 108904467 | 18.5% |
| `job_company_location_postal_code` | 85,001,567 | 85001567 | 14.5% |
| `job_company_location_region` | 103,596,904 | 103596904 | 17.6% |
| `job_company_location_street_address` | 82,203,209 | 82203209 | 14.0% |
| `job_company_name` | 144,513,919 | 144513919 | 24.6% |
| `job_company_size` | 113,967,621 | 113967621 | 19.4% |
| `job_company_ticker` | 20,263,034 | 20263034 | 3.5% |
| `job_company_total_funding_raised` | 29,417,752 | 29417752 | 5.0% |
| `job_company_twitter_url` | 54,617,944 | 54617944 | 9.3% |
| `job_company_type` | 113,967,621 | 113967621 | 19.4% |
| `job_company_website` | 103,824,308 | 103824308 | 17.7% |
| `job_history` | 251,778,850 | 251778850 | 42.9% |
| `job_history.company_id` | 206,507,242 | 206507242 | 35.2% |
| `job_history.company_name` | 247,772,300 | 247772300 | 42.2% |
| `job_history.first_seen` | 251,778,850 | 251778850 | 42.9% |
| `job_history.last_seen` | 251,778,850 | 251778850 | 42.9% |
| `job_history.num_sources` | 251,778,850 | 251778850 | 42.9% |
| `job_history.title` | 234,726,079 | 234726079 | 40.0% |
| `job_last_changed` | 147,624,787 | 147624787 | 25.1% |
| `job_last_verified` | 147,624,787 | 147624787 | 25.1% |
| `job_onet_broad_occupation` | 72,775,447 | 72775447 | 12.4% |
| `job_onet_code` | 72,775,447 | 72775447 | 12.4% |
| `job_onet_major_group` | 72,775,447 | 72775447 | 12.4% |
| `job_onet_minor_group` | 72,775,447 | 72775447 | 12.4% |
| `job_onet_specific_occupation` | 72,775,447 | 72775447 | 12.4% |
| `job_onet_specific_occupation_detail` | 28,289,887 | 28289887 | 4.8% |
| `job_start_date` | 102,063,736 | 102063736 | 17.4% |
| `job_summary` | 32,932,079 | 32932079 | 5.6% |
| `job_title` | 146,250,715 | 146250715 | 24.9% |
| `job_title_class` | 103,036,177 | 103036177 | 17.5% |
| `job_title_levels` | 53,670,435 | 53670435 | 9.1% |
| `job_title_role` | 103,036,177 | 103036177 | 17.5% |
| `job_title_sub_role` | 83,369,241 | 83369241 | 14.2% |
| `languages` | 108,725,790 | 108725790 | 18.5% |
| `languages.name` | 108,725,790 | 108725790 | 18.5% |
| `languages.proficiency` | 8,350,834 | 8350834 | 1.4% |
| `last_initial` | 587,237,067 | 587237067 | 100.0% |
| `last_name` | 586,392,133 | 586392133 | 99.9% |
| `linkedin_connections` | 179,045,627 | 179045627 | 30.5% |
| `linkedin_id` | 177,836,300 | 177836300 | 30.3% |
| `linkedin_url` | 184,486,785 | 184486785 | 31.4% |
| `linkedin_username` | 184,486,785 | 184486785 | 31.4% |
| `location_address_line_2` | 38,383,760 | 38383760 | 6.5% |
| `location_continent` | 451,385,535 | 451385535 | 76.9% |
| `location_country` | 451,370,324 | 451370324 | 76.9% |
| `location_geo` | 406,273,315 | 406273315 | 69.2% |
| `location_last_updated` | 274,843,872 | 274843872 | 46.8% |
| `location_locality` | 407,543,946 | 407543946 | 69.4% |
| `location_metro` | 265,750,551 | 265750551 | 45.3% |
| `location_name` | 451,385,535 | 451385535 | 76.9% |
| `location_names` | 409,542,778 | 409542778 | 69.7% |
| `location_postal_code` | 243,488,044 | 243488044 | 41.5% |
| `location_region` | 416,223,366 | 416223366 | 70.9% |
| `location_street_address` | 225,059,436 | 225059436 | 38.3% |
| `middle_initial` | 160,094,645 | 160094645 | 27.3% |
| `middle_name` | 89,428,910 | 89428910 | 15.2% |
| `mobile_phone` | 101,029,412 | 101029412 | 17.2% |
| `name_aliases` | 55,046,563 | 55046563 | 9.4% |
| `num_records` | 587,237,067 | 587237067 | 100.0% |
| `num_sources` | 587,237,067 | 587237067 | 100.0% |
| `personal_emails` | 393,604,239 | 393604239 | 67.0% |
| `phone_numbers` | 219,678,757 | 219678757 | 37.4% |
| `phones` | 219,678,757 | 219678757 | 37.4% |
| `phones.first_seen` | 219,678,757 | 219678757 | 37.4% |
| `phones.last_seen` | 219,678,757 | 219678757 | 37.4% |
| `phones.num_sources` | 219,678,757 | 219678757 | 37.4% |
| `phones.number` | 219,678,757 | 219678757 | 37.4% |
| `possible_birth_dates` | 67,953,973 | 67953973 | 11.6% |
| `possible_emails` | 78,294,704 | 78294704 | 13.3% |
| `possible_emails.address` | 78,294,704 | 78294704 | 13.3% |
| `possible_emails.first_seen` | 78,294,704 | 78294704 | 13.3% |
| `possible_emails.last_seen` | 78,294,704 | 78294704 | 13.3% |
| `possible_emails.md5_hash` | 78,294,704 | 78294704 | 13.3% |
| `possible_emails.num_sources` | 78,294,704 | 78294704 | 13.3% |
| `possible_emails.sha_256_hash` | 78,294,704 | 78294704 | 13.3% |
| `possible_emails.type` | 68,419,885 | 68419885 | 11.7% |
| `possible_location_names` | 315,977,882 | 315977882 | 53.8% |
| `possible_phones` | 34,769,970 | 34769970 | 5.9% |
| `possible_phones.first_seen` | 34,769,970 | 34769970 | 5.9% |
| `possible_phones.last_seen` | 34,769,970 | 34769970 | 5.9% |
| `possible_phones.num_sources` | 34,769,970 | 34769970 | 5.9% |
| `possible_phones.number` | 34,769,970 | 34769970 | 5.9% |
| `possible_profiles` | 28,420,361 | 28420361 | 4.8% |
| `possible_profiles.first_seen` | 28,420,361 | 28420361 | 4.8% |
| `possible_profiles.id` | 12,473,280 | 12473280 | 2.1% |
| `possible_profiles.last_seen` | 28,420,361 | 28420361 | 4.8% |
| `possible_profiles.network` | 28,420,361 | 28420361 | 4.8% |
| `possible_profiles.num_sources` | 28,420,361 | 28420361 | 4.8% |
| `possible_profiles.url` | 28,420,361 | 28420361 | 4.8% |
| `possible_profiles.username` | 27,731,437 | 27731437 | 4.7% |
| `possible_street_addresses` | 37,910,071 | 37910071 | 6.5% |
| `possible_street_addresses.address_line_2` | 6,984,613 | 6984613 | 1.2% |
| `possible_street_addresses.continent` | 37,910,071 | 37910071 | 6.5% |
| `possible_street_addresses.country` | 37,910,071 | 37910071 | 6.5% |
| `possible_street_addresses.first_seen` | 37,910,071 | 37910071 | 6.5% |
| `possible_street_addresses.geo` | 37,908,842 | 37908842 | 6.5% |
| `possible_street_addresses.last_seen` | 37,910,071 | 37910071 | 6.5% |
| `possible_street_addresses.locality` | 37,909,555 | 37909555 | 6.5% |
| `possible_street_addresses.metro` | 32,125,624 | 32125624 | 5.5% |
| `possible_street_addresses.name` | 37,910,071 | 37910071 | 6.5% |
| `possible_street_addresses.num_sources` | 37,910,071 | 37910071 | 6.5% |
| `possible_street_addresses.postal_code` | 37,685,058 | 37685058 | 6.4% |
| `possible_street_addresses.region` | 37,909,708 | 37909708 | 6.5% |
| `possible_street_addresses.street_address` | 37,910,071 | 37910071 | 6.5% |
| `profiles` | 238,140,860 | 238140860 | 40.6% |
| `profiles.first_seen` | 238,140,860 | 238140860 | 40.6% |
| `profiles.id` | 223,556,851 | 223556851 | 38.1% |
| `profiles.last_seen` | 238,140,860 | 238140860 | 40.6% |
| `profiles.network` | 238,140,860 | 238140860 | 40.6% |
| `profiles.num_sources` | 238,140,860 | 238140860 | 40.6% |
| `profiles.url` | 238,140,860 | 238140860 | 40.6% |
| `profiles.username` | 232,452,149 | 232452149 | 39.6% |
| `recommended_personal_email` | 393,603,151 | 393603151 | 67.0% |
| `regions` | 418,974,847 | 418974847 | 71.3% |
| `sex` | 471,887,792 | 471887792 | 80.4% |
| `skills` | 83,779,996 | 83779996 | 14.3% |
| `street_addresses` | 232,744,821 | 232744821 | 39.6% |
| `street_addresses.address_line_2` | 79,179,703 | 79179703 | 13.5% |
| `street_addresses.continent` | 232,744,821 | 232744821 | 39.6% |
| `street_addresses.country` | 232,744,821 | 232744821 | 39.6% |
| `street_addresses.first_seen` | 232,744,821 | 232744821 | 39.6% |
| `street_addresses.geo` | 232,259,312 | 232259312 | 39.6% |
| `street_addresses.last_seen` | 232,744,821 | 232744821 | 39.6% |
| `street_addresses.locality` | 232,322,871 | 232322871 | 39.6% |
| `street_addresses.metro` | 200,240,730 | 200240730 | 34.1% |
| `street_addresses.name` | 232,744,821 | 232744821 | 39.6% |
| `street_addresses.num_sources` | 232,744,821 | 232744821 | 39.6% |
| `street_addresses.postal_code` | 231,326,282 | 231326282 | 39.4% |
| `street_addresses.region` | 232,367,375 | 232367375 | 39.6% |
| `street_addresses.street_address` | 232,744,821 | 232744821 | 39.6% |
| `summary` | 62,880,993 | 62880993 | 10.7% |
| `twitter_url` | 10,228,763 | 10228763 | 1.7% |
| `twitter_username` | 10,228,763 | 10228763 | 1.7% |
| `work_email` | 63,485,224 | 63485224 | 10.8% |

*Stats shown are accurate as of data version 33.1*

Updated 6 days ago

---

Did this page help you?

Yes

No

---
# https://docs.peopledatalabs.com/docs/data-delivery-using-s3

Our preferred mode of delivery is through Amazon's AWS S3 service.

To set up this delivery, do the following:

1. Sign into the AWS S3 console.
2. Create a bucket for deliveries (for example, `s3://YOURCOMPANY-data-deliveries`).
   1. If you are using an existing bucket, ensure that [Requester Pays](https://docs.aws.amazon.com/AmazonS3/latest/userguide/RequesterPaysExamples.html) is disabled.
3. Modify the bucket policy in the **Permissions** tab.
4. Paste the following into your permissions and replace `{{your bucket name}}` with your new bucket name (for example, `YOURCOMPANY-data-deliveries`) and click **Save**.

JSON

```
{
    "Version": "2012-10-17",
    "Statement": [
        {
            "Sid": "People Data Labs Bucket Permissions",
            "Effect": "Allow",
            "Principal": {
                "AWS": "arn:aws:iam::556708831556:role/pdl-customer-deliveries"
            },
            "Action": [
                "s3:ListBucket",
                "s3:GetObject",
                "s3:PutObject",
                "s3:ListBucketMultipartUploads",
                "s3:ListMultipartUploadParts",
                "s3:AbortMultipartUpload",
                "s3:DeleteObject",
                "s3:GetBucketAcl",
                "s3:GetBucketPublicAccessBlock",
                "s3:GetBucketPolicyStatus"
            ],
            "Resource": [
                "arn:aws:s3:::{{your bucket name}}",
                "arn:aws:s3:::{{your bucket name}}/*"
            ]
        }
    ]
}
```

5. Email [success@peopledatalabs.com](mailto:success@peopledatalabs.com?Subject=S3%20YOURCOMPANY) with your bucket URL.

### Note on S3 Saving

When you click **Save** on the **Bucket Policy** page, AWS may **not** provide a **"Saved"** notification message and may also display the following:

This is a standard AWS message but for some it can be confusing. To confirm the new policy above is saved, refresh the page and check if the policy is still there.

### Note on Data Delivery & IAM

Per best practices, we do **not** support the use of IAM users for data delivery. IAM users utilize Access Keys / Secret Access Keys and would need to be rotated regularly. The best practice is to use **roles** with the policy described above, which allows our PDL role to deliver the data to you.

Updated 4 months ago

---

Did this page help you?

Yes

No

---
# https://docs.peopledatalabs.com/docs/rust-sdk

# The People Data Labs Rust Helper Library

The People Data Labs Rust Library makes it easy to interact with our APIs from your Rust application. You can find the [most recent version of the library on Crates.io](https://crates.io/crates/peopledatalabs).

## How To Install the Library

This library is available as a Rust Package, and you can install it like this:

Shell

```
cargo add peopledatalabs
```

## Using the Library

Make sure that you sign up for a [free PDL API key](https://www.peopledatalabs.com/signup) if you don't already have one.

Rust

```
let api_key = std::env::var("PDL_API_KEY").unwrap();
let client = PDL::new(&api_key);

let mut person_params = PersonParams::default();
person_params.profile = Some(vec!["linkedin.com/in/seanthorne".to_string()]);

let mut enrich_params = EnrichPersonParams::default();
enrich_params.person_params = person_params.clone();

let results = client.person.enrich(enrich_params);

println!("{:#?}", results);
```

## More Information, Pull Requests, Feature Suggestions and Bug Reports

We've open-sourced the library, which is available on GitHub. Go there to view more information. You can also submit pull requests, feature suggestions and bug reports.

[github.com

GitHub - peopledatalabs/peopledatalabs-rust: A Rust client for the People Data Labs API](https://github.com/peopledatalabs/peopledatalabs-rust)

Updated 4 months ago

---

Did this page help you?

Yes

No

---
# https://docs.peopledatalabs.com/docs/go-sdk

# The People Data Labs Go Helper Library

The People Data Labs Go Helper Library makes it easy to interact with our APIs from your Go application. You can find the [most recent version of the library on Go Packages](https://pkg.go.dev/github.com/peopledatalabs/peopledatalabs-go).

## How To Install the Library

This library is available as a Go package, and you can install it like this:

Shell

```
go get github.com/peopledatalabs/peopledatalabs-go
```

## Using the Library

Make sure that you sign up for a [free PDL API key](https://www.peopledatalabs.com/signup) if you don't already have one.

Go

```
package main

import (
    "fmt"
    "context"
)

// See https://github.com/peopledatalabs/peopledatalabs-go
import (
    pdl "github.com/peopledatalabs/peopledatalabs-go"
    pdlmodel "github.com/peopledatalabs/peopledatalabs-go/model"
)

func main() {
    // Set your API key
    apiKey := "API_KEY"
    // Set API key as environmental variable
    // apiKey := os.Getenv("API_KEY")

    // Create a client, specifying your API key
    client := pdl.New(apiKey)
    
    // Create a parameters JSON object
    params := pdlmodel.EnrichPersonParams {
        PersonParams: pdlmodel.PersonParams {
            Profile: []string{"linkedin.com/in/seanthorne"},
        },
    }

    // Pass the parameters object to the Person Enrichment API
    result, err := client.Person.Enrich(context.Background(), params)

    // Print the API response
    if err == nil {
        fmt.Printf("Status: %d, FullName: %s\n", result.Status, result.Data.FullName)
    }  
}
```

## More Information, Pull Requests, Feature Suggestions and Bug Reports

We've open-sourced the library, which is available on GitHub. Go there to view more information. You can also submit pull requests, feature suggestions and bug reports.

[github.com

GitHub - peopledatalabs/peopledatalabs-go: A Go client for the People Data Labs API](https://github.com/peopledatalabs/peopledatalabs-go)

Updated 4 months ago

---

Did this page help you?

Yes

No

---
# https://docs.peopledatalabs.com/docs/examples-skill-enrichment-api

> â—ï¸
>
> ### The Skill Enrichment API is now fully removed
>
> This endpoint was removed in our April 2025 (v30.0) Release and is no longer available. This page is retained for historical documentation purposes.
>
> For more information, please see our [April 2025 Release Notes (v30.0)](/changelog/april-2025-release-notes-v300).

We've provided code samples in Python, cURL, Ruby, Go and JavaScript. If you aren't comfortable working in any of these languages, feel free to use this [handy tool](https://curl.trillworks.com/) to convert code from cURL to the language of your choice.

> ðŸ’¡
>
> ### We want your feedback!
>
> Do you see a bug? Is there an example you'd like to see that's not listed here?
>
> Head over to the public roadmap and submit a [bug ticket](https://peopledatalabs.canny.io/bugs) or a [feature request](https://peopledatalabs.canny.io/feature-requests) and receive automatic notifications as your bug is resolved or your request is implemented.

## Basic Usage

*"I want to look up information for a skill that I have."*

Python3 SDKcURLJavaScriptRubyGoPython3

```
# See https://github.com/peopledatalabs/peopledatalabs-python
from peopledatalabs import PDLPY

# Create a client, specifying your API key
CLIENT = PDLPY(
    api_key="YOUR API KEY",
)

# Create a parameters JSON object
QUERY_STRING = {"skill": "pyspark"}

# Pass the parameters object to the Skill Enrichment API
response = CLIENT.skill(**QUERY_STRING)

# Print the API response
print(response.text)
```

```
curl -X GET -G \
  'https://api.peopledatalabs.com/v5/skill/enrich' \
  -H 'X-Api-Key: YOUR API KEY' \
  --data-urlencode 'skill=pyspark'
```

```
// See https://github.com/peopledatalabs/peopledatalabs-js
import PDLJS from 'peopledatalabs';

// Create a client, specifying your API key
const PDLJSClient = new PDLJS({ apiKey: "YOUR API KEY" });

// Create a parameters JSON object
const queryString = {skill: "pyspark"}

// Pass the parameters object to the Skill API
PDLJSClient.skill(queryString).then((data) => {
    // Print the API response
    console.log(data);
}).catch((error) => {
    console.log(error);
});
```

```
# See https://github.com/peopledatalabs/peopledatalabs-ruby
require 'peopledatalabs'

# Set your API key
Peopledatalabs.api_key = 'YOUR API KEY'

# Pass parameters to the Skill API
response = Peopledatalabs::Skill.retrieve("skill": "pyspark")

# Print the API response
puts response
```

```
package main

import (
    "fmt"
    "context"
)

// See https://github.com/peopledatalabs/peopledatalabs-go
import (
    pdl "github.com/peopledatalabs/peopledatalabs-go"
    pdlmodel "github.com/peopledatalabs/peopledatalabs-go/model"
)

func main() {
    // Set your API key
    apiKey := "YOUR API KEY"
    // Set API key as environmental variable
    // apiKey := os.Getenv("API_KEY")

    // Create a client, specifying your API key
    client := pdl.New(apiKey)
    
    // Create a parameters JSON object
    queryString := pdlmodel.SkillBaseParams{Skill: "pyspark"}
    
    params := pdlmodel.SkillParams{
        SkillBaseParams: queryString,
    }
    
    // Pass the parameters object to the Skill API
    response, err := client.Skill(context.Background(), params)
    // Check for successful response
    if err == nil {
        // Print the API response
        fmt.Println(response)
    }  
}
```

```
import requests

# Set your API key
API_KEY = "YOUR API KEY"

# Set the Skill Enrichment API URL
PDL_URL = "https://api.peopledatalabs.com/v5/skill/enrich"

# Create a parameters JSON object
QUERY_STRING = {"skill": "pyspark"}

# Set headers
HEADERS = {
    'accept': "application/json",
    'content-type': "application/json",
    'x-api-key': API_KEY
}

# Pass the parameters object to the Skill Enrichment API
response = requests.request("GET", PDL_URL, headers=HEADERS, params=QUERY_STRING)

# Print the API response
print(response.text)
```

## Person Searching Using Skill Data

*"I want to search for people with similar skills."*

Python3 SDK (Elasticsearch)Python3 SDK (SQL)JavaScript (Elasticsearch)JavaScript (SQL)Ruby (Elasticsearch)Ruby (SQL)Go (Elasticsearch)Go (SQL)Python3 (Elasticsearch)Python3 (SQL)

```
import json

# See https://github.com/peopledatalabs/peopledatalabs-python
from peopledatalabs import PDLPY

# Create a client, specifying your API key
CLIENT = PDLPY(
    api_key="YOUR API KEY",
)

# Set the maximum number of people to search
MAX_NUM_PEOPLE = 100

# The skill you want to enrich
SKILL = "ai"
# Create a parameters JSON object
QUERY_STRING = {"skill": SKILL}

# Pass the parameters object to the Skill Enrichment API
response = CLIENT.skill(**QUERY_STRING)

# Check for successful response
if response.status_code == 200:
  # Store enriched skill
  enriched_skill = response.json()
  # Build list of skills
  skills = enriched_skill["data"]["similar_skills"]
  skills.insert(0, SKILL)
else:
  enriched_skill = {}
  print(f"Skill Enrichment Error for [{SKILL}]: {response.text}")
                                                      
# Person Search matches
employee_matches = {}

# Check for enriched skill
if enriched_skill:
  # Create an Elasticsearch query
  ES_QUERY = {
  	"query": {
    	"bool": {
        	"must": [
            	{"term": {"location_region": "utah"}},
            	{"terms": {"skills": skills}},
      		]
    	}
  	}
  }

  # Create a parameters JSON object
  PARAMS = {
  	'query': ES_QUERY,
  	'size': MAX_NUM_PEOPLE
  }
  
  # Pass the parameters object to the Person Search API
  response = CLIENT.person.search(**PARAMS).json()

  # Check for successful response
  if response["status"] == 200:
    # Store matches
  	employee_matches = response["data"]
  else:
  	employee_matches = {}
  	print(f"Person Search Error for [{SKILL}]: {response}")

  print(f"Found {len(employee_matches)} employee profiles for {SKILL}.")
```

```
import json

# See https://github.com/peopledatalabs/peopledatalabs-python
from peopledatalabs import PDLPY

# Create a client, specifying your API key
CLIENT = PDLPY(
    api_key="YOUR API KEY",
)

# Set the maximum number of people to search
MAX_NUM_PEOPLE = 100

# The skill you want to enrich
SKILL = "ai"
# Create a parameters JSON object
QUERY_STRING = {"skill": SKILL}

# Pass the parameters object to the Skill Enrichment API
response = CLIENT.skill(**QUERY_STRING)

# Check for successful response
if response.status_code == 200:
  # Store enriched skill
  enriched_skill = response.json()
  # Build list of skills
  skills = enriched_skill["data"]["similar_skills"]
  skills.insert(0, SKILL)
  skills_string_rep = ", ".join(
    (f"'{skl}'" for skl in skills)
  )
else:
  enriched_skill = {}
  print(f"Skill Enrichment Error for [{SKILL}]: {response.text}")
                                                      
# Person Search matches
employee_matches = {}

# Check for enriched skill
if enriched_skill:
  # Create an SQL query
  SQL_QUERY = f"""
  SELECT * FROM person
  WHERE location_region='utah'
  AND skills IN ({skills_string_rep});
  """

  # Create a parameters JSON object
  PARAMS = {
  	'sql': SQL_QUERY,
  	'size': MAX_NUM_PEOPLE
  }
  
  # Pass the parameters object to the Person Search API
  response = CLIENT.person.search(**PARAMS).json()

  # Check for successful response
  if response["status"] == 200:
    # Store matches
  	employee_matches = response["data"]
  else:
  	employee_matches = {}
  	print(f"Person Search Error for [{SKILL}]: {response}")

  print(f"Found {len(employee_matches)} employee profiles for {SKILL}.")
```

```
// See https://github.com/peopledatalabs/peopledatalabs-js
import PDLJS from 'peopledatalabs';

// Create a client, specifying your API key
const PDLJSClient = new PDLJS({ apiKey: "YOUR API KEY" });

// Set the maximum number of people to search
const maxNumPeople = 100;

// The skill you want to enrich
const skill = "ai";
// Create a parameters JSON object
const queryString = {skill: skill};

// Pass the parameters object to the Skill API
PDLJSClient.skill(queryString).then((data) => {
    // Store enriched skill
    var enrichedSkill = data;
    // Build list of skills
    var skills = enrichedSkill["data"]["similar_skills"];
    skills.splice(0, 0, skill);
    
    // Create an Elasticsearch query
    const esQuery = {
        "query": {
            "bool": {
                "must": [
                    {"term": {"location_region": "utah"}},
                    {"terms": {"skills": skills}}
      		    ]
    	   }
        }
    }

    // Create a parameters JSON object
    const params = {
        searchQuery: esQuery,
        size: maxNumPeople
    }

    // Pass the parameters object to the Person Search API
    PDLJSClient.person.search.elastic(params).then((data) => {
        // Store matches
        var employeeMatches = data["data"];       
        console.log(`Found ${employeeMatches.length} employee profiles for ${skill}.`); 
    }).catch((error) => {
        console.log(`Person Search Error for [${skill}]:`, error);
    });
       
}).catch((error) => {
    console.log(`Skill Enrichment Error for [${skill}]:`, error);
});
```

```
// See https://github.com/peopledatalabs/peopledatalabs-js
import PDLJS from 'peopledatalabs';

// Create a client, specifying your API key
const PDLJSClient = new PDLJS({ apiKey: "YOUR API KEY" });

// Set the maximum number of people to search
const maxNumPeople = 100;

// The skill you want to enrich
const skill = "ai";
// Create a parameters JSON object
const queryString = {skill: skill};

// Pass the parameters object to the Skill API
PDLJSClient.skill(queryString).then((data) => {
    // Store enriched skill
    var enrichedSkill = data;
    // Build list of skills
    var skills = enrichedSkill["data"]["similar_skills"];
    skills.splice(0, 0, skill);
    var skillsStringRep = "'" + skills.join("', '") + "'";
    
    // Create an SQL query
    const sqlQuery = `SELECT * FROM person 
                        WHERE location_region='utah'
                        AND skills IN (${skillsStringRep});`

    // Create a parameters JSON object
    const params = {
        searchQuery: sqlQuery,
        size: maxNumPeople
    }

    // Pass the parameters object to the Person Search API
    PDLJSClient.person.search.sql(params).then((data) => {
        // Store matches
        var employeeMatches = data["data"];       
        console.log(`Found ${employeeMatches.length} employee profiles for ${skill}.`); 
    }).catch((error) => {
        console.log(`Person Search Error for [${skill}]:`, error);
    });
       
}).catch((error) => {
    console.log(`Skill Enrichment Error for [${skill}]:`, error);
});
```

```
# See https://github.com/peopledatalabs/peopledatalabs-ruby
require 'peopledatalabs'

# Set your API key
Peopledatalabs.api_key = 'YOUR API KEY'

# Set the maximum number of people to search
MAX_NUM_PEOPLE = 100

# The skill you want to enrich
SKILL = "ai"

# Pass parameters to the Skill API
response = Peopledatalabs::Skill.retrieve("skill":SKILL)

# Check for successful response
if response['status'] == 200
  # Store enriched skill
  enriched_skill = response
  # Build list of skills
  skills = enriched_skill['data']['similar_skills']
  skills.insert(0, SKILL)
else
  enriched_skill = {}
  puts "Skill Enrichment Error for [#{SKILL}]: #{response}"
end

# Person Search matches
employee_matches = {}

# Check for enriched job title
if !enriched_skill.nil?
  # Create an Elasticsearch query
  ES_QUERY = {
  	"query": {
    	"bool": {
        	"must": [
            	{"term": {"location_region": "utah"}},
            	{"terms": {"skills": skills}}
      		]
    	}
  	}
  }

  # Pass parameters to the Person Search API
  response = Peopledatalabs::Search.person(searchType: 'elastic', query: ES_QUERY, size: MAX_NUM_PEOPLE)

  # Check for successful response
  if response['status'] == 200
    # Store matches
  	employee_matches = response['data']
  else
  	employee_matches = {}
  	puts "Person Search Error for [#{SKILL}]: #{response}"
  end

  puts "Found #{employee_matches.length()} employee profiles for #{SKILL}."
end
```

```
# See https://github.com/peopledatalabs/peopledatalabs-ruby
require 'peopledatalabs'

# Set your API key
Peopledatalabs.api_key = 'YOUR API KEY'

# Set the maximum number of people to search
MAX_NUM_PEOPLE = 100

# The skill you want to enrich
SKILL = "ai"

# Pass parameters to the Skill API
response = Peopledatalabs::Skill.retrieve("skill":SKILL)

# Check for successful response
if response['status'] == 200
  # Store enriched skill
  enriched_skill = response
  # Build list of skills
  skills = enriched_skill['data']['similar_skills']
  skills.insert(0, SKILL)
  skills_string_rep = "'" + skills.join("','") + "'"
else
  enriched_skill = {}
  puts "Skill Enrichment Error for [#{SKILL}]: #{response}"
end

# Person Search matches
employee_matches = {}

# Check for enriched job title
if !enriched_skill.nil?
  # Create an SQL query
  SQL_QUERY = """
    SELECT * FROM person
    WHERE location_region='utah'
    AND skills IN (#{skills_string_rep});
   """

  # Pass parameters to the Person Search API
  response = Peopledatalabs::Search.person(searchType: 'sql', query: SQL_QUERY, size: MAX_NUM_PEOPLE)

  # Check for successful response
  if response['status'] == 200
    # Store matches
  	employee_matches = response['data']
  else
  	employee_matches = {}
  	puts "Person Search Error for [#{SKILL}]: #{response}"
  end

  puts "Found #{employee_matches.length()} employee profiles for #{SKILL}."
end
```

```
package main

import (
    "fmt"
    "encoding/json"
    "reflect"
    "context"
)

// See https://github.com/peopledatalabs/peopledatalabs-go
import (
    pdl "github.com/peopledatalabs/peopledatalabs-go"
    pdlmodel "github.com/peopledatalabs/peopledatalabs-go/model"
)

func main() {
    // Set your API key
    apiKey := "YOUR API KEY"
    // Set API key as environmental variable
    // apiKey := os.Getenv("API_KEY")

    // Create a client, specifying your API key
    client := pdl.New(apiKey)
    
    // Set the maximum number of people to search
    const maxNumPeople = 100
    
    // The skill you want to enrich
    skill := "ai"
    
    var skills []string
    
    // Create a parameters JSON object
    queryString := pdlmodel.SkillBaseParams{Skill: skill}
    
    params := pdlmodel.SkillParams{
        SkillBaseParams: queryString,
    }
    
    // Pass the parameters object to the Skill API
    response, err := client.Skill(context.Background(), params)
    
    var enrichedSkill map[string][]string

    // Check for successful response
    if err == nil {
        // Convert the API response to JSON
        jsonResponse, jsonErr := json.Marshal(response.Data)
        if jsonErr == nil {
            // Store enriched skill
            json.Unmarshal(jsonResponse, &enrichedSkill)
            // Build list of skills
            skills = enrichedSkill["similar_skills"]
            skills = append(skills, skill)
        }
    } else {
        fmt.Printf("Skill Enrichment Error for [%s]:\n\t", skill)
        fmt.Println(err)
   	}
    
    // Person Search matches
    var employeeMatches []pdlmodel.Person

    // Check for enriched job title
    if !reflect.DeepEqual(enrichedSkill, pdlmodel.SkillResponse{}) {
        // Create an Elasticsearch query
        elasticSearchQuery := map[string]interface{} {
            "query": map[string]interface{} {
                "bool": map[string]interface{} {
                    "must": []map[string]interface{} {
                        {"term": map[string]interface{}{"location_region": "utah"}},
                        {"terms": map[string]interface{}{"skills": skills}},
                   },
                },
            },
        }
    
        // Create a parameters JSON object
        params := pdlmodel.SearchParams {
            BaseParams: pdlmodel.BaseParams {
                Size: maxNumPeople,
            },
            SearchBaseParams: pdlmodel.SearchBaseParams {
                Query: elasticSearchQuery,
            },
        }

        // Pass the parameters object to the Person Search API
        response, err := client.Person.Search(context.Background(), params)

        // Check for successful response
        if err == nil {
            // Store matches
            employeeMatches = response.Data
            fmt.Printf("Found %d employee profiles for %s.\n", len(employeeMatches), skill)
        } else {
            fmt.Printf("Person Search Error for [%s]:\n\t", skill)
            fmt.Println(err)
        }
    }
}
```

```
package main

import (
    "fmt"
    "encoding/json"
    "strings"
    "reflect"
    "context"
)

// See https://github.com/peopledatalabs/peopledatalabs-go
import (
    pdl "github.com/peopledatalabs/peopledatalabs-go"
    pdlmodel "github.com/peopledatalabs/peopledatalabs-go/model"
)

func main() {
    // Set your API key
    apiKey := "YOUR API KEY"
    // Set API key as environmental variable
    // apiKey := os.Getenv("API_KEY")

    // Create a client, specifying your API key
    client := pdl.New(apiKey)
    
    // Set the maximum number of people to search
    const maxNumPeople = 100
    
    // The skill you want to enrich
    skill := "ai"
    
    var skills []string
    
    // Create a parameters JSON object
    queryString := pdlmodel.SkillBaseParams{Skill: skill}
    
    params := pdlmodel.SkillParams{
        SkillBaseParams: queryString,
    }
    
    // Pass the parameters object to the Skill API
    response, err := client.Skill(context.Background(), params)
    
    var enrichedSkill map[string][]string
    var skillsStringRep string

    // Check for successful response
    if err == nil {
        // Convert the API response to JSON
        jsonResponse, jsonErr := json.Marshal(response.Data)
        if jsonErr == nil {
            // Store enriched skill
            json.Unmarshal(jsonResponse, &enrichedSkill)
            // Build list of skills
            skills = enrichedSkill["similar_skills"]
            skills = append(skills, skill)
            skillsStringRep = "'" + strings.Join(skills[:], "','") + "'"
        }
    } else {
        fmt.Printf("Skill Enrichment Error for [%s]:\n\t", skill)
        fmt.Println(err)
   	}
    
    // Person Search matches
    var employeeMatches []pdlmodel.Person

    // Check for enriched job title
    if !reflect.DeepEqual(enrichedSkill, pdlmodel.SkillResponse{}) {
        // Create an SQL query
        sqlQuery := "SELECT * FROM person" +
                    " WHERE location_region='utah'" +
                    " AND skills IN (" + skillsStringRep + ");"
   
        // Create a parameters JSON object
        params := pdlmodel.SearchParams {
            BaseParams: pdlmodel.BaseParams {
                Size: maxNumPeople,
            },
            SearchBaseParams: pdlmodel.SearchBaseParams {
                SQL: sqlQuery,
            },
        }

        // Pass the parameters object to the Person Search API
        response, err := client.Person.Search(context.Background(), params)

        // Check for successful response
        if err == nil {
            // Store matches
            employeeMatches = response.Data
            fmt.Printf("Found %d employee profiles for %s.\n", len(employeeMatches), skill)
        } else {
            fmt.Printf("Person Search Error for [%s]:\n\t", skill)
            fmt.Println(err)
        }
    }
}
```

```
import requests, json

# Set your API key
API_KEY = "YOUR API KEY"

# Set the Skill Enrichment API URL
PDL_SKILL_ENRICH_URL = "https://api.peopledatalabs.com/v5/skill/enrich"
# Set the Person Search API URL
PDL_PERSON_SEARCH_URL = "https://api.peopledatalabs.com/v5/person/search"

# Set the maximum number of people to search
MAX_NUM_PEOPLE = 100

# The skill you want to enrich
SKILL = "ai"
# Create a parameters JSON object
QUERY_STRING = {"skill": SKILL}

# Set headers
HEADERS = {
  'accept': "application/json",
  'content-type': "application/json",
  'x-api-key': API_KEY
}

# Pass the parameters object to the Skill Enrichment API
response = requests.request("GET", PDL_SKILL_ENRICH_URL, 
                            headers=HEADERS, params=QUERY_STRING)

# Check for successful response
if response.status_code == 200:
  # Store enriched skill
  enriched_skill = response.json()
  # Build list of skills
  skills = enriched_skill["data"]["similar_skills"]
  skills.insert(0, SKILL)
else:
  enriched_job_title = {}
  print(f"Skill Enrichment Error for [{SKILL}]: {response.text}")
                                                      
# Person Search matches
employee_matches = {}

# Check for enriched skill
if enriched_skill:
  # Create an Elasticsearch query
  ES_QUERY = {
  	"query": {
    	"bool": {
        	"must": [
            	{"term": {"location_region": "utah"}},
            	{"terms": {"skills": skills}},
      		]
    	}
  	}
  }

  # Create a parameters JSON object
  PARAMS = {
  	'query': json.dumps(ES_QUERY),
  	'size': MAX_NUM_PEOPLE
  }

  # Pass the parameters object to the Person Search API
  response = requests.get(PDL_PERSON_SEARCH_URL, headers=HEADERS, params=PARAMS)

  # Check for successful response
  if response.status_code == 200:
    # Store matches
  	employee_matches = response.json()["data"]
  else:
  	employee_matches = {}
  	print(f"Person Search Error for [{SKILL}]: {response.text}")

  print(f"Found {len(employee_matches)} employee profiles for {SKILL}.")
```

```
import requests, json

# Set your API key
API_KEY = "YOUR API KEY"

# Set the Skill Enrichment API URL
PDL_SKILL_ENRICH_URL = "https://api.peopledatalabs.com/v5/skill/enrich"
# Set the Person Search API URL
PDL_PERSON_SEARCH_URL = "https://api.peopledatalabs.com/v5/person/search"

# Set the maximum number of people to search
MAX_NUM_PEOPLE = 100

# The skill you want to enrich
SKILL = "ai"
# Create a parameters JSON object
QUERY_STRING = {"skill": SKILL}

# Set headers
HEADERS = {
  'accept': "application/json",
  'content-type': "application/json",
  'x-api-key': API_KEY
}

# Pass the parameters object to the Skill Enrichment API
response = requests.request("GET", PDL_SKILL_ENRICH_URL, 
                            headers=HEADERS, params=QUERY_STRING)

# Check for successful response
if response.status_code == 200:
  # Store enriched skill
  enriched_skill = response.json()
  # Build list of skills
  skills = enriched_skill["data"]["similar_skills"]
  skills.insert(0, SKILL)
  skills_string_rep = ", ".join(
    (f"'{skl}'" for skl in skills)
  )

else:
  enriched_job_title = {}
  print(f"Skill Enrichment Error for [{SKILL}]: {response.text}")
                                                      
# Person Search matches
employee_matches = {}

# Check for enriched skill
if enriched_skill:
  # Create an SQL query
  SQL_QUERY = f"""
  SELECT * FROM person
  WHERE location_region='utah'
  AND skills IN ({skills_string_rep});
  """
    
  # Create a parameters JSON object
  PARAMS = {
  	'sql': SQL_QUERY,
  	'size': MAX_NUM_PEOPLE
  }

  # Pass the parameters object to the Person Search API
  response = requests.get(PDL_PERSON_SEARCH_URL, headers=HEADERS, params=PARAMS)

  # Check for successful response
  if response.status_code == 200:
    # Store matches
  	employee_matches = response.json()["data"]
  else:
  	employee_matches = {}
  	print(f"Person Search Error for [{SKILL}]: {response.text}")

  print(f"Found {len(employee_matches)} employee profiles for {SKILL}.")
```

Updated 4 months ago

---

Did this page help you?

Yes

No

---
# https://docs.peopledatalabs.com/docs/examples-autocomplete-api

We've provided code samples in Python, cURL, Ruby, Go and JavaScript. If you aren't comfortable working in any of these languages, feel free to use this [handy tool](https://curl.trillworks.com/) to convert code from cURL to the language of your choice.

> ðŸ’¡
>
> ### We want your feedback!
>
> Do you see a bug? Is there an example you'd like to see that's not listed here?
>
> Head over to the public roadmap and submit a [bug ticket](https://peopledatalabs.canny.io/bugs) or a [feature request](https://peopledatalabs.canny.io/feature-requests) and receive automatic notifications as your bug is resolved or your request is implemented

## Company Autocomplete Example

*"Give me 10 suggestions for companies starting with`"ama"`* ."

Python3 SDKcURLJavaScriptRubyGoPython3

```
import json

# See https://github.com/peopledatalabs/peopledatalabs-python
from peopledatalabs import PDLPY

# Create a client, specifying your API key
CLIENT = PDLPY(
    api_key="YOUR API KEY",
)

# Create a parameters JSON object
PARAMS = {
    "field": "company",
    "text": "ama",
    "pretty": True
}

# Pass the parameters object to the Autocomplete API
json_response = CLIENT.autocomplete(**PARAMS).json()

# Print the API response in JSON format
print(json_response)
```

```
curl -X GET -G \
  'https://api.peopledatalabs.com/v5/autocomplete'\
  -H 'X-Api-Key: xxxx' \
  --data-urlencode 'field=company'\
  --data-urlencode 'text=ama'
```

```
// See https://github.com/peopledatalabs/peopledatalabs-js
import PDLJS from 'peopledatalabs';

// Create a client, specifying your API key
const PDLJSClient = new PDLJS({ apiKey: "YOUR API KEY" });

// Create a parameters JSON object
const params = {
    "field": "company",
    "text": "ama",
    "pretty": true
}

// Pass the parameters object to the Autocomplete API
PDLJSClient.autocomplete(params).then((data) => {
    // Print the API response in JSON format
    console.log(data);
}).catch((error) => {
    console.log(error);
});
```

```
# See https://github.com/peopledatalabs/peopledatalabs-ruby
require 'peopledatalabs'

# Set your API key
Peopledatalabs.api_key = 'YOUR API KEY'

# Pass parameters to the Autocomplete API
json_response = Peopledatalabs::Autocomplete.retrieve(field: "company", text: "ama", pretty: true)

# Print the API response in JSON format
puts JSON.dump(json_response)
```

```
package main

import (
    "fmt"
    "encoding/json"
    "context"
)

// See https://github.com/peopledatalabs/peopledatalabs-go
import (
    pdl "github.com/peopledatalabs/peopledatalabs-go"
    pdlmodel "github.com/peopledatalabs/peopledatalabs-go/model"
)

func main() {
    // Set your API key
    apiKey := "YOUR API KEY"
    // Set API key as environmental variable
    // apiKey := os.Getenv("API_KEY")

    // Create a client, specifying your API key
    client := pdl.New(apiKey)
    
    // Create a parameters JSON object
    params := pdlmodel.AutocompleteParams {
        BaseParams: pdlmodel.BaseParams {
            Pretty: true,
        },
        AutocompleteBaseParams: pdlmodel.AutocompleteBaseParams {
            Field: "company",
            Text: "ama",
        },
    }
    
    // Pass the parameters object to the Autocomplete API
    response, err := client.Autocomplete(context.Background(), params)
    // Check for successful response
    if err == nil {
        // Convert the API response to JSON
        jsonResponse, jsonErr := json.Marshal(response)
        // Print the API response
        if (jsonErr == nil) {
            fmt.Println(string(jsonResponse))
        }
    }
}
```

```
import requests, json

# Set your API key
API_KEY = "YOUR API KEY"

# Set the Autocomplete API URL
PDL_URL = "https://api.peopledatalabs.com/v5/autocomplete"

# Create a parameters JSON object
PARAMS = {
    "api_key": API_KEY,
    "field": "company",
    "text": "ama",
    "pretty": True
}

# Pass the parameters object to the Autocomplete API
json_response = requests.get(PDL_URL, params=PARAMS).json()
# Print the API response in JSON format
print(json_response)
```

## Job Title Autocomplete Example

*"Give me 20 suggestions for job titles starting with the prefix`"data"`."*

Python3 SDKcURLJavaScriptRubyGoPython3

```
import json

# See https://github.com/peopledatalabs/peopledatalabs-python
from peopledatalabs import PDLPY

# Create a client, specifying your API key
CLIENT = PDLPY(
    api_key="YOUR API KEY",
)

# Create a parameters JSON object
PARAMS = {
    "field": "title",
    "text": "data",
    "size": 20,
    "pretty": True
}

# Pass the parameters object to the Autocomplete API
json_response = CLIENT.autocomplete(**PARAMS).json()

# Print the API response in JSON format
print(json_response)
```

```
curl -X GET -G \
  'https://api.peopledatalabs.com/v5/autocomplete'\
  -H 'X-Api-Key: your-api-key' \
  --data-urlencode 'field=title'\
  --data-urlencode 'text=data'\
  --data-urlencode 'size=20'
```

```
// See https://github.com/peopledatalabs/peopledatalabs-js
import PDLJS from 'peopledatalabs';

// Create a client, specifying your API key
const PDLJSClient = new PDLJS({ apiKey: "YOUR API KEY" });

// Create a parameters JSON object
const params = {
    "field": "title",
    "text": "data",
    "size": 20,
    "pretty": true
}

// Pass the parameters object to the Autocomplete API
PDLJSClient.autocomplete(params).then((data) => {
    // Print the API response in JSON format
    console.log(data);
}).catch((error) => {
    console.log(error);
});
```

```
# See https://github.com/peopledatalabs/peopledatalabs-ruby
require 'peopledatalabs'

# Set your API key
Peopledatalabs.api_key = 'YOUR API KEY'

# Pass parameters to the Autocomplete API
json_response = Peopledatalabs::Autocomplete.retrieve(field: "title", text: "data", size: 20, pretty: true)

# Print the API response in JSON format
puts JSON.dump(json_response)
```

```
package main

import (
    "fmt"
    "encoding/json"
    "context"
)

// See https://github.com/peopledatalabs/peopledatalabs-go
import (
    pdl "github.com/peopledatalabs/peopledatalabs-go"
    pdlmodel "github.com/peopledatalabs/peopledatalabs-go/model"
)

func main() {
    // Set your API key
    apiKey := "YOUR API KEY"
    // Set API key as environmental variable
    // apiKey := os.Getenv("API_KEY")

    // Create a client, specifying your API key
    client := pdl.New(apiKey)
    
    // Create a parameters JSON object
    params := pdlmodel.AutocompleteParams {
        BaseParams: pdlmodel.BaseParams {
            Size: 20,
            Pretty: true,
        },
        AutocompleteBaseParams: pdlmodel.AutocompleteBaseParams {
            Field: "title",
            Text: "data",
        },
    }
    
    // Pass the parameters object to the Autocomplete API
    response, err := client.Autocomplete(context.Background(), params)
    // Check for successful response
    if err == nil {
        // Convert the API response to JSON
        jsonResponse, jsonErr := json.Marshal(response)
        // Print the API response
        if (jsonErr == nil) {
            fmt.Println(string(jsonResponse))
        }
    }
}
```

```
import requests, json

# Set your API key
API_KEY = "YOUR API KEY"

# Set the Autocomplete API URL
PDL_URL = "https://api.peopledatalabs.com/v5/autocomplete"

# Create a parameters JSON object
PARAMS = {
    "api_key": API_KEY,
    "field": "title",
    "text": "data",
    "size": 20,
    "pretty": True
}

# Pass the parameters object to the Autocomplete API
json_response = requests.get(PDL_URL, params=PARAMS).json()

# Print the API response in JSON format
print(json_response)
```

## Skill Autocomplete Example Using POST

*"Give me 5 suggestions for skills starting with the prefix`"python"`* ."

> ðŸ“˜
>
> ### Difference Between GET and POST Requests
>
> See this article for a comparison of the [differences between GET and POST requests](https://www.w3schools.com/tags/ref_httpmethods.asp). The biggest difference is that POST requests don't have any limit on the amount of data that you can pass in a request.

Python3cURL

```
import requests, json

# Set your API key
API_KEY = "YOUR API KEY"

# Set the Person Search API URL
PDL_URL = "https://api.peopledatalabs.com/v5/autocomplete"

HEADERS = {
  'Content-Type': "application/json",
  'X-api-key': API_KEY
}

# Create a parameters JSON object
PARAMS = {
    "api_key": API_KEY,
    "field": "skill",
    "text": "python",
    "pretty": True
}

# Pass the parameters object to the Autocomplete API using POST method
response = requests.post(
  PDL_URL,
  headers=HEADERS,
  json=PARAMS # Passing the data directly as a JSON object
).json()

#Print the API response in JSON format
print(response)
```

```
curl -X POST \
  'https://api.peopledatalabs.com/v5/autocomplete' \
  -H 'X-Api-Key: your-api-key' \
  -H 'Content-Type: application/json' \
  -d '{
    "field": "skill",
    "text": "python",
    "pretty": true
}'
```

Updated 4 months ago

---

Did this page help you?

Yes

No

---
# https://docs.peopledatalabs.com/docs/data-delivery-using-gcp

1. Log into GCP and navigate to your storage bucket (or [create one](https://cloud.google.com/storage/docs/creating-buckets)).
2. Go to the [Roles](https://console.cloud.google.com/iam-admin/roles?_ga=2.228584605.1668895779.1693419425-1245431273.1693419425) page and click [Create Role](https://cloud.google.com/iam/docs/creating-custom-roles#creating).
   1. Name the role â€œPDL-deliveriesâ€
   2. Add the following permissions:

   ```
   storage.buckets.get
   storage.objects.create
   storage.objects.delete
   storage.objects.get
   storage.objects.list
   storagetransfer.jobs.create
   storagetransfer.jobs.get
   storagetransfer.jobs.list
   ```
3. Go to the [Buckets](https://console.cloud.google.com/storage/browser?_ga=2.203957520.1668895779.1693419425-1245431273.1693419425) page and select the PDL storage bucket (where we will deliver data to)
4. Select the Permissions tab of the bucket.
5. [Add a principal](https://cloud.google.com/storage/docs/access-control/using-iam-permissions#bucket-add) to the bucket.
   1. Use the email â€œ[pdl.delivery@peopledatalabs.com](mailto:pdl.delivery@peopledatalabs.com)â€
   2. Assign it the â€œPDL-deliveriesâ€ role

Updated 4 months ago

---

Did this page help you?

Yes

No

---
# https://docs.peopledatalabs.com/docs/preview-search-api

## Overview

The Preview Search API supports our [Person Search API](/docs/person-search-api) by providing a preview of which fields have data in each record matching a search query.

## Request Format

The endpoint for the Preview Search API is `https://api.peopledatalabs.com/v5/person/search`.

> ðŸ“˜
>
> ### Creating an API Key for Preview Search
>
> The Preview Search API uses **the same endpoint** as the [Person Search API](/docs/person-search-api). Your [API Key](/docs/quickstart#create-an-account) will determine whether you use the Person Search or Preview Search API.
>
> To create an API Key that supports the Person Search Preview API, speak with your [data consultant](https://www.peopledatalabs.com/talk-to-sales).

See [Input Parameters - Person Search API](/docs/input-parameters-person-search-api) for details on the supported parameters. All valid input parameters for the Person Search API will work the same way for the Preview Search API.

### Example

Python3 (Elasticsearch)Python3 (SQL)cURL

```
import requests, json

# Set your API key
API_KEY = "YOUR PREVIEW SEARCH ENABLED API KEY"

# Set the Preview Search API URL
PDL_URL = "https://api.peopledatalabs.com/v5/person/search"

# Set the headers
HEADERS = {
    "X-Api-Key": API_KEY
}

# Create an Elasticsearch query
ES_QUERY = {
  "query": {
    "bool": {
      "must": [
        {"term": {"job_company_name": "people data labs"}}
      ]
    }
  }
}

# Create a parameters JSON object
PARAMS = {
  'query': json.dumps(ES_QUERY),
  'size': 10,
  'pretty': True
}

# Pass the parameters object to the Person Enrichment API
json_response = requests.get(PDL_URL, headers=HEADERS, params=PARAMS).json()

# Check for successful response
if json_response["status"] == 200:
  record = json_response['data']

  # Save preview data to JSON file
  with open("my_pdl_search_preview.jsonl", "w") as out:
    out.write(json.dumps(record) + "\n")
else:
  print("Search preview unsuccessful. See error and try again.")
  print("error:", json_response)
```

```
import requests, json

# Set your API key
API_KEY = "YOUR PREVIEW SEARCH ENABLED API KEY"

# Set the Preview Search API URL
PDL_URL = "https://api.peopledatalabs.com/v5/person/search"

# Set the headers
HEADERS = {
    "X-Api-Key": API_KEY
}

# Create a SQL query
SQL_QUERY = \
"""
  SELECT * FROM person
  WHERE job_company_name='people data labs';
"""

# Create a parameters JSON object
PARAMS = {
  'query': SQL_QUERY,
  'size': 10,
  'pretty': True
}

# Pass the parameters object to the Person Enrichment API
json_response = requests.get(PDL_URL, headers=HEADERS, params=PARAMS).json()

# Check for successful response
if json_response["status"] == 200:
  record = json_response['data']

  # Save preview data to JSON file
  with open("my_pdl_search_preview.jsonl", "w") as out:
    out.write(json.dumps(record) + "\n")
else:
  print("Search preview unsuccessful. See error and try again.")
  print("error:", json_response)
```

```
# Elasticsearch
curl -X GET 'https://api.peopledatalabs.com/v5/person/search' \
-H 'X-Api-Key: xxxx' \
--data-raw '{
  "size": 10,
  "query": {
    "bool": {
      "must": [
        {"term": {"job_company_name": "people data labs"}}
      ]
    }
  }
}'

# SQL
curl -X GET \
  'https://api.peopledatalabs.com/v5/person/search' \
  -H 'X-Api-Key: xxxx' \
  --data-raw '{
    "size": 10,
    "sql": "SELECT * FROM person WHERE job_company_name='\''people data labs'\'';"
}'
```

## Response Format

The Preview Search API is a wrapper on the Person Search API, meaning it returns all of [the same fields](/docs/fields) as the Person Search API, but with **true / false** values instead (**true** meaning we have a value for that field and **false** meaning we do not have a value for it).

Any nested objects will not be included in the Preview Search response. For example, if a record has data for the `education` field, the response will have `"education": true`, but will not list any of the subfields (such as `education.major`).

To help users know which record they're looking at, the following fields will have the actual data if it exists for the record: `id`, `full_name`, `sex`, `linkedin_url`, `industry`, `job_title`, `job_title_levels`, `job_company_name`, `job_company_website`, `location_name`. All other fields will have true/false values as described above.

The output is formatted as such:

| Field Name | Type | Description |
| --- | --- | --- |
| `status` | `Integer` | The HTTP status code. |
| `data` | `Array (Object)` | The person response objects that match the input query. |
| `scroll_token` | `String` | The scroll token to use to fetch the next batch of results for the query. |
| `total` | `Integer` | The total number of search results matching the input query. |

### Full Example Response

JSON

```
{
   "status": 200,
   "data": [
     {
       "id": "qEnOZ5Oh0poWnQ1luFBfVw_0000",
       "full_name": "sean thorne",
       "sex": "male",
       "linkedin_url": "linkedin.com/in/seanthorne",
       "industry": "computer software",
       "job_title": "co-founder and chief executive officer",
       "job_title_role": null,
       "job_title_sub_role": null,
       "job_title_levels": [
           "owner",
           "cxo"
       ],
       "job_company_name": "people data labs",
       "job_company_website": "peopledatalabs.com",
       "location_name": "san francisco, california, united states",
       "birth_date": false,
       "birth_year": true,
       "countries": true,
       "education": true,
       "emails": true,
       "experience": true,
       "facebook_id": true,
       "facebook_url": true,
       "facebook_username": true,
       "first_name": true,
       "github_url": false,
       "github_username": false,
       "interests": true,
       "job_company_facebook_url": true,
       "job_company_founded": true,
       "job_company_id": true,
       "job_company_industry": true,
       "job_company_linkedin_id": true,
       "job_company_linkedin_url": true,
       "job_company_location_address_line_2": true,
       "job_company_location_continent": true,
       "job_company_location_country": true,
       "job_company_location_geo": true,
       "job_company_location_locality": true,
       "job_company_location_metro": true,
       "job_company_location_name": true,
       "job_company_location_postal_code": true,
       "job_company_location_region": true,
       "job_company_location_street_address": true,
       "job_company_size": true,
       "job_company_twitter_url": true,
       "job_last_updated": true,
       "job_last_changed": true,
       "job_last_verified": true,
       "job_start_date": true,
       "last_initial": true,
       "last_name": true,
       "linkedin_id": true,
       "linkedin_username": true,
       "location_address_line_2": false,
       "location_continent": true,
       "location_country": true,
       "location_geo": true,
       "location_last_updated": true,
       "location_locality": true,
       "location_metro": true,
       "location_names": true,
       "location_postal_code": false,
       "location_region": true,
       "location_street_address": false,
       "middle_initial": true,
       "middle_name": true,
       "mobile_phone": true,
       "personal_emails": false,
       "phone_numbers": true,
       "profiles": true,
       "regions": true,
       "skills": true,
       "street_addresses": false,
       "twitter_url": true,
       "twitter_username": true,
       "work_email": true
     },
     ...
   ],
   "scroll_token": "1117$12.176522",
   "total": 10
}
```

### Field Availability

The Preview Search API will only return the fields shown in the example response above. Even if you have purchased additional fields or bundles for Person Search, those fields will not show in the Preview Search response.

### Errors

If the request encounters an error, it will instead return an Error Response in the format described in [Errors](/docs/errors).

## Access & Billing

The Preview Search API is available for purchase by enterprise API customers. If youâ€™d like access, please [reach out to us](https://www.peopledatalabs.com/talk-to-sales).

The Preview Search API uses its own set of credits. To add Preview Search credits to your Preview Search API Key, speak with your [data consultant](https://www.peopledatalabs.com/talk-to-sales).

Updated 4 months ago

---

Did this page help you?

Yes

No

---
# https://docs.peopledatalabs.com/docs/quickstart-company-enrichment-api

## Getting Started

In order to use our Company Enrichment API, you must have an active API key. You can look up your API key by logging into our [self-serve dashboard](https://www.peopledatalabs.com/main/api-keys) and going to the **API Keys** section.

> ðŸ‘
>
> ### Need an API Key?
>
> If you don't have an API key, you can easily create one by [signing up](https://peopledatalabs.com/signup) for a self-serve account. For more information, check out our [Self-Serve Quickstart Guide](https://blog.peopledatalabs.com/post/self-signup-api-quickstart), which walks you through the sign-up process as well as shows you how to use the self-serve API dashboard.

## Simple Example

As mentioned in the [Overview](/docs/company-enrichment-api#overview), the Company Enrichment API is a means of performing a one-to-one match of a company with those included in our [Company](/docs/company-schema) Dataset. In order to use the Company Enrichment API, **you will need one of the[input parameters](/docs/input-parameters-company-enrichment-api) of the API**.

Here's a quick example that demonstrates retrieving a record with a `website` of `google.com`:

Python3 SDKcURLJavaScriptRubyGoPython3

```
# See https://github.com/peopledatalabs/peopledatalabs-python
from peopledatalabs import PDLPY

# Create a client, specifying your API key
CLIENT = PDLPY(
    api_key="YOUR API KEY",
)

# Create a parameters JSON object
QUERY_STRING = {"website":"google.com"}

# Pass the parameters object to the Company Enrichment API
response = CLIENT.company.enrichment(**QUERY_STRING)

# Print the API response
print(response.text)
```

```
curl -X GET -G \
  'https://api.peopledatalabs.com/v5/company/enrich'\
  -H 'X-Api-Key: xxxx'\
  --data-urlencode 'website=google.com'
```

```
// See https://github.com/peopledatalabs/peopledatalabs-js
import PDLJS from 'peopledatalabs';

// Create a client, specifying your API key
const PDLJSClient = new PDLJS({ apiKey: "YOUR API KEY" });

// Create a parameters JSON object
const queryString = {"website":"google.com"}

// Pass the parameters object to the Company Enrichment API
PDLJSClient.company.enrichment(queryString).then((response) => {
    // Print the API response
    console.log(response);
}).catch((error) => {
    console.log(error);
});
```

```
# See https://github.com/peopledatalabs/peopledatalabs-ruby
require 'peopledatalabs'

# Set your API key
Peopledatalabs.api_key = 'YOUR API KEY'

# Create a parameters JSON object
QUERY_STRING = {"website":"google.com"}

# Pass the parameters object to the Company Enrichment API
response = Peopledatalabs::Enrichment.company(params: QUERY_STRING)

# Print the API response
puts response
```

```
package main

import (
    "fmt"
    "context"
)

// See https://github.com/peopledatalabs/peopledatalabs-go
import (
    pdl "github.com/peopledatalabs/peopledatalabs-go"
    pdlmodel "github.com/peopledatalabs/peopledatalabs-go/model"
)

func main() {
    // Set your API key
    apiKey := "YOUR API KEY"
    // Set API key as environmental variable
    // apiKey := os.Getenv("API_KEY")

    // Create a client, specifying your API key
    client := pdl.New(apiKey)
    
    // Create a parameters JSON object
    queryString := pdlmodel.CompanyParams{Website: "google.com"}
    
    params := pdlmodel.EnrichCompanyParams{
        CompanyParams: queryString,
    }
    
    // Pass the parameters object to the Company Enrichment API
    response, err := client.Company.Enrich(context.Background(), params)
    
    // Check for successful response
    if err == nil {
        // Print the API response
        fmt.Println(response)
    }  
}
```

```
import requests

# Set your API key
API_KEY = "YOUR API KEY"

# Set the Company Enrichment API URL
PDL_URL = "https://api.peopledatalabs.com/v5/company/enrich"

# Create a parameters JSON object
QUERY_STRING = {"website":"google.com"}

# Set headers
HEADERS = {
    'accept': "application/json",
    'content-type': "application/json",
    'x-api-key': API_KEY
    }

# Pass the parameters object to the Company Enrichment API
response = requests.request("GET", PDL_URL, headers=HEADERS, params=QUERY_STRING)

# Print the API response
print(response.text)
```

The API will return the matching company record if the website matches one in our dataset.

The result of running the above code should be the profile for Google from our [Company Dataset](/docs/company-stats). To see a full company profile that would be returned, check out our [Example Company Record](/docs/example-company-record).

JSON

```
{
  "status": 200,
  "name": "google",
  "id": "aKCIYBNF9ey6o5CjHCCO4goHYKlf",
  ...
  "likelihood": 4
}
```

If you don't get this response, check out our [Errors](/docs/errors) page for more information.

---

Updated 4 months ago

---

Did this page help you?

Yes

No

---
# https://docs.peopledatalabs.com/docs/identify-api-examples

We've provided code samples in Python, cURL, Ruby, Go and JavaScript. If you aren't comfortable working in any of these languages, feel free to use this [handy tool](https://curl.trillworks.com/) to convert code from cURL to the language of your choice.

> ðŸ’¡
>
> ### We want your feedback!
>
> Do you see a bug? Is there an example you'd like to see that's not listed here?
>
> Head over to the public roadmap and submit a [bug ticket](https://peopledatalabs.canny.io/bugs) or a [feature request](https://peopledatalabs.canny.io/feature-requests) and receive automatic notifications as your bug is resolved or your request is implemented.

## Basic Usage

*I would like to find the most strongly associated profiles for the name "Sean Thorne."*

Python3 SDKcURLJavaScriptRubyGoPython3

```
import json

# See https://github.com/peopledatalabs/peopledatalabs-python
from peopledatalabs import PDLPY

# Create a client, specifying your API key
CLIENT = PDLPY(
    api_key="YOUR API KEY",
)

# Create a parameters JSON object
PARAMS = {
 "first_name": "sean", 
 "last_name": "thorne", 
 "company": "people data labs",
 "pretty": True
}

# Pass the parameters object to the Person Identify API
response_data = CLIENT.person.identify(**PARAMS).json()

# Check for successful response
if json_response["status"] == 200:
   # Create a list of matches
   identities = response_data['matches']

   # Print the matches in JSON format
   print(identities)
   print(f"Found {len(identities)} identities!")
else:
   print("Identify unsuccessful. See error and try again.")
   print("error:", json_response)
```

```
API_KEY="ENTER YOUR API KEY HERE"
curl -X GET -G \
 "https://api.peopledatalabs.com/v5/person/identify"\
 -H "X-Api-Key: ${API_KEY}" \
 --data-urlencode 'first_name=sean'\
 --data-urlencode 'last_name=thorne'\
 --data-urlencode 'company="people data labs"'\
 --data-urlencode 'pretty=True'
```

```
// See https://github.com/peopledatalabs/peopledatalabs-js
import PDLJS from 'peopledatalabs';

// Create a client, specifying your API key
const PDLJSClient = new PDLJS({ apiKey: "YOUR API KEY" });

// Create a parameters JSON object
const params = {
  first_name: "sean", 
  last_name: "thorne", 
  company: "people data labs",
  pretty: true,
}

// Pass the parameters object to the Person Identify API
PDLJSClient.person.identify(params).then((data) => {
  // Create a list of matches
  var identities = data["matches"]
  
  // Print the matches in JSON format
  console.log(identities);
  console.log(`Found ${identities.length} identities!`)
}).catch((error) => {
  console.log("Identify unsuccessful. See error and try again.")
  console.log(error);
});
```

```
# See https://github.com/peopledatalabs/peopledatalabs-ruby
require 'peopledatalabs'

# Set your API key
Peopledatalabs.api_key = 'YOUR API KEY'

# Create a parameters JSON object
PARAMS = {
 "first_name": "sean", 
 "last_name": "thorne", 
 "company": "people data labs",
 "pretty": true
}

# Pass the parameters object to the Person Identify API
response = Peopledatalabs::Identify.person(params: PARAMS)

# Check for successful response
if json_response['status'] == 200

    # Create a list of matches
    identities = response['matches']

    # Print the matches in JSON format
    puts identities
    puts "Found #{identities.length()} identities!"
    end
else
    puts "Identify unsuccessful. See error and try again."
    puts "error: #{json_response}"
end
```

```
package main

import (
    "fmt"
    "encoding/json"
    "context"
)

// See https://github.com/peopledatalabs/peopledatalabs-go
import (
    pdl "github.com/peopledatalabs/peopledatalabs-go"
    pdlmodel "github.com/peopledatalabs/peopledatalabs-go/model"
)

func main() {
    // Set your API key
    apiKey := "YOUR API KEY"
    // Set API key as environmental variable
    // apiKey := os.Getenv("API_KEY")

    // Create a client, specifying your API key
    client := pdl.New(apiKey)
    
    // Create a parameters JSON object
    params := pdlmodel.IdentifyPersonParams {
        BaseParams: pdlmodel.BaseParams {
            Pretty: true,
        },
        PersonParams: pdlmodel.PersonParams {
            FirstName: []string{"sean"},
            LastName: []string{"thorne"},
            Company: []string{"people data labs"},
        },
    }
    
    // Pass the parameters object to the Person Identify API
    response, err := client.Person.Identify(context.Background(), params)
    // Check for successful response
    if err == nil {
        // Create a list of matches
        identities := response.Matches
        // Convert the matches to JSON
        jsonResponse, jsonErr := json.Marshal(identities)
        // Print the matches
        if (jsonErr == nil) {
            fmt.Println(string(jsonResponse))
        }
        
        fmt.Printf("Found %d identities!\n", len(identities))
    } else {
        fmt.Println("Identify unsuccessful. See error and try again.")
        fmt.Println("error:", err)
    }
}
```

```
import requests

# Set your API key
API_KEY = "YOUR API KEY"

# Set the Person Identify API URL
PDL_URL = "https://api.peopledatalabs.com/v5/person/identify"

# Create a parameters JSON object
PARAMS = {
 "first_name": "sean", 
 "last_name": "thorne", 
 "company": "people data labs",
 "pretty": True,
 "api_key": API_KEY
}

# Pass the parameters object to the Person Identify API
json_response = requests.get(PDL_URL, params=PARAMS).json()

# Check for successful response
if json_response['status'] == 200:
   # Create a list of matches
   identities = json_response['matches']

   # Print the matches in JSON format
   print(identities)
   print(f"Found {len(identities)} identities!")

else:
   print("Identify unsuccessful. See error and try again.")
   print("error:", json_response)
```

## Associated LinkedIn Profiles

*I would like to find the most strongly associated profiles for a particular LinkedIn account.*

Python3 SDKcURLJavaScriptRubyGoPython3

```
import json

# See https://github.com/peopledatalabs/peopledatalabs-python
from peopledatalabs import PDLPY

# Create a client, specifying your API key
CLIENT = PDLPY(
    api_key="YOUR API KEY",
)

# Create a parameters JSON object
PARAMS = {
 "profile": "linkedin.com/in/seanthorne",
 "pretty": True
}

# Pass the parameters object to the Person Identify API
response_data = CLIENT.person.identify(**PARAMS).json()

# Check for successful response
if json_response["status"] == 200:
   # Create a list of matches
   identities = response_data['matches']

   # Print the matches in JSON format
   print(identities)
   print(f"Found {len(identities)} identities!")
else:
   print("Identify unsuccessful. See error and try again.")
   print("error:", json_response)
```

```
API_KEY="ENTER YOUR API KEY HERE"
curl -X GET -G \
 "https://api.peopledatalabs.com/v5/person/identify"\
 -H "X-Api-Key: ${API_KEY}" \
 --data-urlencode 'profile=linkedin.com/in/seanthorne'\
 --data-urlencode 'pretty=True'
```

```
// See https://github.com/peopledatalabs/peopledatalabs-js
import PDLJS from 'peopledatalabs';

// Create a client, specifying your API key
const PDLJSClient = new PDLJS({ apiKey: "YOUR API KEY" });

// Create a parameters JSON object
const params = {
  profile: "linkedin.com/in/seanthorne",
  pretty: true,
}

// Pass the parameters object to the Person Identify API
PDLJSClient.person.identify(params).then((data) => {
  // Create a list of matches
  var identities = data["matches"]
  
  // Print the matches in JSON format
  console.log(identities);
  console.log(`Found ${identities.length} identities!`)
}).catch((error) => {
  console.log("Identify unsuccessful. See error and try again.")
  console.log(error);
});
```

```
# See https://github.com/peopledatalabs/peopledatalabs-ruby
require 'peopledatalabs'

# Set your API key
Peopledatalabs.api_key = 'YOUR API KEY'

# Create a parameters JSON object
PARAMS = {
 "profile": "linkedin.com/in/seanthorne",
 "pretty": true
}

# Pass the parameters object to the Person Identify API
response = Peopledatalabs::Identify.person(params: PARAMS)

# Check for successful response
if json_response['status'] == 200

    # Create a list of matches
    identities = response['matches']

    # Print the matches in JSON format
    puts identities
    puts "Found #{identities.length()} identities!"
    end
else
    puts "Identify unsuccessful. See error and try again."
    puts "error: #{json_response}"
end
```

```
package main

import (
    "fmt"
    "encoding/json"
    "context"
)

// See https://github.com/peopledatalabs/peopledatalabs-go
import (
    pdl "github.com/peopledatalabs/peopledatalabs-go"
    pdlmodel "github.com/peopledatalabs/peopledatalabs-go/model"
)

func main() {
    // Set your API key
    apiKey := "YOUR API KEY"
    // Set API key as environmental variable
    // apiKey := os.Getenv("API_KEY")

    // Create a client, specifying your API key
    client := pdl.New(apiKey)
    
    // Create a parameters JSON object
    params := pdlmodel.IdentifyPersonParams {
        BaseParams: pdlmodel.BaseParams {
            Pretty: true,
        },
        PersonParams: pdlmodel.PersonParams {
            Profile: []string{"linkedin.com/in/seanthorne"},
        },
    }
    
    // Pass the parameters object to the Person Identify API
    response, err := client.Person.Identify(context.Background(), params)
    // Check for successful response
    if err == nil {
        // Create a list of matches
        identities := response.Matches
        // Convert the matches to JSON
        jsonResponse, jsonErr := json.Marshal(identities)
        // Print the matches
        if (jsonErr == nil) {
            fmt.Println(string(jsonResponse))
        }
        
        fmt.Printf("Found %d identities!\n", len(identities))
    } else {
        fmt.Println("Identify unsuccessful. See error and try again.")
        fmt.Println("error:", err)
    }
}
```

```
import requests

# Set your API key
API_KEY = "YOUR API KEY"

# Set the Person Identify API URL
PDL_URL = "https://api.peopledatalabs.com/v5/person/identify"

# Create a parameters JSON object
PARAMS = {
 "profile": "linkedin.com/in/seanthorne",
 "pretty": True,
 "api_key": API_KEY
}

# Pass the parameters object to the Person Identify API
json_response = requests.get(PDL_URL, params=PARAMS).json()

# Check for successful response
if json_response['status'] == 200:
   # Create a list of matches
   identities = json_response['matches']

   # Print the matches in JSON format
   print(identities)
   print(f"Found {len(identities)} identities!")

else:
   print("Identify unsuccessful. See error and try again.")
   print("error:", json_response)
```

Updated 4 months ago

---

Did this page help you?

Yes

No

---
# https://docs.peopledatalabs.com/docs/consumer-social-stats

## Description

The Consumer Social Slice Dataset is a subset of our full [Person Dataset](/docs/stats) and is composed of all the records containing a Facebook URL. The table below summarizes some key statistics and fill rates for fields within this dataset. Premium fields are not accessible by default.

**Common Use Cases**  
*Contact Info Enrichment, Sales and Marketing, Fraud, Background Checks, People Search*

| Field | Count | Numeric | Fill Percentage |
| --- | --- | --- | --- |
| `Total` | 703,540,454 | 703540454 | 100.0% |
| `birth_date` | 14,560,434 | 14560434 | 2.1% |
| `birth_year` | 43,162,939 | 43162939 | 6.1% |
| `certifications` | 5,103,553 | 5103553 | 0.7% |
| `certifications.end_date` | 3,853,452 | 3853452 | 0.5% |
| `certifications.name` | 5,103,553 | 5103553 | 0.7% |
| `certifications.organization` | 4,990,169 | 4990169 | 0.7% |
| `certifications.start_date` | 4,124,415 | 4124415 | 0.6% |
| `countries` | 428,226,645 | 428226645 | 60.9% |
| `education` | 336,104,872 | 336104872 | 47.8% |
| `education.degrees` | 21,375,068 | 21375068 | 3.0% |
| `education.end_date` | 31,962,628 | 31962628 | 4.5% |
| `education.gpa` | 1,156,975 | 1156975 | 0.2% |
| `education.majors` | 39,006,398 | 39006398 | 5.5% |
| `education.minors` | 355,394 | 355394 | 0.1% |
| `education.raw` | 74,060,069 | 74060069 | 10.5% |
| `education.school` | 335,907,423 | 335907423 | 47.7% |
| `education.school.domain` | 190,351,665 | 190351665 | 27.1% |
| `education.school.facebook_url` | 107,526,282 | 107526282 | 15.3% |
| `education.school.id` | 202,765,885 | 202765885 | 28.8% |
| `education.school.linkedin_id` | 202,765,885 | 202765885 | 28.8% |
| `education.school.linkedin_url` | 202,748,268 | 202748268 | 28.8% |
| `education.school.location` | 169,587,777 | 169587777 | 24.1% |
| `education.school.location.continent` | 169,587,777 | 169587777 | 24.1% |
| `education.school.location.country` | 169,587,777 | 169587777 | 24.1% |
| `education.school.location.locality` | 160,271,465 | 160271465 | 22.8% |
| `education.school.location.name` | 169,587,777 | 169587777 | 24.1% |
| `education.school.location.region` | 164,380,149 | 164380149 | 23.4% |
| `education.school.name` | 335,907,377 | 335907377 | 47.7% |
| `education.school.raw` | 335,897,173 | 335897173 | 47.7% |
| `education.school.twitter_url` | 101,683,730 | 101683730 | 14.5% |
| `education.school.type` | 251,831,925 | 251831925 | 35.8% |
| `education.school.website` | 190,351,665 | 190351665 | 27.1% |
| `education.start_date` | 15,622,788 | 15622788 | 2.2% |
| `education.summary` | 7,027,552 | 7027552 | 1.0% |
| `emails` | 52,147,146 | 52147146 | 7.4% |
| `emails.address` | 52,147,146 | 52147146 | 7.4% |
| `emails.first_seen` | 52,147,146 | 52147146 | 7.4% |
| `emails.last_seen` | 52,147,146 | 52147146 | 7.4% |
| `emails.md5_hash` | 52,147,146 | 52147146 | 7.4% |
| `emails.num_sources` | 52,147,146 | 52147146 | 7.4% |
| `emails.sha_256_hash` | 52,147,146 | 52147146 | 7.4% |
| `emails.type` | 48,757,837 | 48757837 | 6.9% |
| `experience` | 249,024,092 | 249024092 | 35.4% |
| `experience.company` | 243,990,513 | 243990513 | 34.7% |
| `experience.company.facebook_url` | 66,236,398 | 66236398 | 9.4% |
| `experience.company.founded` | 86,522,096 | 86522096 | 12.3% |
| `experience.company.id` | 121,971,457 | 121971457 | 17.3% |
| `experience.company.industry` | 114,936,094 | 114936094 | 16.3% |
| `experience.company.industry_v2` | 110,682,133 | 110682133 | 15.7% |
| `experience.company.linkedin_id` | 121,971,457 | 121971457 | 17.3% |
| `experience.company.linkedin_url` | 121,971,457 | 121971457 | 17.3% |
| `experience.company.location` | 115,689,396 | 115689396 | 16.4% |
| `experience.company.location.address_line_2` | 13,649,441 | 13649441 | 1.9% |
| `experience.company.location.continent` | 115,357,039 | 115357039 | 16.4% |
| `experience.company.location.country` | 115,689,160 | 115689160 | 16.4% |
| `experience.company.location.geo` | 106,706,487 | 106706487 | 15.2% |
| `experience.company.location.locality` | 108,448,836 | 108448836 | 15.4% |
| `experience.company.location.metro` | 54,265,650 | 54265650 | 7.7% |
| `experience.company.location.name` | 115,689,396 | 115689396 | 16.4% |
| `experience.company.location.postal_code` | 93,725,785 | 93725785 | 13.3% |
| `experience.company.location.region` | 109,888,899 | 109888899 | 15.6% |
| `experience.company.location.street_address` | 87,366,946 | 87366946 | 12.4% |
| `experience.company.name` | 243,984,294 | 243984294 | 34.7% |
| `experience.company.raw` | 243,990,459 | 243990459 | 34.7% |
| `experience.company.size` | 121,971,457 | 121971457 | 17.3% |
| `experience.company.ticker` | 21,054,034 | 21054034 | 3.0% |
| `experience.company.twitter_url` | 60,813,650 | 60813650 | 8.6% |
| `experience.company.type` | 121,971,457 | 121971457 | 17.3% |
| `experience.company.website` | 107,139,358 | 107139358 | 15.2% |
| `experience.end_date` | 37,344,112 | 37344112 | 5.3% |
| `experience.first_seen` | 249,024,092 | 249024092 | 35.4% |
| `experience.is_primary` | 249,024,092 | 249024092 | 35.4% |
| `experience.last_seen` | 249,024,092 | 249024092 | 35.4% |
| `experience.location_names` | 71,425,768 | 71425768 | 10.2% |
| `experience.num_sources` | 249,024,092 | 249024092 | 35.4% |
| `experience.start_date` | 99,586,244 | 99586244 | 14.2% |
| `experience.summary` | 24,209,570 | 24209570 | 3.4% |
| `experience.title` | 142,509,021 | 142509021 | 20.3% |
| `experience.title.class` | 86,895,192 | 86895192 | 12.4% |
| `experience.title.levels` | 39,245,676 | 39245676 | 5.6% |
| `experience.title.name` | 142,509,021 | 142509021 | 20.3% |
| `experience.title.raw` | 142,509,021 | 142509021 | 20.3% |
| `experience.title.role` | 86,895,192 | 86895192 | 12.4% |
| `experience.title.sub_role` | 75,323,421 | 75323421 | 10.7% |
| `facebook_friends` | 36,281,095 | 36281095 | 5.2% |
| `facebook_id` | 682,838,566 | 682838566 | 97.1% |
| `facebook_url` | 703,540,450 | 703540450 | 100.0% |
| `facebook_username` | 703,540,450 | 703540450 | 100.0% |
| `first_name` | 703,540,454 | 703540454 | 100.0% |
| `first_seen` | 703,540,454 | 703540454 | 100.0% |
| `full_name` | 703,540,454 | 703540454 | 100.0% |
| `github_url` | 454,205 | 454205 | 0.1% |
| `github_username` | 454,205 | 454205 | 0.1% |
| `headline` | 13,140,872 | 13140872 | 1.9% |
| `id` | 703,540,454 | 703540454 | 100.0% |
| `industry` | 20,468,125 | 20468125 | 2.9% |
| `inferred_salary` | 27,028,870 | 27028870 | 3.8% |
| `inferred_years_experience` | 98,638,948 | 98638948 | 14.0% |
| `interests` | 19,341,870 | 19341870 | 2.7% |
| `job_company_12mo_employee_growth_rate` | 32,714,060 | 32714060 | 4.6% |
| `job_company_employee_count` | 32,871,034 | 32871034 | 4.7% |
| `job_company_facebook_url` | 17,479,085 | 17479085 | 2.5% |
| `job_company_founded` | 23,180,433 | 23180433 | 3.3% |
| `job_company_id` | 32,875,391 | 32875391 | 4.7% |
| `job_company_industry` | 31,149,248 | 31149248 | 4.4% |
| `job_company_industry_v2` | 29,837,332 | 29837332 | 4.2% |
| `job_company_inferred_revenue` | 32,871,034 | 32871034 | 4.7% |
| `job_company_linkedin_id` | 32,875,391 | 32875391 | 4.7% |
| `job_company_linkedin_url` | 32,875,391 | 32875391 | 4.7% |
| `job_company_location_address_line_2` | 3,065,476 | 3065476 | 0.4% |
| `job_company_location_continent` | 31,214,463 | 31214463 | 4.4% |
| `job_company_location_country` | 31,307,460 | 31307460 | 4.4% |
| `job_company_location_geo` | 29,081,656 | 29081656 | 4.1% |
| `job_company_location_locality` | 29,541,702 | 29541702 | 4.2% |
| `job_company_location_metro` | 15,171,822 | 15171822 | 2.2% |
| `job_company_location_name` | 31,307,637 | 31307637 | 4.5% |
| `job_company_location_postal_code` | 24,726,393 | 24726393 | 3.5% |
| `job_company_location_region` | 29,887,090 | 29887090 | 4.2% |
| `job_company_location_street_address` | 23,336,557 | 23336557 | 3.3% |
| `job_company_name` | 66,034,515 | 66034515 | 9.4% |
| `job_company_size` | 32,875,391 | 32875391 | 4.7% |
| `job_company_ticker` | 4,763,069 | 4763069 | 0.7% |
| `job_company_total_funding_raised` | 7,592,184 | 7592184 | 1.1% |
| `job_company_twitter_url` | 14,160,966 | 14160966 | 2.0% |
| `job_company_type` | 32,875,391 | 32875391 | 4.7% |
| `job_company_website` | 28,938,251 | 28938251 | 4.1% |
| `job_history` | 249,042,051 | 249042051 | 35.4% |
| `job_history.company_id` | 127,575,572 | 127575572 | 18.1% |
| `job_history.company_name` | 244,086,575 | 244086575 | 34.7% |
| `job_history.first_seen` | 249,042,051 | 249042051 | 35.4% |
| `job_history.last_seen` | 249,042,051 | 249042051 | 35.4% |
| `job_history.num_sources` | 249,042,051 | 249042051 | 35.4% |
| `job_history.title` | 142,537,539 | 142537539 | 20.3% |
| `job_last_changed` | 67,723,600 | 67723600 | 9.6% |
| `job_last_verified` | 67,723,600 | 67723600 | 9.6% |
| `job_onet_broad_occupation` | 25,789,510 | 25789510 | 3.7% |
| `job_onet_code` | 25,789,510 | 25789510 | 3.7% |
| `job_onet_major_group` | 25,789,510 | 25789510 | 3.7% |
| `job_onet_minor_group` | 25,789,510 | 25789510 | 3.7% |
| `job_onet_specific_occupation` | 25,789,510 | 25789510 | 3.7% |
| `job_onet_specific_occupation_detail` | 9,821,011 | 9821011 | 1.4% |
| `job_start_date` | 65,587,397 | 65587397 | 9.3% |
| `job_summary` | 9,125,741 | 9125741 | 1.3% |
| `job_title` | 54,171,586 | 54171586 | 7.7% |
| `job_title_class` | 32,167,761 | 32167761 | 4.6% |
| `job_title_levels` | 14,369,317 | 14369317 | 2.0% |
| `job_title_role` | 32,167,761 | 32167761 | 4.6% |
| `job_title_sub_role` | 26,343,791 | 26343791 | 3.7% |
| `languages` | 95,173,008 | 95173008 | 13.5% |
| `languages.name` | 95,173,008 | 95173008 | 13.5% |
| `languages.proficiency` | 1,415,877 | 1415877 | 0.2% |
| `last_initial` | 703,540,454 | 703540454 | 100.0% |
| `last_name` | 703,519,156 | 703519156 | 100.0% |
| `linkedin_connections` | 34,390,657 | 34390657 | 4.9% |
| `linkedin_id` | 26,970,208 | 26970208 | 3.8% |
| `linkedin_url` | 28,041,253 | 28041253 | 4.0% |
| `linkedin_username` | 28,041,253 | 28041253 | 4.0% |
| `location_address_line_2` | 3,772,386 | 3772386 | 0.5% |
| `location_continent` | 428,227,266 | 428227266 | 60.9% |
| `location_country` | 428,226,494 | 428226494 | 60.9% |
| `location_geo` | 377,863,189 | 377863189 | 53.7% |
| `location_last_updated` | 63,525,022 | 63525022 | 9.0% |
| `location_locality` | 379,949,975 | 379949975 | 54.0% |
| `location_metro` | 94,142,429 | 94142429 | 13.4% |
| `location_name` | 428,227,266 | 428227266 | 60.9% |
| `location_names` | 380,121,347 | 380121347 | 54.0% |
| `location_postal_code` | 29,544,050 | 29544050 | 4.2% |
| `location_region` | 425,816,711 | 425816711 | 60.5% |
| `location_street_address` | 27,615,633 | 27615633 | 3.9% |
| `middle_initial` | 161,120,008 | 161120008 | 22.9% |
| `middle_name` | 141,062,387 | 141062387 | 20.1% |
| `mobile_phone` | 180,262,344 | 180262344 | 25.6% |
| `name_aliases` | 14,283,512 | 14283512 | 2.0% |
| `num_records` | 703,540,454 | 703540454 | 100.0% |
| `num_sources` | 703,540,454 | 703540454 | 100.0% |
| `personal_emails` | 40,123,799 | 40123799 | 5.7% |
| `phone_numbers` | 235,064,638 | 235064638 | 33.4% |
| `phones` | 235,064,638 | 235064638 | 33.4% |
| `phones.first_seen` | 235,064,638 | 235064638 | 33.4% |
| `phones.last_seen` | 235,064,638 | 235064638 | 33.4% |
| `phones.num_sources` | 235,064,638 | 235064638 | 33.4% |
| `phones.number` | 235,064,638 | 235064638 | 33.4% |
| `possible_birth_dates` | 31,060,306 | 31060306 | 4.4% |
| `possible_emails` | 16,001,867 | 16001867 | 2.3% |
| `possible_emails.address` | 16,001,867 | 16001867 | 2.3% |
| `possible_emails.first_seen` | 16,001,867 | 16001867 | 2.3% |
| `possible_emails.last_seen` | 16,001,867 | 16001867 | 2.3% |
| `possible_emails.md5_hash` | 16,001,867 | 16001867 | 2.3% |
| `possible_emails.num_sources` | 16,001,867 | 16001867 | 2.3% |
| `possible_emails.sha_256_hash` | 16,001,867 | 16001867 | 2.3% |
| `possible_emails.type` | 13,042,119 | 13042119 | 1.9% |
| `possible_location_names` | 248,891,923 | 248891923 | 35.4% |
| `possible_phones` | 5,941,218 | 5941218 | 0.8% |
| `possible_phones.first_seen` | 5,941,218 | 5941218 | 0.8% |
| `possible_phones.last_seen` | 5,941,218 | 5941218 | 0.8% |
| `possible_phones.num_sources` | 5,941,218 | 5941218 | 0.8% |
| `possible_phones.number` | 5,941,218 | 5941218 | 0.8% |
| `possible_profiles` | 29,098,593 | 29098593 | 4.1% |
| `possible_profiles.first_seen` | 29,098,593 | 29098593 | 4.1% |
| `possible_profiles.id` | 26,169,425 | 26169425 | 3.7% |
| `possible_profiles.last_seen` | 29,098,593 | 29098593 | 4.1% |
| `possible_profiles.network` | 29,098,593 | 29098593 | 4.1% |
| `possible_profiles.num_sources` | 29,098,593 | 29098593 | 4.1% |
| `possible_profiles.url` | 29,098,593 | 29098593 | 4.1% |
| `possible_profiles.username` | 12,155,248 | 12155248 | 1.7% |
| `possible_street_addresses` | 3,447,279 | 3447279 | 0.5% |
| `possible_street_addresses.address_line_2` | 773,866 | 773866 | 0.1% |
| `possible_street_addresses.continent` | 3,447,279 | 3447279 | 0.5% |
| `possible_street_addresses.country` | 3,447,279 | 3447279 | 0.5% |
| `possible_street_addresses.first_seen` | 3,447,279 | 3447279 | 0.5% |
| `possible_street_addresses.geo` | 3,446,754 | 3446754 | 0.5% |
| `possible_street_addresses.last_seen` | 3,447,279 | 3447279 | 0.5% |
| `possible_street_addresses.locality` | 3,447,232 | 3447232 | 0.5% |
| `possible_street_addresses.metro` | 2,948,645 | 2948645 | 0.4% |
| `possible_street_addresses.name` | 3,447,279 | 3447279 | 0.5% |
| `possible_street_addresses.num_sources` | 3,447,279 | 3447279 | 0.5% |
| `possible_street_addresses.postal_code` | 3,402,564 | 3402564 | 0.5% |
| `possible_street_addresses.region` | 3,447,263 | 3447263 | 0.5% |
| `possible_street_addresses.street_address` | 3,447,279 | 3447279 | 0.5% |
| `profiles` | 703,540,454 | 703540454 | 100.0% |
| `profiles.first_seen` | 703,540,454 | 703540454 | 100.0% |
| `profiles.id` | 683,511,857 | 683511857 | 97.2% |
| `profiles.last_seen` | 703,540,454 | 703540454 | 100.0% |
| `profiles.network` | 703,540,454 | 703540454 | 100.0% |
| `profiles.num_sources` | 703,540,454 | 703540454 | 100.0% |
| `profiles.url` | 703,540,454 | 703540454 | 100.0% |
| `profiles.username` | 703,540,454 | 703540454 | 100.0% |
| `recommended_personal_email` | 40,123,029 | 40123029 | 5.7% |
| `regions` | 426,225,236 | 426225236 | 60.6% |
| `sex` | 472,580,967 | 472580967 | 67.2% |
| `skills` | 17,931,180 | 17931180 | 2.5% |
| `street_addresses` | 29,593,575 | 29593575 | 4.2% |
| `street_addresses.address_line_2` | 15,978,892 | 15978892 | 2.3% |
| `street_addresses.continent` | 29,593,575 | 29593575 | 4.2% |
| `street_addresses.country` | 29,593,575 | 29593575 | 4.2% |
| `street_addresses.first_seen` | 29,593,575 | 29593575 | 4.2% |
| `street_addresses.geo` | 29,489,176 | 29489176 | 4.2% |
| `street_addresses.last_seen` | 29,593,575 | 29593575 | 4.2% |
| `street_addresses.locality` | 29,532,619 | 29532619 | 4.2% |
| `street_addresses.metro` | 26,970,562 | 26970562 | 3.8% |
| `street_addresses.name` | 29,593,575 | 29593575 | 4.2% |
| `street_addresses.num_sources` | 29,593,575 | 29593575 | 4.2% |
| `street_addresses.postal_code` | 29,224,082 | 29224082 | 4.2% |
| `street_addresses.region` | 29,539,341 | 29539341 | 4.2% |
| `street_addresses.street_address` | 29,593,575 | 29593575 | 4.2% |
| `summary` | 10,692,037 | 10692037 | 1.5% |
| `twitter_url` | 3,313,999 | 3313999 | 0.5% |
| `twitter_username` | 3,313,999 | 3313999 | 0.5% |
| `work_email` | 7,694,069 | 7694069 | 1.1% |

*Stats shown are accurate as of data version 33.1*

Updated 6 days ago

---

Did this page help you?

Yes

No

---
# https://docs.peopledatalabs.com/docs/ruby-sdk

# The People Data Labs Ruby Helper Library

The People Data Labs Ruby Helper Library makes it easy to interact with our APIs from your Ruby application. You can find the [most recent version of the library on RubyGems](https://rubygems.org/gems/peopledatalabs).

## How To Install the Library

This library is available as a Ruby gem, and you can install it like this:

Shell

```
gem install peopledatalabs
```

## Using the Library

Make sure that you sign up for a [free PDL API key](https://www.peopledatalabs.com/signup) if you don't already have one.

Ruby

```
# See https://github.com/peopledatalabs/peopledatalabs-ruby
require 'peopledatalabs'
require 'json'

# Set your API key
Peopledatalabs.api_key = 'api_key'

# Pass parameters to the Person Enrichment API
result = Peopledatalabs::Enrichment.person(params: { profile: 'linkedin.com/in/seanthorne' })

# Check for successful response
if result['status'] == 200
    # Print the API response in JSON format
    puts JSON.pretty_generate(result['data'])
else
    puts "Status: #{result['status']};"\
       "\nReason: #{result['error']['type']};"\
       "\nMessage: #{result['error']['message']};"
end
```

## More Information, Pull Requests, Feature Suggestions and Bug Reports

We've open-sourced the library, which is available on GitHub. Go there to view more information. You can also submit pull requests, feature suggestions and bug reports.

[github.com

GitHub - peopledatalabs/peopledatalabs-ruby: A Ruby client for the People Data Labs API](https://github.com/peopledatalabs/peopledatalabs-ruby)

Updated 4 months ago

---

Did this page help you?

Yes

No

---
# https://docs.peopledatalabs.com/docs/identify-api-input-parameters

## Required Parameters

A valid Person Identify API request must include **at least one** of the following:

* [`profile`](#profile)
* [`email`](#email)
* [`phone`](#phone)
* [`email_hash`](#email_hash)
* [`lid`](#lid)
* [`street_address`](#street_address)
* [`locality`](#locality)
* [`region`](#region)
* [`company`](#company)
* [`school`](#school)
* [`location`](#location)
* [`postal_code`](#postal_code)
* [`name`](#name)
* [`first_name`](#first_name) AND [`last_name`](#last_name)

  

### `api_key`

| Type | Description | Default | Example |
| --- | --- | --- | --- |
| `String` | Your secret API key. |  |  |

Your API Key **must** be included in either the request header or the `api_key` parameter. For more information about request authentication, see the [Authentication](/docs/authentication) page.

---

## Optional Parameters

### `name`

| Type | Description | Example |
| --- | --- | --- |
| `String` | The person's full name, at least the first and last. | `Jennifer C. Jackson` |

  

### `first_name`

| Type | Description | Example |
| --- | --- | --- |
| `String` | The person's first name. | `Jennifer` |

  

### `last_name`

| Type | Description | Example |
| --- | --- | --- |
| `String` | The person's last name. | `Jackson` |

  

### `middle_name`

| Type | Description | Example |
| --- | --- | --- |
| `String` | The person's middle name. | `Cassandra` |

  

### `location`

| Type | Description | Example |
| --- | --- | --- |
| `String` | The location where a person lives. This can be anything from a street address to a country name. | `Medford, OR USA` |

  

### `street_address`

| Type | Description | Example |
| --- | --- | --- |
| `String` | The street address where the person lives. | `1234 Main Street` |

  

### `locality`

| Type | Description | Example |
| --- | --- | --- |
| `String` | The locality where the person lives. | `Boise` |

  

### `region`

| Type | Description | Example |
| --- | --- | --- |
| `String` | The state or region where the person lives. | `Idaho` |

  

### `country`

| Type | Description | Example |
| --- | --- | --- |
| `String` | The country where the person lives. | `United States` |

  

### `postal_code`

| Type | Description | Example |
| --- | --- | --- |
| `String` | The postal code where the person lives. If there is no value for country, the postal code is assumed to be US. | `83701` |

  

### `company`

| Type | Description | Example |
| --- | --- | --- |
| `String` | The name, website, or social URL of a company where the person has worked. | `Amazon` |

  

### `school`

| Type | Description | Example |
| --- | --- | --- |
| `String` | The name, website, or social URL of a university or college the person has attended. | `University of Iowa` |

  

### `phone`

| Type | Description | Example |
| --- | --- | --- |
| `String` | A phone number the person has used. **Input must begin with `+[country code]` for a match to be returned.** | `+1 555-234-1234` |

  

### `email`

| Type | Description | Example |
| --- | --- | --- |
| `String` | An email the person has used. | `renee.c.paulsen1959@yahoo.com` |

  

### `email_hash`

| Type | Description | Example |
| --- | --- | --- |
| `String` | The SHA-256 or MD5 email hash for an email the person has used. | `e206e6cd7fa5f9499fd6d2d943dcf7d9c1469bad351061483f5ce7181663b8d4` |

  

### `profile`

| Type | Description | Example |
| --- | --- | --- |
| `String` | A social profile that the person has used (see [list of supported social profiles](/docs/social-networks)). | `https://linkedin.com/in/seanthorne` |

  

### `lid`

| Type | Description | Example |
| --- | --- | --- |
| `String` | The person's LinkedIn ID. | `145991517` |

  

### `birth_date`

| Type | Description | Example |
| --- | --- | --- |
| `String` | The person's birth date: either the year or a full birth date in the format `YYYY-MM-DD`. | `1996-10-01` |

  

### `pretty`

| Type | Description | Default | Example |
| --- | --- | --- | --- |
| `Boolean` | Whether the output should have [human-readable](http://jsonprettyprint.net/) indentation. | `false` | `true` |

  

### `titlecase`

| Type | Description | Default | Example |
| --- | --- | --- | --- |
| `Boolean` | All text in API responses returns as lowercase by default. Setting `titlecase` to `true` will titlecase response data instead. | `false` | `true` |

### `data_include`

| Type | Description | Default | Example |
| --- | --- | --- | --- |
| `String` | A comma-separated string of fields that you want the response to include. |  | `"full_name,emails.address"` |

### `include_if_matched`

| Type | Description | Default | Example |
| --- | --- | --- | --- |
| `Boolean` | If `true`, the response will include the field [`matches.matched_on`](/docs/output-response-person-identify-api#matchesmatched_on) that contains a list of every query input that matched this profile. | `false` | `true` |

As an example, if we wanted to enrich Sean Thorne using the following query:

JSON

```
{
   "first_name": "sean",
   "last_name": "thorne",
   "company": "people data labs",
   "location": "abu dhabi",
   "include_if_matched": true
}
```

Since Sean's location is in California and not Abu Dhabi in the dataset, the response would contain:

JSON

```
{
   "matched": [
        "company",
        "name"
    ]
}
```

Updated 4 months ago

---

Did this page help you?

Yes

No

---
# https://docs.peopledatalabs.com/docs/quickstart-cleaner-apis

## Getting Started

In order to use one of our Cleaner APIs, you must have an active API key. You can look up your API key by logging into our [self-serve dashboard](https://www.peopledatalabs.com/main/api-keys) and going to the **API Keys** section.

> ðŸ‘
>
> ### Need an API Key?
>
> If you don't have an API key, you can easily create one by [signing up](https://peopledatalabs.com/signup) for a self-serve account. For more information, check out our [Self-Serve Quickstart Guide](https://blog.peopledatalabs.com/post/self-signup-api-quickstart), which walks you through the sign-up process as well as shows you how to use the self-serve API dashboard.

## Simple Example

As mentioned in the [Overview](/docs/cleaner-apis#overview), the Cleaner APIs are a means of cleaning company, school and location data in order to get the best results from your API queries. To use the Cleaner APIs, **you will need a set of[input parameters](/docs/input-parameters-cleaner-apis) for the particular Cleaner API that you are using**.

Here's a quick example that demonstrates cleaning a company record with a `website` of `peopledatalabs.com`:

Python3 SDKJavaScriptRubyGoPython3

```
# See https://github.com/peopledatalabs/peopledatalabs-python
from peopledatalabs import PDLPY

# Create a client, specifying your API key
CLIENT = PDLPY(
    api_key="YOUR API KEY",
)

# Create a parameters JSON object
QUERY_STRING = {"website":"peopledatalabs.com"}

# Pass the parameters object to the Company Cleaner API
response = CLIENT.company.cleaner(**QUERY_STRING)

# Print the API response
print(response.text)
```

```
// See https://github.com/peopledatalabs/peopledatalabs-js
import PDLJS from 'peopledatalabs';

// Create a client, specifying your API key
const PDLJSClient = new PDLJS({ apiKey: "YOUR API KEY" });

// Create a parameters JSON object
const queryString = {
  website: "peopledatalabs.com"
}

// Pass the parameters object to the Company Cleaner API
PDLJSClient.company.cleaner(queryString).then((response) => {
  // Print the API response
  console.log(response);
}).catch((error) => {
  console.log(error);
});
```

```
# See https://github.com/peopledatalabs/peopledatalabs-ruby
require 'peopledatalabs'

# Set your API key
Peopledatalabs.api_key = 'YOUR API KEY'

# Pass parameters to the Company Cleaner API
response = Peopledatalabs::Cleaner.company(kind: 'website', value: "peopledatalabs.com")

# Print the API response
puts response
```

```
package main

import (
    "fmt"
    "context"
)

// See https://github.com/peopledatalabs/peopledatalabs-go
import (
    pdl "github.com/peopledatalabs/peopledatalabs-go"
    pdlmodel "github.com/peopledatalabs/peopledatalabs-go/model"
)

func main() {
    // Set your API key
    apiKey := "YOUR API KEY"
    // Set API key as environmental variable
    // apiKey := os.Getenv("API_KEY")

    // Create a client, specifying your API key
    client := pdl.New(apiKey)
    
    // Create a parameters JSON object
    queryString := pdlmodel.CleanCompanyParams{Website: "peopledatalabs.com"}

    // Pass the parameters object to the Company Cleaner API
    response, err := client.Company.Clean(context.Background(), queryString)
  
    // Check for successful response
    if err == nil {
        // Print the API response
        fmt.Println(response)
    }  
}
```

```
import requests

# Set your API key
API_KEY = "YOUR API KEY"

# Set the Company Cleaner API URL
PDL_URL = "https://api.peopledatalabs.com/v5/company/clean"

# Create a parameters JSON object
QUERY_STRING = {"website":"peopledatalabs.com"}

# Set headers
HEADERS = {
    'accept': "application/json",
    'content-type': "application/json",
    'x-api-key': API_KEY
}

# Pass the parameters object to the Company Cleaner API
response = requests.request("GET", PDL_URL, headers=HEADERS, params=QUERY_STRING)

# Print the API response
print(response.text)
```

The response that the API returns is a cleaned company profile if the input parameters passed to it matches a record in our company dataset:

JSON

```
{
  "status": 200,
  "name": "people data labs",
  "size": "11-50",
  "id": "tnHcNHbCv8MKeLh92946LAkX6PKg",
  "founded": 2015,
  "industry": "computer software",
  "location": {
    "name": "san francisco, california, united states",
    "locality": "san francisco",
    "region": "california",
    "metro": "san francisco, california",
    "country": "united states",
    "continent": "north america",
    "street_address": "455 market street",
    "address_line_2": "suite 1670",
    "postal_code": "94105",
    "geo": "37.77,-122.41"
  },
  "linkedin_url": "linkedin.com/company/peopledatalabs",
  "linkedin_id": "18170482",
  "facebook_url": "facebook.com/peopledatalabs",
  "twitter_url": "twitter.com/peopledatalabs",
  "website": "peopledatalabs.com",
  "ticker": null,
  "type": "private",
  "raw": [],
  "score": 3.0,
  "fuzzy_match": false
}
```

If you don't get this response, check out our [Errors](/docs/errors) page for more information.

---

Updated 4 months ago

---

Did this page help you?

Yes

No

---
# https://docs.peopledatalabs.com/docs/phone-stats

## Description

The Phone Slice Dataset is a subset of our full [Person Dataset](/docs/stats) and is composed of all the records containing at least one phone number. The table below summarizes some key statistics and fill rates for fields within this dataset. Premium fields are not accessible by default.

**Common Use Cases**  
*Background Checks, People Search*

| Field | Count | Numeric | Fill Percentage |
| --- | --- | --- | --- |
| `Total` | 770,761,928 | 770761928 | 100.0% |
| `birth_date` | 116,843,157 | 116843157 | 15.2% |
| `birth_year` | 208,603,383 | 208603383 | 27.1% |
| `certifications` | 12,389,970 | 12389970 | 1.6% |
| `certifications.end_date` | 9,157,645 | 9157645 | 1.2% |
| `certifications.name` | 12,389,970 | 12389970 | 1.6% |
| `certifications.organization` | 12,092,757 | 12092757 | 1.6% |
| `certifications.start_date` | 9,796,938 | 9796938 | 1.3% |
| `countries` | 509,565,635 | 509565635 | 66.1% |
| `education` | 160,357,161 | 160357161 | 20.8% |
| `education.degrees` | 37,492,292 | 37492292 | 4.9% |
| `education.end_date` | 48,754,465 | 48754465 | 6.3% |
| `education.gpa` | 3,129,309 | 3129309 | 0.4% |
| `education.majors` | 49,895,265 | 49895265 | 6.5% |
| `education.minors` | 845,555 | 845555 | 0.1% |
| `education.raw` | 67,395,891 | 67395891 | 8.7% |
| `education.school` | 160,305,536 | 160305536 | 20.8% |
| `education.school.domain` | 112,697,383 | 112697383 | 14.6% |
| `education.school.facebook_url` | 70,612,198 | 70612198 | 9.2% |
| `education.school.id` | 117,392,868 | 117392868 | 15.2% |
| `education.school.linkedin_id` | 117,392,868 | 117392868 | 15.2% |
| `education.school.linkedin_url` | 117,390,360 | 117390360 | 15.2% |
| `education.school.location` | 99,238,214 | 99238214 | 12.9% |
| `education.school.location.continent` | 99,238,214 | 99238214 | 12.9% |
| `education.school.location.country` | 99,238,213 | 99238213 | 12.9% |
| `education.school.location.locality` | 96,402,386 | 96402386 | 12.5% |
| `education.school.location.name` | 99,238,214 | 99238214 | 12.9% |
| `education.school.location.region` | 97,587,073 | 97587073 | 12.7% |
| `education.school.name` | 160,305,345 | 160305345 | 20.8% |
| `education.school.raw` | 160,155,501 | 160155501 | 20.8% |
| `education.school.twitter_url` | 69,174,865 | 69174865 | 9.0% |
| `education.school.type` | 129,345,601 | 129345601 | 16.8% |
| `education.school.website` | 112,697,383 | 112697383 | 14.6% |
| `education.start_date` | 41,023,074 | 41023074 | 5.3% |
| `education.summary` | 15,483,878 | 15483878 | 2.0% |
| `emails` | 219,520,125 | 219520125 | 28.5% |
| `emails.address` | 219,520,125 | 219520125 | 28.5% |
| `emails.first_seen` | 219,520,125 | 219520125 | 28.5% |
| `emails.last_seen` | 219,520,125 | 219520125 | 28.5% |
| `emails.md5_hash` | 219,520,125 | 219520125 | 28.5% |
| `emails.num_sources` | 219,520,125 | 219520125 | 28.5% |
| `emails.sha_256_hash` | 219,520,125 | 219520125 | 28.5% |
| `emails.type` | 199,503,925 | 199503925 | 25.9% |
| `experience` | 169,257,760 | 169257760 | 22.0% |
| `experience.company` | 166,413,916 | 166413916 | 21.6% |
| `experience.company.facebook_url` | 74,233,192 | 74233192 | 9.6% |
| `experience.company.founded` | 86,804,506 | 86804506 | 11.3% |
| `experience.company.id` | 111,573,018 | 111573018 | 14.5% |
| `experience.company.industry` | 107,543,064 | 107543064 | 14.0% |
| `experience.company.industry_v2` | 103,490,849 | 103490849 | 13.4% |
| `experience.company.linkedin_id` | 111,573,018 | 111573018 | 14.5% |
| `experience.company.linkedin_url` | 111,573,018 | 111573018 | 14.5% |
| `experience.company.location` | 108,648,269 | 108648269 | 14.1% |
| `experience.company.location.address_line_2` | 23,550,237 | 23550237 | 3.1% |
| `experience.company.location.continent` | 108,431,628 | 108431628 | 14.1% |
| `experience.company.location.country` | 108,648,089 | 108648089 | 14.1% |
| `experience.company.location.geo` | 103,923,200 | 103923200 | 13.5% |
| `experience.company.location.locality` | 104,526,951 | 104526951 | 13.6% |
| `experience.company.location.metro` | 80,188,838 | 80188838 | 10.4% |
| `experience.company.location.name` | 108,648,269 | 108648269 | 14.1% |
| `experience.company.location.postal_code` | 96,326,143 | 96326143 | 12.5% |
| `experience.company.location.region` | 104,941,896 | 104941896 | 13.6% |
| `experience.company.location.street_address` | 93,435,157 | 93435157 | 12.1% |
| `experience.company.name` | 166,410,351 | 166410351 | 21.6% |
| `experience.company.raw` | 166,410,805 | 166410805 | 21.6% |
| `experience.company.size` | 111,573,018 | 111573018 | 14.5% |
| `experience.company.ticker` | 25,768,177 | 25768177 | 3.3% |
| `experience.company.twitter_url` | 67,010,695 | 67010695 | 8.7% |
| `experience.company.type` | 111,573,018 | 111573018 | 14.5% |
| `experience.company.website` | 103,343,267 | 103343267 | 13.4% |
| `experience.end_date` | 51,404,837 | 51404837 | 6.7% |
| `experience.first_seen` | 169,257,760 | 169257760 | 22.0% |
| `experience.is_primary` | 169,257,760 | 169257760 | 22.0% |
| `experience.last_seen` | 169,257,760 | 169257760 | 22.0% |
| `experience.location_names` | 82,380,054 | 82380054 | 10.7% |
| `experience.num_sources` | 169,257,760 | 169257760 | 22.0% |
| `experience.start_date` | 84,958,801 | 84958801 | 11.0% |
| `experience.summary` | 38,242,056 | 38242056 | 5.0% |
| `experience.title` | 126,347,262 | 126347262 | 16.4% |
| `experience.title.class` | 98,466,557 | 98466557 | 12.8% |
| `experience.title.levels` | 57,385,705 | 57385705 | 7.4% |
| `experience.title.name` | 126,347,262 | 126347262 | 16.4% |
| `experience.title.raw` | 126,347,262 | 126347262 | 16.4% |
| `experience.title.role` | 98,466,557 | 98466557 | 12.8% |
| `experience.title.sub_role` | 89,009,942 | 89009942 | 11.5% |
| `facebook_friends` | 14,082,877 | 14082877 | 1.8% |
| `facebook_id` | 439,949,605 | 439949605 | 57.1% |
| `facebook_url` | 235,986,826 | 235986826 | 30.6% |
| `facebook_username` | 235,986,826 | 235986826 | 30.6% |
| `first_name` | 770,761,928 | 770761928 | 100.0% |
| `first_seen` | 770,761,928 | 770761928 | 100.0% |
| `full_name` | 770,761,928 | 770761928 | 100.0% |
| `github_url` | 523,470 | 523470 | 0.1% |
| `github_username` | 523,470 | 523470 | 0.1% |
| `headline` | 40,384,069 | 40384069 | 5.2% |
| `id` | 770,761,928 | 770761928 | 100.0% |
| `industry` | 70,241,275 | 70241275 | 9.1% |
| `inferred_salary` | 48,983,392 | 48983392 | 6.4% |
| `inferred_years_experience` | 84,480,185 | 84480185 | 11.0% |
| `interests` | 65,438,355 | 65438355 | 8.5% |
| `job_company_12mo_employee_growth_rate` | 54,130,941 | 54130941 | 7.0% |
| `job_company_employee_count` | 54,505,983 | 54505983 | 7.1% |
| `job_company_facebook_url` | 31,530,964 | 31530964 | 4.1% |
| `job_company_founded` | 40,202,076 | 40202076 | 5.2% |
| `job_company_id` | 54,510,665 | 54510665 | 7.1% |
| `job_company_industry` | 52,493,667 | 52493667 | 6.8% |
| `job_company_industry_v2` | 49,716,924 | 49716924 | 6.5% |
| `job_company_inferred_revenue` | 54,505,983 | 54505983 | 7.1% |
| `job_company_linkedin_id` | 54,510,665 | 54510665 | 7.1% |
| `job_company_linkedin_url` | 54,510,665 | 54510665 | 7.1% |
| `job_company_location_address_line_2` | 7,088,737 | 7088737 | 0.9% |
| `job_company_location_continent` | 52,279,139 | 52279139 | 6.8% |
| `job_company_location_country` | 52,449,840 | 52449840 | 6.8% |
| `job_company_location_geo` | 49,818,745 | 49818745 | 6.5% |
| `job_company_location_locality` | 50,148,564 | 50148564 | 6.5% |
| `job_company_location_metro` | 38,178,053 | 38178053 | 5.0% |
| `job_company_location_name` | 52,449,983 | 52449983 | 6.8% |
| `job_company_location_postal_code` | 44,015,901 | 44015901 | 5.7% |
| `job_company_location_region` | 50,427,934 | 50427934 | 6.5% |
| `job_company_location_street_address` | 42,465,186 | 42465186 | 5.5% |
| `job_company_name` | 77,043,420 | 77043420 | 10.0% |
| `job_company_size` | 54,510,665 | 54510665 | 7.1% |
| `job_company_ticker` | 8,393,596 | 8393596 | 1.1% |
| `job_company_total_funding_raised` | 13,772,770 | 13772770 | 1.8% |
| `job_company_twitter_url` | 26,196,006 | 26196006 | 3.4% |
| `job_company_type` | 54,510,665 | 54510665 | 7.1% |
| `job_company_website` | 49,273,528 | 49273528 | 6.4% |
| `job_history` | 169,305,938 | 169305938 | 22.0% |
| `job_history.company_id` | 114,648,178 | 114648178 | 14.9% |
| `job_history.company_name` | 166,626,426 | 166626426 | 21.6% |
| `job_history.first_seen` | 169,305,938 | 169305938 | 22.0% |
| `job_history.last_seen` | 169,305,938 | 169305938 | 22.0% |
| `job_history.num_sources` | 169,305,938 | 169305938 | 22.0% |
| `job_history.title` | 126,422,882 | 126422882 | 16.4% |
| `job_last_changed` | 78,721,100 | 78721100 | 10.2% |
| `job_last_verified` | 78,721,100 | 78721100 | 10.2% |
| `job_onet_broad_occupation` | 40,557,060 | 40557060 | 5.3% |
| `job_onet_code` | 40,557,060 | 40557060 | 5.3% |
| `job_onet_major_group` | 40,557,060 | 40557060 | 5.3% |
| `job_onet_minor_group` | 40,557,060 | 40557060 | 5.3% |
| `job_onet_specific_occupation` | 40,557,060 | 40557060 | 5.3% |
| `job_onet_specific_occupation_detail` | 15,454,055 | 15454055 | 2.0% |
| `job_start_date` | 62,431,487 | 62431487 | 8.1% |
| `job_summary` | 16,480,520 | 16480520 | 2.1% |
| `job_title` | 73,563,001 | 73563001 | 9.5% |
| `job_title_class` | 54,167,855 | 54167855 | 7.0% |
| `job_title_levels` | 26,821,442 | 26821442 | 3.5% |
| `job_title_role` | 54,167,855 | 54167855 | 7.0% |
| `job_title_sub_role` | 45,017,497 | 45017497 | 5.8% |
| `languages` | 155,025,966 | 155025966 | 20.1% |
| `languages.name` | 155,025,966 | 155025966 | 20.1% |
| `languages.proficiency` | 2,168,690 | 2168690 | 0.3% |
| `last_initial` | 770,761,928 | 770761928 | 100.0% |
| `last_name` | 770,333,660 | 770333660 | 99.9% |
| `linkedin_connections` | 75,253,611 | 75253611 | 9.8% |
| `linkedin_id` | 70,038,759 | 70038759 | 9.1% |
| `linkedin_url` | 73,827,986 | 73827986 | 9.6% |
| `linkedin_username` | 73,827,986 | 73827986 | 9.6% |
| `location_address_line_2` | 29,985,176 | 29985176 | 3.9% |
| `location_continent` | 509,565,902 | 509565902 | 66.1% |
| `location_country` | 509,565,238 | 509565238 | 66.1% |
| `location_geo` | 485,740,172 | 485740172 | 63.0% |
| `location_last_updated` | 309,281,836 | 309281836 | 40.1% |
| `location_locality` | 486,832,863 | 486832863 | 63.2% |
| `location_metro` | 302,690,386 | 302690386 | 39.3% |
| `location_name` | 509,565,902 | 509565902 | 66.1% |
| `location_names` | 487,118,307 | 487118307 | 63.2% |
| `location_postal_code` | 273,148,982 | 273148982 | 35.4% |
| `location_region` | 506,183,329 | 506183329 | 65.7% |
| `location_street_address` | 262,348,889 | 262348889 | 34.0% |
| `middle_initial` | 243,873,033 | 243873033 | 31.6% |
| `middle_name` | 123,002,455 | 123002455 | 16.0% |
| `mobile_phone` | 485,540,161 | 485540161 | 63.0% |
| `name_aliases` | 61,396,034 | 61396034 | 8.0% |
| `num_records` | 770,761,928 | 770761928 | 100.0% |
| `num_sources` | 770,761,928 | 770761928 | 100.0% |
| `personal_emails` | 161,131,687 | 161131687 | 20.9% |
| `phone_numbers` | 770,761,928 | 770761928 | 100.0% |
| `phones` | 770,761,928 | 770761928 | 100.0% |
| `phones.first_seen` | 770,761,928 | 770761928 | 100.0% |
| `phones.last_seen` | 770,761,928 | 770761928 | 100.0% |
| `phones.num_sources` | 770,761,928 | 770761928 | 100.0% |
| `phones.number` | 770,761,928 | 770761928 | 100.0% |
| `possible_birth_dates` | 99,797,175 | 99797175 | 12.9% |
| `possible_emails` | 54,577,882 | 54577882 | 7.1% |
| `possible_emails.address` | 54,577,882 | 54577882 | 7.1% |
| `possible_emails.first_seen` | 54,577,882 | 54577882 | 7.1% |
| `possible_emails.last_seen` | 54,577,882 | 54577882 | 7.1% |
| `possible_emails.md5_hash` | 54,577,882 | 54577882 | 7.1% |
| `possible_emails.num_sources` | 54,577,882 | 54577882 | 7.1% |
| `possible_emails.sha_256_hash` | 54,577,882 | 54577882 | 7.1% |
| `possible_emails.type` | 47,275,650 | 47275650 | 6.1% |
| `possible_location_names` | 436,802,520 | 436802520 | 56.7% |
| `possible_phones` | 22,443,701 | 22443701 | 2.9% |
| `possible_phones.first_seen` | 22,443,701 | 22443701 | 2.9% |
| `possible_phones.last_seen` | 22,443,701 | 22443701 | 2.9% |
| `possible_phones.num_sources` | 22,443,701 | 22443701 | 2.9% |
| `possible_phones.number` | 22,443,701 | 22443701 | 2.9% |
| `possible_profiles` | 36,953,668 | 36953668 | 4.8% |
| `possible_profiles.first_seen` | 36,953,668 | 36953668 | 4.8% |
| `possible_profiles.id` | 28,744,034 | 28744034 | 3.7% |
| `possible_profiles.last_seen` | 36,953,668 | 36953668 | 4.8% |
| `possible_profiles.network` | 36,953,668 | 36953668 | 4.8% |
| `possible_profiles.num_sources` | 36,953,668 | 36953668 | 4.8% |
| `possible_profiles.url` | 36,953,668 | 36953668 | 4.8% |
| `possible_profiles.username` | 19,403,594 | 19403594 | 2.5% |
| `possible_street_addresses` | 18,081,150 | 18081150 | 2.3% |
| `possible_street_addresses.address_line_2` | 3,935,274 | 3935274 | 0.5% |
| `possible_street_addresses.continent` | 18,081,150 | 18081150 | 2.3% |
| `possible_street_addresses.country` | 18,081,150 | 18081150 | 2.3% |
| `possible_street_addresses.first_seen` | 18,081,150 | 18081150 | 2.3% |
| `possible_street_addresses.geo` | 18,080,564 | 18080564 | 2.3% |
| `possible_street_addresses.last_seen` | 18,081,150 | 18081150 | 2.3% |
| `possible_street_addresses.locality` | 18,080,982 | 18080982 | 2.3% |
| `possible_street_addresses.metro` | 15,555,215 | 15555215 | 2.0% |
| `possible_street_addresses.name` | 18,081,150 | 18081150 | 2.3% |
| `possible_street_addresses.num_sources` | 18,081,150 | 18081150 | 2.3% |
| `possible_street_addresses.postal_code` | 17,908,450 | 17908450 | 2.3% |
| `possible_street_addresses.region` | 18,081,045 | 18081045 | 2.3% |
| `possible_street_addresses.street_address` | 18,081,150 | 18081150 | 2.3% |
| `profiles` | 515,241,796 | 515241796 | 66.8% |
| `profiles.first_seen` | 515,241,796 | 515241796 | 66.8% |
| `profiles.id` | 493,181,869 | 493181869 | 64.0% |
| `profiles.last_seen` | 515,241,796 | 515241796 | 66.8% |
| `profiles.network` | 515,241,796 | 515241796 | 66.8% |
| `profiles.num_sources` | 515,241,796 | 515241796 | 66.8% |
| `profiles.url` | 515,241,796 | 515241796 | 66.8% |
| `profiles.username` | 296,203,988 | 296203988 | 38.4% |
| `recommended_personal_email` | 161,113,062 | 161113062 | 20.9% |
| `regions` | 506,562,086 | 506562086 | 65.7% |
| `sex` | 600,178,034 | 600178034 | 77.9% |
| `skills` | 39,333,352 | 39333352 | 5.1% |
| `street_addresses` | 268,291,053 | 268291053 | 34.8% |
| `street_addresses.address_line_2` | 87,183,149 | 87183149 | 11.3% |
| `street_addresses.continent` | 268,291,053 | 268291053 | 34.8% |
| `street_addresses.country` | 268,291,053 | 268291053 | 34.8% |
| `street_addresses.first_seen` | 268,291,053 | 268291053 | 34.8% |
| `street_addresses.geo` | 267,987,952 | 267987952 | 34.8% |
| `street_addresses.last_seen` | 268,291,053 | 268291053 | 34.8% |
| `street_addresses.locality` | 268,000,395 | 268000395 | 34.8% |
| `street_addresses.metro` | 230,776,968 | 230776968 | 29.9% |
| `street_addresses.name` | 268,291,053 | 268291053 | 34.8% |
| `street_addresses.num_sources` | 268,291,053 | 268291053 | 34.8% |
| `street_addresses.postal_code` | 267,293,401 | 267293401 | 34.7% |
| `street_addresses.region` | 268,032,920 | 268032920 | 34.8% |
| `street_addresses.street_address` | 268,291,053 | 268291053 | 34.8% |
| `summary` | 27,481,743 | 27481743 | 3.6% |
| `twitter_url` | 4,989,176 | 4989176 | 0.6% |
| `twitter_username` | 4,989,176 | 4989176 | 0.6% |
| `work_email` | 25,887,333 | 25887333 | 3.4% |

*Stats shown are accurate as of data version 33.1*

Updated 6 days ago

---

Did this page help you?

Yes

No

---
# https://docs.peopledatalabs.com/docs/autocomplete-api-quickstart

## Simple Example

Let's say that you are interested in getting all schools that begin with "harv." The Autocomplete API is the perfect tool for doing this, as it allows you to find multiple schools using a small set of input characteristics.

The [list of supported inputs](/docs/input-parameters-autocomplete-api) includes the field that you're seeking and the text that you want to complete. In this example, we'll use the following parameters:

**Input Parameters**

| Parameter Name | Parameter Value |
| --- | --- |
| [`field`](/docs/input-parameters-autocomplete-api#field) | `school` |
| [`text`](/docs/input-parameters-autocomplete-api#text) | `harv` |
| [`size`](/docs/input-parameters-autocomplete-api#size) | `10` |
| [`titlecase`](/docs/input-parameters-autocomplete-api#titlecase) | `True` |
| [`pretty`](/docs/input-parameters-autocomplete-api#pretty) | `True` |

Using this information, you can now query the Autocomplete API to find schools beginning with "harv":

Python3 SDKcURLJavaScriptRubyGoPython3

```
import json

# See https://github.com/peopledatalabs/peopledatalabs-python
from peopledatalabs import PDLPY

# Create a client, specifying your API key
CLIENT = PDLPY(
    api_key="YOUR API KEY",
)

# Create a parameters JSON object
PARAMS = {
    "field": "school",
    "text": "harv",
    "size": 10,
    "titlecase": True,
    "pretty": True
}

# Pass the parameters object to the Autocomplete API
json_response = CLIENT.autocomplete(**PARAMS).json()

# Print the API response in JSON format
print(json_response)
```

```
curl -X GET -G \
  'https://api.peopledatalabs.com/v5/autocomplete'\
  -H 'X-Api-Key: xxxx' \
  --data-urlencode 'field=school'\
  --data-urlencode 'text=harv'\
  --data-urlencode 'titlecase=true'\
  --data-urlencode 'size=10'
```

```
// See https://github.com/peopledatalabs/peopledatalabs-js
import PDLJS from 'peopledatalabs';

// Create a client, specifying your API key
const PDLJSClient = new PDLJS({ apiKey: "YOUR API KEY" });

// Create a parameters JSON object
const params = {
    "field": "school",
    "text": "harv",
    "size": 10,
    "titlecase"; true,
    "pretty": true
}

// Pass the parameters object to the Autocomplete API
PDLJSClient.autocomplete(params).then((data) => {
    // Print the API response in JSON format
    console.log(data);
}).catch((error) => {
    console.log(error);
});
```

```
# See https://github.com/peopledatalabs/peopledatalabs-ruby
require 'peopledatalabs'

# Set your API key
Peopledatalabs.api_key = 'YOUR API KEY'

# Pass parameters to the Autocomplete API
json_response = Peopledatalabs::Autocomplete.retrieve(field: "school", text: "harv", size: 10, titlecase: true, pretty: true)

# Print the API response in JSON format
puts JSON.dump(json_response)
```

```
package main

import (
    "fmt"
    "encoding/json"
    "context"
)

// See https://github.com/peopledatalabs/peopledatalabs-go
import (
    pdl "github.com/peopledatalabs/peopledatalabs-go"
    pdlmodel "github.com/peopledatalabs/peopledatalabs-go/model"
)

func main() {
    // Set your API key
    apiKey := "YOUR API KEY"
    // Set API key as environmental variable
    // apiKey := os.Getenv("API_KEY")

    // Create a client, specifying your API key
    client := pdl.New(apiKey)
    
    // Create a parameters JSON object
    params := pdlmodel.AutocompleteParams {
        BaseParams: pdlmodel.BaseParams {
            Size: 10,
            Titlecase: true
            Pretty: true,
        },
        AutocompleteBaseParams: pdlmodel.AutocompleteBaseParams {
            Field: "school",
            Text: "harv",
        },
      
        AdditionalParams: pdlmodel.AdditionalParams {
            TitleCase: true,
        },
    }
    
    // Pass the parameters object to the Autocomplete API
    response, err := client.Autocomplete(context.Background(), params)
    // Check for successful response
    if err == nil {
        // Convert the API response to JSON
        jsonResponse, jsonErr := json.Marshal(response)
        // Print the API response
        if (jsonErr == nil) {
            fmt.Println(string(jsonResponse))
        }
    }
}
```

```
import requests, json

# Set your API key
API_KEY = "YOUR API KEY"

# Set the Autocomplete API URL
PDL_URL = "https://api.peopledatalabs.com/v5/autocomplete"

# Create a parameters JSON object
PARAMS = {
    "api_key": API_KEY,
    "field": "school",
    "text": "harv",
    "size": 10,
    "titlecase": True,
    "pretty": True
}

# Pass the parameters object to the Autocomplete API
json_response = requests.get(PDL_URL, params=PARAMS).json()

# Print the API response in JSON format
print(json_response)
```

The response that the API returns is as follows:

JSON

```
{
  "data": [
    {
      "name": "Harvard University",
      "count": 1927529,
      "meta": {
        "id": "3533/1_nmK6OO9uG-7wiyTDSIrDiA_0",
        "website": "harvard.edu",
        "location_name": "Cambridge, Massachusetts, United States"
      }
    },
    ...
  ],
    "fields": [
    "education.school.name"
  ],
  "status": 200
}
```

You can see the full response here:

Full Response (click to toggle):

JSON

```
{
  "data": [
    {
      "name": "Harvard University",
      "count": 1927529,
      "meta": {
        "id": "3533/1_nmK6OO9uG-7wiyTDSIrDiA_0",
        "website": "harvard.edu",
        "location_name": "Cambridge, Massachusetts, United States"
      }
    },
    {
      "name": "Harvard Business School",
      "count": 220817,
      "meta": {
        "id": "3533/1_qBjTBJNpBK2gzteZ59vd8A_0",
        "website": "hbs.edu",
        "location_name": "Boston, Massachusetts, United States"
      }
    },
    {
      "name": "Harvard - Westlake School",
      "count": 124263,
      "meta": {
        "id": "3533/1_NH1qPhIlKjFKZ1nf2Qgt3g_0",
        "website": "hw.com",
        "location_name": "Studio City, California, United States"
      }
    },
    {
      "name": "Harvard Law School",
      "count": 96958,
      "meta": {
        "id": "3533/1_teCnNBZuJ7ec9lfQzEOvyg_0",
        "website": "hls.harvard.edu",
        "location_name": "Cambridge, Massachusetts, United States"
      }
    },
    {
      "name": "Harvard Business School Online",
      "count": 70877,
      "meta": {
        "id": "3533/1_UB212jNfQFFVng4KfGkYlQ_0",
        "website": "online.hbs.edu",
        "location_name": "Boston, Massachusetts, United States"
      }
    },
    {
      "name": "Harvard Medical School",
      "count": 61403,
      "meta": {
        "id": "3533/1_YNnwi4r2jhgVlAvd7O400Q_0",
        "website": "hms.harvard.edu",
        "location_name": "Boston, Massachusetts, United States"
      }
    },
    {
      "name": "Harvard Extension School",
      "count": 38259,
      "meta": {
        "id": "3861/1_hJfk3w2iEDrBWBdwlSOyzg_0"
      }
    },
    {
      "name": "Harvard Graduate School of Education",
      "count": 31485,
      "meta": {
        "id": "3533/1_R-t9DblDP5zWHDnIlJjY9g_0",
        "website": "gse.harvard.edu",
        "location_name": "Cambridge, Massachusetts, United States"
      }
    },
    {
      "name": "Harvard Kennedy School",
      "count": 30697,
      "meta": {
        "id": "3533/1_nTJjAd36aI1cfDBojvtlHA_0",
        "website": "hks.harvard.edu",
        "location_name": "Cambridge, Massachusetts, United States"
      }
    },
    {
      "name": "Harvard Business School Executive Education",
      "count": 27768,
      "meta": {
        "id": "3533/1_HTv2bAJvLvwEEeG0ai63BQ_0",
        "website": "hbs.me",
        "location_name": "Boston, Massachusetts, United States"
      }
    }
  ],
  "fields": [
    "education.school.name"
  ],
  "status": 200
}
```

Updated 4 months ago

---

Did this page help you?

Yes

No

---
# https://docs.peopledatalabs.com/docs/legacy-mapping-title-subroles-to-roles-prev-v271

> â—ï¸
>
> ### Deprecated as of v29.1 (Feb 2025)
>
> As of v29.1 (Feb 2025), **the Role / Sub Role Taxonomy on this page is no longer supported in our datasets**.
>
> This page contains the legacy taxonomy prior to the release of our improved Role / Sub Role Taxonomy in Feb 2025, and is provided for historical documentation purposes.
>
> For the currently supported roles values, please see: [Mapping Title Subroles to Roles](/docs/title-subroles-to-roles).
>
> For more information, please see our [February 2025 Release Notes (v29.1)](/changelog/february-2025-release-notes-v291).

| subrole | role |
| --- | --- |
| customer\_success | customer\_service |
| support | customer\_service |
| graphic\_design | design |
| product\_design | design |
| web\_design | design |
| education\_administration | education |
| professor | education |
| instructor | education |
| researcher | education |
| teacher | education |
| data | engineering |
| devops | engineering |
| electrical | engineering |
| information\_technology | engineering |
| mechanical | engineering |
| network | engineering |
| project\_engineering | engineering |
| quality\_assurance | engineering |
| security | engineering |
| software | engineering |
| systems | engineering |
| web | engineering |
| accounting | finance |
| investment | finance |
| tax | finance |
| dental | health |
| doctor | health |
| fitness | health |
| nursing | health |
| therapy | health |
| wellness | health |
| compensation | human\_resources |
| employee\_development | human\_resources |
| recruiting | human\_resources |
| judicial | legal |
| lawyer | legal |
| paralegal | legal |
| brand\_marketing | marketing |
| content\_marketing | marketing |
| product\_marketing | marketing |
| marketing\_communications | marketing |
| broadcasting | media |
| editorial | media |
| journalism | media |
| video | media |
| writing | media |
| logistics | operations |
| office\_management | operations |
| product | operations |
| project\_management | operations |
| events | public\_relations |
| media\_relations | public\_relations |
| property\_management | real\_estate |
| realtor | real\_estate |
| accounts | sales |
| business\_development | sales |
| pipeline | sales |

*Contents of this table were sourced from the following file on our public S3 bucket:[sub\_roles.txt](https://pdl-prod-schema.s3.us-west-2.amazonaws.com/28.0/enums/sub_roles.txt)*

  

## See Also

* [Job Title Roles](/docs/job-title-roles)
* [Job Title Subroles](/docs/job-title-subroles)

Updated 4 months ago

---

Did this page help you?

Yes

No

---
# https://docs.peopledatalabs.com/docs/output-response-autocomplete-api

## Response Data Structure

### Abridged Response Data Structure

Here is an example response from the Autocomplete API when querying for `field = "company"` and `text = "goog"`:

JSON

```
{
  "data": [
    {
      "name": "Google",
      "count": 197302,
      "meta": {
        "id": "aKCIYBNF9ey6o5CjHCCO4goHYKlf",
        "website": "google.com",
        "industry": "Internet",
        "location_name": "Mountain View, California, United States",
        "display_name": "Google",
        "display_name_history": [
          "Google"
        ],
        "alternative_names": [
          "\u8c37\u6b4c",
          "Google, Social Marketing Tools",
          "\uad6c\uae00",
          "Google Inc.",
          "Google Pay",
          "Google, Inc.",
          "Google Deepmind",
          "Google Inc",
          "Google Digital Skills for Africa",
          "Google, Inc"
        ]
      }
    },
   ...
  ],
  "fields": [
    "job_company_name",
    "experience.company.name"
  ],
  "status": 200
}
```

### Full Example Response

Full Output Response (click to expand)

JSON

```
{
  "data": [
    {
      "name": "Google",
      "count": 197302,
      "meta": {
        "id": "aKCIYBNF9ey6o5CjHCCO4goHYKlf",
        "website": "google.com",
        "industry": "Internet",
        "location_name": "Mountain View, California, United States",
        "display_name": "Google",
        "display_name_history": [
          "Google"
        ],
        "alternative_names": [
          "\u8c37\u6b4c",
          "Google, Social Marketing Tools",
          "\uad6c\uae00",
          "Google Inc.",
          "Google Pay",
          "Google, Inc.",
          "Google Deepmind",
          "Google Inc",
          "Google Digital Skills for Africa",
          "Google, Inc"
        ]
      }
    },
    {
      "name": "Google Operations Center",
      "count": 4032,
      "meta": {
        "id": "T0pYt4X5ITzm8Uj41SnuoAbuEQG9",
        "website": "googleoperationscenter.com",
        "industry": "Internet",
        "display_name": "Google Operations Center",
        "display_name_history": [
          "Google Operations Center"
        ],
        "alternative_names": [
          "Google",
          "Google Data Center",
          "Google Operations Center.",
          "Google Operations Center Philippines",
          "Associated Engineering Surveyors Limited",
          "Google Operations",
          "Google Operation Center",
          "Google Express",
          "Google/Google Operations Center",
          "Metas of Seventh Day Adventists School"
        ]
      }
    },
    {
      "name": "Bangkit Academy Led by Google, Tokopedia, Gojek, & Traveloka",
      "count": 3705,
      "meta": {
        "id": "cr3tG4Z9VAknYR7HMY35rAaIXxtL",
        "website": "bangkit.academy",
        "industry": "Information Technology and Services",
        "location_name": "Jakarta, Indonesia",
        "display_name": "Bangkit Academy led by Google, Tokopedia, Gojek, & Traveloka",
        "display_name_history": [
          "Bangkit Academy led by Google, Tokopedia, Gojek, & Traveloka"
        ],
        "alternative_names": [
          "Google Bangkit",
          "Bangkit Academy Led by Google, Tokopedia, Gojek & Traveloka",
          "Bangkit",
          "Bangkit Led by Google, Tokopedia, Gojek & Traveloka",
          "Bangkit Academy Led by Google, Tokopedia, Gojek, & Traveloka Participant",
          "Bangkit Academy L",
          "Bangkit Academy Led by Google, Goto, & Traveloka",
          "Bangkit Academy Led Google, Tokopedia, Gojek & Traveloka",
          "Bangkit Academy",
          "Bangk"
        ]
      }
    },
    {
      "name": "Google Developer Student Clubs",
      "count": 2911,
      "meta": {
        "id": "G0b4fuHWApIrWFIg8Yw3AQlChpWJ",
        "website": "developers.google.com/community/gdsc",
        "industry": "Education Management",
        "location_name": "Pune, Maharashtra, India",
        "display_name": "Google Developer Student Clubs",
        "display_name_history": [
          "DSC JSCOE, Pune",
          "Google Developer Student Clubs"
        ],
        "alternative_names": [
          "DSC Jscoe, Pune",
          "Google Developer Student Clubs Iipe Visakhapatnam",
          "Google Developer Student Club",
          "Google Developer Student Clubs- Srcasw",
          "Google Developer Student Club - Bu",
          "Google Developer Student Clubs at Pnu",
          "Google Developer Student Clubs Universitas Muhammadiyah Malang",
          "Google Developer Student Clubs - Federal University Dutsin-Ma.",
          "Google Developer Student Clubs @ Queen's University",
          "Google Developer Student Clubs Oau"
        ]
      }
    },
    {
      "name": "Google Adsense",
      "count": 2105,
      "meta": {
        "id": "96xZ8JtUnvLnlB8jpFGrsgH2q6OY",
        "website": "google.com/adsense",
        "industry": "Consumer Services",
        "location_name": "Mountain View, California, United States",
        "display_name": "Google AdSense",
        "display_name_history": [
          "Google AdSense"
        ],
        "alternative_names": [
          "Google",
          "Wahana Kerja Indonesia",
          "Google ph.g, HTC Champions, Lg Ambassadors",
          "thecspedia.com",
          "Gtplast Ab",
          "Blogger",
          "Google Adsense, Facebook Ads, Google Adwords, Affiliate Marketing",
          "Google Adsense and Amazon Product Ranking",
          "Self-Employed",
          "Google LLC"
        ]
      }
    },
    {
      "name": "Google Deepmind",
      "count": 1934,
      "meta": {
        "id": "StyaWCIGgDNCuBaCNAhGWwCKPEQb",
        "website": "deepmind.google",
        "industry": "Research",
        "location_name": "London, United Kingdom",
        "display_name": "Google DeepMind",
        "display_name_history": [
          "Google DeepMind",
          "DeepMind"
        ],
        "alternative_names": [
          "Deepmind",
          "Deepmind Health",
          "Deepmind / Google Health",
          "Building Something New",
          "Self-Employed",
          "Deepmind Technlogies",
          "Deepmind (Google)",
          "Deepmind Technologies",
          "Google, Google Health"
        ]
      }
    },
    {
      "name": "Mandiant",
      "count": 1522,
      "meta": {
        "id": "yWcH1EiAH4BCKHMSP57f6wRIccqa",
        "website": "mandiant.com",
        "industry": "Computer & Network Security",
        "location_name": "Reston, Virginia, United States",
        "display_name": "Mandiant",
        "display_name_history": [
          "Mandiant (now part of Google Cloud)",
          "Mandiant"
        ],
        "alternative_names": [
          "Mandiant (Now Part of Google Cloud)",
          "Mandiant, a Fireeye Company",
          "Mandiant a Fireeye Company",
          "Mandiant (Acquired by Fireeye)",
          "Mandiant / Fireeye",
          "Mandiant, a Division of Fireeye",
          "Mandiant Security Consulting",
          "Mandiant Threat Intelligence",
          "Fireeye/Mandiant",
          "Mandiant Corporation"
        ]
      }
    },
    {
      "name": "Developer Students",
      "count": 1073,
      "meta": {
        "id": "fUCW2Lc4PFzqyOCuuxtPlQhpN53H",
        "website": "developers.google.com/community/dsc",
        "industry": "Education Management",
        "location_name": "San Francisco, California, United States",
        "display_name": "Developer Students",
        "display_name_history": [
          "Developer Students",
          "Google Developer Student Clubs",
          "Developer Student Clubs"
        ],
        "alternative_names": [
          "Google Developer Student Clubs",
          "Developer Student Clubs",
          "Google Developer Student Clubs (Canada & Usa)",
          "Developer Student Clubs - North America",
          "Developer Student Clubs - Na",
          "Google Developer Student Clubs #Developerstudentclubs",
          "Developers",
          "Google Developper Student Club",
          "Developer Student Clubs - Qmul",
          "Developer Student Clubs - Amity University, Noida."
        ]
      }
    },
    {
      "name": "Google Developers",
      "count": 941,
      "meta": {
        "id": "rXDaaEKS6y8krSdQQFuqfwvAVJmy",
        "website": "developers.google.com",
        "industry": "Internet",
        "location_name": "Mountain View, California, United States",
        "display_name": "Google Developers",
        "display_name_history": [
          "Google Developers"
        ],
        "alternative_names": [
          "Google",
          "Google Developers Students Club Utp",
          "Google Developers Experts Program",
          "Google Developer Student Clubs Ntou",
          "Developer Student Clubs - Muet Jamshoro",
          "Developers Student Club Al-Azhar - Powered by Google Developers",
          "Google Developer Student Club",
          "Google Africa",
          "Taiwan Cogeneration Corporation",
          "Google Women Techmakers"
        ]
      }
    },
    {
      "name": "Google Developers Group",
      "count": 814,
      "meta": {
        "id": "1U34ahOyq403GKx9nKM5yQuYs39E",
        "website": "developers.google.com/groups",
        "industry": "Computer Software",
        "display_name": "Google Developers Group",
        "display_name_history": [
          "Google Developers Group"
        ],
        "alternative_names": [
          "Google Developers Group Culiac\u00e1n (Comunidad)",
          "Google Developers",
          "Google",
          "Google Developers Group, Bhubaneshwar",
          "Self-Employed",
          "Google Developers Group 6 October",
          "Google Developers Group - Houston",
          "Google Developers Groups",
          "Google Developers Group Agadir",
          "Google Developers Group Mysuru"
        ]
      }
    }
  ],
  "fields": [
    "job_company_name",
    "experience.company.name"
  ],
  "status": 200
}
```

## Response Fields

### `fields`

| Type | Description |
| --- | --- |
| `Array (String)` | The list of fields in the [Person Schema](/docs/fields) that the Autocomplete API has returned suggestions for. It determines these based on the value that you used for the [`field` input parameter](/docs/input-parameters-autocomplete-api#field). |

See the [`field` input parameter description](/docs/input-parameters-autocomplete-api#field) for the mapping between Autocomplete API fields and Person Schema fields.

  

### `data`

| Type | Description |
| --- | --- |
| `Array (Object)` | The list of suggestions that the Autocomplete API has returned.  It sorts results in descending order based on `data.count`. The [`size` input parameter](/docs/input-parameters-autocomplete-api#size) determines the size of the list. |

  

### `data.count`

| Type | Description |
| --- | --- |
| `Integer` | The number of records in our [Person Dataset (resume slice)](/docs/resume-stats) for this Autocomplete suggestion. |

  

### `data.name`

| Type | Description |
| --- | --- |
| `String` | The plain text Autocomplete API suggestion. For example, company name, school name, location name, title and so forth. The prefix of this field will match the value of the [`text` input parameter](/docs/input-parameters-autocomplete-api#text). |

  

### `data.meta.*`

| Type | Description |
| --- | --- |
| `Object` | A set of additional fields that the API returns for each result in the data array. The metadata fields depend on the [`field` input parameter](/docs/input-parameters-autocomplete-api#field). |

The Autocomplete API returns some additional metadata fields along with autocomplete suggestion to provide additional context about it. The specific metadata fields that it returns depends on which [`field`](/docs/input-parameters-autocomplete-api#field) was set in the input parameters.

The tables below describe the metadata fields that the API returns for each input `field` parameter.

#### Metadata Fields for Company

*The metadata fields that the API returns when`field = "company"` in the input parameters:*

| Metadata Field | Type | Description | Example |
| --- | --- | --- | --- |
| `id` | `String` | The PDL ID for this company. | `tnHcNHbCv8MKeLh92946LAkX6PKg` |
| `website` | `String` | The website associated with this company. | `peopledatalabs.com` |
| `industry` | `Enum (String)` | The most relevant [industry](/docs/industries) for this company. | `internet` |
| `location_name` | `String` | The name of the most relevant location for this company. | `san francisco, california, united states` |
| `display_name` | `String` | The company name, capitalized using the companyâ€™s self-reported name. | `People Data Labs` |
| `display_name_history` | `Array [String]` | A list of the companyâ€™s historical primary names with proper capitalization. | `["People Data Labs"]` |
| `alternative_names` | `Array [String]` | A list of other names associated with this company. | `[]` |

#### Metadata Fields for Country

*The metadata fields that the API returns when`field = "country"` in the input parameters:*

| Metadata Field | Type | Description | Example |
| --- | --- | --- | --- |
| None | -- | -- | -- |

#### Metadata Fields for Industry

*The metadata fields that the API returns when`field = "industry"` in the input parameters:*

| Metadata Field | Type | Description | Example |
| --- | --- | --- | --- |
| None | -- | -- | -- |

#### Metadata Fields for Location

*The metadata fields that the API returns when`field = "location_name"` in the input parameters:*

| Metadata Field | Type | Description | Example |
| --- | --- | --- | --- |
| `country` | `Enum (String)` | The [country](/docs/location-countries) of this location. | `united states` |
| `locality` | `String` | The locality of this location. | `san francisco` |
| `metro` | `String` | The metro associated with this location. **Only returned for US-based locations.** | `san diego, california` |
| `region` | `String` | The region of this location. | `california` |

#### Metadata Fields for Major

*The metadata fields that the API returns when`field = "major"` in the input parameters:*

| Metadata Field | Type | Description | Example |
| --- | --- | --- | --- |
| None | -- | -- | -- |

#### Metadata Fields for Region

*The metadata fields that the API returns when`field = "region"` in the input parameters:*

| Metadata Field | Type | Description | Example |
| --- | --- | --- | --- |
| None | -- | -- | -- |

#### Metadata Fields for Role

*The metadata fields that the API returns when`field = "role"` in the input parameters:*

| Metadata Field | Type | Description | Example |
| --- | --- | --- | --- |
| None | -- | -- | -- |

#### Metadata Fields for Sub\_Role

*The metadata fields that the API returns when`field = "sub_role"` in the input parameters:*

| Metadata Field | Type | Description | Example |
| --- | --- | --- | --- |
| `role` | `Enum (String)` | The role associated with this subrole (see [Mapping Title Subroles to Roles](/docs/title-subroles-to-roles).) | `engineering` |

#### Metadata Fields for Class

*The metadata fields that the API returns when`field = "class"` in the input parameters:*

| Metadata Field | Type | Description | Example |
| --- | --- | --- | --- |
| None | -- | -- | -- |

#### Metadata Fields for School

*The metadata fields that the API returns when`field = "school"` in the input parameters:*

| Metadata Field | Type | Description | Example |
| --- | --- | --- | --- |
| `location_name` | `String` | The name of the most relevant location for this school. | `eugene, oregon, united states` |
| `website` | `String` | The website associated with this school. | `business.uoregon.edu` |
| `id` | `String` | The PDL ID for this school. | `a56df063-4562-4e59-bc4c-68b33c14df1e` â€‹ |

#### Metadata Fields for Skill

*The metadata fields that the API returns when`field = "skill"` in the input parameters:*

| Metadata Field | Type | Description | Example |
| --- | --- | --- | --- |
| None | -- | -- | -- |

#### Metadata Fields for Title

*The metadata fields that the API returns when`field = "title"` in the input parameters:*

| Metadata Field | Type | Description | Example |
| --- | --- | --- | --- |
| None | -- | -- | -- |

#### Metadata Fields for Website

*The metadata fields that the API returns when`field = "website"` in the input parameters:*

| Metadata Field | Type | Description | Example |
| --- | --- | --- | --- |
| `id` | `String` | The PDL ID for this company. | `tnHcNHbCv8MKeLh92946LAkX6PKg` |
| `website` | `String` | The website associated with this company. | `peopledatalabs.com` |
| `industry` | `Enum (String)` | The most relevant [industry](/docs/industries) for this company. | `internet` |
| `location_name` | `String` | The name of the most relevant location for this company. | `san francisco, california, united states` |
| `display_name` | `String` | The company name, capitalized using the companyâ€™s self-reported name. | `People Data Labs` |
| `display_name_history` | `Array [String]` | A list of the companyâ€™s historical primary names with proper capitalization. | `["People Data Labs"]` |
| `alternative_names` | `Array [String]` | A list of other names associated with this company. | `[]` |

  

### `status`

| Type | Description |
| --- | --- |
| `Integer` | The [API response code](/docs/errors). |

Updated 4 months ago

---

Did this page help you?

Yes

No

---
# https://docs.peopledatalabs.com/docs/quickstart-person-identify-api

## Getting Started

In order to use the Person Identify API, you must have an active API key. You can look up your API key by logging into our [self-serve dashboard](https://www.peopledatalabs.com/main/api-keys) and going to the API Keys section.

> ðŸ‘
>
> ### Need an API Key?
>
> If you don't have an API key, you can easily create one by [signing up](https://peopledatalabs.com/signup) for a self-serve account. Check out our [Self-Serve Quickstart Guide](https://blog.peopledatalabs.com/post/self-signup-api-quickstart), which walks you through the sign up process as well as how to use the self-serve API dashboard.

## Simple Example

Let's say that you want to find all the profiles associated with the CEO of People Data Labs, Sean Thorne. The Person Identify API is the perfect tool for doing this, as it allows you to find multiple profiles using a set of input characteristics, similar to our [Person Enrichment API](/docs/enrichment-api).

The [list of supported inputs](/docs/identify-api-input-parameters) includes names, email addresses, company information, profiles and much more. In this case, we'll assume all we have is Sean's name and his company's name:

**Input Parameters**

| Parameter Name | Parameter Value |
| --- | --- |
| [`first_name`](/docs/identify-api-input-parameters#first_name) | `sean` |
| [`last_name`](/docs/identify-api-input-parameters#last_name) | `thorne` |
| [`company`](/docs/identify-api-input-parameters#company) | `people data labs` |
| [`pretty`](/docs/identify-api-input-parameters#pretty) | `True` |

Using this information, you can now query the Person Identify API to find the profiles associated with Sean:

Python3 SDKcURLJavaScriptRubyGoPython3

```
import json

# See https://github.com/peopledatalabs/peopledatalabs-python
from peopledatalabs import PDLPY

# Create a client, specifying your API key
CLIENT = PDLPY(
    api_key="YOUR API KEY",
)

# Create a parameters JSON object
PARAMS = {
 "first_name": "sean", 
 "last_name": "thorne", 
 "company": "people data labs",
 "pretty": True
}

# Pass the parameters object to the Person Identify API
response_data = CLIENT.person.identify(**PARAMS).json()

# Check for successful response
if json_response["status"] == 200:
   # Create a list of matches
   identities = response_data['matches']

   # Print the matches in JSON format
   print(identities)
   print(f"Found {len(identities)} identities!")
else:
   print("Identify unsuccessful. See error and try again.")
   print("error:", json_response)
```

```
API_KEY="ENTER YOUR API KEY HERE"
curl -X GET -G \
 "https://api.peopledatalabs.com/v5/person/identify"\
 -H "X-Api-Key: ${API_KEY}" \
 --data-urlencode 'first_name=sean'\
 --data-urlencode 'last_name=thorne'\
 --data-urlencode 'company="people data labs"'\
 --data-urlencode 'pretty=True'
```

```
// See https://github.com/peopledatalabs/peopledatalabs-js
import PDLJS from 'peopledatalabs';

// Create a client, specifying your API key
const PDLJSClient = new PDLJS({ apiKey: "YOUR API KEY" });

// Create a parameters JSON object
const params = {
  first_name: "sean", 
  last_name: "thorne", 
  company: "people data labs",
  pretty: true,
}

// Pass the parameters object to the Person Identify API
PDLJSClient.person.identify(params).then((data) => {
  // Create a list of matches
  var identities = data["matches"]
  
  // Print the matches in JSON format
  console.log(identities);
  console.log(`Found ${identities.length} identities!`)
}).catch((error) => {
  console.log("Identify unsuccessful. See error and try again.")
  console.log(error);
});
```

```
# See https://github.com/peopledatalabs/peopledatalabs-ruby
require 'peopledatalabs'

# Set your API key
Peopledatalabs.api_key = 'YOUR API KEY'

# Create a parameters JSON object
PARAMS = {
 "first_name": "sean", 
 "last_name": "thorne", 
 "company": "people data labs",
 "pretty": true
}

# Pass the parameters object to the Person Identify API
response = Peopledatalabs::Identify.person(params: PARAMS)

# Check for successful response
if json_response['status'] == 200

    # Create a list of matches
    identities = response['matches']

    # Print the matches in JSON format
    puts identities
    puts "Found #{identities.length()} identities!"
    end
else
    puts "Identify unsuccessful. See error and try again."
    puts "error: #{json_response}"
end
```

```
package main

import (
    "fmt"
    "encoding/json"
    "context"
)

// See https://github.com/peopledatalabs/peopledatalabs-go
import (
    pdl "github.com/peopledatalabs/peopledatalabs-go"
    pdlmodel "github.com/peopledatalabs/peopledatalabs-go/model"
)

func main() {
    // Set your API key
    apiKey := "YOUR API KEY"
    // Set API key as environmental variable
    // apiKey := os.Getenv("API_KEY")

    // Create a client, specifying your API key
    client := pdl.New(apiKey)
    
    // Create a parameters JSON object
    params := pdlmodel.IdentifyPersonParams {
        BaseParams: pdlmodel.BaseParams {
            Pretty: true,
        },
        PersonParams: pdlmodel.PersonParams {
            FirstName: []string{"sean"},
            LastName: []string{"thorne"},
            Company: []string{"people data labs"},
        },
    }
    
    // Pass the parameters object to the Person Identify API
    response, err := client.Person.Identify(context.Background(), params)
    // Check for successful response
    if err == nil {
        // Create a list of matches
        identities := response.Matches
        // Convert the matches to JSON
        jsonResponse, jsonErr := json.Marshal(identities)
        // Print the matches
        if (jsonErr == nil) {
            fmt.Println(string(jsonResponse))
        }
        
        fmt.Printf("Found %d identities!\n", len(identities))
    } else {
        fmt.Println("Identify unsuccessful. See error and try again.")
        fmt.Println("error:", err)
    }
}
```

```
import requests

# Set your API key
API_KEY = "YOUR API KEY"

# Set the Person Identify API URL
PDL_URL = "https://api.peopledatalabs.com/v5/person/identify"

# Create a parameters JSON object
PARAMS = {
 "first_name": "sean", 
 "last_name": "thorne", 
 "company": "people data labs",
 "pretty": True,
 "api_key": API_KEY
}

# Pass the parameters object to the Person Identify API
json_response = requests.get(PDL_URL, params=PARAMS).json()

# Check for successful response
if json_response['status'] == 200:
   # Create a list of matches
   identities = json_response['matches']

   # Print the matches in JSON format
   print(identities)
   print(f"Found {len(identities)} identities!")

else:
   print("Identify unsuccessful. See error and try again.")
   print("error:", json_response)
```

The returned API response is a list of the records in our dataset that match the request query sorted by match strength in the format:

JSON

```
{
  "status": 200,
  "matches": [
    {
      "data": {
        ...
      },
      "match_score": 92,
      "matched_on": [
        "company",
        "name"
      ]
    },
    {
      "data": {
        ...
      },
      "match_score": 5,
      "matched_on": [
        "name"
      ]
    },
    ...
  ]
}
```

> ðŸ“˜
>
> ### Got a Different Result?
>
> If you didn't get this response, check out our [Errors](/docs/errors) page for more information.

Each object in the `matches` array contains a unique profile from our Person Dataset as well as a [`match_score`](/docs/identify-api-output-response#matchesmatch_score), which the API uses to sort the profiles in the `matches` array. You can use this profile data for various purposes. Typically, our users tend to fuse this with additional data to build more comprehensive identities.

Updated 4 months ago

---

Did this page help you?

Yes

No

---
# https://docs.peopledatalabs.com/docs/examples-cleaner-apis

We've provided code samples in cURL, Python, Ruby, Go and JavaScript. If you aren't comfortable working in any of these languages, feel free to use this [handy tool](https://curl.trillworks.com/) to convert code from cURL to the language of your choice.

> ðŸ’¡
>
> ### We want your feedback!
>
> Do you see a bug? Is there an example you'd like to see that's not listed here?
>
> Head over to the public roadmap and submit a [bug ticket](https://peopledatalabs.canny.io/bugs) or a [feature request](https://peopledatalabs.canny.io/feature-requests) and receive automatic notifications as your bug is resolved or your request is implemented.

## Company Cleaner API Example

*"Show me how this company is stored in PDL based on the website."*

Python3 SDKcURLJavaScriptRubyGoPython3

```
# See https://github.com/peopledatalabs/peopledatalabs-python
from peopledatalabs import PDLPY

# Create a client, specifying your API key
CLIENT = PDLPY(
    api_key="YOUR_API_KEY",
)

# Create a parameters JSON object
QUERY_STRING = {"website":"peopledatalabs.com"}

# Pass the parameters object to the Company Cleaner API
response = CLIENT.company.cleaner(**QUERY_STRING)

# Print the API response
print(response.text)
```

```
curl -X GET -G \
  'https://api.peopledatalabs.com/v5/company/clean' \
  -H 'X-Api-Key: xxxx' \
  --data-urlencode 'website=peopledatalabs.com'
```

```
// See https://github.com/peopledatalabs/peopledatalabs-js
import PDLJS from 'peopledatalabs';

// Create a client, specifying your API key
const PDLJSClient = new PDLJS({ apiKey: "YOUR API KEY" });

// Create a parameters JSON object
const params = {
  website: "peopledatalabs.com"
}

// Pass the parameters object to the Company Cleaner API
PDLJSClient.company.cleaner(params).then((data) => {
  // Print the API response
  console.log(data);
}).catch((error) => {
  console.log(error);
});
```

```
# See https://github.com/peopledatalabs/peopledatalabs-ruby
require 'peopledatalabs'

# Set your API key
Peopledatalabs.api_key = 'YOUR API KEY'

# Pass parameters to the Company Cleaner API
response = Peopledatalabs::Cleaner.company(kind: "website", value: "peopledatalabs.com")

# Print the API response
puts response
```

```
package main

import (
    "fmt"
    "context"
)

// See https://github.com/peopledatalabs/peopledatalabs-go
import (
    pdl "github.com/peopledatalabs/peopledatalabs-go"
    pdlmodel "github.com/peopledatalabs/peopledatalabs-go/model"
)

func main() {
    // Set your API key
    apiKey := "YOUR API KEY"
    // Set API key as environmental variable
    // apiKey := os.Getenv("API_KEY")

    // Create a client, specifying your API key
    client := pdl.New(apiKey)
    
    // Create a parameters JSON object
    params := pdlmodel.CleanCompanyParams {
        Website: "peopledatalabs.com",
    }
    
    // Pass the parameters object to the Company Cleaner API
    response, err := client.Company.Clean(context.Background(), params)
    // Check for successful response
    if err == nil {
        // Print the API response
        fmt.Println(response)
    }  
}
```

```
import requests

# Set your API key
API_KEY = "YOUR API KEY"

# Set the Company Cleaner API URL
PDL_URL = "https://api.peopledatalabs.com/v5/company/clean"

# Create a parameters JSON object
QUERY_STRING = {"website":"peopledatalabs.com"}

# Set headers
HEADERS = {
    'accept': "application/json",
    'content-type': "application/json",
    'x-api-key': API_KEY
}

# Pass the parameters object to the Company Cleaner API
response = requests.request("GET", PDL_URL, headers=HEADERS, params=QUERY_STRING)

# Print the API response
print(response.text)
```

## Location Cleaner API Example

*"Show me information about this specific location."*

Python3 SDKcURLJavaScriptRubyGoPython3

```
# See https://github.com/peopledatalabs/peopledatalabs-python
from peopledatalabs import PDLPY

# Create a client, specifying your API key
CLIENT = PDLPY(
    api_key="YOUR_API_KEY",
)

# Create a parameters JSON object
QUERY_STRING = {"location":"239 NW 13th Ave, Portland, Oregon 97209, US"}

# Pass the parameters object to the Location Cleaner API
response = CLIENT.location.cleaner(**QUERY_STRING)

# Print the API response
print(response.text)
```

```
curl -X GET -G \
  'https://api.peopledatalabs.com/v5/location/clean' \
  -H 'X-Api-Key: xxxx' \
  --data-urlencode 'location=239 NW 13th Ave, Portland, Oregon 97209, US'
```

```
// See https://github.com/peopledatalabs/peopledatalabs-js
import PDLJS from 'peopledatalabs';

// Create a client, specifying your API key
const PDLJSClient = new PDLJS({ apiKey: "YOUR API KEY" });

// Create a parameters JSON object
const params = {
  location:"239 NW 13th Ave, Portland, Oregon 97209, US"
}

// Pass the parameters object to the Location Cleaner API
PDLJSClient.location.cleaner(params).then((data) => {
  // Print the API response
  console.log(data);
}).catch((error) => {
  console.log(error);
});
```

```
# See https://github.com/peopledatalabs/peopledatalabs-ruby
require 'peopledatalabs'

# Set your API key
Peopledatalabs.api_key = 'YOUR API KEY'

# Pass parameters to the Location Cleaner API
response = Peopledatalabs::Cleaner.location(value: "239 NW 13th Ave, Portland, Oregon 97209, US")

# Print the API response
puts response
```

```
package main

import (
    "fmt"
    "context"
)

// See https://github.com/peopledatalabs/peopledatalabs-go
import (
    pdl "github.com/peopledatalabs/peopledatalabs-go"
    pdlmodel "github.com/peopledatalabs/peopledatalabs-go/model"
)

func main() {
    // Set your API key
    apiKey := "YOUR API KEY"
    // Set API key as environmental variable
    // apiKey := os.Getenv("API_KEY")

    // Create a client, specifying your API key
    client := pdl.New(apiKey)
    
    // Create a parameters JSON object
    querystring := pdlmodel.LocationParams{Location: "239 NW 13th Ave, Portland, Oregon 97209, US"}
    
    // Pass the parameters object to the Location Cleaner API
    params := pdlmodel.CleanLocationParams {
        LocationParams: querystring,
    }
    
    // Check for successful response
    response, err := client.Location.Clean(context.Background(), params)
    if err == nil {
        // Print the API response
        fmt.Println(response)
    }  
}
```

```
import requests

# Set your API key
API_KEY = "YOUR API KEY"

# Set the Location Cleaner API URL
PDL_URL = "https://api.peopledatalabs.com/v5/location/clean"

# Create a parameters JSON object
QUERY_STRING = {"location":"239 NW 13th Ave, Portland, Oregon 97209, US"}

# Set headers
HEADERS = {
    'accept': "application/json",
    'content-type': "application/json",
    'x-api-key': API_KEY
}

# Pass the parameters object to the Location Cleaner API
response = requests.request("GET", PDL_URL, headers=HEADERS, params=QUERY_STRING)

# Print the API response
print(response.text)
```

## School Cleaner API Example

*"Show me how this school is stored in PDL based on the LinkedIn URL."*

Python3 SDKcURLJavaScriptRubyGoPython3

```
# See https://github.com/peopledatalabs/peopledatalabs-python
from peopledatalabs import PDLPY

# Create a client, specifying your API key
CLIENT = PDLPY(
    api_key="YOUR_API_KEY",
)

# Create a parameters JSON object
QUERY_STRING = {"profile":"linkedin.com/school/ucla"}

# Pass the parameters object to the School Cleaner API
response = CLIENT.school.cleaner(**QUERY_STRING)

# Print the API response
print(response.text)
```

```
curl -X GET -G \
  'https://api.peopledatalabs.com/v5/school/clean' \
  -H 'X-Api-Key: xxxx' \
  --data-urlencode 'profile=linkedin.com/school/ucla'
```

```
// See https://github.com/peopledatalabs/peopledatalabs-js
import PDLJS from 'peopledatalabs';

// Create a client, specifying your API key
const PDLJSClient = new PDLJS({ apiKey: "YOUR API KEY" });

// Create a parameters JSON object
const params = {
  profile:"linkedin.com/school/ucla"
}

// Pass the parameters object to the School Cleaner API
PDLJSClient.school.cleaner(params).then((data) => {
  // Print the API response
  console.log(data);
}).catch((error) => {
  console.log(error);
});
```

```
# See https://github.com/peopledatalabs/peopledatalabs-ruby
require 'peopledatalabs'

# Set your API key
Peopledatalabs.api_key = 'YOUR API KEY'

# Pass parameters to the School Cleaner API
response = Peopledatalabs::Cleaner.school(kind: "profile", value: "linkedin.com/school/ucla")

# Print the API response
puts response
```

```
package main

import (
    "fmt"
    "context"
)

// See https://github.com/peopledatalabs/peopledatalabs-go
import (
    pdl "github.com/peopledatalabs/peopledatalabs-go"
    pdlmodel "github.com/peopledatalabs/peopledatalabs-go/model"
)

func main() {
    // Set your API key
    apiKey := "YOUR API KEY"
    // Set API key as environmental variable
    // apiKey := os.Getenv("API_KEY")

    // Create a client, specifying your API key
    client := pdl.New(apiKey)
    
    // Create a parameters JSON object
    querystring := pdlmodel.SchoolParams{Profile: "linkedin.com/school/ucla"}
    
    // Pass the parameters object to the School Cleaner API
    params := pdlmodel.CleanSchoolParams {
        SchoolParams: querystring,
    }
    
    // Check for successful response
    response, err := client.School.Clean(context.Background(), params)
    if err == nil {
        // Print the API response
        fmt.Println(response)
    }  
}
```

```
import requests

# Set your API key
API_KEY = "YOUR API KEY"

# Set the School Cleaner API URL
PDL_URL = "https://api.peopledatalabs.com/v5/school/clean"

# Create a parameters JSON object
QUERY_STRING = {"profile":"linkedin.com/school/ucla"}

# Set headers
HEADERS = {
    'accept': "application/json",
    'content-type': "application/json",
    'x-api-key': API_KEY
}

# Pass the parameters object to the School Cleaner API
response = requests.request("GET", PDL_URL, headers=HEADERS, params=QUERY_STRING)

# Print the API response
print(response.text)
```

## Company Cleaner API Example Using POST

*"Show me how this company is stored in PDL based on the name using a POST request."*

> ðŸ“˜
>
> ### Difference Between GET and POST Requests
>
> See this article for a comparison of the [differences between GET and POST requests](https://www.w3schools.com/tags/ref_httpmethods.asp). The biggest difference is that POST requests don't have any limit on the amount of data that you can pass in a request.

Python3cURL

```
import requests

# Set your API key
API_KEY = "YOUR API KEY"

# Set the School Cleaner API URL
PDL_URL = "https://api.peopledatalabs.com/v5/company/clean"

# Create a parameters JSON object
QUERY_STRING = {"name":"peopledatalabs"}

# Set headers
HEADERS = {
    'accept': "application/json",
    'content-type': "application/json",
    'x-api-key': API_KEY
}

# Pass the parameters object to the Company Cleaner API using POST method
response = requests.post(
  PDL_URL,
  headers=HEADERS,
  json=QUERY_STRING # Passing the data directly as a JSON object
).json()

# Print the API response
print(response)
```

```
curl -X POST \
  'https://api.peopledatalabs.com/v5/company/clean' \
  -H 'X-Api-Key: your-api-key' \
  -H 'Content-Type: application/json' \
  -d '{
    "name": "peopledatalabs",
    "pretty": true
}'
```

## Advanced Example

"*I want to find employees at a particular company but don't have the PDL identifier for the company.*"

Python3 SDK (Elasticsearch)Python3 SDK (SQL)JavaScript (Elasticsearch)JavaScript (SQL)Ruby (Elasticsearch)Ruby (SQL)Go (Elasticsearch)Go (SQL)Python3 (Elasticsearch)Python3 (SQL)

```
import json

# See https://github.com/peopledatalabs/peopledatalabs-python
from peopledatalabs import PDLPY

# Create a client, specifying your API key
CLIENT = PDLPY(
    api_key="YOUR_API_KEY",
)

# Set the website of the company you want to search
COMPANY_WEBSITE = "peopledatalabs.com"

# Create a parameters JSON object for the Company Cleaner API
QUERY_STRING = { "website": COMPANY_WEBSITE }

# Pass the parameters object to the Company Cleaner API
response = CLIENT.company.cleaner(**QUERY_STRING)

# Check for successful response
if response.status_code == 200:
    # Store the cleaned company from the API response
    cleaned_company = response.json()
else:
    cleaned_company = {}
    print(f"Company Cleaner API Error for [{COMPANY_WEBSITE}]: {response.text}")

# Employees at the cleaned company
company_employee_matches = {}

# Check for cleaned company
if cleaned_company:
    # Create an Elasticsearch query
    ES_QUERY = {
        "query": {
            "bool": {
                "must": [
                    {"term": {"job_company_id": cleaned_company['id']}}
                ]
            }
        }
    }

    # Create a parameters JSON object for the Person Search API
    PARAMS = {
        'query': ES_QUERY,
        'size': 100
    }

    # Pass the parameters object to the Person Search API
    response = CLIENT.person.search(**PARAMS)

    # Check for successful response
    if response.status_code == 200:
        # Store the employees of the cleaned company from the API response
        company_employee_matches = response.json()['data']
    else:
        company_employee_matches = {}
        print(f"Person Search Error for [{COMPANY_WEBSITE}]: {response.text}")

print(f"Found {len(company_employee_matches)} employee profiles at {COMPANY_WEBSITE}.")
```

```
import json

# See https://github.com/peopledatalabs/peopledatalabs-python
from peopledatalabs import PDLPY

# Create a client, specifying your API key
CLIENT = PDLPY(
    api_key="YOUR_API_KEY",
)

# Set the website of the company you want to search
COMPANY_WEBSITE = "peopledatalabs.com"

# Create a parameters JSON object for the Company Cleaner API
QUERY_STRING = { "website": COMPANY_WEBSITE }

# Pass the parameters object to the Company Cleaner API
response = CLIENT.company.cleaner(**QUERY_STRING)

# Check for successful response
if response.status_code == 200:
    # Store the cleaned company from the API response
    cleaned_company = response.json()
else:
    cleaned_company = {}
    print(f"Company Cleaner API Error for [{COMPANY_WEBSITE}]: {response.text}")

# Employees at the cleaned company
company_employee_matches = {}

# Check for cleaned company
if cleaned_company:
    # Create an SQL query
    SQL_QUERY = f"""
    SELECT * FROM person
    WHERE job_company_id = '{cleaned_company['id']}'
    """

    # Create a parameters JSON object for the Person Search API
    PARAMS = {
        'sql': SQL_QUERY,
        'size': 100
    }

    # Pass the parameters object to the Person Search API
    response = CLIENT.person.search(**PARAMS)

    # Check for successful response
    if response.status_code == 200:
        # Store the employees of the cleaned company from the API response
        company_employee_matches = response.json()['data']
    else:
        company_employee_matches = {}
        print(f"Person Search Error for [{COMPANY_WEBSITE}]: {response.text}")

print(f"Found {len(company_employee_matches)} employee profiles at {COMPANY_WEBSITE}.")
```

```
// See https://github.com/peopledatalabs/peopledatalabs-js
import PDLJS from 'peopledatalabs';

// Create a client, specifying your API key
const PDLJSClient = new PDLJS({ apiKey: "YOUR_API_KEY" });

// Set the website of the company you want to search
const companyWebsite = "peopledatalabs.com";

// Create a parameters JSON object for the Company Cleaner API
const queryString = { "website": companyWebsite };

// The cleaned company
var cleanedCompany;

// Pass the parameters object to the Company Cleaner API
PDLJSClient.company.cleaner(queryString).then((data) => {

    // Store the cleaned company from the API response
    cleanedCompany = data;
    
    // Employees at the cleaned company
    var companyEmployeeMatches = {};
    
    // Create an Elasticsearch query
    const esQuery = {
      query: {
         bool: {
            must:[
               {"term": {"job_company_id": cleanedCompany["id"]}}
            ]
         }
      }
    }
    
    // Create a parameters JSON object for the Person Search API
    const params = {
        searchQuery: esQuery, 
        size: 100,
    }
    
    // Pass the parameters object to the Person Search API
    PDLJSClient.person.search.elastic(params).then((data) => {
        // Store the employees of the cleaned company from the API response
        companyEmployeeMatches = data.data;
        console.log(`Found ${companyEmployeeMatches.length} employee profiles at ${companyWebsite}.`);
    }).catch((error) => {
        companyEmployeeMatches = {};
        console.log(`Person Search Error for [${companyWebsite}]: ${error}`);
    });
    
}).catch((error) => {
    console.log(error);
});
```

```
// See https://github.com/peopledatalabs/peopledatalabs-js
import PDLJS from 'peopledatalabs';

// Create a client, specifying your API key
const PDLJSClient = new PDLJS({ apiKey: "YOUR API KEY" });

// Set the website of the company you want to search
const companyWebsite = "peopledatalabs.com";

// Create a parameters JSON object for the Company Cleaner API
const queryString = { "website": companyWebsite };

// The cleaned company
var cleanedCompany;

// Pass the parameters object to the Company Cleaner API
PDLJSClient.company.cleaner(queryString).then((data) => {

    // Store the cleaned company from the API response
    cleanedCompany = data;
    
    // Employees at the cleaned company
    var companyEmployeeMatches = {};
    
    // Create an SQL query
    const sqlQuery = `SELECT * FROM person
                        WHERE job_company_id = '` + cleanedCompany["id"] + `';`;
    
    // Create a parameters JSON object for the Person Search API
    const params = {
        searchQuery: sqlQuery, 
        size: 100,
    }
    
    // Pass the parameters object to the Person Search API
    PDLJSClient.person.search.sql(params).then((data) => {
        // Store the employees of the cleaned company from the API response
        companyEmployeeMatches = data.data;
        console.log(`Found ${companyEmployeeMatches.length} employee profiles at ${companyWebsite}.`);
    }).catch((error) => {
        companyEmployeeMatches = {};
        console.log(`Person Search Error for [${companyWebsite}]: ${error}`);
    });
    
}).catch((error) => {
    console.log(error);
});
```

```
require 'json'

# See https://github.com/peopledatalabs/peopledatalabs-ruby
require 'peopledatalabs'

# Set your API key
Peopledatalabs.api_key = 'YOUR API KEY'

# Set the website of the company you want to search
COMPANY_WEBSITE = "peopledatalabs.com"

# Pass parameters to the Company Cleaner API
response = Peopledatalabs::Cleaner.company(kind: "website", value: COMPANY_WEBSITE)

# Check for successful response
if response['status'] == 200
    # Store the cleaned company from the API response
    cleaned_company = response
else
    cleaned_company = {}
    puts "Company Cleaner API Error for #{COMPANY_WEBSITE}: #{response}"
end

# Employees at the cleaned company
company_employee_matches = {}

# Check for cleaned company
if cleaned_company
    # Create an Elasticsearch query
    ES_QUERY = {
        "query": {
            "bool": {
                "must": [
                    {"term": {"job_company_id": cleaned_company['id']}}
                ]
            }
        }
    }

    # Pass parameters to the Person Search API
    response = Peopledatalabs::Search.people(searchType: 'elastic', query: ES_QUERY, size: 100)

    # Check for successful response
    if response['status'] == 200
        # Store the employees of the cleaned company from the API response
        company_employee_matches = response['data']
    else
        company_employee_matches = []
        puts "Person Search Error for [#{COMPANY_WEBSITE}]: #{response}"
    end
end
puts "Found #{company_employee_matches.length()} employee profiles at #{COMPANY_WEBSITE}."
```

```
require 'json'

# See https://github.com/peopledatalabs/peopledatalabs-ruby
require 'peopledatalabs'

# Set your API key
Peopledatalabs.api_key = 'YOUR API KEY'

# Set the website of the company you want to search
COMPANY_WEBSITE = "peopledatalabs.com"

# Pass parameters to the Company Cleaner API
response = Peopledatalabs::Cleaner.company(kind: "website", value: COMPANY_WEBSITE)

# Check for successful response
if response['status'] == 200
    # Store the cleaned company from the API response
    cleaned_company = response
else
    cleaned_company = {}
    puts "Company Cleaner API Error for #{COMPANY_WEBSITE}: #{response}"
end

# Employees at the cleaned company
company_employee_matches = {}

# Check for cleaned company
if cleaned_company
    # Create an SQL query
    SQL_QUERY = """
    SELECT * FROM person
    WHERE job_company_id = '#{cleaned_company['id']}'
    """

    # Pass parameters to the Person Search API
    response = Peopledatalabs::Search.people(searchType: 'sql', query: SQL_QUERY, size: 10)

    # Check for successful response
    if response['status'] == 200
        # Store the employees of the cleaned company from the API response
        company_employee_matches = response['data']
    else
        company_employee_matches = []
        puts "Person Search Error for [#{COMPANY_WEBSITE}]: #{response}"
    end
end
puts "Found #{company_employee_matches.length()} employee profiles at #{COMPANY_WEBSITE}."
```

```
package main

import (
    "fmt"
    "encoding/json"
    "reflect"
    "context"
)

// See https://github.com/peopledatalabs/peopledatalabs-go
import (
    pdl "github.com/peopledatalabs/peopledatalabs-go"
    pdlmodel "github.com/peopledatalabs/peopledatalabs-go/model"
)

func main() {
    // Set your API key
    apiKey := "YOUR API KEY"
    // Set API key as environmental variable
    // apiKey := os.Getenv("API_KEY")

    // Create a client, specifying your API key
    client := pdl.New(apiKey)
    
    // Set the website of the company you want to search
    companyWebsite := "peopledatalabs.com"

    // Create a parameters JSON object for the Company Cleaner API
    cleanParams := pdlmodel.CleanCompanyParams {
        Website: "peopledatalabs.com",
    }
    
    // The cleaned company
    var cleanedCompany pdlmodel.CleanCompanyResponse
    
    // Pass the parameters object to the Company Cleaner API
    cleanResponse, cleanErr := client.Company.Clean(context.Background(), cleanParams)
    // Check for successful response
    if cleanErr == nil {
        // Store the cleaned company from the API response
        cleanedCompany = cleanResponse
    } else {
        fmt.Printf("Company Cleaner API Error for [%s]: %s", companyWebsite, cleanResponse)
    }
    
    // Check for cleaned company
    if !reflect.ValueOf(cleanedCompany).IsZero() {
        // Create an Elasticsearch query
        elasticSearchQuery := map[string]interface{} {
            "query": map[string]interface{} {
                "bool": map[string]interface{} {
                    "must": []map[string]interface{} {
                        {"term": map[string]interface{}{"job_company_id": cleanedCompany.Id}},
                    },
                },
            },
        }

        // Create a parameters JSON object for the Person Search API
        searchParams := pdlmodel.SearchParams {
            BaseParams: pdlmodel.BaseParams {
                Size: 100,
            },
            SearchBaseParams: pdlmodel.SearchBaseParams {
                Query: elasticSearchQuery,
            },
        }
        
        // Pass the parameters object to the Person Search API
        SearchResponse, SearchErr := client.Person.Search(context.Background(), searchParams)
        // Check for successful response
        if SearchErr == nil {
            data := SearchResponse.Data
            // Store the employees of the cleaned company from the API response in JSON format
            companyEmployeeMatches, jsonErr := json.Marshal(data)
     
            if jsonErr == nil && !reflect.ValueOf(companyEmployeeMatches).IsZero() {
                fmt.Printf("Found %d employee profiles at %s.\n", len(data), companyWebsite)
            }
        } else {
            fmt.Printf("Company Cleaner API Error for [%s]: %s\n", companyWebsite, SearchResponse)
        }
    }
}
```

```
package main

import (
    "fmt"
    "encoding/json"
    "reflect"
    "context"
)

// See https://github.com/peopledatalabs/peopledatalabs-go
import (
    pdl "github.com/peopledatalabs/peopledatalabs-go"
    pdlmodel "github.com/peopledatalabs/peopledatalabs-go/model"
)

func main() {
    // Set your API key
    apiKey := "YOUR API KEY"
    // Set API key as environmental variable
    // apiKey := os.Getenv("API_KEY")

    // Create a client, specifying your API key
    client := pdl.New(apiKey)
    
    // Set the website of the company you want to search
    companyWebsite := "peopledatalabs.com"

    // Create a parameters JSON object for the Company Cleaner API
    cleanParams := pdlmodel.CleanCompanyParams {
        Website: "peopledatalabs.com",
    }
    
    // The cleaned company
    var cleanedCompany pdlmodel.CleanCompanyResponse
    
    // Pass the parameters object to the Company Cleaner API
    cleanResponse, cleanErr := client.Company.Clean(context.Background(), cleanParams)
    // Check for successful response
    if cleanErr == nil {
        // Store the cleaned company from the API response
        cleanedCompany = cleanResponse
    } else {
        fmt.Printf("Company Cleaner API Error for [%s]: %s", companyWebsite, cleanResponse)
    }
    
    // Check for cleaned company
    if !reflect.ValueOf(cleanedCompany).IsZero() {
        // Create an SQL query
        sqlQuery := "SELECT * FROM person" +
            " WHERE job_company_id='" + cleanedCompany.Id + "';"

        // Create a parameters JSON object for the Person Search API
        searchParams := pdlmodel.SearchParams {
            BaseParams: pdlmodel.BaseParams {
                Size: 100,
            },
            SearchBaseParams: pdlmodel.SearchBaseParams {
                SQL: sqlQuery,
            },
        }
        
        // Pass the parameters object to the Person Search API
        SearchResponse, SearchErr := client.Person.Search(context.Background(), searchParams)
        // Check for successful response
        if SearchErr == nil {
            data := SearchResponse.Data
            // Store the employees of the cleaned company from the API response in JSON format
            companyEmployeeMatches, jsonErr := json.Marshal(data)
     
            if jsonErr == nil && !reflect.ValueOf(companyEmployeeMatches).IsZero() {
                fmt.Printf("Found %d employee profiles at %s.\n", len(data), companyWebsite)
            }
        } else {
            fmt.Printf("Company Cleaner API Error for [%s]: %s\n", companyWebsite, SearchResponse)
        }
    }
}
```

```
import json
import requests

# Set your API key
API_KEY = "YOUR API KEY"

# Set the Company Cleaner API URL
PDL_COMPANY_CLEANER_URL = "https://api.peopledatalabs.com/v5/company/clean"
# Set the Person Search API URL
PDL_PERSON_SEARCH_URL = "https://api.peopledatalabs.com/v5/person/search"

# Set the website of the company you want to search
COMPANY_WEBSITE = "peopledatalabs.com"

# Create a parameters JSON object for the Company Cleaner API
QUERY_STRING = { "website": COMPANY_WEBSITE }

# Set headers
HEADERS = {
    'accept': "application/json",
    'content-type': "application/json",
    'x-api-key': API_KEY
}

# Pass the parameters object to the Company Cleaner API
response = requests.request("GET", PDL_COMPANY_CLEANER_URL, headers=HEADERS, params=QUERY_STRING)

# Check for successful response
if response.status_code == 200:
    # Store the cleaned company from the API response
    cleaned_company = response.json()
else:
    cleaned_company = {}
    print(f"Company Cleaner API Error for [{COMPANY_WEBSITE}]: {response.text}")

# Employees at the cleaned company
company_employee_matches = {}

# Check for cleaned company
if cleaned_company:
    # Set headers
    HEADERS = {
        'Content-Type': "application/json",
        'X-api-key': API_KEY
    }

    # Create an Elasticsearch query
    ES_QUERY = {
        "query": {
            "bool": {
                "must": [
                    {"term": {"job_company_id": cleaned_company['id']}}
                ]
            }
        }
    }

    # Create a parameters JSON object for the Person Search API
    PARAMS = {
        'query': json.dumps(ES_QUERY),
        'size': 100
    }

    # Pass the parameters object to the Person Search API
    response = requests.get(PDL_PERSON_SEARCH_URL, headers=HEADERS, params=PARAMS)

    # Check for successful response
    if response.status_code == 200:
        # Store the employees of the cleaned company from the API response
        company_employee_matches = response.json()['data']
    else:
        company_employee_matches = {}
        print(f"Person Search Error for [{COMPANY_WEBSITE}]: {response.text}")

print(f"Found {len(company_employee_matches)} employee profiles at {COMPANY_WEBSITE}.")
```

```
import json
import requests

# Set your API key
API_KEY = "YOUR API KEY"

# Set the Company Cleaner API URL
PDL_COMPANY_CLEANER_URL = "https://api.peopledatalabs.com/v5/company/clean"
# Set the Person Search API URL
PDL_PERSON_SEARCH_URL = "https://api.peopledatalabs.com/v5/person/search"

# Set the website of the company you want to search
COMPANY_WEBSITE = "peopledatalabs.com"

# Create a parameters JSON object for the Company Cleaner API
QUERY_STRING = { "website": COMPANY_WEBSITE }

# Set headers
HEADERS = {
    'accept': "application/json",
    'content-type': "application/json",
    'x-api-key': API_KEY
}

# Pass the parameters object to the Company Cleaner API
response = requests.request("GET", PDL_COMPANY_CLEANER_URL, headers=HEADERS, params=QUERY_STRING)

# Check for successful response
if response.status_code == 200:
    # Store the cleaned company from the API response
    cleaned_company = response.json()
else:
    cleaned_company = {}
    print(f"Company Cleaner API Error for [{COMPANY_WEBSITE}]: {response.text}")

# Employees at the cleaned company
company_employee_matches = {}

# Check for cleaned company
if cleaned_company:
    # Set HEADERS
    headers = {
        'Content-Type': "application/json",
        'X-api-key': API_KEY
    }

    # Create an SQL query
    SQL_QUERY = f"""
    SELECT * FROM person
    WHERE job_company_id = '{cleaned_company['id']}'
    """

    # Create a parameters JSON object for the Person Search API
    PARAMS = {
        'sql': SQL_QUERY,
        'size': 100
    }

    # Pass the parameters object to the Person Search API
    response = requests.get(PDL_PERSON_SEARCH_URL, headers=HEADERS, params=PARAMS)

    # Check for successful response
    if response.status_code == 200:
        # Store the employees of the cleaned company from the API response
        company_employee_matches = response.json()['data']
    else:
        company_employee_matches = {}
        print(f"Person Search Error for [{COMPANY_WEBSITE}]: {response.text}")

print(f"Found {len(company_employee_matches)} employee profiles at {COMPANY_WEBSITE}.")
```

Updated 4 months ago

---

Did this page help you?

Yes

No

---
# https://docs.peopledatalabs.com/docs/examples-company-search-api

# Examples

We've provided code samples in Python, cURL, Ruby, Go and JavaScript. If you aren't comfortable working in any of these languages, feel free to use this [handy tool](https://curl.trillworks.com/) to convert code from cURL to the language of your choice.

> â—ï¸
>
> ### Heads Up! Credit Usage
>
> Company Search API calls cost the number of **total search results** returned.
>
> If you are making a search that could have a large number of results, make sure to use the [`size` parameter](/docs/input-parameters-company-search-api#size) to set the maximum number of results and cap your credit usage.

> ðŸ’¡
>
> ### We want your feedback!
>
> Do you see a bug? Is there an example you'd like to see that's not listed here?
>
> Head over to the public roadmap and submit a [bug ticket](https://peopledatalabs.canny.io/bugs) or a [feature request](https://peopledatalabs.canny.io/feature-requests) and receive automatic notifications as your bug is resolved or your request is implemented.

## Basic Usage

*"I want to make a query and save the results to a file."*

Python3 SDK (Elasticsearch)Python3 SDK (SQL)cURLJavaScript (Elasticsearch)JavaScript (SQL)Ruby (Elasticsearch)Ruby (SQL)Go (Elasticsearch)Go (SQL)Python3 (Elasticsearch)Python3 (SQL)

```
import json

# See https://github.com/peopledatalabs/peopledatalabs-python
from peopledatalabs import PDLPY

# Create a client, specifying your API key
CLIENT = PDLPY(
    api_key="YOUR API KEY",
)

# Create an Elasticsearch query
ES_QUERY = {
  "query": {
    "bool": {
      "must": [
        {"term": {"website": "google.com"}}
      ]
    }
  }
}

# Create a parameters JSON object
PARAMS = {
  'query': ES_QUERY,
  'size': 10,
  'pretty': True
}

# Pass the parameters object to the Company Search API
response = CLIENT.company.search(**PARAMS).json()

# Check for successful response
if response["status"] == 200:
  data = response['data']
  # Write out each profile found to file
  with open("my_pdl_search.jsonl", "w") as out:
    for record in data:
      out.write(json.dumps(record) + "\n")
  print(f"Successfully grabbed {len(data)} records from PDL.")
  print(f"{response['total']} total PDL records exist matching this query.")
else:
  print("NOTE: The carrier pigeons lost motivation in flight. See error and try again.")
  print("Error:", response)
```

```
import json

# See https://github.com/peopledatalabs/peopledatalabs-python
from peopledatalabs import PDLPY

# Create a client, specifying your API key
CLIENT = PDLPY(
    api_key="YOUR API KEY",
)

# Create an SQL query
SQL_QUERY = \
"""
  SELECT * FROM company
  WHERE website='google.com';
 """

# Create a parameters JSON object
PARAMS = {
  'sql': SQL_QUERY,
  'size': 10,
  'pretty': True
}

# Pass the parameters object to the Company Search API
response = CLIENT.company.search(**PARAMS).json()

# Check for successful response
if response["status"] == 200:
  data = response['data']
  # Write out each profile found to file
  with open("my_pdl_search.jsonl", "w") as out:
    for record in data:
      out.write(json.dumps(record) + "\n")
  print(f"Successfully grabbed {len(data)} records from PDL.")
  print(f"{response['total']} total PDL records exist matching this query.")
else:
  print("NOTE: The carrier pigeons lost motivation in flight. See error and try again.")
  print("Error:", response)
```

```
# Elasticsearch
curl -X GET 'https://api.peopledatalabs.com/v5/company/search' \
-H 'X-Api-Key: xxxx' \
--data-raw '{
  "size": 10,
  "query": {
    "bool": {
      "must": [
        {"term": {"website": "google.com"}}
      ]
    }
  }
}'

# SQL
curl -X GET \
  'https://api.peopledatalabs.com/v5/company/search' \
  -H 'X-Api-Key: xxxx' \
  --data-raw '{
    "size": 10,
    "sql": "SELECT * FROM company WHERE website='\''google.com'\'';"
}'
```

```
// See https://github.com/peopledatalabs/peopledatalabs-js
import PDLJS from 'peopledatalabs';

import fs from 'fs';

// Create a client, specifying your API key
const PDLJSClient = new PDLJS({ apiKey: "YOUR API KEY" });

// Create an Elasticsearch query
const esQuery = {
  query: {
    bool: {
      must:[
        {"term": {"website": "google.com"}} 
      ]
    }
  }
}

// Create a parameters JSON object
const params = {
  searchQuery: esQuery, 
  size: 10,
  pretty: true
}

// Pass the parameters object to the Company Search API
PDLJSClient.company.search.elastic(params).then((data) => {
    // Write out all profiles found to file
    fs.writeFile("my_pdl_search.jsonl", Buffer.from(JSON.stringify(data.data)), (err) => {
        if (err) throw err;
    });
    console.log(`Successfully grabbed ${data.data.length} records from PDL.`);
    console.log(`${data["total"]} total PDL records exist matching this query.`)
}).catch((error) => {
    console.log("NOTE: The carrier pigeons lost motivation in flight. See error and try again.")
    console.log(error);
});
```

```
// See https://github.com/peopledatalabs/peopledatalabs-js
import PDLJS from 'peopledatalabs';

import fs from 'fs';

// Create a client, specifying your API key
const PDLJSClient = new PDLJS({ apiKey: "YOUR API KEY" });

// Create an SQL query
const sqlQuery = `SELECT * FROM company
                    WHERE website='google.com';`;

// Create a parameters JSON object
const params = {
    searchQuery: sqlQuery, 
  	size: 10,
  	pretty: true
}

// Pass the parameters object to the Company Search API
PDLJSClient.company.search.sql(params).then((data) => {
    // Write out all profiles found to file
    fs.writeFile("my_pdl_search.jsonl", Buffer.from(JSON.stringify(data.data)), (err) => {
        if (err) throw err;
    });
    console.log(`Successfully grabbed ${data.data.length} records from PDL.`);
    console.log(`${data["total"]} total PDL records exist matching this query.`)
}).catch((error) => {
    console.log("NOTE: The carrier pigeons lost motivation in flight. See error and try again.")
    console.log(error);
});
```

```
require 'json'

# See https://github.com/peopledatalabs/peopledatalabs-ruby
require 'peopledatalabs'

# Set your API key
Peopledatalabs.api_key = 'YOUR API KEY'

# Create an Elasticsearch query
ES_QUERY = {
  "query": {
    "bool": {
      "must": [
        {"term": {"website": "google.com"}},
      ]
    }
  }
}

# Pass parameters to the Company Search API
response = Peopledatalabs::Search.company(searchType: 'elastic', query: ES_QUERY, size: 10, pretty: true)

# Check for successful response
if response['status'] == 200
    data = response['data']
    # Write out each profile found to file
    File.open("my_pdl_search.jsonl", "w") do |out|
        data.each { |record| out.write(JSON.dump(record) + "\n") }
    end
    puts "Successfully grabbed #{data.length()} records from PDL."
    puts "#{response['total']} total PDL records exist matching this query."
else
    puts "NOTE: The carrier pigeons lost motivation in flight. See error and try again."
    puts "Error: #{response}"
end
```

```
require 'json'

# See https://github.com/peopledatalabs/peopledatalabs-ruby
require 'peopledatalabs'

# Set your API key
Peopledatalabs.api_key = 'YOUR API KEY'

# Create an SQL query
SQL_QUERY = \
"""
  SELECT * FROM company
  WHERE website='google.com';
 """

# Pass parameters to the Company Search API
response = Peopledatalabs::Search.company(searchType: 'sql', query: SQL_QUERY, size: 10, pretty: true)

# Check for successful response
if response['status'] == 200
    data = response['data']
    # Write out each profile found to file
    File.open("my_pdl_search.jsonl", "w") do |out|
        data.each { |record| out.write(JSON.dump(record) + "\n") }
    end
    puts "Successfully grabbed #{data.length()} records from PDL."
    puts "#{response['total']} total PDL records exist matching this query."
else
    puts "NOTE: The carrier pigeons lost motivation in flight. See error and try again."
    puts "Error: #{response}"
end
```

```
package main

import(
    "fmt"
    "os"
    "encoding/json"
    "context"
)

// See https://github.com/peopledatalabs/peopledatalabs-go
import (
    pdl "github.com/peopledatalabs/peopledatalabs-go"
    pdlmodel "github.com/peopledatalabs/peopledatalabs-go/model"
)

func main() {
    // Set your API key
    apiKey := "YOUR API KEY"
    // Set API key as environmental variable
    // apiKey := os.Getenv("API_KEY")

    // Create a client, specifying your API key
    client := pdl.New(apiKey)

    // Create an Elasticsearch query
    elasticSearchQuery := map[string]interface{} {
        "query": map[string]interface{} {
            "bool": map[string]interface{} {
                "must": []map[string]interface{} {
                    {"term": map[string]interface{}{"website": "google.com"}},
                },
            },
        },
    }

    // Create a parameters JSON object
    params := pdlmodel.SearchParams {
        BaseParams: pdlmodel.BaseParams {
            Size: 10,
            Pretty: true,
        },
        SearchBaseParams: pdlmodel.SearchBaseParams {
            Query: elasticSearchQuery,
        },
    }
    
    // Pass the parameters object to the Company Search API
    response, err := client.Company.Search(context.Background(), params)
    // Check for successful response
    if err == nil {
        data := response.Data
        // Create file
        out, outErr := os.Create("my_pdl_search.jsonl")
        defer out.Close()
        if (outErr == nil) {
            for i := range data {
                // Convert each profile found to JSON
                record, jsonErr := json.Marshal(data[i])
                // Write out each profile to file
                if (jsonErr == nil) {
                    out.WriteString(string(record) + "\n")
                }
            }
            out.Sync()
        }
        fmt.Printf("Successfully grabbed %d records from PDL.\n", len(data))
        fmt.Printf("%d total PDL records exist matching this query.\n", response.Total)
    } else {
        fmt.Println("NOTE: The carrier pigeons lost motivation in flight. See error and try again.")
        fmt.Println("Error:", err)
    } 
}
```

```
package main

import(
    "fmt"
    "os"
    "encoding/json"
    "context"
)

// See https://github.com/peopledatalabs/peopledatalabs-go
import (
    pdl "github.com/peopledatalabs/peopledatalabs-go"
    pdlmodel "github.com/peopledatalabs/peopledatalabs-go/model"
)

func main() {
    // Set your API key
    apiKey := "YOUR API KEY"
    // Set API key as environmental variable
    // apiKey := os.Getenv("API_KEY")

    // Create a client, specifying your API key
    client := pdl.New(apiKey)

    // Create an SQL query
    sqlQuery := "SELECT * FROM company" +
        " WHERE website='google.com';"

    // Create a parameters JSON object
    params := pdlmodel.SearchParams {
        BaseParams: pdlmodel.BaseParams {
            Size: 10,
            Pretty: true,
        },
        SearchBaseParams: pdlmodel.SearchBaseParams {
            SQL: sqlQuery,
        },
    }
    
    // Pass the parameters object to the Company Search API
    response, err := client.Company.Search(context.Background(), params)
    // Check for successful response
    if err == nil {
        data := response.Data
        // Create file
        out, outErr := os.Create("my_pdl_search.jsonl")
        defer out.Close()
        if (outErr == nil) {
            for i := range data {
                // Convert each profile found to JSON
                record, jsonErr := json.Marshal(data[i])
                // Write out each profile to file
                if (jsonErr == nil) {
                    out.WriteString(string(record) + "\n")
                }
            }
            out.Sync()
        }
        fmt.Printf("Successfully grabbed %d records from PDL.\n", len(data))
        fmt.Printf("%d total PDL records exist matching this query.\n", response.Total)
    } else {
        fmt.Println("NOTE: The carrier pigeons lost motivation in flight. See error and try again.")
        fmt.Println("Error:", err)
    } 
}
```

```
import requests, json

# Set your API key
API_KEY = "YOUR API KEY"

# Set the Company Search API URL
PDL_URL = "https://api.peopledatalabs.com/v5/company/search"

# Set headers
HEADERS = {
  'Content-Type': "application/json",
  'X-api-key': API_KEY
}

# Create an Elasticsearch query
ES_QUERY = {
  "query": {
    "bool": {
      "must": [
        {"term": {"website": "google.com"}}
      ]
    }
  }
}

# Create a parameters JSON object
PARAMS = {
  'query': json.dumps(ES_QUERY),
  'size': 10,
  'pretty': True
}

# Pass the parameters object to the Company Search API
response = requests.get(
  PDL_URL,
  headers=HEADERS,
  params=PARAMS
).json()

# Check for successful response
if response["status"] == 200:
  data = response['data']
  # Write out each profile found to file
  with open("my_pdl_search.jsonl", "w") as out:
    for record in data:
      out.write(json.dumps(record) + "\n")
  print(f"Successfully grabbed {len(data)} records from PDL.")
  print(f"{response['total']} total PDL records exist matching this query.")
else:
  print("NOTE: The carrier pigeons lost motivation in flight. See error and try again.")
  print("Error:", response)
```

```
import requests, json

# Set your API key
API_KEY = "YOUR API KEY"

# Set the Company Search API URL
PDL_URL = "https://api.peopledatalabs.com/v5/company/search"

# Set headers
HEADERS = {
  'Content-Type': "application/json",
  'X-api-key': API_KEY
}

# Create an SQL query
SQL_QUERY = \
"""
  SELECT * FROM company
  WHERE website='google.com';
 """

# Create a parameters JSON object
PARAMS = {
  'sql': SQL_QUERY,
  'size': 10,
  'pretty': True
}

# Pass the parameters object to the Company Search API
response = requests.get(
  PDL_URL,
  headers=HEADERS,
  params=PARAMS
).json()

# Check for successful response
if response["status"] == 200:
  data = response['data']
  # Write out each profile found to file
  with open("my_pdl_search.jsonl", "w") as out:
    for record in data:
      out.write(json.dumps(record) + "\n")
  print(f"Successfully grabbed {len(data)} records from PDL.")
  print(f"{response['total']} total PDL records exist matching this query.")
else:
  print("NOTE: The carrier pigeons lost motivation in flight. See error and try again.")
  print("error:", response)
```

## Using POST Requests

*"I would like to use POST requests to query instead of GET requests so that I can make queries with a lot of parameters."*

> ðŸ“˜
>
> ### Difference Between GET and POST Requests
>
> See this article for a comparison of the [differences between GET and POST requests](https://www.w3schools.com/tags/ref_httpmethods.asp). The biggest difference is that POST requests don't have any limit on the amount of data that you can pass in a request.

Python3 (Elasticsearch)Python3 (SQL)cURL

```
import requests, json

# Set your API key
API_KEY = "YOUR API KEY"

# Set the Company Search API URL
PDL_URL = "https://api.peopledatalabs.com/v5/company/search"

# Set headers
HEADERS = {
  'Content-Type': "application/json",
  'X-api-key': API_KEY
}

# Create an Elasticsearch query
ES_QUERY = {
  "query": {
    "bool": {
      "must": [
        {"term": {"website": "google.com"}},
      ]
    }
  }
}

# Create a parameters JSON object
PARAMS = {
  'query': ES_QUERY, # This is a different syntax than when using GET requests
  'size': 10,
  'pretty': True
}

# Pass the parameters object to the Person Search API using POST method
response = requests.post( # Using POST method
  PDL_URL,
  headers=HEADERS,
  json=PARAMS # Pass the data directly as a JSON object
  # data=json.dumps(PARAMS) # This is an alternative way of passing data using a string
).json()

# Check for successful response
if response["status"] == 200:
  data = response['data']
  # Write out each profile found to file
  with open("my_pdl_search.jsonl", "w") as out:
    for record in data:
      out.write(json.dumps(record) + "\n")
  print(f"Successfully grabbed {len(data)} records from PDL.")
  print(f"{response['total']} total PDL records exist matching this query.")
else:
  print("NOTE: The carrier pigeons lost motivation in flight. See error and try again.")
  print("Error:", response)
```

```
import requests, json

# Set your API key
API_KEY = # YOUR API KEY

# Set the Company Search API URL
PDL_URL = "https://api.peopledatalabs.com/v5/company/search"

# Set headers
HEADERS = {
  'Content-Type': "application/json",
  'X-api-key': API_KEY
}

# Create an SQL query
SQL_QUERY = \
"""
  SELECT * FROM company
  WHERE website='google.com';
 """

# Create a parameters JSON object
PARAMS = {
  'sql': SQL_QUERY,
  'size': 10,
  'pretty': True
}

# Pass the parameters object to the Person Search API using POST method
response = requests.post( # Using POST method
  PDL_URL,
  headers=HEADERS,
  json=PARAMS # Pass the data directly as a JSON object
  # data=json.dumps(PARAMS) # This is an alternative way of passing data using a string
).json()

# Check for successful response
if response["status"] == 200:
  data = response['data']
  # Write out each profile found to file
  with open("my_pdl_search.jsonl", "w") as out:
    for record in data:
      out.write(json.dumps(record) + "\n")
  print(f"Successfully grabbed {len(data)} records from PDL.")
  print(f"{response['total']} total PDL records exist matching this query.")
else:
  print("NOTE: The carrier pigeons lost motivation in flight. See error and try again.")
  print("Error:", response)
```

```
# Elasticsearch
curl -X POST 'https://api.peopledatalabs.com/v5/company/search' \
  -H 'X-Api-Key: your-api-key' \
  -H 'Content-Type: application/json' \
  -d '{
  "size": 10,
  "query": {
    "bool": {
      "must": [
        {"term": {"website": "google.com"}}
      ]
    }
  }
}'

# SQL
curl -X POST \
  'https://api.peopledatalabs.com/v5/company/search' \
  -H 'X-Api-Key: your-api-key' \
  -H 'Content-Type: application/json' \
  -d '{
    "size": 10,
    "sql": "SELECT * FROM company WHERE website='\''google.com'\''"
}'
```

## Company Search by Tags

*"I want to find US-based companies tagged as 'big data' in the financial services industry."*

Python3 SDK (Elasticsearch)Python3 SDK (SQL)JavaScript (Elasticsearch)JavaScript (SQL)Ruby (Elasticsearch)Ruby (SQL)Go (Elasticsearch)Go (SQL)Python3 (Elasticsearch)Python3 (SQL)

```
import json

# See https://github.com/peopledatalabs/peopledatalabs-python
from peopledatalabs import PDLPY

# Create a client, specifying your API key
CLIENT = PDLPY(
    api_key="YOUR API KEY",
)

# Create an Elasticsearch query
ES_QUERY = {
  "query": {
    "bool": {
      "must": [
        {"term": {"tags": "big data"}},
        {"term": {"industry": "financial services"}},
        {"term": {"location.country": "united states"}}
      ]
    }
  }
}

# Create a parameters JSON object
PARAMS = {
  'query': ES_QUERY,
  'size': 10,
  'pretty': True
}

# Pass the parameters object to the Company Search API
response = CLIENT.company.search(**PARAMS).json()

# Check for successful response
if response["status"] == 200:
  data = response['data']
  # Write out each profile found to file
  with open("my_pdl_search.jsonl", "w") as out:
    for record in data:
      out.write(json.dumps(record) + "\n")
  print(f"Successfully grabbed {len(data)} records from PDL.")
  print(f"{response['total']} total PDL records exist matching this query.")
else:
  print("NOTE: The carrier pigeons lost motivation in flight. See error and try again.")
  print("Error:", response)
```

```
import json

# See https://github.com/peopledatalabs/peopledatalabs-python
from peopledatalabs import PDLPY

# Create a client, specifying your API key
CLIENT = PDLPY(
    api_key="YOUR API KEY",
)

# Create an SQL query
SQL_QUERY = \
"""
  SELECT * FROM company
  WHERE tags='big data'
  AND industry='financial services'
  AND location.country='united states';
 """

# Create a parameters JSON object
PARAMS = {
  'sql': SQL_QUERY,
  'size': 10,
  'pretty': True
}

# Pass the parameters object to the Company Search API
response = CLIENT.company.search(**PARAMS).json()

# Check for successful response
if response["status"] == 200:
  data = response['data']
  # Write out each profile found to file
  with open("my_pdl_search.jsonl", "w") as out:
    for record in data:
      out.write(json.dumps(record) + "\n")
  print(f"Successfully grabbed {len(data)} records from PDL.")
  print(f"{response['total']} total PDL records exist matching this query.")
else:
  print("NOTE: The carrier pigeons lost motivation in flight. See error and try again.")
  print("Error:", response)
```

```
// See https://github.com/peopledatalabs/peopledatalabs-js
import PDLJS from 'peopledatalabs';

import fs from 'fs';

// Create a client, specifying your API key
const PDLJSClient = new PDLJS({ apiKey: "YOUR API KEY" });

// Create an Elasticsearch query
const esQuery = {
  query: {
    bool: {
      must:[
        {"term": {"tags": "big data"}},
        {"term": {"industry": "financial services"}},
        {"term": {"location.country": "united states"}}
      ]
    }
  }
}

// Create a parameters JSON object
const params = {
  searchQuery: esQuery, 
  size: 10,
  pretty: true
}

// Pass the parameters object to the Company Search API
PDLJSClient.company.search.elastic(params).then((data) => {
    // Write out all profiles found to file
    fs.writeFile("my_pdl_search.jsonl", Buffer.from(JSON.stringify(data.data)), (err) => {
        if (err) throw err;
    });
    console.log(`Successfully grabbed ${data.data.length} records from PDL.`);
    console.log(`${data["total"]} total PDL records exist matching this query.`)
}).catch((error) => {
    console.log("NOTE: The carrier pigeons lost motivation in flight. See error and try again.")
    console.log(error);
});
```

```
// See https://github.com/peopledatalabs/peopledatalabs-js
import PDLJS from 'peopledatalabs';

import fs from 'fs';

// Create a client, specifying your API key
const PDLJSClient = new PDLJS({ apiKey: "YOUR API KEY" });

// Create an SQL query
const sqlQuery = `SELECT * FROM company
                    WHERE tags='big data'
                    AND industry='financial services'
                    AND location.country='united states';`;

// Create a parameters JSON object
const params = {
    searchQuery: sqlQuery, 
  	size: 10,
  	pretty: true
}

// Pass the parameters object to the Company Search API
PDLJSClient.company.search.sql(params).then((data) => {
    // Write out all profiles found to file
    fs.writeFile("my_pdl_search.jsonl", Buffer.from(JSON.stringify(data.data)), (err) => {
        if (err) throw err;
    });
    console.log(`Successfully grabbed ${data.data.length} records from PDL.`);
    console.log(`${data["total"]} total PDL records exist matching this query.`)
}).catch((error) => {
    console.log("NOTE: The carrier pigeons lost motivation in flight. See error and try again.")
    console.log(error);
});
```

```
require 'json'

# See https://github.com/peopledatalabs/peopledatalabs-ruby
require 'peopledatalabs'

# Set your API key
Peopledatalabs.api_key = 'YOUR API KEY'

# Create an Elasticsearch query
ES_QUERY = {
  "query": {
    "bool": {
      "must": [
        {"term": {"tags": "big data"}},
        {"term": {"industry": "financial services"}},
        {"term": {"location.country": "united states"}}
      ]
    }
  }
}

# Pass parameters to the Company Search API
response = Peopledatalabs::Search.company(searchType: 'elastic', query: ES_QUERY, size: 10, pretty: true)

# Check for successful response
if response['status'] == 200
    data = response['data']
    # Write out each profile found to file
    File.open("my_pdl_search.jsonl", "w") do |out|
        data.each { |record| out.write(JSON.dump(record) + "\n") }
    end
    puts "Successfully grabbed #{data.length()} records from PDL."
    puts "#{response['total']} total PDL records exist matching this query."
else
    puts "NOTE: The carrier pigeons lost motivation in flight. See error and try again."
    puts "Error: #{response}"
end
```

```
require 'json'

# See https://github.com/peopledatalabs/peopledatalabs-ruby
require 'peopledatalabs'

# Set your API key
Peopledatalabs.api_key = 'YOUR API KEY'

# Create an SQL query
SQL_QUERY = \
"""
  SELECT * FROM company
  WHERE tags='big data'
  AND industry='financial services'
  AND location.country='united states';
 """

# Pass parameters to the Company Search API
response = Peopledatalabs::Search.company(searchType: 'sql', query: SQL_QUERY, size: 10, pretty: true)

# Check for successful response
if response['status'] == 200
    data = response['data']
    # Write out each profile found to file
    File.open("my_pdl_search.jsonl", "w") do |out|
        data.each { |record| out.write(JSON.dump(record) + "\n") }
    end
    puts "Successfully grabbed #{data.length()} records from PDL."
    puts "#{response['total']} total PDL records exist matching this query."
else
    puts "NOTE: The carrier pigeons lost motivation in flight. See error and try again."
    puts "Error: #{response}"
end
```

```
package main

import(
    "fmt"
    "os"
    "encoding/json"
    "context"
)

// See https://github.com/peopledatalabs/peopledatalabs-go
import (
    pdl "github.com/peopledatalabs/peopledatalabs-go"
    pdlmodel "github.com/peopledatalabs/peopledatalabs-go/model"
)

func main() {
    // Set your API key
    apiKey := "YOUR API KEY"
    // Set API key as environmental variable
    // apiKey := os.Getenv("API_KEY")

    // Create a client, specifying your API key
    client := pdl.New(apiKey)

    // Create an Elasticsearch query
    elasticSearchQuery := map[string]interface{} {
        "query": map[string]interface{} {
            "bool": map[string]interface{} {
                "must": []map[string]interface{} {
                    {"term": map[string]interface{}{"tags": "big data"}},
                    {"term": map[string]interface{}{"industry": "financial services"}},
                    {"term": map[string]interface{}{"location.country": "united states"}},
                },
            },
        },
    }

    // Create a parameters JSON object
    params := pdlmodel.SearchParams {
        BaseParams: pdlmodel.BaseParams {
            Size: 10,
            Pretty: true,
        },
        SearchBaseParams: pdlmodel.SearchBaseParams {
            Query: elasticSearchQuery,
        },
    }
    
    // Pass the parameters object to the Company Search API
    response, err := client.Company.Search(context.Background(), params)
    // Check for successful response
    if err == nil {
        data := response.Data
        // Create file
        out, outErr := os.Create("my_pdl_search.jsonl")
        defer out.Close()
        if (outErr == nil) {
            for i := range data {
                // Convert each profile found to JSON
                record, jsonErr := json.Marshal(data[i])
                // Write out each profile to file
                if (jsonErr == nil) {
                    out.WriteString(string(record) + "\n")
                }
            }
            out.Sync()
        }
        fmt.Printf("Successfully grabbed %d records from PDL.\n", len(data))
        fmt.Printf("%d total PDL records exist matching this query.\n", response.Total)
    } else {
        fmt.Println("NOTE: The carrier pigeons lost motivation in flight. See error and try again.")
        fmt.Println("Error:", err)
    } 
}
```

```
package main

import(
    "fmt"
    "os"
    "encoding/json"
    "context"
)

// See https://github.com/peopledatalabs/peopledatalabs-go
import (
    pdl "github.com/peopledatalabs/peopledatalabs-go"
    pdlmodel "github.com/peopledatalabs/peopledatalabs-go/model"
)

func main() {
    // Set your API key
    apiKey := "YOUR API KEY"
    // Set API key as environmental variable
    // apiKey := os.Getenv("API_KEY")

    // Create a client, specifying your API key
    client := pdl.New(apiKey)

    // Create an SQL query
    sqlQuery := "SELECT * FROM company" +
        " WHERE tags='big data'" +
        " AND industry='financial services'" +
        " AND location.country='united states';"

    // Create a parameters JSON object
    params := pdlmodel.SearchParams {
        BaseParams: pdlmodel.BaseParams {
            Size: 10,
            Pretty: true,
        },
        SearchBaseParams: pdlmodel.SearchBaseParams {
            SQL: sqlQuery,
        },
    }
    
    // Pass the parameters object to the Company Search API
    response, err := client.Company.Search(context.Background(), params)
    // Check for successful response
    if err == nil {
        data := response.Data
        // Create file
        out, outErr := os.Create("my_pdl_search.jsonl")
        defer out.Close()
        if (outErr == nil) {
            for i := range data {
                // Convert each profile found to JSON
                record, jsonErr := json.Marshal(data[i])
                // Write out each profile to file
                if (jsonErr == nil) {
                    out.WriteString(string(record) + "\n")
                }
            }
            out.Sync()
        }
        fmt.Printf("Successfully grabbed %d records from PDL.\n", len(data))
        fmt.Printf("%d total PDL records exist matching this query.\n", response.Total)
    } else {
        fmt.Println("NOTE: The carrier pigeons lost motivation in flight. See error and try again.")
        fmt.Println("Error:", err)
    } 
}
```

```
import requests, json

# Set your API key
API_KEY = "YOUR API KEY"

# Set the Company Search API URL
PDL_URL = "https://api.peopledatalabs.com/v5/company/search"

# Set headers
HEADERS = {
  'Content-Type': "application/json",
  'X-api-key': API_KEY
}

# Create an Elasticsearch query
ES_QUERY = {
  "query": {
    "bool": {
      "must": [
        {"term": {"tags": "big data"}},
        {"term": {"industry": "financial services"}},
        {"term": {"location.country": "united states"}}
      ]
    }
  }
}

# Create a parameters JSON object
PARAMS = {
  'query': json.dumps(ES_QUERY),
  'size': 10,
  'pretty': True
}

# Pass the parameters object to the Company Search API
response = requests.get(
  PDL_URL,
  headers=HEADERS,
  params=PARAMS
).json()

# Check for successful response
if response["status"] == 200:
  data = response['data']
  # Write out each profile found to file
  with open("my_pdl_search.jsonl", "w") as out:
    for record in data:
      out.write(json.dumps(record) + "\n")
  print(f"Successfully grabbed {len(data)} records from PDL.")
  print(f"{response['total']} total PDL records exist matching this query.")
else:
  print("NOTE: The carrier pigeons lost motivation in flight. See error and try again.")
  print("Error:", response)
```

```
import requests, json

# Set your API key
API_KEY = "YOUR API KEY"

# Set the Company Search API URL
PDL_URL = "https://api.peopledatalabs.com/v5/company/search"

# Set headers
HEADERS = {
  'Content-Type': "application/json",
  'X-api-key': API_KEY
}

# Create an SQL query
SQL_QUERY = \
"""
  SELECT * FROM company
  WHERE tags='big data'
  AND industry='financial services'
  AND location.country='united states';
 """

# Create a parameters JSON object
PARAMS = {
  'sql': SQL_QUERY,
  'size': 10,
  'pretty': True
}

# Pass the parameters object to the Company Search API
response = requests.get(
  PDL_URL,
  headers=HEADERS,
  params=PARAMS
).json()

# Check for successful response
if response["status"] == 200:
  data = response['data']
  # Write out each profile found to file
  with open("my_pdl_search.jsonl", "w") as out:
    for record in data:
      out.write(json.dumps(record) + "\n")
  print(f"Successfully grabbed {len(data)} records from PDL.")
  print(f"{response['total']} total PDL records exist matching this query.")
else:
  print("NOTE: The carrier pigeons lost motivation in flight. See error and try again.")
  print("Error:", response)
```

## Sales and Marketing

*"I want to find companies offering account-based marketing services in the United States."*

Python3 SDK (Elasticsearch)JavaScript (Elasticsearch)Ruby (Elasticsearch)Go (Elasticsearch)Python3 (Elasticsearch)

```
import json

# See https://github.com/peopledatalabs/peopledatalabs-python
from peopledatalabs import PDLPY

# Create a client, specifying your API key
CLIENT = PDLPY(
    api_key="YOUR API KEY",
)

# Create an Elasticsearch query
ES_QUERY = {
  "query": {
    "bool": {
      "must": [
        {"match": {"summary": "account based marketing"}},
        {"term": {"location.country" : "united states"}}
      ]
    }
  }
}

# Create a parameters JSON object
PARAMS = {
  'query': ES_QUERY,
  'size': 100
}

# Pass the parameters object to the Company Search API
response = CLIENT.company.search(**PARAMS).json()

# Check for successful response
if response["status"] == 200:
  
  data = response['data']
  
  # Write out each profile found to file
  with open("my_pdl_search.jsonl", "w") as out:
    for record in data:
      out.write(json.dumps(record) + "\n")
  
  print(f"Successfully grabbed {len(data)} records from PDL.")
  print(f"{response['total']} total PDL records exist matching this query.")
else:
  print("NOTE: The eager beaver was not so eager. See error and try again.")
  print("error:", response)
```

```
// See https://github.com/peopledatalabs/peopledatalabs-js
import PDLJS from 'peopledatalabs';

import fs from 'fs';

// Create a client, specifying your API key
const PDLJSClient = new PDLJS({ apiKey: "YOUR API KEY" });

// Create an Elasticsearch query
const esQuery = {
  query: {
    bool: {
      must:[
        {"match": {"summary": "account based marketing"}},
        {"term": {"location.country" : "united states"}}
      ]
    }
  }
}

// Create a parameters JSON object
const params = {
  searchQuery: esQuery, 
  size: 100,
}

// Pass the parameters object to the Company Search API
PDLJSClient.company.search.elastic(params).then((data) => {
    // Write out all profiles found to file
    fs.writeFile("my_pdl_search.jsonl", Buffer.from(JSON.stringify(data.data)), (err) => {
        if (err) throw err;
    });
    console.log(`Successfully grabbed ${data.data.length} records from PDL.`);
    console.log(`${data["total"]} total PDL records exist matching this query.`)
}).catch((error) => {
    console.log("NOTE: The carrier pigeons lost motivation in flight. See error and try again.")
    console.log(error);
});
```

```
require 'json'

# See https://github.com/peopledatalabs/peopledatalabs-ruby
require 'peopledatalabs'

# Set your API key
Peopledatalabs.api_key = 'YOUR API KEY'

# Create an Elasticsearch query
ES_QUERY = {
  "query": {
    "bool": {
      "must": [
        {"match": {"summary": "account based marketing"}},
        {"term": {"location.country": "united states"}}
      ]
    }
  }
}

# Pass parameters to the Company Search API
response = Peopledatalabs::Search.company(searchType: 'elastic', query: ES_QUERY, size: 100, pretty: true)

# Check for successful response
if response['status'] == 200
    data = response['data']
    # Write out each profile found to file
    File.open("my_pdl_search.jsonl", "w") do |out|
        data.each { |record| out.write(JSON.dump(record) + "\n") }
    end
    puts "Successfully grabbed #{data.length()} records from PDL."
    puts "#{response['total']} total PDL records exist matching this query."
else
    puts "NOTE: The carrier pigeons lost motivation in flight. See error and try again."
    puts "Error: #{response}"
end
```

```
package main

import(
    "fmt"
    "os"
    "encoding/json"
    "context"
)

// See https://github.com/peopledatalabs/peopledatalabs-go
import (
    pdl "github.com/peopledatalabs/peopledatalabs-go"
    pdlmodel "github.com/peopledatalabs/peopledatalabs-go/model"
)

func main() {
    // Set your API key
    apiKey := "YOUR API KEY"
    // Set API key as environmental variable
    // apiKey := os.Getenv("API_KEY")

    // Create a client, specifying your API key
    client := pdl.New(apiKey)

    // Create an Elasticsearch query
    elasticSearchQuery := map[string]interface{} {
        "query": map[string]interface{} {
            "bool": map[string]interface{} {
                "must": []map[string]interface{} {
                    {"match": map[string]interface{}{"summary": "account based marketing"}},
                    {"term": map[string]interface{}{"location.country": "united states"}},
                },
            },
        },
    }

    // Create a parameters JSON object
    params := pdlmodel.SearchParams {
        BaseParams: pdlmodel.BaseParams {
            Size: 10,
        },
        SearchBaseParams: pdlmodel.SearchBaseParams {
            Query: elasticSearchQuery,
        },
    }
    
    // Pass the parameters object to the Company Search API
    response, err := client.Company.Search(context.Background(), params)
    // Check for successful response
    if err == nil {
        data := response.Data
        // Create file
        out, outErr := os.Create("my_pdl_search.jsonl")
        defer out.Close()
        if (outErr == nil) {
            for i := range data {
                // Convert each profile found to JSON
                record, jsonErr := json.Marshal(data[i])
                // Write out each profile to file
                if (jsonErr == nil) {
                    out.WriteString(string(record) + "\n")
                }
            }
            out.Sync()
        }
        fmt.Printf("Successfully grabbed %d records from PDL.\n", len(data))
        fmt.Printf("%d total PDL records exist matching this query.\n", response.Total)
    } else {
        fmt.Println("NOTE: The eager beaver was not so eager. See error and try again.")
        fmt.Println("Error:", err)
    } 
}
```

```
import requests, json

# Set your API key
API_KEY = "YOUR API KEY"

# Set the Company Search API URL
PDL_URL = "https://api.peopledatalabs.com/v5/company/search"

# Set headers
HEADERS = {
  'Content-Type': "application/json",
  'X-api-key': API_KEY
}

# Create an Elasticsearch query
ES_QUERY = {
  "query": {
    "bool": {
      "must": [
        {"match": {"summary": "account based marketing"}},
        {"term": {"location.country" : "united states"}}
      ]
    }
  }
}

# Create a parameters JSON object
PARAMS = {
  'query': json.dumps(ES_QUERY),
  'size': 100
}

# Pass the parameters object to the Company Search API
response = requests.get(
  PDL_URL,
  headers=HEADERS,
  params=PARAMS
).json()

# Check for successful response
if response["status"] == 200:
  
  data = response['data']
  
  # Write out each profile found to file
  with open("my_pdl_search.jsonl", "w") as out:
    for record in data:
      out.write(json.dumps(record) + "\n")
  
  print(f"Successfully grabbed {len(data)} records from PDL.")
  print(f"{response['total']} total PDL records exist matching this query.")
else:
  print("NOTE: The eager beaver was not so eager. See error and try again.")
  print("error:", response)
```

## Investment Research

*"I want to find 100 small biotech companies headquartered in the San Francisco area with under 50 employees ."*

Python3 SDK (Elasticsearch)Python3 SDK (SQL)JavaScript (Elasticsearch)JavaScript (SQL)Ruby (Elasticsearch)Ruby (SQL)Go (Elasticsearch)Go (SQL)Python3 (Elasticsearch)Python3 (SQL)

```
import json

# See https://github.com/peopledatalabs/peopledatalabs-python
from peopledatalabs import PDLPY

# Create a client, specifying your API key
CLIENT = PDLPY(
    api_key="YOUR API KEY",
)

# https://pdl-prod-schema.s3-us-west-2.amazonaws.com/14.0/enums/industry.txt
# for enumerated possible values of industry

# https://pdl-prod-schema.s3-us-west-2.amazonaws.com/14.0/enums/job_company_size.txt
# for enumerated possible values of company sizes

# Create an Elasticsearch query
ES_QUERY = {
  "query": {
    "bool": {
      "must": [
        {"terms": {"size": ["1-10", "11-50"]}},
        {"term": {"industry" : "biotechnology"}},
        {"term": {"location.locality": "san francisco"}}
      ]
    }
  }
}

# Create a parameters JSON object
PARAMS = {
    "query": ES_QUERY,
    "size": 100
}

# Pass the parameters object to the Company Search API
response = CLIENT.company.search(**PARAMS).json()

# Check for successful response
if response["status"] == 200:
  
  data = response['data']
  
  # Write out each profile found to file
  with open("my_pdl_search.jsonl", "w") as out:
    for record in data:
      out.write(json.dumps(record) + "\n")
  
  print(f"Successfully grabbed {len(data)} records from PDL.")
  print(f"{response['total']} total PDL records exist matching this query.")
else:
  print("NOTE: The eager beaver was not so eager. See error and try again.")
  print("error:", response)
```

```
import json

# See https://github.com/peopledatalabs/peopledatalabs-python
from peopledatalabs import PDLPY

# Create a client, specifying your API key
CLIENT = PDLPY(
    api_key="YOUR API KEY",
)

# https://pdl-prod-schema.s3-us-west-2.amazonaws.com/14.0/enums/industry.txt
# for enumerated possible values of industry

# https://pdl-prod-schema.s3-us-west-2.amazonaws.com/14.0/enums/job_company_size.txt
# for enumerated possible values of company sizes

# Create an SQL query
SQL_QUERY = \
f"""
  SELECT * FROM company
  WHERE size IN ('1-10', '11-50')
  AND industry = 'biotechnology'
  AND location.locality='san francisco';
"""

# Create a parameters JSON object
PARAMS = {
  'sql': SQL_QUERY,
  'size': 100
}

# Pass the parameters object to the Company Search API
response = CLIENT.company.search(**PARAMS).json()

# Check for successful response
if response["status"] == 200:
  
  data = response['data']
  
  # Write out each profile found to file
  with open("my_pdl_search.jsonl", "w") as out:
    for record in data:
      out.write(json.dumps(record) + "\n")
  
  print(f"Successfully grabbed {len(data)} records from PDL.")
  print(f"{response['total']} total PDL records exist matching this query.")
else:
  print("NOTE: The eager beaver was not so eager. See error and try again.")
  print("error:", response)
```

```
// See https://github.com/peopledatalabs/peopledatalabs-js
import PDLJS from 'peopledatalabs';

import fs from 'fs';

// Create a client, specifying your API key
const PDLJSClient = new PDLJS({ apiKey: "YOUR API KEY" });

// Create an Elasticsearch query
const esQuery = {
  query: {
    bool: {
      must:[
        {"terms": {"size": ["1-10", "11-50"]}},
        {"term": {"industry" : "biotechnology"}},
        {"term": {"location.locality": "san francisco"}}
      ]
    }
  }
}

// Create a parameters JSON object
const params = {
  searchQuery: esQuery, 
  size: 100,
}

// Pass the parameters object to the Company Search API
PDLJSClient.company.search.elastic(params).then((data) => {
    // Write out all profiles found to file
    fs.writeFile("my_pdl_search.jsonl", Buffer.from(JSON.stringify(data.data)), (err) => {
        if (err) throw err;
    });
    console.log(`Successfully grabbed ${data.data.length} records from PDL.`);
    console.log(`${data["total"]} total PDL records exist matching this query.`)
}).catch((error) => {
    console.log("NOTE: The carrier pigeons lost motivation in flight. See error and try again.")
    console.log(error);
});
```

```
// See https://github.com/peopledatalabs/peopledatalabs-js
import PDLJS from 'peopledatalabs';

import fs from 'fs';

// Create a client, specifying your API key
const PDLJSClient = new PDLJS({ apiKey: "YOUR API KEY" });

// Create an SQL query
const sqlQuery = `SELECT * FROM company
                    WHERE size IN ('1-10', '11-50')
                    AND industry = 'biotechnology'
                    AND location.locality='san francisco';`;

// Create a parameters JSON object
const params = {
    searchQuery: sqlQuery, 
    size: 100
}

// Pass the parameters object to the Company Search API
PDLJSClient.company.search.sql(params).then((data) => {
    // Write out all profiles found to file
    fs.writeFile("my_pdl_search.jsonl", Buffer.from(JSON.stringify(data.data)), (err) => {
        if (err) throw err;
    });
    console.log(`Successfully grabbed ${data.data.length} records from PDL.`);
    console.log(`${data["total"]} total PDL records exist matching this query.`)
}).catch((error) => {
    console.log("NOTE: The carrier pigeons lost motivation in flight. See error and try again.")
    console.log(error);
});
```

```
require 'json'

# See https://github.com/peopledatalabs/peopledatalabs-ruby
require 'peopledatalabs'

# Set your API key
Peopledatalabs.api_key = 'YOUR API KEY'

# https://pdl-prod-schema.s3-us-west-2.amazonaws.com/14.0/enums/industry.txt
# for enumerated possible values of industry

# https://pdl-prod-schema.s3-us-west-2.amazonaws.com/14.0/enums/job_company_size.txt
# for enumerated possible values of company sizes

# Create an Elasticsearch query
ES_QUERY = {
  "query": {
    "bool": {
      "must": [
        {"terms": {"size": ["1-10", "11-50"]}},
        {"term": {"industry": "biotechnology"}},
        {"term": {"location.locality": "san francisco"}}
      ]
    }
  }
}

# Pass parameters to the Company Search API
response = Peopledatalabs::Search.company(searchType: 'elastic', query: ES_QUERY, size: 100, pretty: true)

# Check for successful response
if response['status'] == 200
    data = response['data']
    # Write out each profile found to file
    File.open("my_pdl_search.jsonl", "w") do |out|
        data.each { |record| out.write(JSON.dump(record) + "\n") }
    end
    puts "Successfully grabbed #{data.length()} records from PDL."
    puts "#{response['total']} total PDL records exist matching this query."
else
    puts "NOTE: The carrier pigeons lost motivation in flight. See error and try again."
    puts "Error: #{response}"
end
```

```
require 'json'

# See https://github.com/peopledatalabs/peopledatalabs-ruby
require 'peopledatalabs'

# Set your API key
Peopledatalabs.api_key = 'YOUR API KEY'

# https://pdl-prod-schema.s3-us-west-2.amazonaws.com/14.0/enums/industry.txt
# for enumerated possible values of industry

# https://pdl-prod-schema.s3-us-west-2.amazonaws.com/14.0/enums/job_company_size.txt
# for enumerated possible values of company sizes

# Create an SQL query
SQL_QUERY = \
"""
  SELECT * FROM company
  WHERE size IN ('1-10', '11-50')
  AND industry = 'biotechnology'
  AND location.locality='san francisco';
"""

# Pass parameters to the Company Search API
response = Peopledatalabs::Search.company(searchType: 'sql', query: SQL_QUERY, size: 100, pretty: true)

# Check for successful response
if response['status'] == 200
    data = response['data']
    # Write out each profile found to file
    File.open("my_pdl_search.jsonl", "w") do |out|
        data.each { |record| out.write(JSON.dump(record) + "\n") }
    end
    puts "Successfully grabbed #{data.length()} records from PDL."
    puts "#{response['total']} total PDL records exist matching this query."
else
    puts "NOTE: The carrier pigeons lost motivation in flight. See error and try again."
    puts "Error: #{response}"
end
```

```
package main

import(
    "fmt"
    "os"
    "encoding/json"
    "context"
)

// See https://github.com/peopledatalabs/peopledatalabs-go
import (
    pdl "github.com/peopledatalabs/peopledatalabs-go"
    pdlmodel "github.com/peopledatalabs/peopledatalabs-go/model"
)

func main() {
    // Set your API key
    apiKey := "YOUR API KEY"
    // Set API key as environmental variable
    // apiKey := os.Getenv("API_KEY")

    // Create a client, specifying your API key
    client := pdl.New(apiKey)

    // https://pdl-prod-schema.s3-us-west-2.amazonaws.com/14.0/enums/industry.txt
    // for enumerated possible values of industry

    // https://pdl-prod-schema.s3-us-west-2.amazonaws.com/14.0/enums/job_company_size.txt
    // for enumerated possible values of company sizes

    // Create an Elasticsearch query
    elasticSearchQuery := map[string]interface{} {
        "query": map[string]interface{} {
            "bool": map[string]interface{} {
                "must": []map[string]interface{} {
                    {"terms": map[string]interface{}{"size": []string{"1-10", "11-50"}}},
                    {"term": map[string]interface{}{"industry": "biotechnology"}},
                    {"term": map[string]interface{}{"location.locality": "san francisco"}},
                },
            },
        },
    }

    // Create a parameters JSON object
    params := pdlmodel.SearchParams {
        BaseParams: pdlmodel.BaseParams {
            Size: 100,
        },
        SearchBaseParams: pdlmodel.SearchBaseParams {
            Query: elasticSearchQuery,
        },
    }
    
    // Pass the parameters object to the Company Search API
    response, err := client.Company.Search(context.Background(), params)
    // Check for successful response
    if err == nil {
        data := response.Data
        // Create file
        out, outErr := os.Create("my_pdl_search.jsonl")
        defer out.Close()
        if (outErr == nil) {
            for i := range data {
                // Convert each profile found to JSON
                record, jsonErr := json.Marshal(data[i])
                // Write out each profile to file
                if (jsonErr == nil) {
                    out.WriteString(string(record) + "\n")
                }
            }
            out.Sync()
        }
        fmt.Printf("Successfully grabbed %d records from pdl.\n", len(data))
        fmt.Printf("%d total PDL records exist matching this query.\n", response.Total)
    } else {
        fmt.Println("NOTE: The eager beaver was not so eager. See error and try again.")
        fmt.Println("Error:", err)
    } 
}
```

```
package main

import(
    "fmt"
    "os"
    "encoding/json"
    "context"
)

// See https://github.com/peopledatalabs/peopledatalabs-go
import (
    pdl "github.com/peopledatalabs/peopledatalabs-go"
    pdlmodel "github.com/peopledatalabs/peopledatalabs-go/model"
)

func main() {
    // Set your API key
    apiKey := "YOUR API KEY"
    // Set API key as environmental variable
    // apiKey := os.Getenv("API_KEY")

    // Create a client, specifying your API key
    client := pdl.New(apiKey)

    // https://pdl-prod-schema.s3-us-west-2.amazonaws.com/14.0/enums/industry.txt
    // for enumerated possible values of industry

    // https://pdl-prod-schema.s3-us-west-2.amazonaws.com/14.0/enums/job_company_size.txt
    // for enumerated possible values of company sizes

    // Create an SQL query
    sqlQuery := "SELECT * FROM company" +
        " WHERE size IN ('1-10', '11-50')" +
        " AND industry = 'biotechnology'" +
        " AND location.locality='san francisco';"

    // Create a parameters JSON object
    params := pdlmodel.SearchParams {
        BaseParams: pdlmodel.BaseParams {
            Size: 100,
            Pretty: true,
        },
        SearchBaseParams: pdlmodel.SearchBaseParams {
            SQL: sqlQuery,
        },
    }
    
    // Pass the parameters object to the Company Search API
    response, err := client.Company.Search(context.Background(), params)
    // Check for successful response
    if err == nil {
        data := response.Data
        // Create file
        out, outErr := os.Create("my_pdl_search.jsonl")
        defer out.Close()
        if (outErr == nil) {
            for i := range data {
                // Convert each profile found to JSON
                record, jsonErr := json.Marshal(data[i])
                // Write out each profile to file
                if (jsonErr == nil) {
                    out.WriteString(string(record) + "\n")
                }
            }
            out.Sync()
        }
        fmt.Printf("Successfully grabbed %d records from PDL.\n", len(data))
        fmt.Printf("%d total PDL records exist matching this query.\n", response.Total)
    } else {
        fmt.Println("NOTE: The eager beaver was not so eager. See error and try again.")
        fmt.Println("Error:", err)
    } 
}
```

```
import requests, json

# Set your API key
API_KEY = "YOUR API KEY"

# Set the Company Search API URL
PDL_URL = "https://api.peopledatalabs.com/v5/company/search"

# Set headers
HEADERS = {
  "Content-Type": "application/json",
  "X-api-key": API_KEY
}

# https://pdl-prod-schema.s3-us-west-2.amazonaws.com/14.0/enums/industry.txt
# for enumerated possible values of industry

# https://pdl-prod-schema.s3-us-west-2.amazonaws.com/14.0/enums/job_company_size.txt
# for enumerated possible values of company sizes

# Create an Elasticsearch query
ES_QUERY = {
  "query": {
    "bool": {
      "must": [
        {"terms": {"size": ["1-10", "11-50"]}},
        {"term": {"industry" : "biotechnology"}},
        {"term": {"location.locality": "san francisco"}}
      ]
    }
  }
}

# Create a parameters JSON object
PARAMS = {
    "query": json.dumps(ES_QUERY),
    "size": 100
}

# Pass the parameters object to the Company Search API
response = requests.get(
    PDL_URL,
    headers=HEADERS,
    params=PARAMS
).json()

# Check for successful response
if response["status"] == 200:
  
  data = response['data']
  
  # Write out each profile found to file
  with open("my_pdl_search.jsonl", "w") as out:
    for record in data:
      out.write(json.dumps(record) + "\n")

  print(f"Successfully grabbed {len(response['data'])} records from PDL.")
  print(f"{response['total']} total PDL records exist matching this query.")
else:
  print("NOTE: The eager beaver was not so eager. See error and try again.")
  print("error:", response)
```

```
import requests, json

# Set your API key
API_KEY = "YOUR API KEY"

# Set the Company Search API URL
PDL_URL = "https://api.peopledatalabs.com/v5/company/search"

# Set headers
HEADERS = {
  "Content-Type": "application/json",
  "X-api-key": API_KEY
}

# https://pdl-prod-schema.s3-us-west-2.amazonaws.com/14.0/enums/industry.txt
# for enumerated possible values of industry

# https://pdl-prod-schema.s3-us-west-2.amazonaws.com/14.0/enums/job_company_size.txt
# for enumerated possible values of company sizes

# Create an SQL query
SQL_QUERY = \
f"""
  SELECT * FROM company
  WHERE size IN ('1-10', '11-50')
  AND industry = 'biotechnology'
  AND location.locality='san francisco';
"""

# Create a parameters JSON object
PARAMS = {
  'sql': SQL_QUERY,
  'size': 100
}

# Pass the parameters object to the Company Search API
response = requests.get(
  PDL_URL,
  headers=HEADERS,
  params=PARAMS
).json()

# Check for successful response
if response["status"] == 200:
  
  data = response['data']
  
  # Write out each profile found to file
  with open("my_pdl_search.jsonl", "w") as out:
    for record in data:
      out.write(json.dumps(record) + "\n")

  print(f"Successfully grabbed {len(response['data'])} records from PDL.")
  print(f"{response['total']} total PDL records exist matching this query.")
else:
  print("NOTE: The eager beaver was not so eager. See error and try again.")
  print("error:", response)
```

## Bulk Retrieval

*"I want to find**all** automotive companies in the Detroit area and save them to a CSV file."*

> ðŸš§
>
> ### High Credit Usage Code Below
>
> The code example below illustrates retrieving all the company profiles in a metro area and is meant primarily for demonstrating the use of the `scroll_token` parameter when requesting large amounts of records. As a result, this code is mostly illustrative in meaning. It further can expend a lot of credits and doesn't have any error handling. The `MAX_NUM_RECORDS_LIMIT` parameter in the example sets the maximum number of profiles that you will retrieve (and the maximum number of credits that you will expend), so please set that accordingly when testing this example.

Python3 SDK (Elasticsearch)Python3 SDK (SQL)JavaScript (Elasticsearch)JavaScript (SQL)Ruby (Elasticsearch)Ruby (SQL)Go (Elasticsearch)Go (SQL)Python3 (Elasticsearch)Python3 (SQL)

```
import json, time, csv

# See https://github.com/peopledatalabs/peopledatalabs-python
from peopledatalabs import PDLPY

# Create a client, specifying your API key
CLIENT = PDLPY(
    api_key="YOUR API KEY",
)

# Limit the number of records to pull (to prevent accidentally using 
# more credits than expected when testing out this code).
MAX_NUM_RECORDS_LIMIT = 150 # The maximum number of records to retrieve
USE_MAX_NUM_RECORDS_LIMIT = True # Set to False to pull all available records

# Create an Elasticsearch query
ES_QUERY = {
  'query': {
    'bool': {
      'must': [
        {'term': {'industry': "automotive"}},
        {'term': {'location.metro': "detroit, michigan"}}
      ]
    }
  }
}

# Create a parameters JSON object
PARAMS = {
  'query': ES_QUERY,
  'size': 100,
  'pretty': True
}

# Pull all results in multiple batches
batch = 1
# Store all records retreived in an array
all_records = []
# Time the process
start_time = time.time()
found_all_records = False
continue_scrolling = True

# While still scrolling through data and still records to be found
while continue_scrolling and not found_all_records: 

  # Check if we reached the maximum number of records we want
  if USE_MAX_NUM_RECORDS_LIMIT:
    num_records_to_request = MAX_NUM_RECORDS_LIMIT - len(all_records)
    # Adjust size parameter
    PARAMS['size'] = max(0, min(100, num_records_to_request))
    # Check if MAX_NUM_RECORDS_LIMIT reached
    if num_records_to_request == 0:
      print(f"Stopping - reached maximum number of records to pull "
            f"[MAX_NUM_RECORDS_LIMIT = {MAX_NUM_RECORDS_LIMIT}].")
      break

  # Pass the parameters object to the Company Search API
  response = CLIENT.company.search(**PARAMS).json()

  # Check for successful response
  if response['status'] == 200:
    # Add records retrieved to the records array
    all_records.extend(response['data'])
    print(f"Retrieved {len(response['data'])} records in batch {batch} "
          f"- {response['total'] - len(all_records)} records remaining.")
  else:
    print(f"Error retrieving some records:\n\t"
          f"[{response['status']} - {response['error']['type']}] "
          f"{response['error']['message']}")
  
  # Get scroll_token from response if exists and store it in parameters object
  if 'scroll_token' in response:
    PARAMS['scroll_token'] = response['scroll_token']
  else:
    continue_scrolling = False
    print(f"Unable to continue scrolling.")

  batch += 1
  found_all_records = (len(all_records) == response['total'])
  time.sleep(6) # avoid hitting rate limit thresholds
 
# Calculate time required to process batches
end_time = time.time()
runtime = end_time - start_time
        
print(f"Successfully recovered {len(all_records)} profiles in "
      f"{batch} batches [{round(runtime, 2)} seconds].")

# Save profiles to CSV (utility function)
def save_profiles_to_csv(profiles, filename, fields=[], delim=','):
  # Define header fields
  if fields == [] and len(profiles) > 0:
      fields = profiles[0].keys()
  # Write CSV file
  with open(filename, 'w') as csvfile:
    writer = csv.writer(csvfile, delimiter=delim)
    # Write header
    writer.writerow(fields)
    # Write body
    count = 0
    for profile in profiles:
      writer.writerow([ profile[field] for field in fields ])
      count += 1
  print(f"Wrote {count} lines to: '{filename}'.")

# Use utility function to save all records retrieved to CSV   
csv_header_fields = ['name', 'website', "linkedin_url",
                     'size', 'tags']
csv_filename = "all_company_profiles.csv"
save_profiles_to_csv(all_records, csv_filename, csv_header_fields)
```

```
import json, time, csv

# See https://github.com/peopledatalabs/peopledatalabs-python
from peopledatalabs import PDLPY

# Create a client, specifying your API key
CLIENT = PDLPY(
    api_key="YOUR API KEY",
)

# Limit the number of records to pull (to prevent accidentally using 
# more credits than expected when testing out this code).
MAX_NUM_RECORDS_LIMIT = 150 # The maximum number of records to retrieve
USE_MAX_NUM_RECORDS_LIMIT = True # Set to False to pull all available records

# Create an SQL query
SQL_QUERY = \
f"""
  SELECT * FROM company
  WHERE industry = 'automotive'
  AND location.metro='detroit, michigan';
"""

# Create a parameters JSON object
PARAMS = {
  'sql': SQL_QUERY,
  'size': 100,
  'pretty': True
}

# Pull all results in multiple batches
batch = 1
# Store all records retreived in an array
all_records = []
# Time the process
start_time = time.time()
found_all_records = False
continue_scrolling = True

# While still scrolling through data and still records to be found
while continue_scrolling and not found_all_records: 

  # Check if we reached the maximum number of records we want
  if USE_MAX_NUM_RECORDS_LIMIT:
    num_records_to_request = MAX_NUM_RECORDS_LIMIT - len(all_records)
    # Adjust size parameter
    PARAMS['size'] = max(0, min(100, num_records_to_request))
    # Check if MAX_NUM_RECORDS_LIMIT reached
    if num_records_to_request == 0:
      print(f"Stopping - reached maximum number of records to pull "
            f"[MAX_NUM_RECORDS_LIMIT = {MAX_NUM_RECORDS_LIMIT}].")
      break

  # Pass the parameters object to the Company Search API
  response = CLIENT.company.search(**PARAMS).json()

  # Check for successful response
  if response['status'] == 200:
    # Add records retrieved to the records array
    all_records.extend(response['data'])
    print(f"Retrieved {len(response['data'])} records in batch {batch} "
          f"- {response['total'] - len(all_records)} records remaining.")
  else:
    print(f"Error retrieving some records:\n\t"
          f"[{response['status']} - {response['error']['type']}] "
          f"{response['error']['message']}")
  
  # Get scroll_token from response if exists and store it in parameters object
  if 'scroll_token' in response:
    PARAMS['scroll_token'] = response['scroll_token']
  else:
    continue_scrolling = False
    print(f"Unable to continue scrolling.")

  batch += 1
  found_all_records = (len(all_records) == response['total'])
  time.sleep(6) # avoid hitting rate limit thresholds
 
# Calculate time required to process batches
end_time = time.time()
runtime = end_time - start_time
        
print(f"Successfully recovered {len(all_records)} profiles in "
      f"{batch} batches [{round(runtime, 2)} seconds].")

# Save profiles to CSV (utility function)
def save_profiles_to_csv(profiles, filename, fields=[], delim=','):
  # Define header fields
  if fields == [] and len(profiles) > 0:
      fields = profiles[0].keys()
  # Write CSV file
  with open(filename, 'w') as csvfile:
    writer = csv.writer(csvfile, delimiter=delim)
    # Write header
    writer.writerow(fields)
    # Write body
    count = 0
    for profile in profiles:
      writer.writerow([ profile[field] for field in fields ])
      count += 1
  print(f"Wrote {count} lines to: '{filename}'.")

# Use utility function to save all records retrieved to CSV   
csv_header_fields = ['name', 'website', "linkedin_url",
                     'size', 'tags']
csv_filename = "all_company_profiles.csv"
save_profiles_to_csv(all_records, csv_filename, csv_header_fields)
```

```
// See https://github.com/peopledatalabs/peopledatalabs-js
import PDLJS from 'peopledatalabs';

// See https://www.npmjs.com/package/csv-writer
import * as csvwriter from 'csv-writer';

// Create a client, specifying your API key
const PDLJSClient = new PDLJS({ apiKey: "YOUR API KEY" });

// Limit the number of records to pull (to prevent accidentally using 
// more credits than expected when testing out this code).
const maxNumRecordsLimit = 150;     // The maximum number of records to retrieve
const useMaxNumRecordsLimit = true; // Set to false to pull all available records

// Create an Elasticsearch query
const esQuery = {
  query: {
    bool: {
      must:[
        {'term': {'industry': "automotive"}},
        {'term': {'location.metro': "detroit, michigan"}}
      ]
    }
  }
}

// Create a parameters JSON object
var params = {
  searchQuery: esQuery, 
  size: 100,
  scroll_token: null,
  pretty: true
}

// Pull all results in multiple batches
var batch = 1;

// Store all records retreived in an array
var allRecords = [];
// Time the process
var startTime = Date.now();
var foundAllRecords = false;
var continueScrolling = true;
var numRetrieved = 0;
// Queue parameter objects in order to iterate through batches
var paramQueue = [];
// The current scroll_token
var scrollToken = null;
var numRecordsToRequest = 100;

while (numRecordsToRequest > 0) { 

    // Check if we reached the maximum number of records we want
    if (useMaxNumRecordsLimit) {
        numRecordsToRequest = maxNumRecordsLimit - numRetrieved;
        // Adjust size parameter
        params.size = Math.max(0, Math.min(100, numRecordsToRequest));
        numRetrieved += params.size;
        // Add batch to the parameter queue
        if (params.size > 0) {       
            paramQueue.push(JSON.parse(JSON.stringify(params)));
        }
    } else {
        break;
    }
}

// Run initial batch
runBatch();

// Retrieve records associated with a batch
function runBatch() {
    // Get the parameters for the current batch
    let currParams = useMaxNumRecordsLimit ? paramQueue[batch-1] : params;
    // Set the scroll_token from the previous batch
    currParams.scroll_token = scrollToken;
    batch++;
                
    // Pass the current parameters object to the Company Search API
    PDLJSClient.company.search.elastic(currParams).then((data) => {
        // Add records retrieved to the records array
        Array.prototype.push.apply(allRecords, data.data);
            
        // Store the scroll_token if exists
        if (data['scroll_token']) {
            scrollToken = data['scroll_token'];
        } else {
            continueScrolling = false;
            console.log("Unable to continue scrolling.");
        }
            
        foundAllRecords = (allRecords.length == data['total']);
            
        console.log(`Retrieved ${data.data.length} records in batch ${(batch-1)}` +
            ` - ${(data['total'] - allRecords.length)} records remaining.`);
            
        // Run next batch recursively, if any
        if (!foundAllRecords && (batch <= paramQueue.length || !useMaxNumRecordsLimit)) {
            runBatch();
        } else {
            console.log(`Stopping - reached maximum number of records to pull [maxNumRecordsLimit = ` +
                `${maxNumRecordsLimit}].`);  
                
            // Calculate time required to process batches
            let endTime = Date.now();
            let runTime = endTime - startTime;
            console.log (`Successfully recovered ${allRecords.length} profiles in ` +
                `${(batch-1)} batches [${Math.round(runTime/1000)} seconds].`);
                
            // Set CSV fields
            let csvHeaderFields = [
                {id: "work_email", title: "work_email"},
                {id: "full_name", title: "full_name"}, 
                {id: "linkedin_url", title: "linkedin_url"},
                {id: "size", title: "size"},
                {id: "tags", title: "tags"}
            ];
            let csvFilename = "all_company_profiles.csv";
            // Write records array to CSV file
            saveProfilesToCSV(allRecords, csvFilename, csvHeaderFields);           
        }
    }).catch((error) => {
        console.log(error);
    });

}

// Write CSV file using csv-writer (https://www.npmjs.com/package/csv-writer) 
// $ npm i -s csv-writer
function saveProfilesToCSV(profiles, filename, fields) {

    // Create CSV file
    const createCsvWriter = csvwriter.createObjectCsvWriter;
    const csvWriter = createCsvWriter({
        path: filename,
        header: fields
    });
    
    let data = [];
    // Iterate through records array
    for (let i = 0; i < profiles.length; i++) {
        let record = profiles[i];
        data[i] = {};
        // Store requested fields
        for (let field in fields) {
            data[i][fields[field].id] = record[fields[field].id];    
        }
     }

    // Write data to CSV file
    csvWriter
        .writeRecords(data)
        .then(()=> console.log('The CSV file was written successfully.'));
}
```

```
// See https://github.com/peopledatalabs/peopledatalabs-js
import PDLJS from 'peopledatalabs';

// See https://www.npmjs.com/package/csv-writer
import * as csvwriter from 'csv-writer';

// Create a client, specifying your API key
const PDLJSClient = new PDLJS({ apiKey: "YOUR API KEY" });

// Limit the number of records to pull (to prevent accidentally using 
// more credits than expected when testing out this code).
const maxNumRecordsLimit = 150;     // The maximum number of records to retrieve
const useMaxNumRecordsLimit = true; // Set to false to pull all available records

// Create an SQL query
const sqlQuery = `SELECT * FROM company
                    WHERE industry = 'automotive'
                    AND location.metro='detroit, michigan';`;

// Create a parameters JSON object
var params = {
  searchQuery: sqlQuery, 
  size: 100,
  scroll_token: null,
  pretty: true
}

// Pull all results in multiple batches
var batch = 1;

// Store all records retreived in an array
var allRecords = [];
// Time the process
var startTime = Date.now();
var foundAllRecords = false;
var continueScrolling = true;
var numRetrieved = 0;
// Queue parameter objects in order to iterate through batches
var paramQueue = [];
// The current scroll_token
var scrollToken = null;
var numRecordsToRequest = 100;

while (numRecordsToRequest > 0) { 

    // Check if we reached the maximum number of records we want
    if (useMaxNumRecordsLimit) {
        numRecordsToRequest = maxNumRecordsLimit - numRetrieved;
        // Adjust size parameter
        params.size = Math.max(0, Math.min(100, numRecordsToRequest));
        numRetrieved += params.size;
        // Add batch to the parameter queue
        if (params.size > 0) {       
            paramQueue.push(JSON.parse(JSON.stringify(params)));
        }
    } else {
        break;
    }
}

// Run initial batch
runBatch();

// Retrieve records associated with a batch
function runBatch() {
    // Get the parameters for the current batch
    let currParams = useMaxNumRecordsLimit ? paramQueue[batch-1] : params;
    // Set the scroll_token from the previous batch
    currParams.scroll_token = scrollToken;
    batch++;
                
    // Pass the current parameters object to the Company Search API
    PDLJSClient.company.search.sql(currParams).then((data) => {
        // Add records retrieved to the records array
        Array.prototype.push.apply(allRecords, data.data);
            
        // Store the scroll_token if exists
        if (data['scroll_token']) {
            scrollToken = data['scroll_token'];
        } else {
            continueScrolling = false;
            console.log("Unable to continue scrolling.");
        }
            
        foundAllRecords = (allRecords.length == data['total']);
            
        console.log(`Retrieved ${data.data.length} records in batch ${(batch-1)}` +
            ` - ${(data['total'] - allRecords.length)} records remaining.`);
            
        // Run next batch recursively, if any
        if (!foundAllRecords && (batch <= paramQueue.length || !useMaxNumRecordsLimit)) {
            runBatch();
        } else {
            console.log(`Stopping - reached maximum number of records to pull [maxNumRecordsLimit = ` +
                `${maxNumRecordsLimit}].`);  
                
            // Calculate time required to process batches
            let endTime = Date.now();
            let runTime = endTime - startTime;
            console.log (`Successfully recovered ${allRecords.length} profiles in ` +
                `${(batch-1)} batches [${Math.round(runTime/1000)} seconds].`);
                
            // Set CSV fields
            let csvHeaderFields = [
                {id: "work_email", title: "work_email"},
                {id: "full_name", title: "full_name"}, 
                {id: "linkedin_url", title: "linkedin_url"},
                {id: "size", title: "size"},
                {id: "tags", title: "tags"}
            ];
            let csvFilename = "all_company_profiles.csv";
            // Write records array to CSV file
            saveProfilesToCSV(allRecords, csvFilename, csvHeaderFields);           
        }
    }).catch((error) => {
        console.log(error);
    });

}

// Write CSV file using csv-writer (https://www.npmjs.com/package/csv-writer)
// $ npm i -s csv-writer
function saveProfilesToCSV(profiles, filename, fields) {

    // Create CSV file
    const createCsvWriter = csvwriter.createObjectCsvWriter;
    const csvWriter = createCsvWriter({
        path: filename,
        header: fields
    });
    
    let data = [];
    for (let i = 0; i < profiles.length; i++) {
        let record = profiles[i];
        data[i] = {};
        // Store requested fields
        for (let field in fields) {
            data[i][fields[field].id] = record[fields[field].id];    
        }
     }

    // Write data to CSV file
    csvWriter
        .writeRecords(data)
        .then(()=> console.log('The CSV file was written successfully.'));
}
```

```
require 'json'
require 'csv'

# See https://github.com/peopledatalabs/peopledatalabs-ruby
require 'peopledatalabs'

# Set your API key
Peopledatalabs.api_key = 'YOUR API KEY'

# Limit the number of records to pull (to prevent accidentally using 
# more credits than expected when testing out this code).
MAX_NUM_RECORDS_LIMIT = 150 # The maximum number of records to retrieve
USE_MAX_NUM_RECORDS_LIMIT = true # Set to false to pull all available records

# Create an Elasticsearch query
ES_QUERY = {
  'query': {
    'bool': {
      'must': [
        {'term': {'industry': "automotive"}},
        {'term': {'location.metro': "detroit, michigan"}}
      ]
    }
  }
}

# Pull all results in multiple batches
batch = 1
# Store all records retreived in an array
all_records = []
# Time the process
start_time = Time.now
found_all_records = false
continue_scrolling = true
scroll_token = {}

# While still scrolling through data and still records to be found
while continue_scrolling && !found_all_records do 

  # Check if we reached the maximum number of records we want
  if USE_MAX_NUM_RECORDS_LIMIT
    num_records_to_request = MAX_NUM_RECORDS_LIMIT - all_records.length()
    # Adjust size parameter
    size = [0, [100, num_records_to_request].min].max
    # Check if MAX_NUM_RECORDS_LIMIT reached
    if num_records_to_request == 0
      puts "Stopping - reached maximum number of records to pull "
      puts "[MAX_NUM_RECORDS_LIMIT = #{MAX_NUM_RECORDS_LIMIT}]."
      break
    end
  end

  # Pass parameters to the Company Search API
  response = Peopledatalabs::Search.company(searchType: 'elastic', query: ES_QUERY, size: size, scroll_token: scroll_token, pretty: true)

  # Check for successful response
  if response['status'] == 200
    # Add records retrieved to the records array
    all_records += response['data']
    puts "Retrieved #{response['data'].length()} records in batch #{batch} "
    puts  "- #{response['total'] - all_records.length()} records remaining."
  else
    puts "Error retrieving some records:\n\t"
    puts "[#{response['status']} - #{response['error']['type']}] "
    puts response['error']['message']
  end
  
  # Get scroll_token from response if exists and store it
  if response.key?('scroll_token')
    scroll_token = response['scroll_token']
  else
    continue_scrolling = false
    puts "Unable to continue scrolling."
  end

  batch += 1
  found_all_records = (all_records.length() == response['total'])
  sleep(6) # avoid hitting rate limit thresholds
end

# Calculate time required to process batches
end_time = Time.now
runtime = end_time - start_time
        
puts "Successfully recovered #{all_records.length()} profiles in "
puts "#{batch} batches [#{runtime.round(2)} seconds]."

# Save profiles to CSV (utility function)
def save_profiles_to_csv(profiles, filename, fields=[], delim=',')
  # Define header fields
  if fields == [] && profiles.length() > 0
      fields = profiles[0].keys
  end
    
  count = 0
  # Write CSV file
  CSV.open(filename, 'w') do |writer|
    # Write header
    writer << fields
    # Write body
    profiles.each do |profile|
      record = []
      fields.each do |field| 
        record << profile[field]
        count += 1
      end
      writer << record
    end
  end
  puts "Wrote #{count} lines to: '#{filename}'."
end

# Use utility function to save profiles to CSV   
csv_header_fields = ['name', 'website', 'linkedin_url',
                     'size', 'tags']
csv_filename = "all_company_profiles.csv"
save_profiles_to_csv(all_records, csv_filename, csv_header_fields)
```

```
require 'json'
require 'csv'

# See https://github.com/peopledatalabs/peopledatalabs-ruby
require 'peopledatalabs'

# Set your API key
Peopledatalabs.api_key = 'YOUR API KEY'

# Limit the number of records to pull (to prevent accidentally using 
# more credits than expected when testing out this code).
MAX_NUM_RECORDS_LIMIT = 150 # The maximum number of records to retrieve
USE_MAX_NUM_RECORDS_LIMIT = true # Set to false to pull all available records

# Create an SQL query
SQL_QUERY = \
"""
  SELECT * FROM company
  WHERE industry = 'automotive'
  AND location.metro='detroit, michigan';
"""

# Pull all results in multiple batches
batch = 1
# Store all records retreived in an array
all_records = []
# Time the process
start_time = Time.now
found_all_records = false
continue_scrolling = true
scroll_token = {}

# While still scrolling through data and still records to be found
while continue_scrolling && !found_all_records do 

  # Check if we reached the maximum number of records we want
  if USE_MAX_NUM_RECORDS_LIMIT
    num_records_to_request = MAX_NUM_RECORDS_LIMIT - all_records.length()
    # Adjust size parameter
    size = [0, [100, num_records_to_request].min].max
    # Check if MAX_NUM_RECORDS_LIMIT reached
    if num_records_to_request == 0
      puts "Stopping - reached maximum number of records to pull "
      puts "[MAX_NUM_RECORDS_LIMIT = #{MAX_NUM_RECORDS_LIMIT}]."
      break
    end
  end

  # Pass parameters to the Company Search API
  response = Peopledatalabs::Search.company(searchType: 'sql', query: SQL_QUERY, size: size, scroll_token: scroll_token, pretty: true)

  # Check for successful response
  if response['status'] == 200
    # Add records retrieved to the records array
    all_records += response['data']
    puts "Retrieved #{response['data'].length()} records in batch #{batch} "
    puts  "- #{response['total'] - all_records.length()} records remaining."
  else
    puts "Error retrieving some records:\n\t"
    puts "[#{response['status']} - #{response['error']['type']}] "
    puts response['error']['message']
  end
  
  # Get scroll_token from response if exists and store it
  if response.key?('scroll_token')
    scroll_token = response['scroll_token']
  else
    continue_scrolling = false
    puts "Unable to continue scrolling."
  end

  batch += 1
  found_all_records = (all_records.length() == response['total'])
  sleep(6) # avoid hitting rate limit thresholds
end

# Calculate time required to process batches
end_time = Time.now
runtime = end_time - start_time
        
puts "Successfully recovered #{all_records.length()} profiles in "
puts "#{batch} batches [#{runtime.round(2)} seconds]."

# Save profiles to CSV (utility function)
def save_profiles_to_csv(profiles, filename, fields=[], delim=',')
  # Define header fields
  if fields == [] && profiles.length() > 0
      fields = profiles[0].keys
  end
    
  count = 0
  # Write CSV file
  CSV.open(filename, 'w') do |writer|
    # Write header
    writer << fields
    # Write body
    profiles.each do |profile|
      record = []
      fields.each do |field| 
        record << profile[field]
        count += 1
      end
      writer << record
    end
  end
  puts "Wrote #{count} lines to: '#{filename}'."
end

# Use utility function to save profiles to CSV 
csv_header_fields = ['name', 'website', 'linkedin_url',
                     'size', 'tags']
csv_filename = "all_company_profiles.csv"
save_profiles_to_csv(all_records, csv_filename, csv_header_fields)
```

```
package main

import (
    "fmt"
    "time"
    "os"
    "math"
    "reflect"
    "encoding/json"
    "encoding/csv"
    "context"
)

// See https://github.com/peopledatalabs/peopledatalabs-go
import (
    pdl "github.com/peopledatalabs/peopledatalabs-go"
    pdlmodel "github.com/peopledatalabs/peopledatalabs-go/model"
)

func main() {
    // Set your API key
    apiKey := "YOUR API KEY"
    // Set API key as environmental variable
    // apiKey := os.Getenv("API_KEY")

    // Create a client, specifying your API key
    client := pdl.New(apiKey)

    // Limit the number of records to pull (to prevent accidentally using 
    // more credits than expected when testing out this code).
    const maxNumRecordsLimit = 150 // The maximum number of records to retrieve
    const useMaxNumRecordsLimit = true // Set to False to pull all available records

    // Create an Elasticsearch query
    elasticSearchQuery := map[string]interface{} {
        "query": map[string]interface{} {
            "bool": map[string]interface{} {
                "must": []map[string]interface{} {
                    {"term": map[string]interface{}{"industry": "automotive"}},
                    {"term": map[string]interface{}{"location.metro": "detroit, michigan"}},
                },
            },
        },
    }

    // Create a parameters JSON object
    p := pdlmodel.SearchParams {
        BaseParams: pdlmodel.BaseParams {
            Size: 50,
            Pretty: true,
        },
        SearchBaseParams: pdlmodel.SearchBaseParams {
            Query: elasticSearchQuery,
        },
    }

    // Pull all results in multiple batches
    batch := 1
    // Store all records retreived in an array
    var allRecords []pdlmodel.Company
    // Time the process
    startTime := time.Now()
    foundAllRecords := false
    continueScrolling := true
    var numRecordsToRequest int
    
    // While still scrolling through data and still records to be found
    for continueScrolling && !foundAllRecords {
        // Check if we reached the maximum number of records we want
        if useMaxNumRecordsLimit {
            numRecordsToRequest = maxNumRecordsLimit - len(allRecords)
            // Adjust size parameter
            p.BaseParams.Size = (int) (math.Max(0.0, math.Min(50.0, (float64) (numRecordsToRequest))))
            // Check if MAX_NUM_RECORDS_LIMIT reached
            if numRecordsToRequest == 0 {
                fmt.Printf("Stopping - reached maximum number of records to pull " +
                           "[MAX_NUM_RECORDS_LIMIT = %d].\n", maxNumRecordsLimit)
                
                break
            }
        }
        
        // Pass the parameters object to the Company Search API
        response, err := client.Company.Search(context.Background(), p)
        
        // Check for successful response
        if err == nil {
            fmt.Printf("Retrieved %d records in batch %d - %d records remaining.\n", 
                       len(response.Data), batch, response.Total - len(allRecords))
        } else {
            fmt.Println("Error retrieving some records:\n\t",
                       err)
        }
        
        // Convert response to JSON
        var data map[string]interface{}
        jsonResponse, jsonErr := json.Marshal(response)
        if jsonErr == nil {
            json.Unmarshal(jsonResponse, &data)
            // Get scroll_token from response if exists and store it in parameters object
            if scrollToken, ok := data["scroll_token"]; ok {
                p.SearchBaseParams.ScrollToken = fmt.Sprintf("%v", scrollToken)
            } else {
                continueScrolling = false
                fmt.Println("Unable to continue scrolling.")
            }
            // Add records retrieved to the records array
            allRecords = append(allRecords, response.Data...)
      }
        
        batch++
        foundAllRecords = (len(allRecords) == response.Total)
        time.Sleep(6 * time.Second) // avoid hitting rate limit thresholds
    }
    
    // Calculate time required to process batches
    endTime := time.Now()
    runtime := endTime.Sub(startTime).Seconds()
        
    fmt.Printf("Successfully recovered %d profiles in %d batches [%d seconds].\n",
               len(allRecords), batch, (int) (math.Round((float64) (runtime))))
    
    // Use utility function to save profiles to CSV    
    csvHeaderFields := []string{"name", "website", "linkedin_url",
                                "size", "tags"}
    csvFilename := "all_company_profiles.csv"
    saveProfilesToCsv(allRecords, csvFilename, csvHeaderFields, ",")
}

// Save profiles to CSV (utility function)
func saveProfilesToCsv(profiles []pdlmodel.Company, filename string, fields []string, delim string) {
    // Define header fields
    if fields == nil && len(profiles) > 0 {
        e := reflect.ValueOf(&(profiles[0])).Elem()
        for i := 0; i < e.NumField(); i++ {
            fields = append(fields, e.Type().Field(i).Name)
        }
    }
    
    // Write CSV file
    csvFile, err := os.Create(filename)
    if err == nil {
        csvwriter := csv.NewWriter(csvFile)
        defer csvwriter.Flush()
        // Write header
        csvwriter.Write(fields)
        // Write body
        count := 0
        for i := range profiles {
            var data map[string]interface{}
            jsonResponse, jsonErr := json.Marshal(profiles[i])
            if jsonErr == nil {
                json.Unmarshal(jsonResponse, &data)
                var record []string
                for j := range fields {
                    record = append(record, fmt.Sprintf("%v", data[fields[j]]))
                }
                csvwriter.Write(record)
                count++
            }
        }
        fmt.Printf("Wrote %d lines to: %s.\n", count, filename)
    }
}
```

```
package main

import (
    "fmt"
    "time"
    "os"
    "math"
    "reflect"
    "encoding/json"
    "encoding/csv"
    "context"
)

// See https://github.com/peopledatalabs/peopledatalabs-go
import (
    pdl "github.com/peopledatalabs/peopledatalabs-go"
    pdlmodel "github.com/peopledatalabs/peopledatalabs-go/model"
)

func main() {
    // Set your API key
    apiKey := "YOUR API KEY"
    // Set API key as environmental variable
    // apiKey := os.Getenv("API_KEY")

    // Create a client, specifying your API key
    client := pdl.New(apiKey)

    // Limit the number of records to pull (to prevent accidentally using 
    // more credits than expected when testing out this code).
    const maxNumRecordsLimit = 150 // The maximum number of records to retrieve
    const useMaxNumRecordsLimit = true // Set to False to pull all available records

    // Create an SQL query
    sqlQuery := "SELECT * FROM company" +
        " WHERE industry = 'automotive'" +
        " AND location.metro='detroit, michigan';"

    // Create a parameters JSON object
    p := pdlmodel.SearchParams {
        BaseParams: pdlmodel.BaseParams {
            Size: 50,
            Pretty: true,
        },
        SearchBaseParams: pdlmodel.SearchBaseParams {
            SQL: sqlQuery,
        },
    }

    // Pull all results in multiple batches
    batch := 1
    // Store all records retreived in an array
    var allRecords []pdlmodel.Company
    // Time the process
    startTime := time.Now()
    foundAllRecords := false
    continueScrolling := true
    var numRecordsToRequest int
    
    // While still scrolling through data and still records to be found
    for continueScrolling && !foundAllRecords {
        // Check if we reached the maximum number of records we want
        if useMaxNumRecordsLimit {
            numRecordsToRequest = maxNumRecordsLimit - len(allRecords)
            // Adjust size parameter
            p.BaseParams.Size = (int) (math.Max(0.0, math.Min(50.0, (float64) (numRecordsToRequest))))
            // Check if MAX_NUM_RECORDS_LIMIT reached
            if numRecordsToRequest == 0 {
                fmt.Printf("Stopping - reached maximum number of records to pull " +
                           "[MAX_NUM_RECORDS_LIMIT = %d].\n", maxNumRecordsLimit)
                
                break
            }
        }
        
        // Pass the parameters object to the Company Search API
        response, err := client.Company.Search(context.Background(), p)
        
        // Check for successful response
        if err == nil {
            fmt.Printf("Retrieved %d records in batch %d - %d records remaining.\n", 
                       len(response.Data), batch, response.Total - len(allRecords))
        } else {
            fmt.Println("Error retrieving some records:\n\t",
                       err)
        }
        
        // Convert response to JSON
        var data map[string]interface{}
        jsonResponse, jsonErr := json.Marshal(response)
        if jsonErr == nil {
            json.Unmarshal(jsonResponse, &data)
            // Get scroll_token from response if exists and store it in parameters object
            if scrollToken, ok := data["scroll_token"]; ok {
                p.SearchBaseParams.ScrollToken = fmt.Sprintf("%v", scrollToken)
            } else {
                continueScrolling = false
                fmt.Println("Unable to continue scrolling.")
            }
            // Add records retrieved to the records array
            allRecords = append(allRecords, response.Data...)
      }
        
        batch++
        foundAllRecords = (len(allRecords) == response.Total)
        time.Sleep(6 * time.Second) // avoid hitting rate limit thresholds
    }
    
    // Calculate time required to process batches
    endTime := time.Now()
    runtime := endTime.Sub(startTime).Seconds()
        
    fmt.Printf("Successfully recovered %d profiles in %d batches [%d seconds].\n",
               len(allRecords), batch, (int) (math.Round((float64) (runtime))))
    
    // Use utility function to save profiles to CSV   
    csvHeaderFields := []string{"name", "website", "linkedin_url",
                                "size", "tags"}
    csvFilename := "all_company_profiles.csv"
    saveProfilesToCsv(allRecords, csvFilename, csvHeaderFields, ",")
}

// Save profiles to CSV (utility function)
func saveProfilesToCsv(profiles []pdlmodel.Company, filename string, fields []string, delim string) {
    // Define header fields
    if fields == nil && len(profiles) > 0 {
        e := reflect.ValueOf(&(profiles[0])).Elem()
        for i := 0; i < e.NumField(); i++ {
            fields = append(fields, e.Type().Field(i).Name)
        }
    }
    
    // Write CSV file
    csvFile, err := os.Create(filename)
    if err == nil {
        csvwriter := csv.NewWriter(csvFile)
        defer csvwriter.Flush()
        // Write header
        csvwriter.Write(fields)
        // Write body
        count := 0
        for i := range profiles {
            var data map[string]interface{}
            jsonResponse, jsonErr := json.Marshal(profiles[i])
            if jsonErr == nil {
                json.Unmarshal(jsonResponse, &data)
                var record []string
                for j := range fields {
                    record = append(record, fmt.Sprintf("%v", data[fields[j]]))
                }
                csvwriter.Write(record)
                count++
            }
        }
        fmt.Printf("Wrote %d lines to: %s.\n", count, filename)
    }
}
```

```
import requests, json, time, csv

# Set your API key
API_KEY = "YOUR API KEY"

# Limit the number of records to pull (to prevent accidentally using 
# more credits than expected when testing out this code).
MAX_NUM_RECORDS_LIMIT = 150 # The maximum number of records to retrieve
USE_MAX_NUM_RECORDS_LIMIT = True # Set to False to pull all available records

# Set the Company Search API URL
PDL_URL = "https://api.peopledatalabs.com/v5/company/search"

# Set headers
HEADERS = {
  'Content-Type': "application/json",
  'X-api-key': API_KEY
}

# Create an Elasticsearch query
ES_QUERY = {
  'query': {
    'bool': {
      'must': [
        {'term': {'industry': "automotive"}},
        {'term': {'location.metro': "detroit, michigan"}}
      ]
    }
  }
}

# Create a parameters JSON object
PARAMS = {
  'query': json.dumps(ES_QUERY),
  'size': 100,
  'pretty': True
}

# Pull all results in multiple batches
batch = 1
# Store all records retreived in an array
all_records = []
# Time the process
start_time = time.time()
found_all_records = False
continue_scrolling = True

# While still scrolling through data and still records to be found
while continue_scrolling and not found_all_records: 

  # Check if we reached the maximum number of records we want
  if USE_MAX_NUM_RECORDS_LIMIT:
    num_records_to_request = MAX_NUM_RECORDS_LIMIT - len(all_records)
    # Adjust size parameter
    PARAMS['size'] = max(0, min(100, num_records_to_request))
    # Check if MAX_NUM_RECORDS_LIMIT reached
    if num_records_to_request == 0:
      print(f"Stopping - reached maximum number of records to pull "
            f"[MAX_NUM_RECORDS_LIMIT = {MAX_NUM_RECORDS_LIMIT}].")
      break

  # Pass the parameters object to the Company Search API
  response = requests.get(
    PDL_URL,
    headers=HEADERS,
    params=PARAMS
  ).json()

  # Check for successful response
  if response['status'] == 200:
    # Add records retrieved to the records array
    all_records.extend(response['data'])
    print(f"Retrieved {len(response['data'])} records in batch {batch} "
          f"- {response['total'] - len(all_records)} records remaining.")
  else:
    print(f"Error retrieving some records:\n\t"
          f"[{response['status']} - {response['error']['type']}] "
          f"{response['error']['message']}")
  
  # Get scroll_token from response if exists and store it in parameters object
  if 'scroll_token' in response:
    PARAMS['scroll_token'] = response['scroll_token']
  else:
    continue_scrolling = False
    print(f"Unable to continue scrolling.")

  batch += 1
  found_all_records = (len(all_records) == response['total'])
  time.sleep(6) # avoid hitting rate limit thresholds
 
# Calculate time required to process batches
end_time = time.time()
runtime = end_time - start_time
        
print(f"Successfully recovered {len(all_records)} profiles in "
      f"{batch} batches [{round(runtime, 2)} seconds].")

# Save profiles to CSV (utility function)
def save_profiles_to_csv(profiles, filename, fields=[], delim=','):
  # Define header fields
  if fields == [] and len(profiles) > 0:
      fields = profiles[0].keys()
  # Write CSV file
  with open(filename, 'w') as csvfile:
    writer = csv.writer(csvfile, delimiter=delim)
    # Write header
    writer.writerow(fields)
    # Write body
    count = 0
    for profile in profiles:
      writer.writerow([ profile[field] for field in fields ])
      count += 1
  print(f"Wrote {count} lines to: '{filename}'.")

# Use utility function to save profiles to CSV   
csv_header_fields = ['name', 'website', "linkedin_url",
                     'size', 'tags']
csv_filename = "all_company_profiles.csv"
save_profiles_to_csv(all_records, csv_filename, csv_header_fields)
```

```
import requests, json, time, csv

# Set your API key
API_KEY = "YOUR API KEY"

# Limit the number of records to pull (to prevent accidentally using 
# more credits than expected when testing out this code).
MAX_NUM_RECORDS_LIMIT = 150 # The maximum number of records to retrieve
USE_MAX_NUM_RECORDS_LIMIT = True # Set to False to pull all available records

# Set the Company Search API URL
PDL_URL = "https://api.peopledatalabs.com/v5/company/search"

# Set headers
HEADERS = {
  'Content-Type': "application/json",
  'X-api-key': API_KEY
}

# Create an SQL query
SQL_QUERY = \
f"""
  SELECT * FROM company
  WHERE industry = 'automotive'
  AND location.metro='detroit, michigan';
"""

# Create a parameters JSON object
PARAMS = {
  'sql': SQL_QUERY,
  'size': 100,
  'pretty': True
}

# Pull all results in multiple batches
batch = 1
# Store all records retreived in an array
all_records = []
# Time the process
start_time = time.time()
found_all_records = False
continue_scrolling = True

# While still scrolling through data and still records to be found
while continue_scrolling and not found_all_records: 

  # Check if we reached the maximum number of records we want
  if USE_MAX_NUM_RECORDS_LIMIT:
    num_records_to_request = MAX_NUM_RECORDS_LIMIT - len(all_records)
    # Adjust size parameter
    PARAMS['size'] = max(0, min(100, num_records_to_request))
    # Check if MAX_NUM_RECORDS_LIMIT reached
    if num_records_to_request == 0:
      print(f"Stopping - reached maximum number of records to pull "
            f"[MAX_NUM_RECORDS_LIMIT = {MAX_NUM_RECORDS_LIMIT}].")
      break

  # Pass the parameters object to the Company Search API
  response = requests.get(
    PDL_URL,
    headers=HEADERS,
    params=PARAMS
  ).json()

  # Check for successful response
  if response['status'] == 200:
    # Add records retrieved to the records array
    all_records.extend(response['data'])
    print(f"Retrieved {len(response['data'])} records in batch {batch} "
          f"- {response['total'] - len(all_records)} records remaining.")
  else:
    print(f"Error retrieving some records:\n\t"
          f"[{response['status']} - {response['error']['type']}] "
          f"{response['error']['message']}")
  
  # Get scroll_token from response if exists and store it in parameters object
  if 'scroll_token' in response:
    PARAMS['scroll_token'] = response['scroll_token']
  else:
    continue_scrolling = False
    print(f"Unable to continue scrolling.")

  batch += 1
  found_all_records = (len(all_records) == response['total'])
  time.sleep(6) # avoid hitting rate limit thresholds
 
# Calculate time required to process batches
end_time = time.time()
runtime = end_time - start_time
        
print(f"Successfully recovered {len(all_records)} profiles in "
      f"{batch} batches [{round(runtime, 2)} seconds].")

# Save profiles to CSV (utility function)
def save_profiles_to_csv(profiles, filename, fields=[], delim=','):
  # Define header fields
  if fields == [] and len(profiles) > 0:
      fields = profiles[0].keys()
  # Write CSV file
  with open(filename, 'w') as csvfile:
    writer = csv.writer(csvfile, delimiter=delim)
    # Write header
    writer.writerow(fields)
    # Write body
    count = 0
    for profile in profiles:
      writer.writerow([ profile[field] for field in fields ])
      count += 1
  print(f"Wrote {count} lines to: '{filename}'.")

# Use utility function to save profiles to CSV    
csv_header_fields = ['name', 'website', "linkedin_url",
                     'size', 'tags']
csv_filename = "all_company_profiles.csv"
save_profiles_to_csv(all_records, csv_filename, csv_header_fields)
```

## Affiliate Lookup

(search by affiliated companies)

*"I want to find all companies that are affiliated with Amazon (who's[Company ID](/docs/company-schema#id) is `hWBI7x4FvSurVNWDXD4uFgQt5ges`)."*

Python3 SDK (Elasticsearch)Python3 SDK (SQL)JavaScript (Elasticsearch)JavaScript (SQL)Ruby (Elasticsearch)Ruby (SQL)Go (Elasticsearch)Go (SQL)Python3 (Elasticsearch)Python3 (SQL)

```
import json

# See https://github.com/peopledatalabs/peopledatalabs-python
from peopledatalabs import PDLPY

# Create a client, specifying your API key
CLIENT = PDLPY(
    api_key="YOUR API KEY",
)

# https://pdl-prod-schema.s3-us-west-2.amazonaws.com/14.0/enums/industry.txt
# for enumerated possible values of industry

# https://pdl-prod-schema.s3-us-west-2.amazonaws.com/14.0/enums/job_company_size.txt
# for enumerated possible values of company sizes

# Create an Elasticsearch query
ES_QUERY = {
  "query": {
    "bool": {
      "must": [
        {"term": {"affiliated_profiles": "hWBI7x4FvSurVNWDXD4uFgQt5ges"}}
      ]
    }
  }
}

# Create a parameters JSON object
PARAMS = {
    "query": ES_QUERY,
    "size": 100
}

# Pass the parameters object to the Company Search API
response = CLIENT.company.search(**PARAMS).json()

# Check for successful response
if response["status"] == 200:
  
  data = response['data']
  
  # Write out each profile found to file
  with open("my_pdl_search.jsonl", "w") as out:
    for record in data:
      out.write(json.dumps(record) + "\n")
  
  print(f"Successfully grabbed {len(data)} records from PDL.")
  print(f"{response['total']} total PDL records exist matching this query.")
else:
  print("NOTE: The eager beaver was not so eager. See error and try again.")
  print("error:", response)
```

```
import json

# See https://github.com/peopledatalabs/peopledatalabs-python
from peopledatalabs import PDLPY

# Create a client, specifying your API key
CLIENT = PDLPY(
    api_key="YOUR API KEY",
)

# https://pdl-prod-schema.s3-us-west-2.amazonaws.com/14.0/enums/industry.txt
# for enumerated possible values of industry

# https://pdl-prod-schema.s3-us-west-2.amazonaws.com/14.0/enums/job_company_size.txt
# for enumerated possible values of company sizes

# Create an SQL query
SQL_QUERY = \
f"""
  SELECT * FROM company
  WHERE affiliated_profiles = 'hWBI7x4FvSurVNWDXD4uFgQt5ges';
"""

# Create a parameters JSON object
PARAMS = {
  'sql': SQL_QUERY,
  'size': 100
}

# Pass the parameters object to the Company Search API
response = CLIENT.company.search(**PARAMS).json()

# Check for successful response
if response["status"] == 200:
  
  data = response['data']
  
  # Write out each profile found to file
  with open("my_pdl_search.jsonl", "w") as out:
    for record in data:
      out.write(json.dumps(record) + "\n")
  
  print(f"Successfully grabbed {len(data)} records from PDL.")
  print(f"{response['total']} total PDL records exist matching this query.")
else:
  print("NOTE: The eager beaver was not so eager. See error and try again.")
  print("error:", response)
```

```
// See https://github.com/peopledatalabs/peopledatalabs-js
import PDLJS from 'peopledatalabs';

import fs from 'fs';

// Create a client, specifying your API key
const PDLJSClient = new PDLJS({ apiKey: "YOUR API KEY" });

// Create an Elasticsearch query
const esQuery = {
  query: {
    bool: {
      must:[
        {"term": {"affiliated_profiles": "hWBI7x4FvSurVNWDXD4uFgQt5ges"}}
      ]
    }
  }
}

// Create a parameters JSON object
const params = {
  searchQuery: esQuery, 
  size: 100,
}

// Pass the parameters object to the Company Search API
PDLJSClient.company.search.elastic(params).then((data) => {
    // Write out all profiles found to file
    fs.writeFile("my_pdl_search.jsonl", Buffer.from(JSON.stringify(data.data)), (err) => {
        if (err) throw err;
    });
    console.log(`Successfully grabbed ${data.data.length} records from PDL.`);
    console.log(`${data["total"]} total PDL records exist matching this query.`)
}).catch((error) => {
    console.log("NOTE: The carrier pigeons lost motivation in flight. See error and try again.")
    console.log(error);
});
```

```
// See https://github.com/peopledatalabs/peopledatalabs-js
import PDLJS from 'peopledatalabs';

import fs from 'fs';

// Create a client, specifying your API key
const PDLJSClient = new PDLJS({ apiKey: "YOUR API KEY" });

// Create an SQL query
const sqlQuery = `SELECT * FROM company
                    WHERE affiliated_profiles = 'hWBI7x4FvSurVNWDXD4uFgQt5ges';`;

// Create a parameters JSON object
const params = {
    searchQuery: sqlQuery, 
    size: 100
}

// Pass the parameters object to the Company Search API
PDLJSClient.company.search.sql(params).then((data) => {
    // Write out all profiles found to file
    fs.writeFile("my_pdl_search.jsonl", Buffer.from(JSON.stringify(data.data)), (err) => {
        if (err) throw err;
    });
    console.log(`Successfully grabbed ${data.data.length} records from PDL.`);
    console.log(`${data["total"]} total PDL records exist matching this query.`)
}).catch((error) => {
    console.log("NOTE: The carrier pigeons lost motivation in flight. See error and try again.")
    console.log(error);
});
```

```
require 'json'

# See https://github.com/peopledatalabs/peopledatalabs-ruby
require 'peopledatalabs'

# Set your API key
Peopledatalabs.api_key = 'YOUR API KEY'

# https://pdl-prod-schema.s3-us-west-2.amazonaws.com/14.0/enums/industry.txt
# for enumerated possible values of industry

# https://pdl-prod-schema.s3-us-west-2.amazonaws.com/14.0/enums/job_company_size.txt
# for enumerated possible values of company sizes

# Create an Elasticsearch query
ES_QUERY = {
  "query": {
    "bool": {
      "must": [
        {"term": {"affiliated_profiles": "hWBI7x4FvSurVNWDXD4uFgQt5ges"}}
      ]
    }
  }
}

# Pass parameters to the Company Search API
response = Peopledatalabs::Search.company(searchType: 'elastic', query: ES_QUERY, size: 100, pretty: true)

# Check for successful response
if response['status'] == 200
    data = response['data']
    # Write out each profile found to file
    File.open("my_pdl_search.jsonl", "w") do |out|
        data.each { |record| out.write(JSON.dump(record) + "\n") }
    end
    puts "Successfully grabbed #{data.length()} records from PDL."
    puts "#{response['total']} total PDL records exist matching this query."
else
    puts "NOTE: The carrier pigeons lost motivation in flight. See error and try again."
    puts "Error: #{response}"
end
```

```
require 'json'

# See https://github.com/peopledatalabs/peopledatalabs-ruby
require 'peopledatalabs'

# Set your API key
Peopledatalabs.api_key = 'YOUR API KEY'

# https://pdl-prod-schema.s3-us-west-2.amazonaws.com/14.0/enums/industry.txt
# for enumerated possible values of industry

# https://pdl-prod-schema.s3-us-west-2.amazonaws.com/14.0/enums/job_company_size.txt
# for enumerated possible values of company sizes

# Create an SQL query
SQL_QUERY = \
"""
  SELECT * FROM company
  WHERE affiliated_profiles = 'hWBI7x4FvSurVNWDXD4uFgQt5ges';
"""

# Pass parameters to the Company Search API
response = Peopledatalabs::Search.company(searchType: 'sql', query: SQL_QUERY, size: 100, pretty: true)

# Check for successful response
if response['status'] == 200
    data = response['data']
    # Write out each profile found to file
    File.open("my_pdl_search.jsonl", "w") do |out|
        data.each { |record| out.write(JSON.dump(record) + "\n") }
    end
    puts "Successfully grabbed #{data.length()} records from PDL."
    puts "#{response['total']} total PDL records exist matching this query."
else
    puts "NOTE: The carrier pigeons lost motivation in flight. See error and try again."
    puts "Error: #{response}"
end
```

```
package main

import(
    "fmt"
    "os"
    "encoding/json"
    "context"
)

// See https://github.com/peopledatalabs/peopledatalabs-go
import (
    pdl "github.com/peopledatalabs/peopledatalabs-go"
    pdlmodel "github.com/peopledatalabs/peopledatalabs-go/model"
)

func main() {
    // Set your API key
    apiKey := "YOUR API KEY"
    // Set API key as environmental variable
    // apiKey := os.Getenv("API_KEY")

    // Create a client, specifying your API key
    client := pdl.New(apiKey)

    // https://pdl-prod-schema.s3-us-west-2.amazonaws.com/14.0/enums/industry.txt
    // for enumerated possible values of industry

    // https://pdl-prod-schema.s3-us-west-2.amazonaws.com/14.0/enums/job_company_size.txt
    // for enumerated possible values of company sizes

    // Create an Elasticsearch query
    elasticSearchQuery := map[string]interface{} {
        "query": map[string]interface{} {
            "bool": map[string]interface{} {
                "must": []map[string]interface{} {
                    {"term": map[string]interface{}{"affiliated_profiles": "hWBI7x4FvSurVNWDXD4uFgQt5ges"}},
                },
            },
        },
    }

    // Create a parameters JSON object
    params := pdlmodel.SearchParams {
        BaseParams: pdlmodel.BaseParams {
            Size: 100,
        },
        SearchBaseParams: pdlmodel.SearchBaseParams {
            Query: elasticSearchQuery,
        },
    }

    // Pass the parameters object to the Company Search API
    response, err := client.Company.Search(context.Background(), params)
    // Check for successful response
    if err == nil {
        data := response.Data
        // Create file
        out, outErr := os.Create("my_pdl_search.jsonl")
        defer out.Close()
        if (outErr == nil) {
            for i := range data {
                // Convert each profile found to JSON
                record, jsonErr := json.Marshal(data[i])
                // Write out each profile to file
                if (jsonErr == nil) {
                    out.WriteString(string(record) + "\n")
                }
            }
            out.Sync()
        }
        fmt.Printf("Successfully grabbed %d records from PDL.\n", len(data))
        fmt.Printf("%d total PDL records exist matching this query.\n", response.Total)
    } else {
        fmt.Println("NOTE: The eager beaver was not so eager. See error and try again.")
        fmt.Println("Error:", err)
    } 
}
```

```
package main

import(
    "fmt"
    "os"
    "encoding/json"
    "context"
)

// See https://github.com/peopledatalabs/peopledatalabs-go
import (
    pdl "github.com/peopledatalabs/peopledatalabs-go"
    pdlmodel "github.com/peopledatalabs/peopledatalabs-go/model"
)

func main() {
    // Set your API key
    apiKey := "YOUR API KEY"
    // Set API key as environmental variable
    // apiKey := os.Getenv("API_KEY")

    // Create a client, specifying your API key
    client := pdl.New(apiKey)

    // https://pdl-prod-schema.s3-us-west-2.amazonaws.com/14.0/enums/industry.txt
    // for enumerated possible values of industry

    // https://pdl-prod-schema.s3-us-west-2.amazonaws.com/14.0/enums/job_company_size.txt
    // for enumerated possible values of company sizes

    // Create an SQL query
    sqlQuery := "SELECT * FROM company" +
        " WHERE affiliated_profiles = 'hWBI7x4FvSurVNWDXD4uFgQt5ges';"

    // Create a parameters JSON object
    params := pdlmodel.SearchParams {
        BaseParams: pdlmodel.BaseParams {
            Size: 100,
            Pretty: true,
        },
        SearchBaseParams: pdlmodel.SearchBaseParams {
            SQL: sqlQuery,
        },
    }

    // Pass the parameters object to the Company Search API
    response, err := client.Company.Search(context.Background(), params)
    // Check for successful response
    if err == nil {
        data := response.Data
        // Create file
        out, outErr := os.Create("my_pdl_search.jsonl")
        defer out.Close()
        if (outErr == nil) {
            for i := range data {
                // Convert each profile found to JSON
                record, jsonErr := json.Marshal(data[i])
                // Write out each profile to file
                if (jsonErr == nil) {
                    out.WriteString(string(record) + "\n")
                }
            }
            out.Sync()
        }
        fmt.Printf("Successfully grabbed %d records from PDL.\n", len(data))
        fmt.Printf("%d total PDL records exist matching this query.\n", response.Total)
    } else {
        fmt.Println("NOTE: The eager beaver was not so eager. See error and try again.")
        fmt.Println("Error:", err)
    } 
}
```

```
import requests, json

# Set your API key
API_KEY = "YOUR API KEY"

# Set the Company Search API URL
PDL_URL = "https://api.peopledatalabs.com/v5/company/search"

# Set headers
HEADERS = {
"Content-Type": "application/json",
"X-api-key": API_KEY
}

# Create an Elasticsearch query
ES_QUERY = {
  "query": {
    "bool": {
      "must": [
        {"term": {"affiliated_profiles": "hWBI7x4FvSurVNWDXD4uFgQt5ges"}}
      ]
    }
  }
}

# Create a parameters JSON object
PARAMS = {
    "query": json.dumps(ES_QUERY),
    "size": 100
}

# Pass the parameters object to the Company Search API
response = requests.get(
    PDL_URL,
    headers=HEADERS,
    params=PARAMS
).json()

# Check for successful response
if response["status"] == 200:
  data = response['data']
  
  # Write out each profile found to file
  with open("my_pdl_search.jsonl", "w") as out:
    for record in data:
      out.write(json.dumps(record) + "\n")

  print(f"Successfully grabbed {len(response['data'])} records from PDL.")
  print(f"{response['total']} total PDL records exist matching this query.")
else:
  print("NOTE: The eager beaver was not so eager. See error and try again.")
  print("error:", response)
```

```
import requests, json

# Set your API key
API_KEY = "YOUR API KEY"

# Set the Company Search API URL
PDL_URL = "https://api.peopledatalabs.com/v5/company/search"

# Set headers
HEADERS = {
"Content-Type": "application/json",
"X-api-key": API_KEY
}

# Create an SQL query
SQL_QUERY = \
f"""
  SELECT * FROM company
  WHERE affiliated_profiles = 'hWBI7x4FvSurVNWDXD4uFgQt5ges';
"""

# Create a parameters JSON object
PARAMS = {
  'sql': SQL_QUERY,
  'size': 100
}

# Pass the parameters object to the Company Search API
response = requests.get(
  PDL_URL,
  headers=HEADERS,
  params=PARAMS
).json()

# Check for successful response
if response["status"] == 200:
  
  data = response['data']
  
  # Write out each profile found to file
  with open("my_pdl_search.jsonl", "w") as out:
    for record in data:
      out.write(json.dumps(record) + "\n")

  print(f"Successfully grabbed {len(response['data'])} records from PDL.")
  print(f"{response['total']} total PDL records exist matching this query.")
else:
  print("NOTE: The eager beaver was not so eager. See error and try again.")
  print("error:", response)
```

Updated 4 months ago

---

Did this page help you?

Yes

No

---
# https://docs.peopledatalabs.com/docs/examples-company-enrichment-api

# Examples

When specifying query parameters within a URL, you should separate them with an ampersand (`&`). When specifying query parameters within a JSON object, you should use lists for the request parameters.

We've provided code samples in cURL, Python, Ruby, Go and JavaScript. If you aren't comfortable working in any of these languages, feel free to use this [handy tool](https://curl.trillworks.com/) to convert code from cURL to the language of your choice.

> ðŸ’¡
>
> ### We want your feedback!
>
> Do you see a bug? Is there an example you'd like to see that's not listed here?
>
> Head over to the public roadmap and submit a [bug ticket](https://peopledatalabs.canny.io/bugs) or a [feature request](https://peopledatalabs.canny.io/feature-requests) and receive automatic notifications as your bug is resolved or your request is implemented.

## PDL ID

Python3 SDKcURLJavaScriptRubyGoPython3

```
# See https://github.com/peopledatalabs/peopledatalabs-python
from peopledatalabs import PDLPY

# Create a client, specifying your API key
CLIENT = PDLPY(
    api_key="YOUR_API_KEY",
)

# Create a parameters JSON object
QUERY_STRING = {"pdl_id":"aKCIYBNF9ey6o5CjHCCO4goHYKlf"}

# Pass the parameters object to the Company Enrichment API
response = CLIENT.company.enrichment(**QUERY_STRING)

# Print the API response
print(response.text)
```

```
curl -X GET -G \
  'https://api.peopledatalabs.com/v5/company/enrich'\
  -H 'X-Api-Key: xxxx'\
  --data-urlencode 'pdl_id=aKCIYBNF9ey6o5CjHCCO4goHYKlf'
```

```
// See https://github.com/peopledatalabs/peopledatalabs-js
import PDLJS from 'peopledatalabs';

// Create a client, specifying your API key
const PDLJSClient = new PDLJS({ apiKey: "YOUR API KEY" });

// Create a parameters JSON object
const queryString = {"pdl_id":"aKCIYBNF9ey6o5CjHCCO4goHYKlf"}

// Pass the parameters object to the Company Enrichment API
PDLJSClient.company.enrichment(queryString).then((data) => {
    // Print the API response
    console.log(data);
}).catch((error) => {
    console.log(error);
});
```

```
# See https://github.com/peopledatalabs/peopledatalabs-ruby
require 'peopledatalabs'

# Set your API key
Peopledatalabs.api_key = 'YOUR API KEY'

# Create a parameters JSON object
QUERY_STRING = {"pdl_id":"aKCIYBNF9ey6o5CjHCCO4goHYKlf"}

# Pass the parameters object to the Company Enrichment API
response = Peopledatalabs::Enrichment.company(params: QUERY_STRING)

# Print the API response
puts response
```

```
package main

import (
    "fmt"
    "context"
)

// See https://github.com/peopledatalabs/peopledatalabs-go
import (
    pdl "github.com/peopledatalabs/peopledatalabs-go"
    pdlmodel "github.com/peopledatalabs/peopledatalabs-go/model"
)

func main() {
    // Set your API key
    apiKey := "YOUR API KEY"
    // Set API key as environmental variable
    // apiKey := os.Getenv("API_KEY")

    // Create a client, specifying your API key
    client := pdl.New(apiKey)
    
    // Create a parameters JSON object
    queryString := pdlmodel.CompanyParams{PdlId: "aKCIYBNF9ey6o5CjHCCO4goHYKlf"}
    
    params := pdlmodel.EnrichCompanyParams{
        CompanyParams: queryString,
    }
    
    // Pass the parameters object to the Company Enrichment API
    response, err := client.Company.Enrich(context.Background(), params)
    // Check for successful response
    if err == nil {
        // Print the API response
        fmt.Println(response)
    }  
}
```

```
import requests

# Set your API key
API_KEY = "YOUR API KEY"

# Set the Company Enrichment API URL
PDL_URL = "https://api.peopledatalabs.com/v5/company/enrich"

# Create a parameters JSON object
QUERY_STRING = {"pdl_id":"aKCIYBNF9ey6o5CjHCCO4goHYKlf"}

# Set headers
HEADERS = {
    'accept': "application/json",
    'content-type': "application/json",
    'x-api-key': API_KEY
    }

# Pass the parameters object to the Company Enrichment API
response = requests.request("GET", PDL_URL, headers=HEADERS, params=QUERY_STRING)

# Print the API response
print(response.text)
```

## Website

Python3 SDKcURLJavaScriptRubyGoPython3

```
# See https://github.com/peopledatalabs/peopledatalabs-python
from peopledatalabs import PDLPY

# Create a client, specifying your API key
CLIENT = PDLPY(
    api_key="YOUR_API_KEY",
)

# Create a parameters JSON object
QUERY_STRING = {"website":"google.com"}

# Pass the parameters object to the Company Enrichment API
response = CLIENT.company.enrichment(**QUERY_STRING)

# Print the API response
print(response.text)
```

```
curl -X GET -G \
  'https://api.peopledatalabs.com/v5/company/enrich'\
  -H 'X-Api-Key: xxxx'\
  --data-urlencode 'website=google.com'
```

```
// See https://github.com/peopledatalabs/peopledatalabs-js
import PDLJS from 'peopledatalabs';

// Create a client, specifying your API key
const PDLJSClient = new PDLJS({ apiKey: "YOUR API KEY" });

// Create a parameters JSON object
const queryString = {"website":"google.com"}

// Pass the parameters object to the Company Enrichment API
PDLJSClient.company.enrichment(queryString).then((data) => {
    // Print the API response
    console.log(data);
}).catch((error) => {
    console.log(error);
});
```

```
# See https://github.com/peopledatalabs/peopledatalabs-ruby
require 'peopledatalabs'

# Set your API key
Peopledatalabs.api_key = 'YOUR API KEY'

# Create a parameters JSON object
QUERY_STRING = {"website":"google.com"}

# Pass the parameters object to the Company Enrichment API
response = Peopledatalabs::Enrichment.company(params: QUERY_STRING)

# Print the API response
puts response
```

```
package main

import (
    "fmt"
    "context"
)

// See https://github.com/peopledatalabs/peopledatalabs-go
import (
    pdl "github.com/peopledatalabs/peopledatalabs-go"
    pdlmodel "github.com/peopledatalabs/peopledatalabs-go/model"
)

func main() {
    // Set your API key
    apiKey := "YOUR API KEY"
    // Set API key as environmental variable
    // apiKey := os.Getenv("API_KEY")

    // Create a client, specifying your API key
    client := pdl.New(apiKey)
    
    // Create a parameters JSON object
    queryString := pdlmodel.CompanyParams{Website: "google.com"}
    
    params := pdlmodel.EnrichCompanyParams{
        CompanyParams: queryString,
    }
    
    // Pass the parameters object to the Company Enrichment API
    response, err := client.Company.Enrich(context.Background(), params)
    // Check for successful response
    if err == nil {
        // Print the API response
        fmt.Println(response)
    }  
}
```

```
import requests

# Set your API key
API_KEY = "YOUR API KEY"

# Set the Company Enrichment API URL
PDL_URL = "https://api.peopledatalabs.com/v5/company/enrich"

# Create a parameters JSON object
QUERY_STRING = {"website":"google.com"}

# Set headers
HEADERS = {
    'accept': "application/json",
    'content-type': "application/json",
    'x-api-key': API_KEY
    }

# Pass the parameters object to the Company Enrichment API
response = requests.request("GET", PDL_URL, headers=HEADERS, params=QUERY_STRING)

# Print the API response
print(response.text)
```

## Name

Python3 SDKcURLJavaScriptRubyGoPython3

```
# See https://github.com/peopledatalabs/peopledatalabs-python
from peopledatalabs import PDLPY

# Create a client, specifying your API key
CLIENT = PDLPY(
    api_key="YOUR_API_KEY",
)

# Create a parameters JSON object
QUERY_STRING = {"name":"Google, Inc."}

# Pass the parameters object to the Company Enrichment API
response = CLIENT.company.enrichment(**QUERY_STRING)

# Print the API response
print(response.text)
```

```
curl -X GET -G \
  'https://api.peopledatalabs.com/v5/company/enrich'\
  -H 'X-Api-Key: xxxx'\
  --data-urlencode 'name=Google, Inc.'
```

```
// See https://github.com/peopledatalabs/peopledatalabs-js
import PDLJS from 'peopledatalabs';

// Create a client, specifying your API key
const PDLJSClient = new PDLJS({ apiKey: "YOUR API KEY" });

// Create a parameters JSON object
const queryString = {"name":"Google, Inc."}

// Pass the parameters object to the Company Enrichment API
PDLJSClient.company.enrichment(queryString).then((data) => {
    // Print the API response
    console.log(data);
}).catch((error) => {
    console.log(error);
});
```

```
# See https://github.com/peopledatalabs/peopledatalabs-ruby
require 'peopledatalabs'

# Set your API key
Peopledatalabs.api_key = 'YOUR API KEY'

# Create a parameters JSON object
QUERY_STRING = {"name":"Google, Inc."}

# Pass the parameters object to the Company Enrichment API
response = Peopledatalabs::Enrichment.company(params: QUERY_STRING)

# Print the API response
puts response
```

```
package main

import (
    "fmt"
    "context"
)

// See https://github.com/peopledatalabs/peopledatalabs-go
import (
    pdl "github.com/peopledatalabs/peopledatalabs-go"
    pdlmodel "github.com/peopledatalabs/peopledatalabs-go/model"
)

func main() {
    // Set your API key
    apiKey := "YOUR API KEY"
    // Set API key as environmental variable
    // apiKey := os.Getenv("API_KEY")

    // Create a client, specifying your API key
    client := pdl.New(apiKey)
    
    // Create a parameters JSON object
    queryString := pdlmodel.CompanyParams{Name: "Google, Inc."}
    
    params := pdlmodel.EnrichCompanyParams{
        CompanyParams: queryString,
    }
    
    // Pass the parameters object to the Company Enrichment API
    response, err := client.Company.Enrich(context.Background(), params)
    // Check for successful response
    if err == nil {
        // Print the API response
        fmt.Println(response)
    }  
}
```

```
import requests

# Set your API key
API_KEY = "YOUR API KEY"

# Set the Company Enrichment API URL
PDL_URL = "https://api.peopledatalabs.com/v5/company/enrich"

# Create a parameters JSON object
QUERY_STRING = {"name":"Google, Inc."}

# Set headers
HEADERS = {
    'accept': "application/json",
    'content-type': "application/json",
    'x-api-key': API_KEY
    }

# Pass the parameters object to the Company Enrichment API
response = requests.request("GET", PDL_URL, headers=HEADERS, params=QUERY_STRING)

# Print the API response
print(response.text)
```

## Ticker

Python3 SDKcURLJavaScriptRubyGoPython3

```
# See https://github.com/peopledatalabs/peopledatalabs-python
from peopledatalabs import PDLPY

# Create a client, specifying your API key
CLIENT = PDLPY(
    api_key="YOUR_API_KEY",
)

# Create a parameters JSON object
QUERY_STRING = {"ticker":"GOOGL"}

# Pass the parameters object to the Company Enrichment API
response = CLIENT.company.enrichment(**QUERY_STRING)

# Print the API response
print(response.text)
```

```
curl -X GET -G \
  'https://api.peopledatalabs.com/v5/company/enrich'\
  -H 'X-Api-Key: xxxx'\
  --data-urlencode 'ticker=GOOGL'
```

```
// See https://github.com/peopledatalabs/peopledatalabs-js
import PDLJS from 'peopledatalabs';

// Create a client, specifying your API key
const PDLJSClient = new PDLJS({ apiKey: "YOUR API KEY" });

// Create a parameters JSON object
const queryString = {"ticker":"GOOGL"}

// Pass the parameters object to the Company Enrichment API
PDLJSClient.company.enrichment(queryString).then((data) => {
    // Print the API response
    console.log(data);
}).catch((error) => {
    console.log(error);
});
```

```
# See https://github.com/peopledatalabs/peopledatalabs-ruby
require 'peopledatalabs'

# Set your API key
Peopledatalabs.api_key = 'YOUR API KEY'

# Create a parameters JSON object
QUERY_STRING = {"ticker":"GOOGL"}

# Pass the parameters object to the Company Enrichment API
response = Peopledatalabs::Enrichment.company(params: QUERY_STRING)

# Print the API response
puts response
```

```
package main

import (
    "fmt"
    "context"
)

// See https://github.com/peopledatalabs/peopledatalabs-go
import (
    pdl "github.com/peopledatalabs/peopledatalabs-go"
    pdlmodel "github.com/peopledatalabs/peopledatalabs-go/model"
)

func main() {
    // Set your API key
    apiKey := "YOUR API KEY"
    // Set API key as environmental variable
    // apiKey := os.Getenv("API_KEY")

    // Create a client, specifying your API key
    client := pdl.New(apiKey)
    
    // Create a parameters JSON object
    queryString := pdlmodel.CompanyParams{Ticker: "GOOGL"}
    
    params := pdlmodel.EnrichCompanyParams{
        CompanyParams: queryString,
    }
    
    // Pass the parameters object to the Company Enrichment API
    response, err := client.Company.Enrich(context.Background(), params)
    // Check for successful response
    if err == nil {
        // Print the API response
        fmt.Println(response)
    }  
}
```

```
import requests

# Set your API key
API_KEY = "YOUR API KEY"

# Set the Company Enrichment API URL
PDL_URL = "https://api.peopledatalabs.com/v5/company/enrich"

# Create a parameters JSON object
QUERY_STRING = {"ticker":"GOOGL"}

# Set headers
HEADERS = {
    'accept': "application/json",
    'content-type': "application/json",
    'x-api-key': API_KEY
    }

# Pass the parameters object to the Company Enrichment API
response = requests.request("GET", PDL_URL, headers=HEADERS, params=QUERY_STRING)

# Print the API response
print(response.text)
```

## Profile

Python3 SDKcURLJavaScriptRubyGoPython3

```
# See https://github.com/peopledatalabs/peopledatalabs-python
from peopledatalabs import PDLPY

# Create a client, specifying your API key
CLIENT = PDLPY(
    api_key="YOUR_API_KEY",
)

# Create a parameters JSON object
QUERY_STRING = {"profile":"linkedin.com/company/google"}

# Pass the parameters object to the Company Enrichment API
response = CLIENT.company.enrichment(**QUERY_STRING)

# Print the API response
print(response.text)
```

```
curl -X GET -G \
  'https://api.peopledatalabs.com/v5/company/enrich'\
  -H 'X-Api-Key: xxxx'\
  --data-urlencode 'profile=linkedin.com/company/google'
```

```
// See https://github.com/peopledatalabs/peopledatalabs-js
import PDLJS from 'peopledatalabs';

// Create a client, specifying your API key
const PDLJSClient = new PDLJS({ apiKey: "YOUR API KEY" });

// Create a parameters JSON object
const queryString = {"profile":"linkedin.com/company/google"}

// Pass the parameters object to the Company Enrichment API
PDLJSClient.company.enrichment(queryString).then((data) => {
    // Print the API response
    console.log(data);
}).catch((error) => {
    console.log(error);
});
```

```
# See https://github.com/peopledatalabs/peopledatalabs-ruby
require 'peopledatalabs'

# Set your API key
Peopledatalabs.api_key = 'YOUR API KEY'

# Create a parameters JSON object
QUERY_STRING = {"profile":"linkedin.com/company/google"}

# Pass the parameters object to the Company Enrichment API
response = Peopledatalabs::Enrichment.company(params: QUERY_STRING)

# Print the API response
puts response
```

```
package main

import (
    "fmt"
    "context"
)

// See https://github.com/peopledatalabs/peopledatalabs-go
import (
    pdl "github.com/peopledatalabs/peopledatalabs-go"
    pdlmodel "github.com/peopledatalabs/peopledatalabs-go/model"
)

func main() {
    // Set your API key
    apiKey := "YOUR API KEY"
    // Set API key as environmental variable
    // apiKey := os.Getenv("API_KEY")

    // Create a client, specifying your API key
    client := pdl.New(apiKey)
    
    // Create a parameters JSON object
    queryString := pdlmodel.CompanyParams{Profile: "linkedin.com/company/google"}
    
    params := pdlmodel.EnrichCompanyParams{
        CompanyParams: queryString,
    }
    
    // Pass the parameters object to the Company Enrichment API
    response, err := client.Company.Enrich(context.Background(), params)
    // Check for successful response
    if err == nil {
        // Print the API response
        fmt.Println(response)
    }  
}
```

```
import requests

# Set your API key
API_KEY = "YOUR API KEY"

# Set the Company Enrichment API URL
PDL_URL = "https://api.peopledatalabs.com/v5/company/enrich"

# Create a parameters JSON object
QUERY_STRING = {"profile":"linkedin.com/company/google"}

# Set headers
HEADERS = {
    'accept': "application/json",
    'content-type': "application/json",
    'x-api-key': API_KEY
    }

# Pass the parameters object to the Company Enrichment API
response = requests.request("GET", PDL_URL, headers=HEADERS, params=QUERY_STRING)

# Print the API response
print(response.text)
```

Updated 4 months ago

---

Did this page help you?

Yes

No

---
# https://docs.peopledatalabs.com/docs/bulk-company-enrichment-api

## Overview

The Bulk Company Enrichment API provides a way to enrich multiple profiles using the [Company Enrichment API](/docs/company-enrichment-api) in one request.

> ðŸ“˜
>
> ### Bulk Enrichment vs Company Search
>
> The Bulk Enrichment API is **NOT** the same as the [Company Search API](/docs/company-search-api).
>
> The Bulk Enrichment API is the same as calling the [Company Enrichment API](/docs/company-enrichment-api) multiple times.
>
> Use the Bulk Enrichment API when you want to get detailed profiles for a set of companies you already know (such as getting the funding details of each company in a list). Use the Company Search API to find an undetermined number of companies that match your search criteria (such as finding fast-growing companies in a certain industry).

## Access & Billing

Any customer that has Company Enrich credits can use the Bulk Company Enrichment API.

We will deduct the number of remaining Company Enrichment credits in your account by the number of `200` status responses in a Bulk Enrichment request as though you made each request individually.

## Request Format

The endpoint for the bulk enrichment api is `POST https://api.peopledatalabs.com/v5/company/enrich/bulk`.

You can enrich up to 100 companies in a single request.

The request body must contain an array called `requests` with 1-100 individual request objects, each containing a `params` object for each request's parameters. See [Input Parameters - Company Enrichment API](/docs/input-parameters-company-enrichment-api) for details on the supported Enrichment API parameters.

| Field Name | Description | Type |
| --- | --- | --- |
| `requests` | All requests to make in the bulk enrichment. | `Array [Object]` |
| `params` | The parameters for a single enrichment call. | `Object` |

JSON

```
{
  "requests": [
    {
      "params": {
        ...
      }
    },
    {
      "params": {
        ...
      }
    },
    ...
  ]
}
```

### Example

Python3cURL

```
import requests
import json

# Set your API key
API_KEY = "YOUR API KEY"

# Pass your API key in header
HEADERS = {
    'X-Api-Key': API_KEY,
    'Content-Type': 'application/json',
}

# Create an array of parameters JSON objects
DATA = {
    "requests": [
        {
            "params": {
                "profile": "https://www.linkedin.com/company/walmart"
            }
        },
        {
            "params": {
                "website": "google.com"
            }
        }
    ]
}

# Pass the bulk parameters object to the Bulk Company Enrichment API using POST method
try:
    response = requests.post(
        'https://api.peopledatalabs.com/v5/company/enrich/bulk',
        headers=HEADERS,
        json=DATA
    )

    # Check if the request was successful (status code 200)
    if response.status_code == 200:
        # Parse the JSON response
        json_responses = response.json()

        # Iterate through the array of API responses
        for response_data in json_responses:

            # Check for successful response
            if response_data["status"] == 200:

                # Print selected fields
                print(
                    response_data['size'],
                    response_data['employee_count'],
                    response_data['industry'],
                    response_data['location']
                )
                print(f"Successfully enriched profile with PDL data.")

                # Save enrichment data to JSON file (append mode)
                with open(f"my_pdl_enrichment.{response_data['linkedin_slug']}.jsonl", "a") as out:
                    out.write(json.dumps(response_data) + "\n")
            else:
                print("Enrichment unsuccessful. See error and try again.")
                print("error:", response_data)
    else:
        print(f"Request failed with status code {response.status_code}")
except requests.exceptions.RequestException as e:
    print(f"An error occurred during the request: {e}")
```

```
curl -X POST "https://api.peopledatalabs.com/v5/company/enrich/bulk" \
-H 'Content-Type: application/json' \
-H 'X-Api-Key: XXXX' \
-d ' {
    "requests": [
        {
            "params": {
                "profile": "https://www.linkedin.com/company/walmart"
            }
        },
            {
            "params": {
                "website": "google.com"
            }
        }
    ]
}'
```

## Response Format

Bulk Enrichment responses are a **JSON Array** of objects with the following fields:

| Field Name | Description | Type |
| --- | --- | --- |
| `data` | The person response object. | `Object` |
| `status` | The HTTP status code. | `Integer` |
| `likelihood` | The likelihood score. | `Integer` |

JSON

```
[
	{"status": 200, "likelihood": 10, "data": ...},
	{"status": 200, "likelihood": 10, "data": ...}
]
```

The order the objects appear in the response list is the same as the order of the `params` in the input `requests` array.

Each response contains an individual status code that shows whether the enrichment for that particular request was successful (`200`) or not. See [Errors](/docs/errors) for a detailed breakdown on all possible status codes.

### Errors

If the request encounters an error, it will instead return an Error Response in the format described in [Errors](/docs/errors).

Updated 4 months ago

---

Did this page help you?

Yes

No

---
# https://docs.peopledatalabs.com/docs/quickstart-job-title-enrichment-api

## Getting Started

In order to use our Job Title Enrichment API, you must have an enterprise account. Contact us at [support@peopledatalabs.com](mailto:support@peopledatalabs.com) to learn more.

## Simple Example

As mentioned in the [Overview](/docs/job-title-enrichment-api#overview), the Job Title Enrichment API is a means of performing a one-to-one match of a job title with those included in our [Job Title](/docs/job-title-schema) Dataset. In order to use the Job Title Enrichment API, **you will need the[job title](/docs/input-parameters-job-title-enrichment-api#job_title) that you want to look up**.

Here's a quick example that demonstrates retrieving a record with a `job_title` of `supply manager`:

Python3 SDKcURLJavaScriptRubyGoPython3

```
# See https://github.com/peopledatalabs/peopledatalabs-python
from peopledatalabs import PDLPY

# Create a client, specifying your API key
CLIENT = PDLPY(
    api_key="YOUR API KEY",
)

# Create a parameters JSON object
QUERY_STRING = {"job_title": "supply manager"}

# Pass the parameters object to the Job Title Enrichment API
response = CLIENT.job_title(**QUERY_STRING)

# Print the API response
print(response.text)
```

```
curl -X GET -G \
  'https://api.peopledatalabs.com/v5/job_title/enrich' \
  -H 'X-Api-Key: YOUR API KEY' \
  --data-urlencode 'job_title=supply manager'
```

```
// See https://github.com/peopledatalabs/peopledatalabs-js
import PDLJS from 'peopledatalabs';

// Create a client, specifying your API key
const PDLJSClient = new PDLJS({ apiKey: "YOUR API KEY" });

// Create a parameters JSON object
const queryString = {jobTitle: "supply manager"}

// Pass the parameters object to the Job Title API
PDLJSClient.jobTitle(queryString).then((data) => {
    // Print the API response
    console.log(data);
}).catch((error) => {
    console.log(error);
});
```

```
# See https://github.com/peopledatalabs/peopledatalabs-ruby
require 'peopledatalabs'

# Set your API key
Peopledatalabs.api_key = 'YOUR API KEY'

# Pass parameters to the Job Title API
response = Peopledatalabs::JobTitle.retrieve("job_title":"supply manager")

# Print the API response
puts response
```

```
package main

import (
    "fmt"
    "context"
)

// See https://github.com/peopledatalabs/peopledatalabs-go
import (
    pdl "github.com/peopledatalabs/peopledatalabs-go"
    pdlmodel "github.com/peopledatalabs/peopledatalabs-go/model"
)

func main() {
    // Set your API key
    apiKey := "YOUR API KEY"
    // Set API key as environmental variable
    // apiKey := os.Getenv("API_KEY")

    // Create a client, specifying your API key
    client := pdl.New(apiKey)
    
    // Create a parameters JSON object
    queryString := pdlmodel.JobTitleBaseParams{JobTitle: "supply manager"}
    
    params := pdlmodel.JobTitleParams{
        JobTitleBaseParams: queryString,
    }
    
    // Pass the parameters object to the Job Title API
    response, err := client.JobTitle(context.Background(), params)
    // Check for successful response
    if err == nil {
        // Print the API response
        fmt.Println(response)
    }  
}
```

```
import requests

# Set your API key
API_KEY = "YOUR API KEY"

# Set the Job Title Enrichment API URL
PDL_URL = "https://api.peopledatalabs.com/v5/job_title/enrich"

# Create a parameters JSON object
QUERY_STRING = {"job_title": "supply manager"}

# Set headers
HEADERS = {
    'accept': "application/json",
    'content-type': "application/json",
    'x-api-key': API_KEY
}

# Pass the parameters object to the Job Title Enrichment API
response = requests.request("GET", PDL_URL, headers=HEADERS, params=QUERY_STRING)

# Print the API response
print(response.text)
```

The API returns a record like the one below if the `job_title` that you passed it exists in our dataset:

JSON

```
{
  "cleaned_job_title": "supply manager",
  "similar_job_titles": [
    "senior supply manager",
    "supply chain manager",
    "supply specialist",
    "supply supervisor",
    "supply coordinator"
  ],
  "relevant_skills": [
    "supply management",
    "spend analysis",
    "supplier development",
    "demand planning",
    "strategic sourcing"
  ]
}
```

If you don't get this response, check out our [Errors](/docs/errors) page for more information.

---

Updated 4 months ago

---

Did this page help you?

Yes

No

---
# https://docs.peopledatalabs.com/docs/react-component-for-autocomplete

## What is the React Component for Autocomplete?

The React Component for Autocomplete lets you use the Autocomplete API to find valid Search API query values for a specific field (along with the number of available records for each suggestion.)

## How Does the Component Work?

The component works by letting users get autocomplete suggestions in a dropdown list. Using this list, they then can make a suggestion that gets passed to a callback function. For example, when a user queries the `company` field for `goog,` the component will display a dropdown list that includes suggestions that most closely matches this search, such as `google`. Then, when the user makes a selection, this gets sent as an argument to a callback function that has been passed to the component as a prop.

## How To Install the Component

This component is available as an [npm](https://www.npmjs.com/package/pdl-react-autocomplete) package, and you can install it like this:

NPMYarn

```
npm i -S pdl-react-autocomplete
```

```
yarn add pdl-react-autocomplete
```

## Using the Component

Make sure that you sign up for a [free PDL API key](https://www.peopledatalabs.com/signup) if you don't already have one.

JavaScript

```
import Autocomplete from 'pdl-react-autocomplete';

return (
  <div className="App">
  	<Autocomplete
      field={'company'}
      size={5}
      onTermSelected={(term) => console.log('onSelectedTerm', term)}
      apiKey={'insertKeyHere'}
		/>
	</div>
);
```

> ðŸš§
>
> ### Security Disclaimer
>
> You should use this library as an internal tool or as a proof of concept, as it fires off requests to the Autocomplete API from the client. This is due to the nature of React components and that API keys are all-encompassing at PDL. We highly suggest referencing the component's codebase for spinning up your own version but accessing the Autocomplete API through a proxy server and not using this in a public production environment.

## More Information, Pull Requests, Feature Suggestions and Bug Reports

We've open-sourced the library, which is available on GitHub. Go there to view more information. You can also submit pull requests, feature suggestions and bug reports.

[github.com

GitHub - peopledatalabs/pdl-react-autocomplete: React Component for AutoComplete](https://github.com/peopledatalabs/pdl-react-autocomplete)

Updated 4 months ago

---

Did this page help you?

Yes

No

---
# https://docs.peopledatalabs.com/docs/python-sdk

# The People Data Labs Python Helper Library

The People Data Labs Python Helper Library makes it easy to interact with our APIs from your Python application. You can find the [most recent version of the library on PyPi](https://pypi.org/project/peopledatalabs/). The People Data Labs Python Helper Library supports Python applications written in Python 3.7 and above.

## How To Install the Library

This library is available as a Python package, and you can install it like this:

Shell

```
pip install peopledatalabs
```

## Using the Library

Make sure that you sign up for a [free PDL API key](https://www.peopledatalabs.com/signup) if you don't already have one.

Python

```
import json

# See https://github.com/peopledatalabs/peopledatalabs-python
from peopledatalabs import PDLPY

# Create a client, specifying your API key
CLIENT = PDLPY(
    api_key="YOUR API KEY",
)

# Create a parameters JSON object
PARAMS = {
    "profile": ["linkedin.com/in/seanthorne"]
}

# Pass the parameters object to the Person Enrichment API
json_response = CLIENT.person.enrichment(**PARAMS).json()

# Print the API response in JSON format
print(json_response)
```

## More Information, Pull Requests, Feature Suggestions and Bug Reports

We've open-sourced the library, which is available on GitHub. Go there to view more information. You can also submit pull requests, feature suggestions and bug reports.

[github.com

GitHub - peopledatalabs/peopledatalabs-python: A Python client for the People Data Labs API](https://github.com/peopledatalabs/peopledatalabs-python)

Updated 4 months ago

---

Did this page help you?

Yes

No

---
# https://docs.peopledatalabs.com/docs/reference-job-title-enrichment-api

## Endpoint

The endpoint for the Job Title Enrichment API is `v5/job_title/enrich`.

## Billing and Access

This API is currently in production, and you can access it by using your API key.

The HTTP response code will be `200` when the API returns a matching job title and `404` when the API neither finds nor returns a matching job title. We charge per match.

## Rate Limiting

Our default limit for free customers is 100 per minute. Our default limit for paying customers is 5,000 per minute.

## Input Parameters

> ðŸ“˜
>
> ### For More Details, See [Job Title Enrichment API - Input Parameters](/docs/input-parameters-job-title-enrichment-api)
>
> You can also click on the individual parameter names in the table below to view more information on them.

| Parameter Name | Required | Description | Default | Example |
| --- | --- | --- | --- | --- |
| [`job_title`](/docs/input-parameters-job-title-enrichment-api#job_title) | Yes | The job title that you are enriching. | None | `pastry chef` |
| [`api_key`](/docs/input-parameters-job-title-enrichment-api#api_key) | No\* | Your secret API key.  While we do not require this as part of the request parameters, if you do not provide it here, then you must provide it using an alternative means, such as in the headers using the `x-api-key` field. For more information, see the [Authentication](/docs/authentication) page. | None |  |
| [`pretty`](/docs/input-parameters-job-title-enrichment-api#pretty) | No | Whether the output should have human-readable indentation. | `false` | `true` |
| [`titlecase`](/docs/input-parameters-job-title-enrichment-api#titlecase) | No | All text in the API responses returns as lowercase by default. Setting `titlecase` to `true` will titlecase the text in `200` responses. | `false` | `true` |

## Output Response

### Response Fields

> ðŸ“˜
>
> ### For More Details, See [Job Title Enrichment API - Output Response](/docs/output-response-job-title-enrichment-api).
>
> You can also click the field names in the table below to view more information on them.

| Field Name | Type | Description |
| --- | --- | --- |
| [`cleaned_job_title`](/docs/output-response-job-title-enrichment-api#cleaned_job_title) | `String` | The job title that matches the API input `job_title` after passing it through our internal job title cleaner. |
| [`similar_job_titles`](/docs/output-response-job-title-enrichment-api#similar_job_titles) | `Array (String)` | A list of up to five of the most contextually-similar job titles to the `cleaned_job_title`, determined using our global resume data.. |
| [`relevant_skills`](/docs/output-response-job-title-enrichment-api#relevant_skills) | `Array (String)` | A list of up to five of the most contextually-similar skills to the `cleaned_job_title`, determined using our global resume data. |

### Full Example Response

Input Query (click to toggle)

Python

```
import requests

url = "https://api.peopledatalabs.com/v5/job_title/enrich"

query_string = {"job_title": "supply manager"}

headers = {
    'accept': "application/json",
    'content-type': "application/json",
    'x-api-key': "YOUR_API_KEY"
    }

response = requests.request("GET", url, headers=headers, params=query_string)

print(response.text)
```

Output Response (full):

JSON

```
{
  "cleaned_job_title": "supply manager",
  "similar_job_titles": [
    "senior supply manager",
    "supply chain manager",
    "supply specialist",
    "supply supervisor",
    "supply coordinator"
  ],
  "relevant_skills": [
    "supply management",
    "spend analysis",
    "supplier development",
    "demand planning",
    "strategic sourcing"
  ]
}
```

Updated 4 months ago

---

Did this page help you?

Yes

No

---
# https://docs.peopledatalabs.com/docs/output-response-company-enrichment-api

## Response Data Structure

Here is an example response from the Company Enrichment API:

JSON

```
{
  "status": 200,
  "name": "people data labs",
  "id": "tnHcNHbCv8MKeLh92946LAkX6PKg",
  ...,
  "likelihood": 6
}
```

See [Example Company Record](/docs/example-company-record) for a full example of the fields included in the response object.

## Response Fields

### `*`

| Type | Description |
| --- | --- |
| `any` | The matched company profile in the format described in our [Company Schema](/docs/company-schema). |

The [PDL profile](/docs/company-schema) for the company that matches the Enrichment API request. Any profile field that we do not have data for will have a `null` value.

Unlike our other APIs, the profile fields for the Company Enrichment API are **NOT** contained in a top-level `data` object.

  

### `status`

| Type | Description |
| --- | --- |
| `Integer` | The [API response code](/docs/errors). |

  

### `likelihood`

| Type | Description |
| --- | --- |
| `Integer` | How confident we are that the returned profile is the same as the company you requested. Will be an integer between `1` and `10`.  You can control the minimum likelihood score that a response must have in order to count as a match by setting the [`min_likelihood` parameter](/docs/input-parameters-company-enrichment-api#min_likelihood) in the API request. |

We assign every match that the API finds during the enrichment process a likelihood score, to represent our confidence that the profile returned is the same as the profile requested. A score of `1` represents a very low confidence level while a score of `10` represents the highest degree of confidence. The likelihood score is logarithmic, so a response that returns a likelihood score of `2` will have roughly a 10-30% chance of being the person requested.

For example, enriching "John Smith, Inc." in "New York" is too vague for us to confidently say which of our profiles is the exact John Smith Inc. that you requested. However, if you were to attach a website, stock ticker, and street address to the request and they matched our data, we would be highly confident that we are returning the correct John Smith Inc.

  

### `matched`

| Type | Description |
| --- | --- |
| `Array (String)` | Every query input from the request that matched this profile.   * \*IMPORTANT:\*\* This field will only be included in the response if the [`include_if_matched` flag](/docs/input-parameters-company-enrichment-api#include_if_matched) is set to `true`. |

See the [`include_if_matched` input parameter](/docs/input-parameters-company-enrichment-api#include_if_matched) for more details.

Updated 4 months ago

---

Did this page help you?

Yes

No

---
# https://docs.peopledatalabs.com/docs/examples-job-title-enrichment-api

We've provided code samples in Python, cURL, Ruby, Go and JavaScript. If you aren't comfortable working in any of these languages, feel free to use this [handy tool](https://curl.trillworks.com/) to convert code from cURL to the language of your choice.

> ðŸ’¡
>
> ### We want your feedback!
>
> Do you see a bug? Is there an example you'd like to see that's not listed here?
>
> Head over to the public roadmap and submit a [bug ticket](https://peopledatalabs.canny.io/bugs) or a [feature request](https://peopledatalabs.canny.io/feature-requests) and receive automatic notifications as your bug is resolved or your request is implemented.

## Basic Usage

*"I want to look up information for a job title that I have."*

Python3 SDKcURLJavaScriptRubyGoPython3

```
# See https://github.com/peopledatalabs/peopledatalabs-python
from peopledatalabs import PDLPY

# Create a client, specifying your API key
CLIENT = PDLPY(
    api_key="YOUR API KEY",
)

# Create a parameters JSON object
QUERY_STRING = {"job_title": "pastry chef"}

# Pass the parameters object to the Job Title Enrichment API
response = CLIENT.job_title(**QUERY_STRING)

# Print the API response
print(response.text)
```

```
curl -X GET -G \
  'https://api.peopledatalabs.com/v5/job_title/enrich' \
  -H 'X-Api-Key: YOUR API KEY' \
  --data-urlencode 'job_title=pastry chef'
```

```
// See https://github.com/peopledatalabs/peopledatalabs-js
import PDLJS from 'peopledatalabs';

// Create a client, specifying your API key
const PDLJSClient = new PDLJS({ apiKey: "YOUR API KEY" });

// Create a parameters JSON object
const queryString = {jobTitle: "pastry chef"}

// Pass the parameters object to the Job Title API
PDLJSClient.jobTitle(queryString).then((data) => {
    // Print the API response
    console.log(data);
}).catch((error) => {
    console.log(error);
});
```

```
# See https://github.com/peopledatalabs/peopledatalabs-ruby
require 'peopledatalabs'

# Set your API key
Peopledatalabs.api_key = 'YOUR API KEY'

# Pass parameters to the Job Title API
response = Peopledatalabs::JobTitle.retrieve("job_title":"pastry chef")

# Print the API response
puts response
```

```
package main

import (
    "fmt"
    "context"
)

// See https://github.com/peopledatalabs/peopledatalabs-go
import (
    pdl "github.com/peopledatalabs/peopledatalabs-go"
    pdlmodel "github.com/peopledatalabs/peopledatalabs-go/model"
)

func main() {
    // Set your API key
    apiKey := "YOUR API KEY"
    // Set API key as environmental variable
    // apiKey := os.Getenv("API_KEY")

    // Create a client, specifying your API key
    client := pdl.New(apiKey)
    
    // Create a parameters JSON object
    queryString := pdlmodel.JobTitleBaseParams{JobTitle: "pastry chef"}
    
    params := pdlmodel.JobTitleParams{
        JobTitleBaseParams: queryString,
    }
    
    // Pass the parameters object to the Job Title API
    response, err := client.JobTitle(context.Background(), params)
    // Check for successful response
    if err == nil {
        // Print the API response
        fmt.Println(response)
    }  
}
```

```
import requests

# Set your API key
API_KEY = "YOUR API KEY"

# Set the Job Title Enrichment API URL
PDL_URL = "https://api.peopledatalabs.com/v5/job_title/enrich"

# Create a parameters JSON object
QUERY_STRING = {"job_title": "pastry chef"}

# Set headers
HEADERS = {
    'accept': "application/json",
    'content-type': "application/json",
    'x-api-key': API_KEY
}

# Pass the parameters object to the Job Title Enrichment API
response = requests.request("GET", PDL_URL, headers=HEADERS, params=QUERY_STRING)

# Print the API response
print(response.text)
```

## Basic Usage Using POST

*"I want to look up information for a job title that I have with a POST request."*

> ðŸ“˜
>
> ### Difference Between GET and POST Requests
>
> See this article for a comparison of the [differences between GET and POST requests](https://www.w3schools.com/tags/ref_httpmethods.asp). The biggest difference is that POST requests don't have any limit on the amount of data that you can pass in a request.

Python3cURL

```
import requests

# Set your API key
API_KEY = "YOUR API KEY"

# Set the Job Title Enrichment API URL
PDL_URL = "https://api.peopledatalabs.com/v5/job_title/enrich"

# Create a parameters JSON object
QUERY_STRING = {"job_title": "pastry chef"}

# Set headers
HEADERS = {
    'accept': "application/json",
    'content-type': "application/json",
    'x-api-key': API_KEY
}

# Pass the parameters object to the Company Cleaner API using POST method
response = requests.post(
  PDL_URL,
  headers=HEADERS,
  json=QUERY_STRING # Passing the data directly as a JSON object
).json()

# Print the API response
print(response)
```

```
curl -X POST \
  'https://api.peopledatalabs.com/v5/job_title/enrich' \
  -H 'X-Api-Key: your-api-key' \
  -H 'Content-Type: application/json' \
  -d '{
    "job_title": "software engineer",
    "pretty": true
}'
```

## Person Searching Using Job Title Data

*"I want to search for people with similar job titles."*

Python3 SDK (Elasticsearch)Python3 SDK (SQL)JavaScript (Elasticsearch)JavaScript (SQL)Ruby (Elasticsearch)Ruby (SQL)Go (Elasticsearch)Go (SQL)Python3 (Elasticsearch)Python3 (SQL)

```
import json

# See https://github.com/peopledatalabs/peopledatalabs-python
from peopledatalabs import PDLPY

# Create a client, specifying your API key
CLIENT = PDLPY(
    api_key="YOUR API KEY",
)

# Set the maximum number of people to search
MAX_NUM_PEOPLE = 100

# The job title you want to enrich
JOB_TITLE = "supply manager"
# Create a parameters JSON object
QUERY_STRING = {"job_title": JOB_TITLE}

# Pass the parameters object to the Job Title Enrichment API
response = CLIENT.job_title(**QUERY_STRING)

# Check for successful response
if response.status_code == 200:
  # Store enriched job title
  enriched_job_title = response.json()
  # Build list of job titles
  job_titles = enriched_job_title["data"]["similar_job_titles"]
  job_titles.insert(0, JOB_TITLE)
else:
  enriched_job_title = {}
  print(f"Job Title Enrichment Error for [{JOB_TITLE}]: {response.text}")
                                                      
# Person Search matches
employee_matches = {}

# Check for enriched job title
if enriched_job_title:
  # Create an Elasticsearch query
  ES_QUERY = {
  	"query": {
    	"bool": {
        	"must": [
            	{"term": {"location_metro": "detroit, michigan"}},
            	{'term': {'industry': "automotive"}},
            	{"terms": {"job_title": job_titles}}
      		]
    	}
  	}
  }

  # Create a parameters JSON object
  PARAMS = {
  	'query': ES_QUERY,
  	'size': MAX_NUM_PEOPLE
  }
  
  # Pass the parameters object to the Person Search API
  response = CLIENT.person.search(**PARAMS).json()

  # Check for successful response
  if response["status"] == 200:
    # Store matches
  	employee_matches = response["data"]
  else:
  	employee_matches = {}
  	print(f"Person Search Error for [{JOB_TITLE}]: {response}")

  print(f"Found {len(employee_matches)} employee profiles for {JOB_TITLE}.")
```

```
import json

# See https://github.com/peopledatalabs/peopledatalabs-python
from peopledatalabs import PDLPY

# Create a client, specifying your API key
CLIENT = PDLPY(
    api_key="YOUR API KEY",
)

# Set the maximum number of people to search
MAX_NUM_PEOPLE = 100

# The job title you want to enrich
JOB_TITLE = "supply manager"
# Create a parameters JSON object
QUERY_STRING = {"job_title": JOB_TITLE}

# Pass the parameters object to the Job Title Enrichment API
response = CLIENT.job_title(**QUERY_STRING)

# Check for successful response
if response.status_code == 200:
  # Store enriched job title
  enriched_job_title = response.json()
  # Build list of job titles
  job_titles = enriched_job_title["data"]["similar_job_titles"]
  job_titles.insert(0, JOB_TITLE)
  job_titles_string_rep = ", ".join(
    (f"'{title}'" for title in job_titles)
  )
else:
  enriched_job_title = {}
  print(f"Job Title Enrichment Error for [{JOB_TITLE}]: {response.text}")
                                                      
# Person Search matches
employee_matches = {}

# Check for enriched job title
if enriched_job_title:
  # Create an SQL query
  SQL_QUERY = \
  f"""
    SELECT * FROM person
    WHERE location_metro='detroit, michigan'
    AND industry = 'automotive'
    AND job_title IN ({job_titles_string_rep});
   """

  # Create a parameters JSON object
  PARAMS = {
  	'sql': SQL_QUERY,
  	'size': MAX_NUM_PEOPLE
  }
  
  # Pass the parameters object to the Person Search API
  response = CLIENT.person.search(**PARAMS).json()

  # Check for successful response
  if response["status"] == 200:
    # Store matches
  	employee_matches = response["data"]
  else:
  	employee_matches = {}
  	print(f"Person Search Error for [{JOB_TITLE}]: {response}")

  print(f"Found {len(employee_matches)} employee profiles for {JOB_TITLE}.")
```

```
// See https://github.com/peopledatalabs/peopledatalabs-js
import PDLJS from 'peopledatalabs';

// Create a client, specifying your API key
const PDLJSClient = new PDLJS({ apiKey: "YOUR API KEY" });

// Set the maximum number of people to search
const maxNumPeople = 100;

// The job title you want to enrich
const jobTitle = "supply manager";
// Create a parameters JSON object
const queryString = {jobTitle: jobTitle};

// Pass the parameters object to the Job Title API
PDLJSClient.jobTitle(queryString).then((data) => {
    // Store enriched job title
    var enrichedJobTitle = data;
    // Build list of job titles
    var jobTitles = enrichedJobTitle["data"]["similar_job_titles"];
    jobTitles.splice(0, 0, jobTitle);
    
    // Create an Elasticsearch query
    const esQuery = {
        "query": {
            "bool": {
                "must": [
                    {"term": {"location_metro": "detroit, michigan"}},
                    {'term': {'industry': "automotive"}},
                    {"terms": {"job_title": jobTitles}}
      		    ]
    	   }
        }
    }

    // Create a parameters JSON object
    const params = {
        searchQuery: esQuery,
        size: maxNumPeople
    }

    // Pass the parameters object to the Person Search API
    PDLJSClient.person.search.elastic(params).then((data) => {
        // Store matches
        var employeeMatches = data["data"];       
        console.log(`Found ${employeeMatches.length} employee profiles for ${jobTitle}.`); 
    }).catch((error) => {
        console.log(`Person Search Error for [${jobTitle}]:`, error);
    });
       
}).catch((error) => {
    console.log(`Job Title Enrichment Error for [${jobTitle}]:`, error);
});
```

```
// See https://github.com/peopledatalabs/peopledatalabs-js
import PDLJS from 'peopledatalabs';

// Create a client, specifying your API key
const PDLJSClient = new PDLJS({ apiKey: "YOUR API KEY" });

// Set the maximum number of people to search
const maxNumPeople = 100;

// The job title you want to enrich
const jobTitle = "supply manager";
// Create a parameters JSON object
const queryString = {jobTitle: jobTitle};

// Pass the parameters object to the Job Title API
PDLJSClient.jobTitle(queryString).then((data) => {
    // Store enriched job title
    var enrichedJobTitle = data;
    // Build list of job titles
    var jobTitles = enrichedJobTitle["data"]["similar_job_titles"];
    jobTitles.splice(0, 0, jobTitle);
    var jobTitlesStringRep = "'" + jobTitles.join("', '") + "'";
    
    // Create an SQL query
    const sqlQuery = `SELECT * FROM person 
                        WHERE location_metro='detroit, michigan'
                        AND industry = 'automotive'
                        AND job_title IN (${jobTitlesStringRep});`

    // Create a parameters JSON object
    const params = {
        searchQuery: sqlQuery,
        size: maxNumPeople
    }

    // Pass the parameters object to the Person Search API
    PDLJSClient.person.search.sql(params).then((data) => {
        // Store matches
        var employeeMatches = data["data"];       
        console.log(`Found ${employeeMatches.length} employee profiles for ${jobTitle}.`); 
    }).catch((error) => {
        console.log(`Person Search Error for [${jobTitle}]:`, error);
    });
       
}).catch((error) => {
    console.log(`Job Title Enrichment Error for [${jobTitle}]:`, error);
});
```

```
# See https://github.com/peopledatalabs/peopledatalabs-ruby
require 'peopledatalabs'

# Set your API key
Peopledatalabs.api_key = 'YOUR API KEY'

# Set the maximum number of people to search
MAX_NUM_PEOPLE = 100

# The job title you want to enrich
JOB_TITLE = "supply manager"

# Pass parameters to the Job Title API
response = Peopledatalabs::JobTitle.retrieve("job_title":JOB_TITLE)

# Check for successful response
if response['status'] == 200
  # Store enriched job title
  enriched_job_title = response
  # Build list of job titles
  job_titles = enriched_job_title['data']['similar_job_titles']
  job_titles.insert(0, JOB_TITLE)
else
  enriched_job_title = {}
  puts "Job Title Enrichment Error for [#{JOB_TITLE}]: #{response}"
end

# Person Search matches
employee_matches = {}

# Check for enriched job title
if !enriched_job_title.nil?
  # Create an Elasticsearch query
  ES_QUERY = {
  	"query": {
    	"bool": {
        	"must": [
            	{"term": {"location_metro": "detroit, michigan"}},
            	{'term': {'industry': "automotive"}},
            	{"terms": {"job_title": job_titles}}
      		]
    	}
  	}
  }

  # Pass parameters to the Person Search API
  response = Peopledatalabs::Search.person(searchType: 'elastic', query: ES_QUERY, size: MAX_NUM_PEOPLE)

  # Check for successful response
  if response['status'] == 200
    # Store matches
  	employee_matches = response['data']
  else
  	employee_matches = {}
  	puts "Person Search Error for [#{JOB_TITLE}]: #{response}"
  end

  puts "Found #{employee_matches.length()} employee profiles for #{JOB_TITLE}."
end
```

```
# See https://github.com/peopledatalabs/peopledatalabs-ruby
require 'peopledatalabs'

# Set your API key
Peopledatalabs.api_key = 'YOUR API KEY'

# Set the maximum number of people to search
MAX_NUM_PEOPLE = 100

# The job title you want to enrich
JOB_TITLE = "supply manager"

# Pass parameters to the Job Title API
response = Peopledatalabs::JobTitle.retrieve("job_title":JOB_TITLE)

# Check for successful response
if response['status'] == 200
  # Store enriched job title
  enriched_job_title = response
  # Build list of job titles
  job_titles = enriched_job_title['data']['similar_job_titles']
  job_titles.insert(0, JOB_TITLE)
  job_titles_string_rep = "'" + job_titles.join("','") + "'"
else
  enriched_job_title = {}
  puts "Job Title Enrichment Error for [#{JOB_TITLE}]: #{response}"
end

# Person Search matches
employee_matches = {}

# Check for enriched job title
if !enriched_job_title.nil?
  # Create an SQL query
  SQL_QUERY = """
    SELECT * FROM person
    WHERE location_metro='detroit, michigan'
    AND industry = 'automotive'
    AND job_title IN (#{job_titles_string_rep});
   """

  # Pass parameters to the Person Search API
  response = Peopledatalabs::Search.person(searchType: 'sql', query: SQL_QUERY, size: MAX_NUM_PEOPLE)

  # Check for successful response
  if response['status'] == 200
    # Store matches
  	employee_matches = response['data']
  else
  	employee_matches = {}
  	puts "Person Search Error for [#{JOB_TITLE}]: #{response}"
  end

  puts "Found #{employee_matches.length()} employee profiles for #{JOB_TITLE}."
end
```

```
package main

import (
    "fmt"
    "encoding/json"
    "reflect"
    "context"
)

// See https://github.com/peopledatalabs/peopledatalabs-go
import (
    pdl "github.com/peopledatalabs/peopledatalabs-go"
    pdlmodel "github.com/peopledatalabs/peopledatalabs-go/model"
)

func main() {
    // Set your API key
    apiKey := "YOUR API KEY"
    // Set API key as environmental variable
    // apiKey := os.Getenv("API_KEY")

    // Create a client, specifying your API key
    client := pdl.New(apiKey)
    
    // Set the maximum number of people to search
    const maxNumPeople = 100
    
    // The job title you want to enrich
    jobTitle := "supply manager"
    
    var jobTitles []string
    
    // Create a parameters JSON object
    queryString := pdlmodel.JobTitleBaseParams{JobTitle: jobTitle}
    
    params := pdlmodel.JobTitleParams{
        JobTitleBaseParams: queryString,
    }
    
    // Pass the parameters object to the Job Title API
    response, err := client.JobTitle(context.Background(), params)
    
    var enrichedJobTitle map[string][]string

    // Check for successful response
    if err == nil {
        // Convert the API response to JSON
        jsonResponse, jsonErr := json.Marshal(response.Data)
        if jsonErr == nil {
            // Store enriched job title
            json.Unmarshal(jsonResponse, &enrichedJobTitle)
            // Build list of job titles
            jobTitles = enrichedJobTitle["similar_job_titles"]
            jobTitles = append(jobTitles, jobTitle)
        }
    } else {
        fmt.Printf("Job Title Enrichment Error for [%s]:\n\t", jobTitle)
        fmt.Println(err)
   	}
    
    // Person Search matches
    var employeeMatches []pdlmodel.Person

    // Check for enriched job title
    if !reflect.DeepEqual(enrichedJobTitle, pdlmodel.JobTitleResponse{}) {
        // Create an Elasticsearch query
        elasticSearchQuery := map[string]interface{} {
            "query": map[string]interface{} {
                "bool": map[string]interface{} {
                    "must": []map[string]interface{} {
                        {"term": map[string]interface{}{"location_metro": "detroit, michigan"}},
                        {"term": map[string]interface{}{"industry": "automotive"}},
                        {"terms": map[string]interface{}{"job_title": jobTitles}},
                   },
                },
            },
        }
    
        // Create a parameters JSON object
        params := pdlmodel.SearchParams {
            BaseParams: pdlmodel.BaseParams {
                Size: maxNumPeople,
            },
            SearchBaseParams: pdlmodel.SearchBaseParams {
                Query: elasticSearchQuery,
            },
        }

        // Pass the parameters object to the Person Search API
        response, err := client.Person.Search(context.Background(), params)

        // Check for successful response
        if err == nil {
            // Store matches
            employeeMatches = response.Data
            fmt.Printf("Found %d employee profiles for %s.\n", len(employeeMatches), jobTitle)
        } else {
            fmt.Printf("Person Search Error for [%s]:\n\t", jobTitle)
            fmt.Println(err)
        }
    }
}
```

```
package main

import (
    "fmt"
    "encoding/json"
    "strings"
    "reflect"
    "context"
)

// See https://github.com/peopledatalabs/peopledatalabs-go
import (
    pdl "github.com/peopledatalabs/peopledatalabs-go"
    pdlmodel "github.com/peopledatalabs/peopledatalabs-go/model"
)

func main() {
    // Set your API key
    apiKey := "YOUR API KEY"
    // Set API key as environmental variable
    // apiKey := os.Getenv("API_KEY")

    // Create a client, specifying your API key
    client := pdl.New(apiKey)
    
    // Set the maximum number of people to search
    const maxNumPeople = 100
    
    // The job title you want to enrich
    jobTitle := "supply manager"
    
    var jobTitles []string
    
    // Create a parameters JSON object
    queryString := pdlmodel.JobTitleBaseParams{JobTitle: jobTitle}
    
    params := pdlmodel.JobTitleParams{
        JobTitleBaseParams: queryString,
    }
    
    // Pass the parameters object to the Job Title API
    response, err := client.JobTitle(context.Background(), params)
    
    var enrichedJobTitle map[string][]string
    var jobTitlesStringRep string

    // Check for successful response
    if err == nil {
        // Convert the API response to JSON
        jsonResponse, jsonErr := json.Marshal(response.Data)
        if jsonErr == nil {
            // Store enriched job title
            json.Unmarshal(jsonResponse, &enrichedJobTitle)
            // Build list of job titles
            jobTitles = enrichedJobTitle["similar_job_titles"]
            jobTitles = append(jobTitles, jobTitle)
            jobTitlesStringRep = "'" + strings.Join(jobTitles[:], "','") + "'"
        }
    } else {
        fmt.Printf("Job Title Enrichment Error for [%s]:\n\t", jobTitle)
        fmt.Println(err)
    }
    
    // Person Search matches
    var employeeMatches []pdlmodel.Person

    // Check for enriched job title
    if !reflect.DeepEqual(enrichedJobTitle, pdlmodel.JobTitleResponse{}) {
        // Create an SQL query
        sqlQuery := "SELECT * FROM person" +
                    " WHERE location_metro='detroit, michigan'" +
                    " AND industry = 'automotive'" +
                    " AND job_title IN (" + jobTitlesStringRep + ");"

    
        // Create a parameters JSON object
        params := pdlmodel.SearchParams {
            BaseParams: pdlmodel.BaseParams {
                Size: maxNumPeople,
            },
            SearchBaseParams: pdlmodel.SearchBaseParams {
                SQL: sqlQuery,
            },
        }

        // Pass the parameters object to the Person Search API
        response, err := client.Person.Search(context.Background(), params)

        // Check for successful response
        if err == nil {
            // Store matches
            employeeMatches = response.Data
            fmt.Printf("Found %d employee profiles for %s.\n", len(employeeMatches), jobTitle)
        } else {
            fmt.Printf("Person Search Error for [%s]:\n\t", jobTitle)
            fmt.Println(err)
        }
    }
}
```

```
import requests, json

# Set your API key
API_KEY = "YOUR API KEY"

# Set the Job Title Enrichment API URL
PDL_JOB_TITLE_ENRICH_URL = "https://api.peopledatalabs.com/v5/job_title/enrich"
# Set the Person Search API URL
PDL_PERSON_SEARCH_URL = "https://api.peopledatalabs.com/v5/person/search"

# Set the maximum number of people to search
MAX_NUM_PEOPLE = 100

# The job title you want to enrich
JOB_TITLE = "supply manager"
# Create a parameters JSON object
QUERY_STRING = {"job_title": JOB_TITLE}

# Set headers
HEADERS = {
  'accept': "application/json",
  'content-type': "application/json",
  'x-api-key': API_KEY
}

# Pass the parameters object to the Job Title Enrichment API
response = requests.request("GET", PDL_JOB_TITLE_ENRICH_URL, 
                            headers=HEADERS, params=QUERY_STRING)

# Check for successful response
if response.status_code == 200:
  # Store enriched job title
  enriched_job_title = response.json()
  # Build list of job titles
  job_titles = enriched_job_title["data"]["similar_job_titles"]
  job_titles.insert(0, JOB_TITLE)
else:
  enriched_job_title = {}
  print(f"Job Title Enrichment Error for [{JOB_TITLE}]: {response.text}")
                                                      
# Person Search matches
employee_matches = {}

# Check for enriched job title
if enriched_job_title:
  # Create an Elasticsearch query
  ES_QUERY = {
  	"query": {
    	"bool": {
        	"must": [
            	{"term": {"location_metro": "detroit, michigan"}},
            	{'term': {'industry': "automotive"}},
            	{"terms": {"job_title": job_titles}},
      		]
    	}
  	}
  }

  # Create a parameters JSON object
  PARAMS = {
  	'query': json.dumps(ES_QUERY),
  	'size': MAX_NUM_PEOPLE
  }

  # Pass the parameters object to the Person Search API
  response = requests.get(PDL_PERSON_SEARCH_URL, headers=HEADERS, params=PARAMS)

  # Check for successful response
  if response.status_code == 200:
    # Store matches
  	employee_matches = response.json()["data"]
  else:
  	employee_matches = {}
  	print(f"Person Search Error for [{JOB_TITLE}]: {response.text}")

  print(f"Found {len(employee_matches)} employee profiles for {JOB_TITLE}.")
```

```
import requests, json

# Set your API key
API_KEY = "YOUR API KEY"

# Set the Job Title Enrichment API URL
PDL_JOB_TITLE_ENRICH_URL = "https://api.peopledatalabs.com/v5/job_title/enrich"
# Set the Person Search API URL
PDL_PERSON_SEARCH_URL = "https://api.peopledatalabs.com/v5/person/search"

# Set the maximum number of people to search
MAX_NUM_PEOPLE = 100

# The job title you want to enrich
JOB_TITLE = "supply manager"
# Create a parameters JSON object
QUERY_STRING = {"job_title": JOB_TITLE}

# Set headers
HEADERS = {
  'accept': "application/json",
  'content-type': "application/json",
  'x-api-key': API_KEY
}

# Pass the parameters object to the Job Title Enrichment API
response = requests.request("GET", PDL_JOB_TITLE_ENRICH_URL, 
                            headers=HEADERS, params=QUERY_STRING)

# Check for successful response
if response.status_code == 200:
  # Store enriched job title
  enriched_job_title = response.json()
  # Build list of job titles
  job_titles = enriched_job_title["data"]["similar_job_titles"]
  job_titles.insert(0, JOB_TITLE)
  job_titles_string_rep = ", ".join(
    (f"'{title}'" for title in job_titles)
  )

else:
  enriched_job_title = {}
  print(f"Job Title Enrichment Error for [{JOB_TITLE}]: {response.text}")
                                                      
# Person Search matches
employee_matches = {}

# Check for enriched job title
if enriched_job_title:
  # Create an SQL query
  SQL_QUERY = f"""
  SELECT * FROM person
  WHERE location_metro='detroit, michigan'
  AND industry = 'automotive'
  AND job_title IN ({job_titles_string_rep});
  """
    
  # Create a parameters JSON object
  PARAMS = {
  	'sql': SQL_QUERY,
  	'size': MAX_NUM_PEOPLE
  }

  # Pass the parameters object to the Person Search API
  response = requests.get(PDL_PERSON_SEARCH_URL, headers=HEADERS, params=PARAMS)

  # Check for successful response
  if response.status_code == 200:
    # Store matches
  	employee_matches = response.json()["data"]
  else:
  	employee_matches = {}
  	print(f"Person Search Error for [{JOB_TITLE}]: {response.text}")

  print(f"Found {len(employee_matches)} employee profiles for {JOB_TITLE}.")
```

Updated 4 months ago

---

Did this page help you?

Yes

No

---
# https://docs.peopledatalabs.com/docs/input-parameters-cleaner-apis

## Company Cleaner API Parameters (`/company/clean`)

While all parameters are optional, we require a *non-ambiguous* match. This means that you must input a `name` OR `website` OR `profile`.

### `name`

| Parameter Name | Required | Description | Example |
| --- | --- | --- | --- |
| `name` | No | The name of the company that you want to identify. We accept unformatted strings with arbitrary capitalizations, leading and trailing whitespaces and so forth. | `People data Labs` |

### `profile`

| Parameter Name | Required | Description | Example |
| --- | --- | --- | --- |
| `profile` | No | The social profile URL of the company that you want to identify. We accept unformatted URLs with arbitrary capitalizations, leading and trailing whitespaces and so forth. | `linkedin.com/company/google` |

### `website`

| Parameter Name | Required | Description | Example |
| --- | --- | --- | --- |
| `website` | No | The website of the company that you want to identify. We accept unformatted URLs with arbitrary capitalizations, leading and trailing whitespaces and so forth. | `www.peopledatalabs.com` |

### `pretty`

| Parameter Name | Required | Description | Example |
| --- | --- | --- | --- |
| `pretty` | No | Whether the output should have human-readable indentation. | `True` |

### `api_key`

| Parameter Name | Required | Description | Example |
| --- | --- | --- | --- |
| `api_key` | No\* | Your secret API key.  While we do not require this as part of the request parameters, if you don't provide it here, then you must provide it in an alternative way, such as by using the `x-api-key` field in the headers. For more information, see the [Authentication](/docs/authentication) page. |  |

  


---

## Location Cleaner API (`/location/clean`)

### `location`

| Parameter Name | Required | Description | Example |
| --- | --- | --- | --- |
| `location` | Yes | The name of the location that you want to identify. We accept unformatted locations with arbitrary capitalizations, leading and trailing whitespaces and so forth. | `San Francisco` |

### `pretty`

| Parameter Name | Required | Description | Example |
| --- | --- | --- | --- |
| `pretty` | No | Whether the output should have human-readable indentation. | `True` |

### `api_key`

| Parameter Name | Required | Description | Example |
| --- | --- | --- | --- |
| `api_key` | No\* | Your secret API key.  While we do not require this as part of the request parameters, if you don't provide it here, then you must provide it in an alternative way, such as by using the `x-api-key` field in the headers. For more information, see the [Authentication](/docs/authentication) page. |  |

  


---

## School Cleaner API (`/school/clean`)

While all parameters are optional, we require a *non-ambiguous* match. This means that you must input a `name` OR `website` OR `profile`.

### `name`

| Parameter Name | Required | Description | Example |
| --- | --- | --- | --- |
| `name` | No | The name of the company that you want to identify. We accept unformatted strings with arbitrary capitalizations, leading and trailing whitespaces and so forth. | `Harvard` |

### `profile`

| Parameter Name | Required | Description | Example |
| --- | --- | --- | --- |
| `profile` | No | The social profile URL of the company that you want to identify. We accept unformatted URLs with arbitrary capitalizations, leading and trailing whitespaces and so forth. | `linkedin.com/school/harvard-university` |

### `website`

| Parameter Name | Required | Description | Example |
| --- | --- | --- | --- |
| `website` | No | The website of the company that you want to identify. We accept unformatted URLs with arbitrary capitalizations, leading and trailing whitespaces and so forth. | `hardvard.edu` |

### `pretty`

| Parameter Name | Required | Description | Example |
| --- | --- | --- | --- |
| `pretty` | No | Whether the output should have human-readable indentation. | `True` |

### `api_key`

| Parameter Name | Required | Description | Example |
| --- | --- | --- | --- |
| `api_key` | No\* | Your secret API key.  While we do not require this as part of the request parameters, if you don't provide it here, then you must provide it in an alternative way, such as by using the `x-api-key` field in the headers. For more information, see the [Authentication](/docs/authentication) page. |  |

Updated 4 months ago

---

Did this page help you?

Yes

No

---
# https://docs.peopledatalabs.com/docs/table-flattened-data-license-format

The Table (Flattened) Data License Format is a file format for our Person and Company Data Licenses, that delivers the datasets as flattened tables (in either parquet or CSV format). This file structure is optimized for loading data into relational databases such as PostgreSQL and MySQL, simplifying data ingestion and enhancing the speed of delivering new information and insights.

## Schema

* [Person Schema](https://drive.google.com/file/d/1qnaivBopVAslTpt8r3QatP2wGi4S9xUz/view?usp=drive_link)
* [Company Schema](https://drive.google.com/file/d/16ouqj0XCCHs0RJld1Bcv7g_nKnLg2Aub/view?usp=drive_link)

*Note: Your contracted bundle/s may not include every field/table in the PDF schema above*

## Access

The Tabular Data License Format is available to all data license customers at no additional cost. To request access, contact your Customer Success or Technical Services team.

*Note: Adopting this format means you will receive data in the tabular format going forward. Previous formats will no longer be provided unless specifically requested.*

Updated 4 months ago

---

Did this page help you?

Yes

No

---
# https://docs.peopledatalabs.com/docs/input-parameters-job-title-enrichment-api

## Required Parameters

### `api_key`

| Type | Description | Default | Example |
| --- | --- | --- | --- |
| `String` | Your secret API key. |  |  |

Your API Key **must** be included in either the request header or the `api_key` parameter. For more information about request authentication, see the [Authentication](/docs/authentication) page.

  

### `job_title`

| Type | Description | Example |
| --- | --- | --- |
| `String` | The job title that you are enriching. | `pastry chef` |

If the provided `job_title` does not represent one from our [Job Title](/docs/job-title-schema) Dataset, then the Job Title Enrichment API will not return a matching record.

---

## Optional Parameters

### `pretty`

| Type | Description | Default | Example |
| --- | --- | --- | --- |
| `Boolean` | Whether the output should have [human-readable](http://jsonprettyprint.net/) indentation. | `false` | `true` |

  

### `titlecase`

| Type | Description | Default | Example |
| --- | --- | --- | --- |
| `Boolean` | All text in API responses returns as lowercase by default. Setting `titlecase` to `true` will titlecase response data instead. | `false` | `true` |

Updated 4 months ago

---

Did this page help you?

Yes

No

---
# https://docs.peopledatalabs.com/docs/job-title-subroles-legacy-v271

> â—ï¸
>
> ### Deprecated as of v29.1 (Feb 2025)
>
> As of v29.1 (Feb 2025), **the set of sub roles on this page are no longer supported in our datasets**.
>
> This page contains the legacy sub role canonical values prior to the release of our improved Role / Sub Role Taxonomy in February 2025, and is provided for historical documentation purposes.
>
> For the currently supported sub roles values, please see: [Job Title Subroles](/docs/job-title-subroles).
>
> For more information, please see our [February 2025 Release Notes (v29.1)](/changelog/february-2025-release-notes-v291).

| Canonical Values for Job Title Subroles |
| --- |
| accounting |
| accounts |
| brand\_marketing |
| broadcasting |
| business\_development |
| compensation |
| content\_marketing |
| customer\_success |
| data |
| dental |
| devops |
| doctor |
| editorial |
| education\_administration |
| electrical |
| employee\_development |
| events |
| fitness |
| graphic\_design |
| information\_technology |
| instructor |
| investment |
| journalism |
| judicial |
| lawyer |
| logistics |
| marketing\_communications |
| mechanical |
| media\_relations |
| network |
| nursing |
| office\_management |
| paralegal |
| pipeline |
| product |
| product\_design |
| product\_marketing |
| professor |
| project\_engineering |
| project\_management |
| property\_management |
| quality\_assurance |
| realtor |
| recruiting |
| researcher |
| security |
| software |
| support |
| systems |
| tax |
| teacher |
| therapy |
| video |
| web |
| web\_design |
| wellness |
| writing |

*Contents of this table were sourced from the following file on our public S3 bucket:[job\_title\_sub\_role.txt](https://pdl-prod-schema.s3.us-west-2.amazonaws.com/28.0/enums/job_title_sub_role.txt)*

## Relevant fields

* [`experience.title.sub_role`](/docs/fields#experiencetitle)
* [`job_title_sub_role`](/docs/fields#job_title_sub_role)
* [`recent_exec_departures.job_title_sub_role`](/docs/company-schema#recent_exec_departures)
* [`recent_exec_departures.new_company_job_title_sub_role`](/docs/company-schema#recent_exec_departures)
* [`recent_exec_hires.job_title_sub_role`](/docs/company-schema#recent_exec_hires)
* [`recent_exec_hires.previous_company_job_title_sub_role`](/docs/company-schema#recent_exec_hires)

  

## See Also

* [Job Title Roles](/docs/job-title-roles)
* [Mapping Title Subroles to Roles](/docs/title-subroles-to-roles)

Updated 4 months ago

---

Did this page help you?

Yes

No